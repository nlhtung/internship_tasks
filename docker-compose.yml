services:
 hive-postgres:
   image: postgres:15
   container_name: hive-postgres
   environment:
     POSTGRES_USER:     hive
     POSTGRES_PASSWORD: hivepw
     POSTGRES_DB:       hive
   ports:
     - "5433:5432"
   volumes:
     - hive_postgres_data:/var/lib/postgresql/data
   healthcheck:
     test: ["CMD-SHELL","pg_isready -U hive -d hive"]
     interval: 10s
     retries: 5
 
 hive-metastore:
   image: apache/hive:4.0.0-beta-1
   container_name: hive-metastore
   depends_on:
     hive-postgres:
       condition: service_healthy
   ports:
     - "9083:9083"
   volumes:
     - ./conf/hive-site.xml:/opt/hive/conf/hive-site.xml:ro
     - ./libs/postgresql-42.7.7.jar:/opt/hive/lib/postgresql-42.7.7.jar:ro
     - ./libs/hadoop-aws-3.3.1.jar:/opt/hive/lib/hadoop-aws-3.3.1.jar:ro
     - ./libs/aws-java-sdk-bundle-1.11.1026.jar:/opt/hive/lib/aws-java-sdk-bundle-1.11.1026.jar:ro
     - ./libs/hadoop-client-3.3.1.jar:/opt/hive/lib/hadoop-client-3.3.1.jar:ro
   entrypoint: >
     bash -c "schematool -dbType postgres -initOrUpgradeSchema &&
              hive --service metastore"
 
 minio:
   image: minio/minio:latest
   container_name: minio
   command: server /data --console-address ":9001"
   environment:
     MINIO_ACCESS_KEY: minioadmin
     MINIO_SECRET_KEY: minioadmin
   ports:
     - "9000:9000"
     - "9001:9001"
   volumes:
     - minio_data:/data
 
 spark-master:
   build: .
   container_name: spark-master
   depends_on:
     - hive-metastore
     - minio
   environment:
     SPARK_MODE:               master
     SPARK_MASTER_HOST:        spark-master
     SPARK_MASTER_PORT:        7077
     SPARK_MASTER_WEBUI_PORT:  8080
     SPARK_LOG_LEVEL:          WARN
   ports:
     - "7077:7077"
     - "8080:8080"
   volumes:
     - ./conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf:ro
     - ./app/write_iceberg.py:/opt/app/write_iceberg.py:ro
     - ./libs/hadoop-aws-3.3.1.jar:/opt/bitnami/spark/jars/hadoop-aws-3.3.1.jar:ro
     - ./libs/aws-java-sdk-bundle-1.11.1026.jar:/opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar:ro
     - ./libs/hadoop-client-3.3.1.jar:/opt/bitnami/spark/jars/hadoop-client-3.3.1.jar:ro
     - ./libs/iceberg-spark-runtime-3.5_2.12-1.9.2.jar:/opt/bitnami/spark/jars/iceberg-spark-runtime-3.5_2.12-1.9.2.jar
 spark-worker:
   build: .
   container_name: spark-worker
   depends_on:
     - spark-master
   environment:
     SPARK_MODE:              worker
     SPARK_MASTER_URL:        spark://spark-master:7077
     SPARK_WORKER_WEBUI_PORT: 8081
     SPARK_LOG_LEVEL:         WARN
   ports:
     - "8081:8081"
   volumes:
     - ./conf/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf:ro
     - ./app/write_iceberg.py:/opt/app/write_iceberg.py:ro
     - ./libs/hadoop-aws-3.3.1.jar:/opt/bitnami/spark/jars/hadoop-aws-3.3.1.jar:ro
     - ./libs/aws-java-sdk-bundle-1.11.1026.jar:/opt/bitnami/spark/jars/aws-java-sdk-bundle-1.11.1026.jar:ro
     - ./libs/hadoop-client-3.3.1.jar:/opt/bitnami/spark/jars/hadoop-client-3.3.1.jar:ro
     - ./libs/iceberg-spark-runtime-3.5_2.12-1.9.2.jar:/opt/bitnami/spark/jars/iceberg-spark-runtime-3.5_2.12-1.9.2.jar
volumes:
 hive_postgres_data:
 minio_data:
 iceberg_data: