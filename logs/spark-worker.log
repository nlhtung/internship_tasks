
starting org.apache.spark.deploy.worker.Worker, logging to /opt/bitnami/spark/logs/spark--org.apache.spark.deploy.worker.Worker-1-934ae21307ff.out
[38;5;6mspark [38;5;5m06:20:03.99 [0m[38;5;2mINFO [0m ==> 
[38;5;6mspark [38;5;5m06:20:03.99 [0m[38;5;2mINFO [0m ==> [1mWelcome to the Bitnami spark container[0m
[38;5;6mspark [38;5;5m06:20:03.99 [0m[38;5;2mINFO [0m ==> Subscribe to project updates by watching [1mhttps://github.com/bitnami/containers[0m
[38;5;6mspark [38;5;5m06:20:04.00 [0m[38;5;2mINFO [0m ==> Submit issues and feature requests at [1mhttps://github.com/bitnami/containers/issues[0m
[38;5;6mspark [38;5;5m06:20:04.00 [0m[38;5;2mINFO [0m ==> 
[38;5;6mspark [38;5;5m06:20:04.01 [0m[38;5;2mINFO [0m ==> ** Starting Spark setup **
[38;5;6mspark [38;5;5m06:20:04.02 [0m[38;5;2mINFO [0m ==> Detected mounted configuration file...
find: '/docker-entrypoint-initdb.d/': No such file or directory
[38;5;6mspark [38;5;5m06:20:04.03 [0m[38;5;2mINFO [0m ==> No custom scripts in /docker-entrypoint-initdb.d
[38;5;6mspark [38;5;5m06:20:04.03 [0m[38;5;2mINFO [0m ==> ** Spark setup finished! **

[38;5;6mspark [38;5;5m06:20:04.04 [0m[38;5;2mINFO [0m ==> ** Starting Spark in worker mode **
starting org.apache.spark.deploy.worker.Worker, logging to /opt/bitnami/spark/logs/spark--org.apache.spark.deploy.worker.Worker-1-934ae21307ff.out
Spark Command: /opt/bitnami/java/bin/java -cp /opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://spark-master:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/07/31 06:20:08 INFO Worker: Started daemon with process name: 33@934ae21307ff
25/07/31 06:20:08 INFO SignalUtils: Registering signal handler for TERM
25/07/31 06:20:08 INFO SignalUtils: Registering signal handler for HUP
25/07/31 06:20:08 INFO SignalUtils: Registering signal handler for INT
25/07/31 06:20:08 INFO SecurityManager: Changing view acls to: spark
25/07/31 06:20:08 INFO SecurityManager: Changing modify acls to: spark
25/07/31 06:20:08 INFO SecurityManager: Changing view acls groups to: 
25/07/31 06:20:08 INFO SecurityManager: Changing modify acls groups to: 
25/07/31 06:20:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
25/07/31 06:20:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/07/31 06:20:10 INFO Utils: Successfully started service 'sparkWorker' on port 34945.
25/07/31 06:20:10 INFO Worker: Worker decommissioning not enabled.
25/07/31 06:20:10 INFO Worker: Starting Spark worker 172.18.0.8:34945 with 12 cores, 6.6 GiB RAM
25/07/31 06:20:10 INFO Worker: Running Spark version 3.4.1
25/07/31 06:20:10 INFO Worker: Spark home: /opt/bitnami/spark
25/07/31 06:20:10 INFO ResourceUtils: ==============================================================
25/07/31 06:20:10 INFO ResourceUtils: No custom resources configured for spark.worker.
25/07/31 06:20:10 INFO ResourceUtils: ==============================================================
25/07/31 06:20:10 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
25/07/31 06:20:10 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/07/31 06:20:10 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://934ae21307ff:8081
25/07/31 06:20:10 INFO Worker: Connecting to master spark-master:7077...
25/07/31 06:20:11 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.6:7077 after 43 ms (0 ms spent in bootstraps)
25/07/31 06:20:11 INFO Worker: Successfully registered with master spark://spark-master:7077
25/07/31 06:20:12 INFO Worker: Asked to launch executor app-20250731062012-0000/0 for Thrift JDBC/ODBC Server
25/07/31 06:20:12 INFO SecurityManager: Changing view acls to: spark
25/07/31 06:20:12 INFO SecurityManager: Changing modify acls to: spark
25/07/31 06:20:12 INFO SecurityManager: Changing view acls groups to: 
25/07/31 06:20:12 INFO SecurityManager: Changing modify acls groups to: 
25/07/31 06:20:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
25/07/31 06:20:12 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=34825" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@7a5ad9badcf6:34825" "--executor-id" "0" "--hostname" "172.18.0.8" "--cores" "12" "--app-id" "app-20250731062012-0000" "--worker-url" "spark://Worker@172.18.0.8:34945" "--resourceProfileId" "0"
25/07/31 06:46:54 INFO Worker: Asked to kill executor app-20250731062012-0000/0
25/07/31 06:46:54 INFO ExecutorRunner: Runner thread for executor app-20250731062012-0000/0 interrupted
25/07/31 06:46:54 INFO ExecutorRunner: Killing process!
25/07/31 06:46:54 INFO Worker: Executor app-20250731062012-0000/0 finished with state KILLED exitStatus 143
25/07/31 06:46:54 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
25/07/31 06:46:54 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20250731062012-0000, execId=0)
25/07/31 06:46:54 INFO Worker: Cleaning up local directories for application app-20250731062012-0000
25/07/31 06:46:54 INFO ExternalShuffleBlockResolver: Application app-20250731062012-0000 removed, cleanupLocalDirs = true
[38;5;6mspark [38;5;5m06:54:03.14 [0m[38;5;2mINFO [0m ==> 
[38;5;6mspark [38;5;5m06:54:03.14 [0m[38;5;2mINFO [0m ==> [1mWelcome to the Bitnami spark container[0m
[38;5;6mspark [38;5;5m06:54:03.14 [0m[38;5;2mINFO [0m ==> Subscribe to project updates by watching [1mhttps://github.com/bitnami/containers[0m
[38;5;6mspark [38;5;5m06:54:03.14 [0m[38;5;2mINFO [0m ==> Submit issues and feature requests at [1mhttps://github.com/bitnami/containers/issues[0m
[38;5;6mspark [38;5;5m06:54:03.15 [0m[38;5;2mINFO [0m ==> 
[38;5;6mspark [38;5;5m06:54:03.16 [0m[38;5;2mINFO [0m ==> ** Starting Spark setup **
[38;5;6mspark [38;5;5m06:54:03.18 [0m[38;5;2mINFO [0m ==> Detected mounted configuration file...
find: '/docker-entrypoint-initdb.d/': No such file or directory
[38;5;6mspark [38;5;5m06:54:03.18 [0m[38;5;2mINFO [0m ==> No custom scripts in /docker-entrypoint-initdb.d
[38;5;6mspark [38;5;5m06:54:03.19 [0m[38;5;2mINFO [0m ==> ** Spark setup finished! **

[38;5;6mspark [38;5;5m06:54:03.20 [0m[38;5;2mINFO [0m ==> ** Starting Spark in worker mode **
starting org.apache.spark.deploy.worker.Worker, logging to /opt/bitnami/spark/logs/spark--org.apache.spark.deploy.worker.Worker-1-7c4eb9604a82.out
Spark Command: /opt/bitnami/java/bin/java -cp /opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://spark-master:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/07/31 06:54:07 INFO Worker: Started daemon with process name: 33@7c4eb9604a82
25/07/31 06:54:07 INFO SignalUtils: Registering signal handler for TERM
25/07/31 06:54:07 INFO SignalUtils: Registering signal handler for HUP
25/07/31 06:54:07 INFO SignalUtils: Registering signal handler for INT
25/07/31 06:54:08 INFO SecurityManager: Changing view acls to: spark
25/07/31 06:54:08 INFO SecurityManager: Changing modify acls to: spark
25/07/31 06:54:08 INFO SecurityManager: Changing view acls groups to: 
25/07/31 06:54:08 INFO SecurityManager: Changing modify acls groups to: 
25/07/31 06:54:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
25/07/31 06:54:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/07/31 06:54:09 INFO Utils: Successfully started service 'sparkWorker' on port 44029.
25/07/31 06:54:09 INFO Worker: Worker decommissioning not enabled.
25/07/31 06:54:09 INFO Worker: Starting Spark worker 172.18.0.8:44029 with 12 cores, 6.6 GiB RAM
25/07/31 06:54:09 INFO Worker: Running Spark version 3.4.1
25/07/31 06:54:09 INFO Worker: Spark home: /opt/bitnami/spark
25/07/31 06:54:09 INFO ResourceUtils: ==============================================================
25/07/31 06:54:09 INFO ResourceUtils: No custom resources configured for spark.worker.
25/07/31 06:54:09 INFO ResourceUtils: ==============================================================
25/07/31 06:54:09 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
25/07/31 06:54:09 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/07/31 06:54:09 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://7c4eb9604a82:8081
25/07/31 06:54:09 INFO Worker: Connecting to master spark-master:7077...
25/07/31 06:54:10 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.6:7077 after 55 ms (0 ms spent in bootstraps)
25/07/31 06:54:10 INFO Worker: Successfully registered with master spark://spark-master:7077
25/07/31 06:54:11 INFO Worker: Asked to launch executor app-20250731065411-0000/0 for Thrift JDBC/ODBC Server
25/07/31 06:54:11 INFO SecurityManager: Changing view acls to: spark
25/07/31 06:54:11 INFO SecurityManager: Changing modify acls to: spark
25/07/31 06:54:11 INFO SecurityManager: Changing view acls groups to: 
25/07/31 06:54:11 INFO SecurityManager: Changing modify acls groups to: 
25/07/31 06:54:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
25/07/31 06:54:11 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=33717" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@771f8ade4a32:33717" "--executor-id" "0" "--hostname" "172.18.0.8" "--cores" "12" "--app-id" "app-20250731065411-0000" "--worker-url" "spark://Worker@172.18.0.8:44029" "--resourceProfileId" "0"
25/07/31 07:09:14 INFO Worker: Executor app-20250731065411-0000/0 finished with state EXITED message Command exited with code 0 exitStatus 0
25/07/31 07:09:14 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
25/07/31 07:09:14 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20250731065411-0000, execId=0)
25/07/31 07:09:14 INFO Worker: Asked to kill unknown executor app-20250731065411-0000/0
25/07/31 07:09:14 INFO ExternalShuffleBlockResolver: Application app-20250731065411-0000 removed, cleanupLocalDirs = true
25/07/31 07:09:14 INFO Worker: Cleaning up local directories for application app-20250731065411-0000
[38;5;6mspark [38;5;5m07:43:24.64 [0m[38;5;2mINFO [0m ==> 
[38;5;6mspark [38;5;5m07:43:24.64 [0m[38;5;2mINFO [0m ==> [1mWelcome to the Bitnami spark container[0m
[38;5;6mspark [38;5;5m07:43:24.64 [0m[38;5;2mINFO [0m ==> Subscribe to project updates by watching [1mhttps://github.com/bitnami/containers[0m
[38;5;6mspark [38;5;5m07:43:24.65 [0m[38;5;2mINFO [0m ==> Submit issues and feature requests at [1mhttps://github.com/bitnami/containers/issues[0m
[38;5;6mspark [38;5;5m07:43:24.65 [0m[38;5;2mINFO [0m ==> 
[38;5;6mspark [38;5;5m07:43:24.67 [0m[38;5;2mINFO [0m ==> ** Starting Spark setup **
[38;5;6mspark [38;5;5m07:43:24.70 [0m[38;5;2mINFO [0m ==> Detected mounted configuration file...
find: '/docker-entrypoint-initdb.d/': No such file or directory
[38;5;6mspark [38;5;5m07:43:24.71 [0m[38;5;2mINFO [0m ==> No custom scripts in /docker-entrypoint-initdb.d
[38;5;6mspark [38;5;5m07:43:24.71 [0m[38;5;2mINFO [0m ==> ** Spark setup finished! **

[38;5;6mspark [38;5;5m07:43:24.73 [0m[38;5;2mINFO [0m ==> ** Starting Spark in worker mode **
starting org.apache.spark.deploy.worker.Worker, logging to /opt/bitnami/spark/logs/spark--org.apache.spark.deploy.worker.Worker-1-ba35b00e27f5.out
Spark Command: /opt/bitnami/java/bin/java -cp /opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/* -Xmx1g org.apache.spark.deploy.worker.Worker --webui-port 8081 spark://spark-master:7077
========================================
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/07/31 07:43:28 INFO Worker: Started daemon with process name: 33@ba35b00e27f5
25/07/31 07:43:28 INFO SignalUtils: Registering signal handler for TERM
25/07/31 07:43:28 INFO SignalUtils: Registering signal handler for HUP
25/07/31 07:43:28 INFO SignalUtils: Registering signal handler for INT
25/07/31 07:43:28 INFO SecurityManager: Changing view acls to: spark
25/07/31 07:43:28 INFO SecurityManager: Changing modify acls to: spark
25/07/31 07:43:28 INFO SecurityManager: Changing view acls groups to: 
25/07/31 07:43:28 INFO SecurityManager: Changing modify acls groups to: 
25/07/31 07:43:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
25/07/31 07:43:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/07/31 07:43:29 INFO Utils: Successfully started service 'sparkWorker' on port 33417.
25/07/31 07:43:29 INFO Worker: Worker decommissioning not enabled.
25/07/31 07:43:29 INFO Worker: Starting Spark worker 172.18.0.8:33417 with 12 cores, 6.6 GiB RAM
25/07/31 07:43:29 INFO Worker: Running Spark version 3.4.1
25/07/31 07:43:29 INFO Worker: Spark home: /opt/bitnami/spark
25/07/31 07:43:29 INFO ResourceUtils: ==============================================================
25/07/31 07:43:29 INFO ResourceUtils: No custom resources configured for spark.worker.
25/07/31 07:43:29 INFO ResourceUtils: ==============================================================
25/07/31 07:43:29 INFO JettyUtils: Start Jetty 0.0.0.0:8081 for WorkerUI
25/07/31 07:43:30 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/07/31 07:43:30 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://ba35b00e27f5:8081
25/07/31 07:43:30 INFO Worker: Connecting to master spark-master:7077...
25/07/31 07:43:30 INFO TransportClientFactory: Successfully created connection to spark-master/172.18.0.6:7077 after 54 ms (0 ms spent in bootstraps)
25/07/31 07:43:30 INFO Worker: Successfully registered with master spark://spark-master:7077
25/07/31 07:43:30 INFO Worker: Asked to launch executor app-20250731074330-0000/0 for Thrift JDBC/ODBC Server
25/07/31 07:43:30 INFO SecurityManager: Changing view acls to: spark
25/07/31 07:43:30 INFO SecurityManager: Changing modify acls to: spark
25/07/31 07:43:30 INFO SecurityManager: Changing view acls groups to: 
25/07/31 07:43:30 INFO SecurityManager: Changing modify acls groups to: 
25/07/31 07:43:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
25/07/31 07:43:30 INFO ExecutorRunner: Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=39297" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@c1be953f9409:39297" "--executor-id" "0" "--hostname" "172.18.0.8" "--cores" "12" "--app-id" "app-20250731074330-0000" "--worker-url" "spark://Worker@172.18.0.8:33417" "--resourceProfileId" "0"
25/07/31 07:58:51 INFO Worker: Asked to kill executor app-20250731074330-0000/0
25/07/31 07:58:51 INFO ExecutorRunner: Runner thread for executor app-20250731074330-0000/0 interrupted
25/07/31 07:58:51 INFO ExecutorRunner: Killing process!
25/07/31 07:58:51 INFO Worker: Executor app-20250731074330-0000/0 finished with state KILLED exitStatus 0
25/07/31 07:58:51 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
25/07/31 07:58:51 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20250731074330-0000, execId=0)
25/07/31 07:58:51 INFO ExternalShuffleBlockResolver: Application app-20250731074330-0000 removed, cleanupLocalDirs = true
25/07/31 07:58:51 INFO Worker: Cleaning up local directories for application app-20250731074330-0000
