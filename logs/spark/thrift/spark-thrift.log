2025-08-06 08:39:58,958 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - Started daemon with process name: 21@1662e5eff489
2025-08-06 08:39:59,011 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 08:39:59,019 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 08:39:59,024 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 08:39:59,041 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - Starting SparkContext
2025-08-06 08:39:59,393 [main] INFO  org.apache.hadoop.hive.conf.HiveConf - Found configuration file null
2025-08-06 08:39:59,611 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.1
2025-08-06 08:39:59,690 [main] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:39:59,692 [main] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-08-06 08:39:59,695 [main] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:39:59,699 [main] INFO  org.apache.spark.SparkContext - Submitted application: Thrift JDBC/ODBC Server
2025-08-06 08:39:59,790 [main] INFO  org.apache.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-08-06 08:39:59,819 [main] INFO  org.apache.spark.resource.ResourceProfile - Limiting resource is cpus at 2 tasks per executor
2025-08-06 08:39:59,829 [main] INFO  org.apache.spark.resource.ResourceProfileManager - Added ResourceProfile id: 0
2025-08-06 08:39:59,982 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:39:59,984 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:39:59,987 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:39:59,991 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:39:59,993 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:40:00,123 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 08:40:00,929 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 39357.
2025-08-06 08:40:01,010 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-08-06 08:40:01,110 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-08-06 08:40:01,141 [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-08-06 08:40:01,145 [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-08-06 08:40:01,156 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-08-06 08:40:01,239 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/blockmgr-44c03f6b-2d04-414f-9016-578fc564a51f
2025-08-06 08:40:01,298 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 127.2 MiB
2025-08-06 08:40:01,325 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-08-06 08:40:01,468 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @8095ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 08:40:01,659 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-08-06 08:40:01,695 [main] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 08:40:01,718 [main] INFO  org.sparkproject.jetty.server.Server - Started @8351ms
2025-08-06 08:40:01,757 [main] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@7f9fc8bd{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-08-06 08:40:01,758 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-08-06 08:40:01,805 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@59bbb974{/,null,AVAILABLE,@Spark}
2025-08-06 08:40:01,940 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Connecting to master spark://spark-master:7077...
2025-08-06 08:40:02,014 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 47 ms (0 ms spent in bootstraps)
2025-08-06 08:40:02,235 [dispatcher-event-loop-10] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Connected to Spark cluster with app ID app-20250806084002-0000
2025-08-06 08:40:02,257 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37215.
2025-08-06 08:40:02,258 [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 1662e5eff489:37215
2025-08-06 08:40:02,262 [main] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 08:40:02,272 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 1662e5eff489, 37215, None)
2025-08-06 08:40:02,278 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 1662e5eff489:37215 with 127.2 MiB RAM, BlockManagerId(driver, 1662e5eff489, 37215, None)
2025-08-06 08:40:02,282 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 1662e5eff489, 37215, None)
2025-08-06 08:40:02,285 [main] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 1662e5eff489, 37215, None)
2025-08-06 08:40:02,479 [main] INFO  org.apache.spark.util.Utils - Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
2025-08-06 08:40:02,481 [main] INFO  org.apache.spark.ExecutorAllocationManager - Dynamic allocation is enabled without a shuffle service.
2025-08-06 08:40:02,549 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor added: app-20250806084002-0000/0 on worker-20250806083959-172.18.0.11-39517 (172.18.0.11:39517) with 2 core(s)
2025-08-06 08:40:02,557 [dispatcher-event-loop-5] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Granted executor ID app-20250806084002-0000/0 on hostPort 172.18.0.11:39517 with 2 core(s), 1024.0 MiB RAM
2025-08-06 08:40:02,587 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@59bbb974{/,null,STOPPED,@Spark}
2025-08-06 08:40:02,593 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@36ef1d65{/jobs,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,595 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f366587{/jobs/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,598 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c02670f{/jobs/job,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,602 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@13bdf540{/jobs/job/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,605 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4dcbae55{/stages,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,607 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7ca16adc{/stages/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,609 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@34414ffc{/stages/stage,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,612 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4041739c{/stages/stage/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,614 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@627ff1b8{/stages/pool,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,618 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@29a33620{/stages/pool/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,621 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@134f8ef6{/storage,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,623 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6a32191e{/storage/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,626 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@9accff0{/storage/rdd,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,628 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@285583d4{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,630 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7f85217c{/environment,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,632 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b202ff{/environment/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,636 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@e700eba{/executors,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,639 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7186b202{/executors/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,641 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@65ef48f2{/executors/threadDump,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,643 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72543547{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,652 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22bf9122{/static,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,658 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@26865482{/,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,667 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@c1050f2{/api,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,671 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5974b233{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,675 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69de5bed{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,688 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2785db06{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:02,691 [main] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2025-08-06 08:40:02,756 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor updated: app-20250806084002-0000/0 is now RUNNING
2025-08-06 08:40:02,902 [main] INFO  org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-08-06 08:40:02,979 [main] INFO  org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
2025-08-06 08:40:03,012 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@67fb5025{/SQL,null,AVAILABLE,@Spark}
2025-08-06 08:40:03,015 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@392781e{/SQL/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:03,018 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@79b18230{/SQL/execution,null,AVAILABLE,@Spark}
2025-08-06 08:40:03,021 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7dee835{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:03,040 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3f9b7fe1{/static/sql,null,AVAILABLE,@Spark}
2025-08-06 08:40:04,626 [main] INFO  org.apache.spark.sql.hive.HiveUtils - Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
2025-08-06 08:40:05,098 [main] INFO  org.apache.spark.sql.hive.client.HiveClientImpl - Warehouse location for Hive client (version 2.3.9) is file:/opt/bitnami/spark/spark-warehouse
2025-08-06 08:40:05,418 [main] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2025-08-06 08:40:05,419 [main] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2025-08-06 08:40:05,420 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-06 08:40:05,504 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2025-08-06 08:40:05,928 [main] INFO  DataNucleus.Persistence - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2025-08-06 08:40:05,935 [main] INFO  DataNucleus.Persistence - Property datanucleus.cache.level2 unknown - will be ignored
2025-08-06 08:40:08,371 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.11:55710) with ID 0,  ResourceProfileId 0
2025-08-06 08:40:08,386 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - New executor 0 has registered (new total is 1)
2025-08-06 08:40:08,560 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 172.18.0.11:44889 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.11, 44889, None)
2025-08-06 08:40:09,055 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2025-08-06 08:40:14,811 [main] INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is DERBY
2025-08-06 08:40:14,815 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2025-08-06 08:40:14,983 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
2025-08-06 08:40:14,985 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.18.0.12
2025-08-06 08:40:15,067 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - Failed to get database default, returning NoSuchObjectException
2025-08-06 08:40:15,428 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - Added admin role in metastore
2025-08-06 08:40:15,437 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - Added public role in metastore
2025-08-06 08:40:15,561 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - No user is added in admin role, since config is empty
2025-08-06 08:40:15,727 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: default
2025-08-06 08:40:15,736 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=spark	ip=unknown-ip-addr	cmd=get_database: default	
2025-08-06 08:40:15,814 [main] INFO  org.apache.spark.sql.hive.HiveUtils - Initializing execution hive, version 2.3.9
2025-08-06 08:40:15,837 [main] INFO  org.apache.spark.sql.hive.client.HiveClientImpl - Warehouse location for Hive client (version 2.3.9) is file:/opt/bitnami/spark/spark-warehouse
2025-08-06 08:40:15,895 [main] INFO  org.apache.hive.service.cli.session.SessionManager - Operation log root directory is created: /tmp/spark/operation_logs
2025-08-06 08:40:15,906 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread pool size: 100
2025-08-06 08:40:15,907 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread wait queue size: 100
2025-08-06 08:40:15,909 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread keepalive time: 10 seconds
2025-08-06 08:40:15,931 [main] INFO  org.apache.hive.service.AbstractService - Service:OperationManager is inited.
2025-08-06 08:40:15,936 [main] INFO  org.apache.hive.service.AbstractService - Service:SessionManager is inited.
2025-08-06 08:40:15,939 [main] INFO  org.apache.hive.service.AbstractService - Service: CLIService is inited.
2025-08-06 08:40:15,941 [main] INFO  org.apache.hive.service.AbstractService - Service:ThriftBinaryCLIService is inited.
2025-08-06 08:40:15,942 [main] INFO  org.apache.hive.service.AbstractService - Service: HiveServer2 is inited.
2025-08-06 08:40:15,944 [main] INFO  org.apache.hive.service.AbstractService - Service:OperationManager is started.
2025-08-06 08:40:15,946 [main] INFO  org.apache.hive.service.AbstractService - Service:SessionManager is started.
2025-08-06 08:40:15,951 [main] INFO  org.apache.hive.service.AbstractService - Service: CLIService is started.
2025-08-06 08:40:15,952 [main] INFO  org.apache.hive.service.AbstractService - Service:ThriftBinaryCLIService is started.
2025-08-06 08:40:16,021 [main] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Starting ThriftBinaryCLIService on port 10000 with 5...500 worker threads
2025-08-06 08:40:16,023 [main] INFO  org.apache.hive.service.AbstractService - Service:HiveServer2 is started.
2025-08-06 08:40:16,026 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - HiveThriftServer2 started
2025-08-06 08:40:16,048 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@34604b32{/sqlserver,null,AVAILABLE,@Spark}
2025-08-06 08:40:16,052 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5354bfce{/sqlserver/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:16,055 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3df681cc{/sqlserver/session,null,AVAILABLE,@Spark}
2025-08-06 08:40:16,060 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fbd47b7{/sqlserver/session/json,null,AVAILABLE,@Spark}
2025-08-06 08:41:08,741 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Requesting to kill executor(s) 0
2025-08-06 08:41:08,744 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Actual list of executor(s) to be killed is 0
2025-08-06 08:41:08,765 [spark-dynamic-executor-allocation] INFO  org.apache.spark.ExecutorAllocationManager - Executors 0 removed due to idle timeout.
2025-08-06 08:41:13,790 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Executor 0 on 172.18.0.11 killed by driver.
2025-08-06 08:41:13,795 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Executor lost: 0 (epoch 0)
2025-08-06 08:41:13,796 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - Executor 0 is removed. Remove reason statistics: (gracefully decommissioned: 0, decommision unfinished: 0, driver killed: 1, unexpectedly exited: 0).
2025-08-06 08:41:13,800 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Trying to remove executor 0 from BlockManagerMaster.
2025-08-06 08:41:13,801 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Removing block manager BlockManagerId(0, 172.18.0.11, 44889, None)
2025-08-06 08:41:13,803 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.BlockManagerMaster - Removed 0 successfully in removeExecutor
2025-08-06 08:41:13,804 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Shuffle files lost for executor: 0 (epoch 0)
2025-08-06 08:42:31,210 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - Started daemon with process name: 21@5f55bbfe1a00
2025-08-06 08:42:31,229 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 08:42:31,231 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 08:42:31,234 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 08:42:31,253 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - Starting SparkContext
2025-08-06 08:42:31,620 [main] INFO  org.apache.hadoop.hive.conf.HiveConf - Found configuration file null
2025-08-06 08:42:31,812 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.1
2025-08-06 08:42:31,918 [main] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:42:31,921 [main] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-08-06 08:42:31,925 [main] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:42:31,928 [main] INFO  org.apache.spark.SparkContext - Submitted application: Thrift JDBC/ODBC Server
2025-08-06 08:42:31,982 [main] INFO  org.apache.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-08-06 08:42:32,008 [main] INFO  org.apache.spark.resource.ResourceProfile - Limiting resource is cpus at 2 tasks per executor
2025-08-06 08:42:32,015 [main] INFO  org.apache.spark.resource.ResourceProfileManager - Added ResourceProfile id: 0
2025-08-06 08:42:32,133 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:42:32,136 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:42:32,139 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:42:32,141 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:42:32,142 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:42:32,301 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 08:42:33,023 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 40351.
2025-08-06 08:42:33,123 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-08-06 08:42:33,250 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-08-06 08:42:33,286 [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-08-06 08:42:33,287 [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-08-06 08:42:33,301 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-08-06 08:42:33,340 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/blockmgr-c07fdf7d-e8f9-4761-9e29-a5b8101f0481
2025-08-06 08:42:33,386 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 127.2 MiB
2025-08-06 08:42:33,423 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-08-06 08:42:33,507 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @7569ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 08:42:33,670 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-08-06 08:42:33,701 [main] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 08:42:33,733 [main] INFO  org.sparkproject.jetty.server.Server - Started @7796ms
2025-08-06 08:42:33,795 [main] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@470d183{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-08-06 08:42:33,796 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-08-06 08:42:33,830 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@575b5f7d{/,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,003 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Connecting to master spark://spark-master:7077...
2025-08-06 08:42:34,073 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 43 ms (0 ms spent in bootstraps)
2025-08-06 08:42:34,295 [dispatcher-event-loop-11] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Connected to Spark cluster with app ID app-20250806084234-0000
2025-08-06 08:42:34,303 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34529.
2025-08-06 08:42:34,306 [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 5f55bbfe1a00:34529
2025-08-06 08:42:34,309 [main] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 08:42:34,315 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 5f55bbfe1a00, 34529, None)
2025-08-06 08:42:34,320 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 5f55bbfe1a00:34529 with 127.2 MiB RAM, BlockManagerId(driver, 5f55bbfe1a00, 34529, None)
2025-08-06 08:42:34,323 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 5f55bbfe1a00, 34529, None)
2025-08-06 08:42:34,326 [main] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 5f55bbfe1a00, 34529, None)
2025-08-06 08:42:34,516 [main] INFO  org.apache.spark.util.Utils - Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
2025-08-06 08:42:34,518 [main] INFO  org.apache.spark.ExecutorAllocationManager - Dynamic allocation is enabled without a shuffle service.
2025-08-06 08:42:34,584 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor added: app-20250806084234-0000/0 on worker-20250806084231-172.18.0.11-33539 (172.18.0.11:33539) with 2 core(s)
2025-08-06 08:42:34,588 [dispatcher-event-loop-9] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Granted executor ID app-20250806084234-0000/0 on hostPort 172.18.0.11:33539 with 2 core(s), 1024.0 MiB RAM
2025-08-06 08:42:34,609 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@575b5f7d{/,null,STOPPED,@Spark}
2025-08-06 08:42:34,612 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a00b15d{/jobs,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,614 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4be0a27d{/jobs/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,618 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60743cdb{/jobs/job,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,620 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@71179b6f{/jobs/job/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,625 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@526e8108{/stages,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,628 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9860{/stages/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,631 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3db432c2{/stages/stage,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,636 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1903b5d{/stages/stage/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,640 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5cff6b74{/stages/pool,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,643 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62b57479{/stages/pool/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,647 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ea04cab{/storage,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,653 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a90265a{/storage/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,657 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66fbc5e7{/storage/rdd,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,660 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52559a69{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,664 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1039bfc4{/environment,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,668 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1fd7a37{/environment/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,671 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58a84a12{/executors,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,677 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6436e181{/executors/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,680 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6b649efa{/executors/threadDump,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,689 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@36068727{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,705 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d88e6b9{/static,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,708 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51e754e1{/,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,712 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@34451ed8{/api,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,716 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f347d7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,718 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5c134052{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,726 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e5e6fc4{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:34,728 [main] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2025-08-06 08:42:34,831 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor updated: app-20250806084234-0000/0 is now RUNNING
2025-08-06 08:42:34,966 [main] INFO  org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-08-06 08:42:35,009 [main] INFO  org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
2025-08-06 08:42:35,035 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2233cac0{/SQL,null,AVAILABLE,@Spark}
2025-08-06 08:42:35,038 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@787e4357{/SQL/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:35,041 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@18a096b5{/SQL/execution,null,AVAILABLE,@Spark}
2025-08-06 08:42:35,047 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1d4f5506{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:35,070 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21ea996f{/static/sql,null,AVAILABLE,@Spark}
2025-08-06 08:42:36,300 [main] INFO  org.apache.spark.sql.hive.HiveUtils - Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
2025-08-06 08:42:36,807 [main] INFO  org.apache.spark.sql.hive.client.HiveClientImpl - Warehouse location for Hive client (version 2.3.9) is file:/opt/bitnami/spark/spark-warehouse
2025-08-06 08:42:37,129 [main] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2025-08-06 08:42:37,131 [main] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2025-08-06 08:42:37,135 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-06 08:42:37,186 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2025-08-06 08:42:37,438 [main] INFO  DataNucleus.Persistence - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2025-08-06 08:42:37,442 [main] INFO  DataNucleus.Persistence - Property datanucleus.cache.level2 unknown - will be ignored
2025-08-06 08:42:40,001 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.11:56220) with ID 0,  ResourceProfileId 0
2025-08-06 08:42:40,025 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - New executor 0 has registered (new total is 1)
2025-08-06 08:42:40,165 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 172.18.0.11:46627 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.11, 46627, None)
2025-08-06 08:42:40,346 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2025-08-06 08:42:44,805 [main] INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is DERBY
2025-08-06 08:42:44,810 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2025-08-06 08:42:44,928 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
2025-08-06 08:42:44,929 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.18.0.12
2025-08-06 08:42:44,969 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - Failed to get database default, returning NoSuchObjectException
2025-08-06 08:42:45,277 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - Added admin role in metastore
2025-08-06 08:42:45,283 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - Added public role in metastore
2025-08-06 08:42:45,382 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - No user is added in admin role, since config is empty
2025-08-06 08:42:45,498 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: default
2025-08-06 08:42:45,501 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=spark	ip=unknown-ip-addr	cmd=get_database: default	
2025-08-06 08:42:45,550 [main] INFO  org.apache.spark.sql.hive.HiveUtils - Initializing execution hive, version 2.3.9
2025-08-06 08:42:45,569 [main] INFO  org.apache.spark.sql.hive.client.HiveClientImpl - Warehouse location for Hive client (version 2.3.9) is file:/opt/bitnami/spark/spark-warehouse
2025-08-06 08:42:45,621 [main] INFO  org.apache.hive.service.cli.session.SessionManager - Operation log root directory is created: /tmp/spark/operation_logs
2025-08-06 08:42:45,631 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread pool size: 100
2025-08-06 08:42:45,634 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread wait queue size: 100
2025-08-06 08:42:45,635 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread keepalive time: 10 seconds
2025-08-06 08:42:45,656 [main] INFO  org.apache.hive.service.AbstractService - Service:OperationManager is inited.
2025-08-06 08:42:45,658 [main] INFO  org.apache.hive.service.AbstractService - Service:SessionManager is inited.
2025-08-06 08:42:45,661 [main] INFO  org.apache.hive.service.AbstractService - Service: CLIService is inited.
2025-08-06 08:42:45,662 [main] INFO  org.apache.hive.service.AbstractService - Service:ThriftBinaryCLIService is inited.
2025-08-06 08:42:45,663 [main] INFO  org.apache.hive.service.AbstractService - Service: HiveServer2 is inited.
2025-08-06 08:42:45,665 [main] INFO  org.apache.hive.service.AbstractService - Service:OperationManager is started.
2025-08-06 08:42:45,665 [main] INFO  org.apache.hive.service.AbstractService - Service:SessionManager is started.
2025-08-06 08:42:45,667 [main] INFO  org.apache.hive.service.AbstractService - Service: CLIService is started.
2025-08-06 08:42:45,667 [main] INFO  org.apache.hive.service.AbstractService - Service:ThriftBinaryCLIService is started.
2025-08-06 08:42:45,725 [main] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Starting ThriftBinaryCLIService on port 10000 with 5...500 worker threads
2025-08-06 08:42:45,726 [main] INFO  org.apache.hive.service.AbstractService - Service:HiveServer2 is started.
2025-08-06 08:42:45,728 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - HiveThriftServer2 started
2025-08-06 08:42:45,745 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@d1973e8{/sqlserver,null,AVAILABLE,@Spark}
2025-08-06 08:42:45,747 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@34604b32{/sqlserver/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:45,749 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4220468{/sqlserver/session,null,AVAILABLE,@Spark}
2025-08-06 08:42:45,751 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3df681cc{/sqlserver/session/json,null,AVAILABLE,@Spark}
2025-08-06 08:43:40,434 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Requesting to kill executor(s) 0
2025-08-06 08:43:40,438 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Actual list of executor(s) to be killed is 0
2025-08-06 08:43:40,487 [spark-dynamic-executor-allocation] INFO  org.apache.spark.ExecutorAllocationManager - Executors 0 removed due to idle timeout.
2025-08-06 08:43:45,523 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Executor 0 on 172.18.0.11 killed by driver.
2025-08-06 08:43:45,527 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - Executor 0 is removed. Remove reason statistics: (gracefully decommissioned: 0, decommision unfinished: 0, driver killed: 1, unexpectedly exited: 0).
2025-08-06 08:43:45,529 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Executor lost: 0 (epoch 0)
2025-08-06 08:43:45,534 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Trying to remove executor 0 from BlockManagerMaster.
2025-08-06 08:43:45,536 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Removing block manager BlockManagerId(0, 172.18.0.11, 46627, None)
2025-08-06 08:43:45,537 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.BlockManagerMaster - Removed 0 successfully in removeExecutor
2025-08-06 08:43:45,538 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Shuffle files lost for executor: 0 (epoch 0)
2025-08-06 08:46:06,360 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 08:46:06,683 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 1: get_all_functions
2025-08-06 08:46:06,684 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=spark	ip=unknown-ip-addr	cmd=get_all_functions	
2025-08-06 08:46:06,699 [HiveServer2-Handler-Pool: Thread-88] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2025-08-06 08:46:06,700 [HiveServer2-Handler-Pool: Thread-88] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2025-08-06 08:46:06,700 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-06 08:46:06,702 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2025-08-06 08:46:06,710 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is DERBY
2025-08-06 08:46:06,711 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2025-08-06 08:46:06,798 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/713713fb-00d2-4a18-be16-1902628daa4d
2025-08-06 08:46:06,833 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with 8a131c83-f873-40ef-935a-c0dd5f361d2a
2025-08-06 08:46:06,836 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 8a131c83-f873-40ef-935a-c0dd5f361d2a
2025-08-06 08:46:08,669 [HiveServer2-Handler-Pool: Thread-88] INFO  hive.metastore - Trying to connect to metastore with URI thrift://hive-metastore:9083
2025-08-06 08:46:08,681 [HiveServer2-Handler-Pool: Thread-88] INFO  hive.metastore - Opened a connection to metastore, current connections: 1
2025-08-06 08:46:08,699 [HiveServer2-Handler-Pool: Thread-88] WARN  org.apache.hadoop.security.ShellBasedUnixGroupsMapping - unable to return groups for user nlhtung
org.apache.hadoop.security.ShellBasedUnixGroupsMapping$PartialGroupNameException: The user name 'nlhtung' is not found. id: 'nlhtung': no such user
id: 'nlhtung': no such user

	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.resolvePartialGroupNames(ShellBasedUnixGroupsMapping.java:294) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:207) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:97) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:51) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.fetchGroupList(Groups.java:387) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:321) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:270) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.get(LocalCache.java:3962) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3985) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4946) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:228) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getGroups(UserGroupInformation.java:1734) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1722) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:496) ~[hive-metastore-2.3.9.jar:2.3.9]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:245) ~[hive-metastore-2.3.9.jar:2.3.9]
	at jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77) ~[?:?]
	at jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:?]
	at java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499) ~[?:?]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:480) ~[?:?]
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740) ~[hive-metastore-2.3.9.jar:2.3.9]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83) ~[hive-metastore-2.3.9.jar:2.3.9]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133) ~[hive-metastore-2.3.9.jar:2.3.9]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104) ~[hive-metastore-2.3.9.jar:2.3.9]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:97) ~[hive-metastore-2.3.9.jar:2.3.9]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]
	at org.apache.iceberg.common.DynMethods$UnboundMethod.invokeChecked(DynMethods.java:60) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.common.DynMethods$UnboundMethod.invoke(DynMethods.java:72) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.common.DynMethods$StaticMethod.invoke(DynMethods.java:189) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.hive.HiveClientPool.newClient(HiveClientPool.java:63) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.hive.HiveClientPool.newClient(HiveClientPool.java:34) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.ClientPoolImpl.get(ClientPoolImpl.java:143) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.ClientPoolImpl.run(ClientPoolImpl.java:70) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.ClientPoolImpl.run(ClientPoolImpl.java:65) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.hive.CachedClientPool.run(CachedClientPool.java:122) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.hive.HiveCatalog.loadNamespaceMetadata(HiveCatalog.java:643) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.spark.SparkCatalog.loadNamespaceMetadata(SparkCatalog.java:461) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.spark.sql.connector.catalog.SupportsNamespaces.namespaceExists(SupportsNamespaces.java:98) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:112) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36) ~[spark-sql_2.12-3.4.1.jar:?]
	at org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36) ~[spark-sql_2.12-3.4.1.jar:?]
	at scala.Option.foreach(Option.scala:407) ~[scala-library-2.12.17.jar:?]
	at org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36) ~[spark-sql_2.12-3.4.1.jar:?]
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.4.1.jar:?]
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.4.1.jar:?]
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.4.1.jar:?]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:219) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:640) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:630) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:671) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:651) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:226) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.runInternal(SparkExecuteStatementOperation.scala:151) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:277) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkOperation$$super$run(SparkExecuteStatementOperation.scala:40) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.$anonfun$run$1(SparkOperation.scala:45) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.17.jar:?]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:79) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:63) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:40) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.run(SparkOperation.scala:45) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.run$(SparkOperation.scala:43) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(SparkExecuteStatementOperation.scala:40) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:484) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatement(HiveSessionImpl.java:460) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:71) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.cli.session.HiveSessionProxy.lambda$invoke$0(HiveSessionProxy.java:58) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at java.security.AccessController.doPrivileged(AccessController.java:712) ~[?:?]
	at javax.security.auth.Subject.doAs(Subject.java:439) ~[?:?]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:58) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at jdk.proxy2.$Proxy38.executeStatement(Unknown Source) ~[?:?]
	at org.apache.hive.service.cli.CLIService.executeStatement(CLIService.java:282) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:456) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1557) ~[hive-service-rpc-3.1.3.jar:3.1.3]
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1542) ~[hive-service-rpc-3.1.3.jar:3.1.3]
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 08:46:08,736 [HiveServer2-Handler-Pool: Thread-88] INFO  hive.metastore - Connected to metastore.
2025-08-06 08:46:08,915 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 8a131c83-f873-40ef-935a-c0dd5f361d2a
2025-08-06 08:46:08,917 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 8a131c83-f873-40ef-935a-c0dd5f361d2a
2025-08-06 08:46:08,922 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'select 1 as id' with fed790e8-ebb4-4f8c-8c29-abd56f26bb74
2025-08-06 08:46:08,925 [HiveServer2-Background-Pool: Thread-95] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with fed790e8-ebb4-4f8c-8c29-abd56f26bb74
2025-08-06 08:46:09,541 [HiveServer2-Background-Pool: Thread-95] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 231.536451 ms
2025-08-06 08:46:09,667 [HiveServer2-Background-Pool: Thread-95] INFO  org.apache.spark.SparkContext - Starting job: run at AccessController.java:712
2025-08-06 08:46:09,685 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (run at AccessController.java:712) with 1 output partitions
2025-08-06 08:46:09,686 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (run at AccessController.java:712)
2025-08-06 08:46:09,688 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-08-06 08:46:09,689 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2025-08-06 08:46:09,692 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[2] at run at AccessController.java:712), which has no missing parents
2025-08-06 08:46:09,731 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.0 KiB, free 127.2 MiB)
2025-08-06 08:46:09,795 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 127.2 MiB)
2025-08-06 08:46:09,807 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 5f55bbfe1a00:34529 (size: 3.6 KiB, free: 127.2 MiB)
2025-08-06 08:46:09,812 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1535
2025-08-06 08:46:09,825 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at run at AccessController.java:712) (first 15 tasks are for partitions Vector(0))
2025-08-06 08:46:09,826 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
2025-08-06 08:46:10,807 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor added: app-20250806084234-0000/1 on worker-20250806084231-172.18.0.11-33539 (172.18.0.11:33539) with 2 core(s)
2025-08-06 08:46:10,808 [dispatcher-event-loop-7] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Granted executor ID app-20250806084234-0000/1 on hostPort 172.18.0.11:33539 with 2 core(s), 1024.0 MiB RAM
2025-08-06 08:46:10,810 [spark-dynamic-executor-allocation] INFO  org.apache.spark.ExecutorAllocationManager - Requesting 1 new executor because tasks are backlogged (new desired total will be 1 for resource profile id: 0)
2025-08-06 08:46:10,903 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor updated: app-20250806084234-0000/1 is now RUNNING
2025-08-06 08:46:13,231 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.11:45494) with ID 1,  ResourceProfileId 0
2025-08-06 08:46:13,232 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - New executor 1 has registered (new total is 1)
2025-08-06 08:46:13,280 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 172.18.0.11:36539 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.11, 36539, None)
2025-08-06 08:46:13,322 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.11, executor 1, partition 0, PROCESS_LOCAL, 7575 bytes) 
2025-08-06 08:46:13,545 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 172.18.0.11:36539 (size: 3.6 KiB, free: 434.4 MiB)
2025-08-06 08:46:14,184 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 869 ms on 172.18.0.11 (executor 1) (1/1)
2025-08-06 08:46:14,187 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-08-06 08:46:14,191 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (run at AccessController.java:712) finished in 4.490 s
2025-08-06 08:46:14,193 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-08-06 08:46:14,194 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-08-06 08:46:14,196 [HiveServer2-Background-Pool: Thread-95] INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: run at AccessController.java:712, took 4.528304 s
2025-08-06 08:46:14,230 [HiveServer2-Background-Pool: Thread-95] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 13.978842 ms
2025-08-06 08:46:14,238 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group fed790e8-ebb4-4f8c-8c29-abd56f26bb74
2025-08-06 08:46:14,239 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with fed790e8-ebb4-4f8c-8c29-abd56f26bb74
2025-08-06 08:46:14,259 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 1: Cleaning up thread local RawStore...
2025-08-06 08:46:14,260 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=nlhtung	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2025-08-06 08:46:14,260 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 1: Done cleaning up thread local RawStore
2025-08-06 08:46:14,260 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=nlhtung	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2025-08-06 08:46:14,268 [HiveServer2-Handler-Pool: Thread-88] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 08:47:14,572 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Requesting to kill executor(s) 1
2025-08-06 08:47:14,573 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Actual list of executor(s) to be killed is 1
2025-08-06 08:47:14,588 [spark-dynamic-executor-allocation] INFO  org.apache.spark.ExecutorAllocationManager - Executors 1 removed due to idle timeout.
2025-08-06 08:47:19,624 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Executor 1 on 172.18.0.11 killed by driver.
2025-08-06 08:47:19,625 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Executor lost: 1 (epoch 1)
2025-08-06 08:47:19,626 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - Executor 1 is removed. Remove reason statistics: (gracefully decommissioned: 0, decommision unfinished: 0, driver killed: 2, unexpectedly exited: 0).
2025-08-06 08:47:19,626 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Trying to remove executor 1 from BlockManagerMaster.
2025-08-06 08:47:19,627 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Removing block manager BlockManagerId(1, 172.18.0.11, 36539, None)
2025-08-06 08:47:19,627 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.BlockManagerMaster - Removed 1 successfully in removeExecutor
2025-08-06 08:47:19,628 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Shuffle files lost for executor: 1 (epoch 1)
2025-08-06 08:51:10,260 [ForkJoinPool.commonPool-worker-2] INFO  hive.metastore - Closed a connection to metastore, current connections: 0
2025-08-06 08:55:01,949 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - Started daemon with process name: 21@f0e4b60b3686
2025-08-06 08:55:01,987 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 08:55:01,989 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 08:55:01,991 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 08:55:02,007 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - Starting SparkContext
2025-08-06 08:55:02,519 [main] INFO  org.apache.hadoop.hive.conf.HiveConf - Found configuration file null
2025-08-06 08:55:02,776 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.1
2025-08-06 08:55:02,863 [main] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:55:02,866 [main] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-08-06 08:55:02,868 [main] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:55:02,871 [main] INFO  org.apache.spark.SparkContext - Submitted application: Thrift JDBC/ODBC Server
2025-08-06 08:55:02,930 [main] INFO  org.apache.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-08-06 08:55:02,952 [main] INFO  org.apache.spark.resource.ResourceProfile - Limiting resource is cpus at 2 tasks per executor
2025-08-06 08:55:02,956 [main] INFO  org.apache.spark.resource.ResourceProfileManager - Added ResourceProfile id: 0
2025-08-06 08:55:03,078 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:55:03,082 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:55:03,085 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:55:03,088 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:55:03,091 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:55:03,213 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 08:55:03,931 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 40913.
2025-08-06 08:55:04,004 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-08-06 08:55:04,096 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-08-06 08:55:04,132 [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-08-06 08:55:04,134 [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-08-06 08:55:04,142 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-08-06 08:55:04,207 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/blockmgr-3e20f926-bb96-44a6-aeb9-474c9b6a480e
2025-08-06 08:55:04,251 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 127.2 MiB
2025-08-06 08:55:04,292 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-08-06 08:55:04,370 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @8374ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 08:55:04,584 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-08-06 08:55:04,609 [main] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 08:55:04,657 [main] INFO  org.sparkproject.jetty.server.Server - Started @8662ms
2025-08-06 08:55:04,727 [main] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@470d183{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-08-06 08:55:04,728 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-08-06 08:55:04,768 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@575b5f7d{/,null,AVAILABLE,@Spark}
2025-08-06 08:55:04,946 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Connecting to master spark://spark-master:7077...
2025-08-06 08:55:05,021 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 49 ms (0 ms spent in bootstraps)
2025-08-06 08:55:05,229 [dispatcher-event-loop-11] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Connected to Spark cluster with app ID app-20250806085505-0000
2025-08-06 08:55:05,238 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46487.
2025-08-06 08:55:05,239 [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on f0e4b60b3686:46487
2025-08-06 08:55:05,242 [main] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 08:55:05,248 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, f0e4b60b3686, 46487, None)
2025-08-06 08:55:05,253 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager f0e4b60b3686:46487 with 127.2 MiB RAM, BlockManagerId(driver, f0e4b60b3686, 46487, None)
2025-08-06 08:55:05,257 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, f0e4b60b3686, 46487, None)
2025-08-06 08:55:05,260 [main] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, f0e4b60b3686, 46487, None)
2025-08-06 08:55:05,454 [main] INFO  org.apache.spark.util.Utils - Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
2025-08-06 08:55:05,456 [main] INFO  org.apache.spark.ExecutorAllocationManager - Dynamic allocation is enabled without a shuffle service.
2025-08-06 08:55:05,535 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor added: app-20250806085505-0000/0 on worker-20250806085503-172.18.0.12-37163 (172.18.0.12:37163) with 2 core(s)
2025-08-06 08:55:05,538 [dispatcher-event-loop-8] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Granted executor ID app-20250806085505-0000/0 on hostPort 172.18.0.12:37163 with 2 core(s), 1024.0 MiB RAM
2025-08-06 08:55:05,579 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@575b5f7d{/,null,STOPPED,@Spark}
2025-08-06 08:55:05,584 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a00b15d{/jobs,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,588 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4be0a27d{/jobs/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,592 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60743cdb{/jobs/job,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,595 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@71179b6f{/jobs/job/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,600 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@526e8108{/stages,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,606 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9860{/stages/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,616 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3db432c2{/stages/stage,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,619 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1903b5d{/stages/stage/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,622 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5cff6b74{/stages/pool,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,630 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62b57479{/stages/pool/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,633 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ea04cab{/storage,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,636 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a90265a{/storage/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,644 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66fbc5e7{/storage/rdd,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,648 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52559a69{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,654 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1039bfc4{/environment,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,657 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1fd7a37{/environment/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,664 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58a84a12{/executors,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,667 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6436e181{/executors/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,674 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6b649efa{/executors/threadDump,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,677 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@36068727{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,713 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d88e6b9{/static,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,715 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51e754e1{/,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,720 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@34451ed8{/api,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,724 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f347d7{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,726 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5c134052{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,736 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e5e6fc4{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:05,739 [main] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2025-08-06 08:55:05,934 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor updated: app-20250806085505-0000/0 is now RUNNING
2025-08-06 08:55:06,056 [main] INFO  org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-08-06 08:55:06,076 [main] INFO  org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
2025-08-06 08:55:06,097 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2233cac0{/SQL,null,AVAILABLE,@Spark}
2025-08-06 08:55:06,099 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@787e4357{/SQL/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:06,101 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@18a096b5{/SQL/execution,null,AVAILABLE,@Spark}
2025-08-06 08:55:06,102 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1d4f5506{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:06,118 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21ea996f{/static/sql,null,AVAILABLE,@Spark}
2025-08-06 08:55:07,552 [main] INFO  org.apache.spark.sql.hive.HiveUtils - Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
2025-08-06 08:55:07,971 [main] INFO  org.apache.spark.sql.hive.client.HiveClientImpl - Warehouse location for Hive client (version 2.3.9) is file:/opt/bitnami/spark/spark-warehouse
2025-08-06 08:55:08,324 [main] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2025-08-06 08:55:08,326 [main] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2025-08-06 08:55:08,327 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-06 08:55:08,524 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2025-08-06 08:55:08,912 [main] INFO  DataNucleus.Persistence - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2025-08-06 08:55:08,914 [main] INFO  DataNucleus.Persistence - Property datanucleus.cache.level2 unknown - will be ignored
2025-08-06 08:55:10,827 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.12:40348) with ID 0,  ResourceProfileId 0
2025-08-06 08:55:10,852 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - New executor 0 has registered (new total is 1)
2025-08-06 08:55:10,981 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 172.18.0.12:35869 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.12, 35869, None)
2025-08-06 08:55:11,724 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2025-08-06 08:55:15,707 [main] INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is DERBY
2025-08-06 08:55:15,712 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2025-08-06 08:55:15,923 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
2025-08-06 08:55:15,924 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.18.0.11
2025-08-06 08:55:15,960 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - Failed to get database default, returning NoSuchObjectException
2025-08-06 08:55:16,382 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - Added admin role in metastore
2025-08-06 08:55:16,390 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - Added public role in metastore
2025-08-06 08:55:16,520 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - No user is added in admin role, since config is empty
2025-08-06 08:55:16,675 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: default
2025-08-06 08:55:16,678 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=spark	ip=unknown-ip-addr	cmd=get_database: default	
2025-08-06 08:55:16,734 [main] INFO  org.apache.spark.sql.hive.HiveUtils - Initializing execution hive, version 2.3.9
2025-08-06 08:55:16,743 [main] INFO  org.apache.spark.sql.hive.client.HiveClientImpl - Warehouse location for Hive client (version 2.3.9) is file:/opt/bitnami/spark/spark-warehouse
2025-08-06 08:55:16,786 [main] INFO  org.apache.hive.service.cli.session.SessionManager - Operation log root directory is created: /tmp/spark/operation_logs
2025-08-06 08:55:16,793 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread pool size: 100
2025-08-06 08:55:16,795 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread wait queue size: 100
2025-08-06 08:55:16,796 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread keepalive time: 10 seconds
2025-08-06 08:55:16,807 [main] INFO  org.apache.hive.service.AbstractService - Service:OperationManager is inited.
2025-08-06 08:55:16,809 [main] INFO  org.apache.hive.service.AbstractService - Service:SessionManager is inited.
2025-08-06 08:55:16,810 [main] INFO  org.apache.hive.service.AbstractService - Service: CLIService is inited.
2025-08-06 08:55:16,815 [main] INFO  org.apache.hive.service.AbstractService - Service:ThriftBinaryCLIService is inited.
2025-08-06 08:55:16,816 [main] INFO  org.apache.hive.service.AbstractService - Service: HiveServer2 is inited.
2025-08-06 08:55:16,817 [main] INFO  org.apache.hive.service.AbstractService - Service:OperationManager is started.
2025-08-06 08:55:16,817 [main] INFO  org.apache.hive.service.AbstractService - Service:SessionManager is started.
2025-08-06 08:55:16,820 [main] INFO  org.apache.hive.service.AbstractService - Service: CLIService is started.
2025-08-06 08:55:16,821 [main] INFO  org.apache.hive.service.AbstractService - Service:ThriftBinaryCLIService is started.
2025-08-06 08:55:16,863 [main] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Starting ThriftBinaryCLIService on port 10000 with 5...500 worker threads
2025-08-06 08:55:16,865 [main] INFO  org.apache.hive.service.AbstractService - Service:HiveServer2 is started.
2025-08-06 08:55:16,867 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - HiveThriftServer2 started
2025-08-06 08:55:16,882 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5ca10d0e{/sqlserver,null,AVAILABLE,@Spark}
2025-08-06 08:55:16,885 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@159408a7{/sqlserver/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:16,887 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@727e61ed{/sqlserver/session,null,AVAILABLE,@Spark}
2025-08-06 08:55:16,888 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3ba815ee{/sqlserver/session/json,null,AVAILABLE,@Spark}
2025-08-06 08:56:11,324 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Requesting to kill executor(s) 0
2025-08-06 08:56:11,328 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Actual list of executor(s) to be killed is 0
2025-08-06 08:56:11,390 [spark-dynamic-executor-allocation] INFO  org.apache.spark.ExecutorAllocationManager - Executors 0 removed due to idle timeout.
2025-08-06 08:56:16,462 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Executor 0 on 172.18.0.12 killed by driver.
2025-08-06 08:56:16,471 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - Executor 0 is removed. Remove reason statistics: (gracefully decommissioned: 0, decommision unfinished: 0, driver killed: 1, unexpectedly exited: 0).
2025-08-06 08:56:16,473 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Executor lost: 0 (epoch 0)
2025-08-06 08:56:16,482 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Trying to remove executor 0 from BlockManagerMaster.
2025-08-06 08:56:16,484 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Removing block manager BlockManagerId(0, 172.18.0.12, 35869, None)
2025-08-06 08:56:16,485 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.BlockManagerMaster - Removed 0 successfully in removeExecutor
2025-08-06 08:56:16,485 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Shuffle files lost for executor: 0 (epoch 0)
2025-08-06 09:04:32,883 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - Started daemon with process name: 21@c15f4bd07d87
2025-08-06 09:04:32,914 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 09:04:32,920 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 09:04:32,921 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 09:04:32,954 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - Starting SparkContext
2025-08-06 09:04:33,505 [main] INFO  org.apache.hadoop.hive.conf.HiveConf - Found configuration file null
2025-08-06 09:04:33,798 [main] INFO  org.apache.spark.SparkContext - Running Spark version 3.4.1
2025-08-06 09:04:33,930 [main] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 09:04:33,934 [main] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
2025-08-06 09:04:33,942 [main] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 09:04:33,947 [main] INFO  org.apache.spark.SparkContext - Submitted application: Thrift JDBC/ODBC Server
2025-08-06 09:04:34,118 [main] INFO  org.apache.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 2, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
2025-08-06 09:04:34,169 [main] INFO  org.apache.spark.resource.ResourceProfile - Limiting resource is cpus at 2 tasks per executor
2025-08-06 09:04:34,177 [main] INFO  org.apache.spark.resource.ResourceProfileManager - Added ResourceProfile id: 0
2025-08-06 09:04:34,460 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:04:34,463 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:04:34,467 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:04:34,469 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:04:34,471 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:04:34,656 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 09:04:35,467 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 43895.
2025-08-06 09:04:35,604 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2025-08-06 09:04:35,758 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2025-08-06 09:04:35,786 [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2025-08-06 09:04:35,789 [main] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
2025-08-06 09:04:35,801 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
2025-08-06 09:04:35,879 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/blockmgr-f55760df-aa32-48d7-8f7f-1912d3cc1971
2025-08-06 09:04:35,915 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 127.2 MiB
2025-08-06 09:04:35,968 [main] INFO  org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
2025-08-06 09:04:36,084 [main] INFO  org.sparkproject.jetty.util.log - Logging initialized @8578ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 09:04:36,341 [main] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:4040 for SparkUI
2025-08-06 09:04:36,364 [main] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 09:04:36,393 [main] INFO  org.sparkproject.jetty.server.Server - Started @8889ms
2025-08-06 09:04:36,468 [main] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@ea52184{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2025-08-06 09:04:36,469 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
2025-08-06 09:04:36,512 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7165d530{/,null,AVAILABLE,@Spark}
2025-08-06 09:04:36,720 [appclient-register-master-threadpool-0] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Connecting to master spark://spark-master:7077...
2025-08-06 09:04:36,797 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 37 ms (0 ms spent in bootstraps)
2025-08-06 09:04:37,027 [dispatcher-event-loop-11] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Connected to Spark cluster with app ID app-20250806090436-0000
2025-08-06 09:04:37,039 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41285.
2025-08-06 09:04:37,039 [main] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on c15f4bd07d87:41285
2025-08-06 09:04:37,043 [main] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 09:04:37,060 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, c15f4bd07d87, 41285, None)
2025-08-06 09:04:37,064 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager c15f4bd07d87:41285 with 127.2 MiB RAM, BlockManagerId(driver, c15f4bd07d87, 41285, None)
2025-08-06 09:04:37,068 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, c15f4bd07d87, 41285, None)
2025-08-06 09:04:37,070 [main] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, c15f4bd07d87, 41285, None)
2025-08-06 09:04:37,245 [main] INFO  org.apache.spark.util.Utils - Using initial executors = 1, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
2025-08-06 09:04:37,247 [main] INFO  org.apache.spark.ExecutorAllocationManager - Dynamic allocation is enabled without a shuffle service.
2025-08-06 09:04:37,315 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor added: app-20250806090436-0000/0 on worker-20250806090434-172.18.0.11-33083 (172.18.0.11:33083) with 2 core(s)
2025-08-06 09:04:37,324 [dispatcher-event-loop-8] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Granted executor ID app-20250806090436-0000/0 on hostPort 172.18.0.11:33083 with 2 core(s), 1024.0 MiB RAM
2025-08-06 09:04:37,365 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Stopped o.s.j.s.ServletContextHandler@7165d530{/,null,STOPPED,@Spark}
2025-08-06 09:04:37,370 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4be0a27d{/jobs,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,372 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6003ad65{/jobs/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,375 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@71179b6f{/jobs/job,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,378 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@526e8108{/jobs/job/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,384 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4a9860{/stages,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,389 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5ae1c281{/stages/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,393 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1903b5d{/stages/stage,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,396 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5cff6b74{/stages/stage/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,398 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62b57479{/stages/pool,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,400 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ea04cab{/stages/pool/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,404 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5a90265a{/storage,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,409 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@66fbc5e7{/storage/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,419 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@52559a69{/storage/rdd,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,423 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1039bfc4{/storage/rdd/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,430 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1fd7a37{/environment,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,438 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58a84a12{/environment/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,440 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6436e181{/executors,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,443 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6b649efa{/executors/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,445 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@36068727{/executors/threadDump,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,452 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3d88e6b9{/executors/threadDump/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,466 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@208205ed{/static,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,468 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@34451ed8{/,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,472 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@67bb4dcd{/api,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,475 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5c134052{/jobs/job/kill,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,477 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@750f64fe{/stages/stage/kill,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,488 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@79980d8d{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,491 [main] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2025-08-06 09:04:37,570 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor updated: app-20250806090436-0000/0 is now RUNNING
2025-08-06 09:04:37,748 [main] INFO  org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
2025-08-06 09:04:37,774 [main] INFO  org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/opt/bitnami/spark/spark-warehouse'.
2025-08-06 09:04:37,818 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@787e4357{/SQL,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,829 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3fcbc766{/SQL/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,833 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1d4f5506{/SQL/execution,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,839 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b57c345{/SQL/execution/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:37,863 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2f79f192{/static/sql,null,AVAILABLE,@Spark}
2025-08-06 09:04:39,290 [main] INFO  org.apache.spark.sql.hive.HiveUtils - Initializing HiveMetastoreConnection version 2.3.9 using Spark classes.
2025-08-06 09:04:39,794 [main] INFO  org.apache.spark.sql.hive.client.HiveClientImpl - Warehouse location for Hive client (version 2.3.9) is file:/opt/bitnami/spark/spark-warehouse
2025-08-06 09:04:40,289 [main] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2025-08-06 09:04:40,293 [main] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2025-08-06 09:04:40,295 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-06 09:04:40,412 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2025-08-06 09:04:40,797 [main] INFO  DataNucleus.Persistence - Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
2025-08-06 09:04:40,800 [main] INFO  DataNucleus.Persistence - Property datanucleus.cache.level2 unknown - will be ignored
2025-08-06 09:04:43,160 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.11:56868) with ID 0,  ResourceProfileId 0
2025-08-06 09:04:43,175 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - New executor 0 has registered (new total is 1)
2025-08-06 09:04:43,388 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 172.18.0.11:34505 with 434.4 MiB RAM, BlockManagerId(0, 172.18.0.11, 34505, None)
2025-08-06 09:04:43,976 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2025-08-06 09:04:47,903 [main] INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is DERBY
2025-08-06 09:04:47,908 [main] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2025-08-06 09:04:48,213 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0
2025-08-06 09:04:48,213 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore UNKNOWN@172.18.0.12
2025-08-06 09:04:48,268 [main] WARN  org.apache.hadoop.hive.metastore.ObjectStore - Failed to get database default, returning NoSuchObjectException
2025-08-06 09:04:48,584 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - Added admin role in metastore
2025-08-06 09:04:48,592 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - Added public role in metastore
2025-08-06 09:04:48,673 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - No user is added in admin role, since config is empty
2025-08-06 09:04:48,777 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 0: get_database: default
2025-08-06 09:04:48,780 [main] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=spark	ip=unknown-ip-addr	cmd=get_database: default	
2025-08-06 09:04:48,803 [main] INFO  org.apache.spark.sql.hive.HiveUtils - Initializing execution hive, version 2.3.9
2025-08-06 09:04:48,813 [main] INFO  org.apache.spark.sql.hive.client.HiveClientImpl - Warehouse location for Hive client (version 2.3.9) is file:/opt/bitnami/spark/spark-warehouse
2025-08-06 09:04:48,861 [main] INFO  org.apache.hive.service.cli.session.SessionManager - Operation log root directory is created: /tmp/spark/operation_logs
2025-08-06 09:04:48,878 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread pool size: 100
2025-08-06 09:04:48,878 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread wait queue size: 100
2025-08-06 09:04:48,879 [main] INFO  org.apache.hive.service.cli.session.SessionManager - HiveServer2: Background operation thread keepalive time: 10 seconds
2025-08-06 09:04:48,890 [main] INFO  org.apache.hive.service.AbstractService - Service:OperationManager is inited.
2025-08-06 09:04:48,891 [main] INFO  org.apache.hive.service.AbstractService - Service:SessionManager is inited.
2025-08-06 09:04:48,893 [main] INFO  org.apache.hive.service.AbstractService - Service: CLIService is inited.
2025-08-06 09:04:48,893 [main] INFO  org.apache.hive.service.AbstractService - Service:ThriftBinaryCLIService is inited.
2025-08-06 09:04:48,894 [main] INFO  org.apache.hive.service.AbstractService - Service: HiveServer2 is inited.
2025-08-06 09:04:48,895 [main] INFO  org.apache.hive.service.AbstractService - Service:OperationManager is started.
2025-08-06 09:04:48,896 [main] INFO  org.apache.hive.service.AbstractService - Service:SessionManager is started.
2025-08-06 09:04:48,898 [main] INFO  org.apache.hive.service.AbstractService - Service: CLIService is started.
2025-08-06 09:04:48,899 [main] INFO  org.apache.hive.service.AbstractService - Service:ThriftBinaryCLIService is started.
2025-08-06 09:04:48,968 [main] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Starting ThriftBinaryCLIService on port 10000 with 5...500 worker threads
2025-08-06 09:04:48,971 [main] INFO  org.apache.hive.service.AbstractService - Service:HiveServer2 is started.
2025-08-06 09:04:48,972 [main] INFO  org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 - HiveThriftServer2 started
2025-08-06 09:04:48,986 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@34604b32{/sqlserver,null,AVAILABLE,@Spark}
2025-08-06 09:04:48,989 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5354bfce{/sqlserver/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:48,995 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3df681cc{/sqlserver/session,null,AVAILABLE,@Spark}
2025-08-06 09:04:48,998 [main] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2fbd47b7{/sqlserver/session/json,null,AVAILABLE,@Spark}
2025-08-06 09:05:43,618 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Requesting to kill executor(s) 0
2025-08-06 09:05:43,628 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Actual list of executor(s) to be killed is 0
2025-08-06 09:05:43,720 [spark-dynamic-executor-allocation] INFO  org.apache.spark.ExecutorAllocationManager - Executors 0 removed due to idle timeout.
2025-08-06 09:05:48,857 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Executor 0 on 172.18.0.11 killed by driver.
2025-08-06 09:05:48,871 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - Executor 0 is removed. Remove reason statistics: (gracefully decommissioned: 0, decommision unfinished: 0, driver killed: 1, unexpectedly exited: 0).
2025-08-06 09:05:48,874 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Executor lost: 0 (epoch 0)
2025-08-06 09:05:48,889 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Trying to remove executor 0 from BlockManagerMaster.
2025-08-06 09:05:48,891 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Removing block manager BlockManagerId(0, 172.18.0.11, 34505, None)
2025-08-06 09:05:48,892 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.BlockManagerMaster - Removed 0 successfully in removeExecutor
2025-08-06 09:05:48,893 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Shuffle files lost for executor: 0 (epoch 0)
2025-08-06 09:06:49,969 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:06:50,470 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 1: get_all_functions
2025-08-06 09:06:50,471 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=spark	ip=unknown-ip-addr	cmd=get_all_functions	
2025-08-06 09:06:50,493 [HiveServer2-Handler-Pool: Thread-88] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2025-08-06 09:06:50,494 [HiveServer2-Handler-Pool: Thread-88] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2025-08-06 09:06:50,495 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-06 09:06:50,497 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2025-08-06 09:06:50,528 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is DERBY
2025-08-06 09:06:50,529 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2025-08-06 09:06:50,647 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/5bbd3fca-5ca1-4f69-a24b-4087441d8ba3
2025-08-06 09:06:50,727 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with 3c102d9e-0c9d-4d6e-9735-74541b482772
2025-08-06 09:06:50,729 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 3c102d9e-0c9d-4d6e-9735-74541b482772
2025-08-06 09:06:53,515 [HiveServer2-Handler-Pool: Thread-88] INFO  hive.metastore - Trying to connect to metastore with URI thrift://hive-metastore:9083
2025-08-06 09:06:53,532 [HiveServer2-Handler-Pool: Thread-88] INFO  hive.metastore - Opened a connection to metastore, current connections: 1
2025-08-06 09:06:53,561 [HiveServer2-Handler-Pool: Thread-88] WARN  org.apache.hadoop.security.ShellBasedUnixGroupsMapping - unable to return groups for user airflow
org.apache.hadoop.security.ShellBasedUnixGroupsMapping$PartialGroupNameException: The user name 'airflow' is not found. id: 'airflow': no such user
id: 'airflow': no such user

	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.resolvePartialGroupNames(ShellBasedUnixGroupsMapping.java:294) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getUnixGroups(ShellBasedUnixGroupsMapping.java:207) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.ShellBasedUnixGroupsMapping.getGroups(ShellBasedUnixGroupsMapping.java:97) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback.getGroups(JniBasedUnixGroupsMappingWithFallback.java:51) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.fetchGroupList(Groups.java:387) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:321) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.Groups$GroupCacheLoader.load(Groups.java:270) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.get(LocalCache.java:3962) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3985) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4946) ~[hadoop-shaded-guava-1.1.1.jar:1.1.1]
	at org.apache.hadoop.security.Groups.getGroups(Groups.java:228) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getGroups(UserGroupInformation.java:1734) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.security.UserGroupInformation.getGroupNames(UserGroupInformation.java:1722) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:496) ~[hive-metastore-2.3.9.jar:2.3.9]
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:245) ~[hive-metastore-2.3.9.jar:2.3.9]
	at jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:77) ~[?:?]
	at jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[?:?]
	at java.lang.reflect.Constructor.newInstanceWithCaller(Constructor.java:499) ~[?:?]
	at java.lang.reflect.Constructor.newInstance(Constructor.java:480) ~[?:?]
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1740) ~[hive-metastore-2.3.9.jar:2.3.9]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:83) ~[hive-metastore-2.3.9.jar:2.3.9]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:133) ~[hive-metastore-2.3.9.jar:2.3.9]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:104) ~[hive-metastore-2.3.9.jar:2.3.9]
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:97) ~[hive-metastore-2.3.9.jar:2.3.9]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]
	at org.apache.iceberg.common.DynMethods$UnboundMethod.invokeChecked(DynMethods.java:60) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.common.DynMethods$UnboundMethod.invoke(DynMethods.java:72) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.common.DynMethods$StaticMethod.invoke(DynMethods.java:189) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.hive.HiveClientPool.newClient(HiveClientPool.java:63) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.hive.HiveClientPool.newClient(HiveClientPool.java:34) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.ClientPoolImpl.get(ClientPoolImpl.java:143) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.ClientPoolImpl.run(ClientPoolImpl.java:70) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.ClientPoolImpl.run(ClientPoolImpl.java:65) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.hive.CachedClientPool.run(CachedClientPool.java:122) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.hive.HiveCatalog.loadNamespaceMetadata(HiveCatalog.java:643) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.iceberg.spark.SparkCatalog.loadNamespaceMetadata(SparkCatalog.java:461) ~[iceberg-spark-runtime-3.5_2.12-1.9.2.jar:?]
	at org.apache.spark.sql.connector.catalog.SupportsNamespaces.namespaceExists(SupportsNamespaces.java:98) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.connector.catalog.CatalogManager.setCurrentNamespace(CatalogManager.scala:112) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2(SetCatalogAndNamespaceExec.scala:36) ~[spark-sql_2.12-3.4.1.jar:?]
	at org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.$anonfun$run$2$adapted(SetCatalogAndNamespaceExec.scala:36) ~[spark-sql_2.12-3.4.1.jar:?]
	at scala.Option.foreach(Option.scala:407) ~[scala-library-2.12.17.jar:?]
	at org.apache.spark.sql.execution.datasources.v2.SetCatalogAndNamespaceExec.run(SetCatalogAndNamespaceExec.scala:36) ~[spark-sql_2.12-3.4.1.jar:?]
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:43) ~[spark-sql_2.12-3.4.1.jar:?]
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:43) ~[spark-sql_2.12-3.4.1.jar:?]
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.executeCollect(V2CommandExec.scala:49) ~[spark-sql_2.12-3.4.1.jar:?]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset.<init>(Dataset.scala:219) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:640) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:630) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:671) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:651) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:226) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.runInternal(SparkExecuteStatementOperation.scala:151) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.cli.operation.Operation.run(Operation.java:277) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkOperation$$super$run(SparkExecuteStatementOperation.scala:40) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.$anonfun$run$1(SparkOperation.scala:45) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.17.jar:?]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:79) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:63) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:40) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.run(SparkOperation.scala:45) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.run$(SparkOperation.scala:43) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.run(SparkExecuteStatementOperation.scala:40) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatementInternal(HiveSessionImpl.java:484) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.cli.session.HiveSessionImpl.executeStatement(HiveSessionImpl.java:460) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:568) ~[?:?]
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:71) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.cli.session.HiveSessionProxy.lambda$invoke$0(HiveSessionProxy.java:58) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at java.security.AccessController.doPrivileged(AccessController.java:712) ~[?:?]
	at javax.security.auth.Subject.doAs(Subject.java:439) ~[?:?]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.hive.service.cli.session.HiveSessionProxy.invoke(HiveSessionProxy.java:58) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at jdk.proxy2.$Proxy38.executeStatement(Unknown Source) ~[?:?]
	at org.apache.hive.service.cli.CLIService.executeStatement(CLIService.java:282) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.cli.thrift.ThriftCLIService.ExecuteStatement(ThriftCLIService.java:456) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1557) ~[hive-service-rpc-3.1.3.jar:3.1.3]
	at org.apache.hive.service.rpc.thrift.TCLIService$Processor$ExecuteStatement.getResult(TCLIService.java:1542) ~[hive-service-rpc-3.1.3.jar:3.1.3]
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:38) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:39) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:06:53,604 [HiveServer2-Handler-Pool: Thread-88] INFO  hive.metastore - Connected to metastore.
2025-08-06 09:06:53,915 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 3c102d9e-0c9d-4d6e-9735-74541b482772
2025-08-06 09:06:53,915 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 3c102d9e-0c9d-4d6e-9735-74541b482772
2025-08-06 09:06:53,920 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_schemas"} */

    show databases
  ' with 92647e82-1425-4018-85a0-1378ceea9200
2025-08-06 09:06:53,923 [HiveServer2-Background-Pool: Thread-95] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 92647e82-1425-4018-85a0-1378ceea9200
2025-08-06 09:06:54,210 [HiveServer2-Background-Pool: Thread-95] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 157.08184 ms
2025-08-06 09:06:54,228 [HiveServer2-Background-Pool: Thread-95] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.088825 ms
2025-08-06 09:06:54,257 [HiveServer2-Background-Pool: Thread-95] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.821935 ms
2025-08-06 09:06:54,276 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<namespace: STRING>
2025-08-06 09:06:54,337 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 92647e82-1425-4018-85a0-1378ceea9200
2025-08-06 09:06:54,338 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 92647e82-1425-4018-85a0-1378ceea9200
2025-08-06 09:06:54,355 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 1: Cleaning up thread local RawStore...
2025-08-06 09:06:54,355 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=airflow	ip=unknown-ip-addr	cmd=Cleaning up thread local RawStore...	
2025-08-06 09:06:54,356 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 1: Done cleaning up thread local RawStore
2025-08-06 09:06:54,356 [HiveServer2-Handler-Pool: Thread-88] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=airflow	ip=unknown-ip-addr	cmd=Done cleaning up thread local RawStore	
2025-08-06 09:06:54,363 [HiveServer2-Handler-Pool: Thread-88] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:06:54,386 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:06:54,389 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/bc560147-3f39-4a31-aafb-4559967989ea
2025-08-06 09:06:54,393 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with 8ec82637-e3bd-4969-84df-9c465b8af142
2025-08-06 09:06:54,394 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 8ec82637-e3bd-4969-84df-9c465b8af142
2025-08-06 09:06:54,430 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 8ec82637-e3bd-4969-84df-9c465b8af142
2025-08-06 09:06:54,430 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 8ec82637-e3bd-4969-84df-9c465b8af142
2025-08-06 09:06:54,433 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
show table extended in default like '*'
  ' with 00bb7bf1-ba5d-4eb0-8a82-0d8fc0e2a51f
2025-08-06 09:06:54,434 [HiveServer2-Background-Pool: Thread-97] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 00bb7bf1-ba5d-4eb0-8a82-0d8fc0e2a51f
2025-08-06 09:06:54,790 [HiveServer2-Background-Pool: Thread-97] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 00bb7bf1-ba5d-4eb0-8a82-0d8fc0e2a51f
2025-08-06 09:06:54,791 [HiveServer2-Background-Pool: Thread-97] ERROR org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Error executing query with 00bb7bf1-ba5d-4eb0-8a82-0d8fc0e2a51f, currentState RUNNING, 
org.apache.spark.sql.AnalysisException: SHOW TABLE EXTENDED is not supported for v2 tables.;
ShowTableExtended *, [namespace#10, tableName#11, isTemporary#12, information#13]
+- ResolvedNamespace org.apache.iceberg.spark.SparkCatalog@4838c7ae, [default]

	at org.apache.spark.sql.errors.QueryCompilationErrors$.commandUnsupportedInV2TableError(QueryCompilationErrors.scala:2035) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$1(CheckAnalysis.scala:224) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$1$adapted(CheckAnalysis.scala:163) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:295) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:163) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:160) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:188) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:156) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:146) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:188) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:211) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:202) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:202) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:201) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:98) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:640) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:630) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:671) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:651) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:226) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:165) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.17.jar:?]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:79) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:63) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:40) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:165) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:160) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at java.security.AccessController.doPrivileged(AccessController.java:712) ~[?:?]
	at javax.security.auth.Subject.doAs(Subject.java:439) ~[?:?]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:174) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:06:54,810 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
show tables in default like '*'
  ' with 83a6d52a-1ef6-46da-8e56-91e5648d9879
2025-08-06 09:06:54,812 [HiveServer2-Background-Pool: Thread-98] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 83a6d52a-1ef6-46da-8e56-91e5648d9879
2025-08-06 09:06:54,918 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<namespace: STRING, tableName: STRING, isTemporary: BOOLEAN>
2025-08-06 09:06:54,927 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 83a6d52a-1ef6-46da-8e56-91e5648d9879
2025-08-06 09:06:54,928 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 83a6d52a-1ef6-46da-8e56-91e5648d9879
2025-08-06 09:06:54,930 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 00bb7bf1-ba5d-4eb0-8a82-0d8fc0e2a51f
2025-08-06 09:06:54,930 [HiveServer2-Handler-Pool: Thread-96] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 00bb7bf1-ba5d-4eb0-8a82-0d8fc0e2a51f
2025-08-06 09:06:54,933 [HiveServer2-Handler-Pool: Thread-96] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:06:55,034 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:06:55,036 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/09480ae9-bd78-496d-8c10-4de5be314f08
2025-08-06 09:06:55,041 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with 91dd206e-4edf-48bc-8d4f-e4039ea303b9
2025-08-06 09:06:55,042 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 91dd206e-4edf-48bc-8d4f-e4039ea303b9
2025-08-06 09:06:55,071 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 91dd206e-4edf-48bc-8d4f-e4039ea303b9
2025-08-06 09:06:55,071 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 91dd206e-4edf-48bc-8d4f-e4039ea303b9
2025-08-06 09:06:55,075 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "node_id": "seed.dag.orders"} */

    create table default.orders (`date` date,`product_id` bigint,`city_id` bigint,`orders` bigint)
    
    
    
    
    
  ' with 7361d1be-7379-4d94-b5d9-ffde7f58468d
2025-08-06 09:06:55,076 [HiveServer2-Background-Pool: Thread-100] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 7361d1be-7379-4d94-b5d9-ffde7f58468d
2025-08-06 09:06:55,286 [HiveServer2-Background-Pool: Thread-100] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table properties set at catalog level through catalog properties: {}
2025-08-06 09:06:55,304 [HiveServer2-Background-Pool: Thread-100] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table properties enforced at catalog level through catalog properties: {}
2025-08-06 09:06:55,457 [HiveServer2-Background-Pool: Thread-100] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 09:06:55,470 [HiveServer2-Background-Pool: Thread-100] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 09:06:55,471 [HiveServer2-Background-Pool: Thread-100] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 09:06:59,140 [HiveServer2-Background-Pool: Thread-100] INFO  org.apache.iceberg.hive.HiveTableOperations - Committed to table hive_catalog.default.orders with the new metadata location s3a://iceberg-warehouse/orders/metadata/00000-6a99bb2a-75ec-45f6-beae-309f5407a37b.metadata.json
2025-08-06 09:06:59,141 [HiveServer2-Background-Pool: Thread-100] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table hive_catalog.default.orders in 3808 ms
2025-08-06 09:06:59,210 [HiveServer2-Background-Pool: Thread-100] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/orders/metadata/00000-6a99bb2a-75ec-45f6-beae-309f5407a37b.metadata.json
2025-08-06 09:07:04,652 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '
          insert into default.orders values
          (cast('2019-12-10' as date),cast(5628.0 as bigint),cast(25.0 as bigint),cast(3.0 as bigint)),(cast('2018-08-15' as date),cast(3646.0 as bigint),cast(14.0 as bigint),cast(157.0 as bigint)),(cast('2018-10-23' as date),cast(1859.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-17' as date),cast(7292.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-06' as date),cast(4344.0 as bigint),cast(25.0 as bigint),cast(3.0 as bigint)),(cast('2018-08-23' as date),cast(1811.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2018-11-21' as date),cast(1282.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-27' as date),cast(5022.0 as bigint),cast(2.0 as bigint),cast(41.0 as bigint)),(cast('2019-06-29' as date),cast(3699.0 as bigint),cast(3.0 as bigint),cast(15.0 as bigint)),(cast('2018-08-30' as date),cast(4373.0 as bigint),cast(11.0 as bigint),cast(3.0 as bigint)),(cast('2019-10-24' as date),cast(6339.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-02' as date),cast(3311.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2019-03-15' as date),cast(5665.0 as bigint),cast(5.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-24' as date),cast(3020.0 as bigint),cast(13.0 as bigint),cast(4.0 as bigint)),(cast('2019-05-29' as date),cast(3833.0 as bigint),cast(26.0 as bigint),cast(240.0 as bigint)),(cast('2019-02-14' as date),cast(202.0 as bigint),cast(2.0 as bigint),cast(4.0 as bigint)),(cast('2019-04-10' as date),cast(977.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-24' as date),cast(2701.0 as bigint),cast(14.0 as bigint),cast(16.0 as bigint)),(cast('2019-06-12' as date),cast(5630.0 as bigint),cast(14.0 as bigint),cast(31.0 as bigint)),(cast('2019-04-13' as date),cast(7163.0 as bigint),cast(2.0 as bigint),cast(20.0 as bigint)),(cast('2019-11-30' as date),cast(1323.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-19' as date),cast(1191.0 as bigint),cast(13.0 as bigint),cast(50.0 as bigint)),(cast('2019-09-13' as date),cast(4635.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2018-08-12' as date),cast(825.0 as bigint),cast(26.0 as bigint),cast(7.0 as bigint)),(cast('2019-07-24' as date),cast(2303.0 as bigint),cast(14.0 as bigint),cast(113.0 as bigint)),(cast('2018-09-14' as date),cast(4487.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-09' as date),cast(6825.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2019-01-24' as date),cast(4152.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-20' as date),cast(5501.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-20' as date),cast(172.0 as bigint),cast(0.0 as bigint),cast(7.0 as bigint)),(cast('2019-07-24' as date),cast(2820.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2018-10-01' as date),cast(7386.0 as bigint),cast(3.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-23' as date),cast(2845.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-11' as date),cast(3121.0 as bigint),cast(17.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-09' as date),cast(4185.0 as bigint),cast(18.0 as bigint),cast(12.0 as bigint)),(cast('2019-01-20' as date),cast(2963.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2018-07-13' as date),cast(3432.0 as bigint),cast(13.0 as bigint),cast(28.0 as bigint)),(cast('2018-08-18' as date),cast(4436.0 as bigint),cast(17.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-15' as date),cast(7025.0 as bigint),cast(14.0 as bigint),cast(33.0 as bigint)),(cast('2019-05-12' as date),cast(2376.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-27' as date),cast(6900.0 as bigint),cast(14.0 as bigint),cast(14.0 as bigint)),(cast('2019-04-07' as date),cast(2898.0 as bigint),cast(18.0 as bigint),cast(45.0 as bigint)),(cast('2018-11-02' as date),cast(1439.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-04' as date),cast(2490.0 as bigint),cast(7.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-03' as date),cast(803.0 as bigint),cast(23.0 as bigint),cast(9.0 as bigint)),(cast('2019-07-01' as date),cast(1533.0 as bigint),cast(18.0 as bigint),cast(57.0 as bigint)),(cast('2018-09-23' as date),cast(2815.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-11' as date),cast(3437.0 as bigint),cast(14.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-11' as date),cast(2860.0 as bigint),cast(28.0 as bigint),cast(41.0 as bigint)),(cast('2019-07-24' as date),cast(7038.0 as bigint),cast(13.0 as bigint),cast(8.0 as bigint)),(cast('2019-06-07' as date),cast(6137.0 as bigint),cast(3.0 as bigint),cast(3.0 as bigint)),(cast('2019-08-12' as date),cast(6344.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-02' as date),cast(2844.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-04' as date),cast(5193.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-26' as date),cast(3196.0 as bigint),cast(29.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-26' as date),cast(4976.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-12' as date),cast(3667.0 as bigint),cast(13.0 as bigint),cast(20.0 as bigint)),(cast('2019-08-04' as date),cast(2837.0 as bigint),cast(18.0 as bigint),cast(370.0 as bigint)),(cast('2019-01-06' as date),cast(4618.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-25' as date),cast(4756.0 as bigint),cast(2.0 as bigint),cast(13.0 as bigint)),(cast('2018-08-05' as date),cast(3760.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-07-20' as date),cast(7025.0 as bigint),cast(14.0 as bigint),cast(22.0 as bigint)),(cast('2019-01-13' as date),cast(5033.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-29' as date),cast(2841.0 as bigint),cast(16.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-01' as date),cast(3541.0 as bigint),cast(2.0 as bigint),cast(5.0 as bigint)),(cast('2019-03-27' as date),cast(666.0 as bigint),cast(23.0 as bigint),cast(4.0 as bigint)),(cast('2019-01-26' as date),cast(1222.0 as bigint),cast(14.0 as bigint),cast(48.0 as bigint)),(cast('2018-11-18' as date),cast(3604.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2018-10-18' as date),cast(588.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-28' as date),cast(2652.0 as bigint),cast(18.0 as bigint),cast(84.0 as bigint)),(cast('2019-10-29' as date),cast(6443.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-30' as date),cast(2918.0 as bigint),cast(26.0 as bigint),cast(3.0 as bigint)),(cast('2018-08-27' as date),cast(7582.0 as bigint),cast(17.0 as bigint),cast(30.0 as bigint)),(cast('2019-07-28' as date),cast(3913.0 as bigint),cast(13.0 as bigint),cast(19.0 as bigint)),(cast('2019-11-13' as date),cast(2199.0 as bigint),cast(14.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-12' as date),cast(289.0 as bigint),cast(24.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-18' as date),cast(5973.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-02' as date),cast(5905.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-28' as date),cast(3044.0 as bigint),cast(7.0 as bigint),cast(7.0 as bigint)),(cast('2019-05-17' as date),cast(420.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-05' as date),cast(1754.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-22' as date),cast(3143.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-26' as date),cast(1985.0 as bigint),cast(14.0 as bigint),cast(13.0 as bigint)),(cast('2018-08-11' as date),cast(6300.0 as bigint),cast(22.0 as bigint),cast(5.0 as bigint)),(cast('2018-07-30' as date),cast(7350.0 as bigint),cast(16.0 as bigint),cast(76.0 as bigint)),(cast('2019-11-13' as date),cast(5288.0 as bigint),cast(18.0 as bigint),cast(7.0 as bigint)),(cast('2019-06-27' as date),cast(3904.0 as bigint),cast(1.0 as bigint),cast(29.0 as bigint)),(cast('2019-07-12' as date),cast(7042.0 as bigint),cast(3.0 as bigint),cast(5.0 as bigint)),(cast('2019-10-11' as date),cast(925.0 as bigint),cast(25.0 as bigint),cast(10.0 as bigint)),(cast('2019-07-09' as date),cast(7214.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-16' as date),cast(7491.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-18' as date),cast(923.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-30' as date),cast(5788.0 as bigint),cast(7.0 as bigint),cast(34.0 as bigint)),(cast('2019-11-12' as date),cast(7354.0 as bigint),cast(25.0 as bigint),cast(16.0 as bigint)),(cast('2019-04-10' as date),cast(300.0 as bigint),cast(14.0 as bigint),cast(462.0 as bigint)),(cast('2019-04-02' as date),cast(5383.0 as bigint),cast(11.0 as bigint),cast(24.0 as bigint)),(cast('2018-08-23' as date),cast(925.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2018-09-27' as date),cast(4690.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-03' as date),cast(4794.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2019-04-13' as date),cast(6206.0 as bigint),cast(2.0 as bigint),cast(24.0 as bigint)),(cast('2018-11-22' as date),cast(6343.0 as bigint),cast(22.0 as bigint),cast(191.0 as bigint)),(cast('2019-12-01' as date),cast(895.0 as bigint),cast(14.0 as bigint),cast(47.0 as bigint)),(cast('2018-08-30' as date),cast(3328.0 as bigint),cast(29.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-24' as date),cast(77.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2018-09-12' as date),cast(6134.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-21' as date),cast(2465.0 as bigint),cast(29.0 as bigint),cast(2.0 as bigint)),(cast('2019-01-20' as date),cast(6592.0 as bigint),cast(25.0 as bigint),cast(11.0 as bigint)),(cast('2018-12-29' as date),cast(1225.0 as bigint),cast(13.0 as bigint),cast(60.0 as bigint)),(cast('2019-10-24' as date),cast(7538.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-08' as date),cast(351.0 as bigint),cast(20.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-13' as date),cast(7059.0 as bigint),cast(14.0 as bigint),cast(11.0 as bigint)),(cast('2019-10-17' as date),cast(3597.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-21' as date),cast(5787.0 as bigint),cast(13.0 as bigint),cast(134.0 as bigint)),(cast('2018-12-15' as date),cast(6288.0 as bigint),cast(2.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-28' as date),cast(6534.0 as bigint),cast(14.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-13' as date),cast(5779.0 as bigint),cast(13.0 as bigint),cast(6.0 as bigint)),(cast('2019-04-23' as date),cast(4523.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-20' as date),cast(1556.0 as bigint),cast(17.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-12' as date),cast(2251.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-15' as date),cast(650.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-19' as date),cast(2646.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-30' as date),cast(7140.0 as bigint),cast(18.0 as bigint),cast(54.0 as bigint)),(cast('2019-12-04' as date),cast(3076.0 as bigint),cast(18.0 as bigint),cast(8.0 as bigint)),(cast('2019-07-19' as date),cast(959.0 as bigint),cast(16.0 as bigint),cast(16.0 as bigint)),(cast('2018-11-22' as date),cast(1440.0 as bigint),cast(16.0 as bigint),cast(23.0 as bigint)),(cast('2019-03-13' as date),cast(5874.0 as bigint),cast(9.0 as bigint),cast(5.0 as bigint)),(cast('2019-07-20' as date),cast(1944.0 as bigint),cast(11.0 as bigint),cast(16.0 as bigint)),(cast('2019-12-16' as date),cast(3828.0 as bigint),cast(11.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-23' as date),cast(6204.0 as bigint),cast(24.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-06' as date),cast(7413.0 as bigint),cast(13.0 as bigint),cast(6.0 as bigint)),(cast('2019-07-12' as date),cast(2242.0 as bigint),cast(8.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-16' as date),cast(7296.0 as bigint),cast(22.0 as bigint),cast(11.0 as bigint)),(cast('2018-10-08' as date),cast(4152.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-07-23' as date),cast(6564.0 as bigint),cast(18.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-17' as date),cast(6049.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-01' as date),cast(3252.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-01' as date),cast(2200.0 as bigint),cast(3.0 as bigint),cast(3.0 as bigint)),(cast('2019-03-14' as date),cast(2087.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-04' as date),cast(4635.0 as bigint),cast(22.0 as bigint),cast(12.0 as bigint)),(cast('2018-10-31' as date),cast(5508.0 as bigint),cast(14.0 as bigint),cast(8.0 as bigint)),(cast('2018-10-31' as date),cast(5112.0 as bigint),cast(10.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-17' as date),cast(1640.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-06' as date),cast(1610.0 as bigint),cast(3.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-09' as date),cast(5284.0 as bigint),cast(25.0 as bigint),cast(8.0 as bigint)),(cast('2019-10-14' as date),cast(5778.0 as bigint),cast(24.0 as bigint),cast(108.0 as bigint)),(cast('2019-04-18' as date),cast(351.0 as bigint),cast(20.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-13' as date),cast(6828.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-09' as date),cast(5290.0 as bigint),cast(3.0 as bigint),cast(139.0 as bigint)),(cast('2019-12-10' as date),cast(561.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-09' as date),cast(1024.0 as bigint),cast(10.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-10' as date),cast(7478.0 as bigint),cast(24.0 as bigint),cast(9.0 as bigint)),(cast('2019-10-15' as date),cast(5066.0 as bigint),cast(18.0 as bigint),cast(14.0 as bigint)),(cast('2019-01-25' as date),cast(7068.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-13' as date),cast(4576.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-10' as date),cast(803.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-04' as date),cast(3888.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-25' as date),cast(568.0 as bigint),cast(8.0 as bigint),cast(25.0 as bigint)),(cast('2019-02-18' as date),cast(6761.0 as bigint),cast(14.0 as bigint),cast(5.0 as bigint)),(cast('2019-12-16' as date),cast(2148.0 as bigint),cast(28.0 as bigint),cast(51.0 as bigint)),(cast('2019-11-08' as date),cast(718.0 as bigint),cast(9.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-28' as date),cast(2627.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-30' as date),cast(7140.0 as bigint),cast(18.0 as bigint),cast(26.0 as bigint)),(cast('2019-11-17' as date),cast(1775.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2018-11-12' as date),cast(2541.0 as bigint),cast(28.0 as bigint),cast(4.0 as bigint)),(cast('2019-06-26' as date),cast(6097.0 as bigint),cast(9.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-05' as date),cast(327.0 as bigint),cast(17.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-11' as date),cast(3946.0 as bigint),cast(30.0 as bigint),cast(9.0 as bigint)),(cast('2019-07-30' as date),cast(5314.0 as bigint),cast(11.0 as bigint),cast(10.0 as bigint)),(cast('2019-11-16' as date),cast(4432.0 as bigint),cast(3.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-25' as date),cast(2876.0 as bigint),cast(1.0 as bigint),cast(4.0 as bigint)),(cast('2019-03-25' as date),cast(6357.0 as bigint),cast(4.0 as bigint),cast(5.0 as bigint)),(cast('2019-01-25' as date),cast(4964.0 as bigint),cast(1.0 as bigint),cast(55.0 as bigint)),(cast('2019-06-24' as date),cast(5450.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-11' as date),cast(3543.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-03' as date),cast(718.0 as bigint),cast(9.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-04' as date),cast(3125.0 as bigint),cast(1.0 as bigint),cast(10.0 as bigint)),(cast('2018-12-16' as date),cast(1475.0 as bigint),cast(16.0 as bigint),cast(8.0 as bigint)),(cast('2019-08-10' as date),cast(585.0 as bigint),cast(17.0 as bigint),cast(13.0 as bigint)),(cast('2019-04-30' as date),cast(4776.0 as bigint),cast(16.0 as bigint),cast(100.0 as bigint)),(cast('2019-01-15' as date),cast(4571.0 as bigint),cast(22.0 as bigint),cast(3.0 as bigint)),(cast('2019-07-13' as date),cast(4180.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2019-04-12' as date),cast(1744.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-05-26' as date),cast(1135.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-08' as date),cast(4785.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2019-01-21' as date),cast(6371.0 as bigint),cast(7.0 as bigint),cast(8.0 as bigint)),(cast('2019-11-29' as date),cast(4294.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2019-05-30' as date),cast(4992.0 as bigint),cast(9.0 as bigint),cast(15.0 as bigint)),(cast('2019-05-29' as date),cast(586.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-25' as date),cast(1123.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-05' as date),cast(4400.0 as bigint),cast(27.0 as bigint),cast(9.0 as bigint)),(cast('2019-07-13' as date),cast(776.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-29' as date),cast(2228.0 as bigint),cast(5.0 as bigint),cast(3.0 as bigint)),(cast('2019-04-21' as date),cast(21.0 as bigint),cast(24.0 as bigint),cast(3.0 as bigint)),(cast('2019-05-18' as date),cast(6828.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-09' as date),cast(5.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-01' as date),cast(5470.0 as bigint),cast(16.0 as bigint),cast(23.0 as bigint)),(cast('2018-08-20' as date),cast(6215.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2018-09-14' as date),cast(3440.0 as bigint),cast(26.0 as bigint),cast(101.0 as bigint)),(cast('2018-08-28' as date),cast(685.0 as bigint),cast(25.0 as bigint),cast(29.0 as bigint)),(cast('2019-01-27' as date),cast(3817.0 as bigint),cast(28.0 as bigint),cast(4.0 as bigint)),(cast('2019-02-06' as date),cast(3449.0 as bigint),cast(28.0 as bigint),cast(5.0 as bigint)),(cast('2019-04-06' as date),cast(2357.0 as bigint),cast(14.0 as bigint),cast(104.0 as bigint)),(cast('2018-11-21' as date),cast(192.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-16' as date),cast(4033.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-07' as date),cast(820.0 as bigint),cast(30.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-05' as date),cast(5722.0 as bigint),cast(25.0 as bigint),cast(260.0 as bigint)),(cast('2019-04-24' as date),cast(6082.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-01' as date),cast(5135.0 as bigint),cast(9.0 as bigint),cast(5.0 as bigint)),(cast('2019-06-24' as date),cast(3919.0 as bigint),cast(2.0 as bigint),cast(22.0 as bigint)),(cast('2018-11-06' as date),cast(3234.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-13' as date),cast(3403.0 as bigint),cast(1.0 as bigint),cast(15.0 as bigint)),(cast('2019-01-04' as date),cast(6588.0 as bigint),cast(28.0 as bigint),cast(7.0 as bigint)),(cast('2019-10-11' as date),cast(3340.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-25' as date),cast(2562.0 as bigint),cast(18.0 as bigint),cast(133.0 as bigint)),(cast('2019-06-30' as date),cast(453.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-01' as date),cast(7266.0 as bigint),cast(19.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-13' as date),cast(3493.0 as bigint),cast(26.0 as bigint),cast(9.0 as bigint)),(cast('2018-09-14' as date),cast(3390.0 as bigint),cast(20.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-14' as date),cast(3047.0 as bigint),cast(4.0 as bigint),cast(24.0 as bigint)),(cast('2019-07-26' as date),cast(4425.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-14' as date),cast(4482.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-15' as date),cast(300.0 as bigint),cast(14.0 as bigint),cast(967.0 as bigint)),(cast('2019-01-22' as date),cast(5002.0 as bigint),cast(13.0 as bigint),cast(15.0 as bigint)),(cast('2019-07-18' as date),cast(4529.0 as bigint),cast(20.0 as bigint),cast(5.0 as bigint)),(cast('2019-11-20' as date),cast(4495.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-26' as date),cast(1503.0 as bigint),cast(21.0 as bigint),cast(12.0 as bigint)),(cast('2018-10-31' as date),cast(4036.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-30' as date),cast(4040.0 as bigint),cast(14.0 as bigint),cast(30.0 as bigint)),(cast('2019-05-15' as date),cast(6683.0 as bigint),cast(13.0 as bigint),cast(8.0 as bigint)),(cast('2019-11-29' as date),cast(4047.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2018-07-22' as date),cast(7554.0 as bigint),cast(13.0 as bigint),cast(12.0 as bigint)),(cast('2018-08-28' as date),cast(4289.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-08' as date),cast(666.0 as bigint),cast(23.0 as bigint),cast(9.0 as bigint)),(cast('2019-08-17' as date),cast(2411.0 as bigint),cast(23.0 as bigint),cast(6.0 as bigint)),(cast('2019-04-21' as date),cast(5200.0 as bigint),cast(28.0 as bigint),cast(19.0 as bigint)),(cast('2018-10-05' as date),cast(1288.0 as bigint),cast(20.0 as bigint),cast(22.0 as bigint)),(cast('2018-08-24' as date),cast(4576.0 as bigint),cast(22.0 as bigint),cast(3.0 as bigint)),(cast('2019-12-09' as date),cast(5489.0 as bigint),cast(13.0 as bigint),cast(23.0 as bigint)),(cast('2018-08-24' as date),cast(496.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-19' as date),cast(4823.0 as bigint),cast(18.0 as bigint),cast(26.0 as bigint)),(cast('2019-08-09' as date),cast(4938.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-25' as date),cast(582.0 as bigint),cast(26.0 as bigint),cast(8.0 as bigint)),(cast('2018-11-20' as date),cast(5450.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-29' as date),cast(5939.0 as bigint),cast(14.0 as bigint),cast(183.0 as bigint)),(cast('2019-11-13' as date),cast(2691.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-28' as date),cast(2185.0 as bigint),cast(13.0 as bigint),cast(6.0 as bigint)),(cast('2019-12-10' as date),cast(2253.0 as bigint),cast(13.0 as bigint),cast(46.0 as bigint)),(cast('2019-12-06' as date),cast(7148.0 as bigint),cast(16.0 as bigint),cast(29.0 as bigint)),(cast('2019-01-04' as date),cast(3614.0 as bigint),cast(29.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-14' as date),cast(2265.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-16' as date),cast(2611.0 as bigint),cast(13.0 as bigint),cast(11.0 as bigint)),(cast('2018-11-14' as date),cast(7239.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-25' as date),cast(792.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-13' as date),cast(3793.0 as bigint),cast(22.0 as bigint),cast(32.0 as bigint)),(cast('2019-05-07' as date),cast(5329.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-30' as date),cast(4794.0 as bigint),cast(14.0 as bigint),cast(5.0 as bigint)),(cast('2019-07-28' as date),cast(4814.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-03' as date),cast(1364.0 as bigint),cast(30.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-04' as date),cast(1775.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-10' as date),cast(7246.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-04' as date),cast(4483.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-10' as date),cast(3505.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2018-11-14' as date),cast(4667.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-03' as date),cast(6694.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-26' as date),cast(1182.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2019-04-28' as date),cast(2850.0 as bigint),cast(16.0 as bigint),cast(6.0 as bigint)),(cast('2019-12-11' as date),cast(972.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-18' as date),cast(2372.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-14' as date),cast(6642.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-21' as date),cast(6567.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-23' as date),cast(704.0 as bigint),cast(13.0 as bigint),cast(10.0 as bigint)),(cast('2019-10-20' as date),cast(5281.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-22' as date),cast(3995.0 as bigint),cast(18.0 as bigint),cast(58.0 as bigint)),(cast('2019-11-03' as date),cast(149.0 as bigint),cast(14.0 as bigint),cast(24.0 as bigint)),(cast('2019-01-22' as date),cast(5618.0 as bigint),cast(21.0 as bigint),cast(3.0 as bigint)),(cast('2019-01-12' as date),cast(4850.0 as bigint),cast(26.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-18' as date),cast(5004.0 as bigint),cast(25.0 as bigint),cast(21.0 as bigint)),(cast('2018-11-21' as date),cast(2017.0 as bigint),cast(11.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-08' as date),cast(5024.0 as bigint),cast(21.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-05' as date),cast(2884.0 as bigint),cast(2.0 as bigint),cast(19.0 as bigint)),(cast('2018-08-18' as date),cast(6716.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-17' as date),cast(4379.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-27' as date),cast(1517.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-17' as date),cast(390.0 as bigint),cast(9.0 as bigint),cast(5.0 as bigint)),(cast('2018-07-27' as date),cast(3635.0 as bigint),cast(16.0 as bigint),cast(48.0 as bigint)),(cast('2018-10-19' as date),cast(6619.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-10' as date),cast(2850.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-15' as date),cast(6368.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-24' as date),cast(5618.0 as bigint),cast(21.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-21' as date),cast(483.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-05' as date),cast(4254.0 as bigint),cast(16.0 as bigint),cast(37.0 as bigint)),(cast('2018-11-20' as date),cast(5009.0 as bigint),cast(28.0 as bigint),cast(12.0 as bigint)),(cast('2018-09-02' as date),cast(1455.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-12' as date),cast(3151.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-02' as date),cast(3601.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-29' as date),cast(3012.0 as bigint),cast(18.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-05' as date),cast(3601.0 as bigint),cast(9.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-02' as date),cast(5653.0 as bigint),cast(17.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-12' as date),cast(3748.0 as bigint),cast(17.0 as bigint),cast(11.0 as bigint)),(cast('2019-05-02' as date),cast(6438.0 as bigint),cast(24.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-31' as date),cast(2981.0 as bigint),cast(26.0 as bigint),cast(1004.0 as bigint)),(cast('2018-08-18' as date),cast(2301.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-05' as date),cast(2012.0 as bigint),cast(8.0 as bigint),cast(32.0 as bigint)),(cast('2019-06-01' as date),cast(1069.0 as bigint),cast(27.0 as bigint),cast(7.0 as bigint)),(cast('2018-09-15' as date),cast(438.0 as bigint),cast(22.0 as bigint),cast(12.0 as bigint)),(cast('2019-07-05' as date),cast(25.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-01' as date),cast(820.0 as bigint),cast(30.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-06' as date),cast(3034.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-07-27' as date),cast(664.0 as bigint),cast(24.0 as bigint),cast(15.0 as bigint)),(cast('2019-08-14' as date),cast(4352.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-20' as date),cast(1533.0 as bigint),cast(18.0 as bigint),cast(8.0 as bigint)),(cast('2018-10-31' as date),cast(7430.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-14' as date),cast(7011.0 as bigint),cast(9.0 as bigint),cast(11.0 as bigint)),(cast('2018-12-29' as date),cast(5118.0 as bigint),cast(13.0 as bigint),cast(125.0 as bigint)),(cast('2018-10-06' as date),cast(4845.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2018-11-10' as date),cast(3345.0 as bigint),cast(13.0 as bigint),cast(23.0 as bigint)),(cast('2019-01-24' as date),cast(4173.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-31' as date),cast(3088.0 as bigint),cast(14.0 as bigint),cast(106.0 as bigint)),(cast('2019-07-17' as date),cast(7223.0 as bigint),cast(2.0 as bigint),cast(28.0 as bigint)),(cast('2018-07-10' as date),cast(6283.0 as bigint),cast(14.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-28' as date),cast(5631.0 as bigint),cast(24.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-04' as date),cast(2981.0 as bigint),cast(26.0 as bigint),cast(461.0 as bigint)),(cast('2019-06-23' as date),cast(652.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2018-11-19' as date),cast(583.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-14' as date),cast(1238.0 as bigint),cast(13.0 as bigint),cast(7.0 as bigint)),(cast('2019-06-13' as date),cast(7057.0 as bigint),cast(2.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-29' as date),cast(1675.0 as bigint),cast(4.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-26' as date),cast(6115.0 as bigint),cast(22.0 as bigint),cast(63.0 as bigint)),(cast('2019-11-20' as date),cast(7467.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-05' as date),cast(5347.0 as bigint),cast(3.0 as bigint),cast(5.0 as bigint)),(cast('2019-03-02' as date),cast(2432.0 as bigint),cast(22.0 as bigint),cast(3.0 as bigint)),(cast('2019-10-21' as date),cast(6729.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-02' as date),cast(1467.0 as bigint),cast(22.0 as bigint),cast(63.0 as bigint)),(cast('2019-10-31' as date),cast(1494.0 as bigint),cast(25.0 as bigint),cast(71.0 as bigint)),(cast('2019-10-27' as date),cast(1130.0 as bigint),cast(14.0 as bigint),cast(48.0 as bigint)),(cast('2018-09-05' as date),cast(45.0 as bigint),cast(13.0 as bigint),cast(38.0 as bigint)),(cast('2018-11-30' as date),cast(4192.0 as bigint),cast(14.0 as bigint),cast(26.0 as bigint)),(cast('2019-07-15' as date),cast(4180.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-05' as date),cast(3862.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-05' as date),cast(6135.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-02' as date),cast(2088.0 as bigint),cast(26.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-04' as date),cast(1097.0 as bigint),cast(26.0 as bigint),cast(17.0 as bigint)),(cast('2019-07-31' as date),cast(4509.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2019-03-22' as date),cast(3064.0 as bigint),cast(8.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-22' as date),cast(7510.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2018-07-26' as date),cast(6857.0 as bigint),cast(18.0 as bigint),cast(61.0 as bigint)),(cast('2018-11-10' as date),cast(2215.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-16' as date),cast(1881.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2019-02-09' as date),cast(1848.0 as bigint),cast(14.0 as bigint),cast(135.0 as bigint)),(cast('2018-09-02' as date),cast(5819.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2019-10-26' as date),cast(1730.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-23' as date),cast(2056.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-03' as date),cast(27.0 as bigint),cast(10.0 as bigint),cast(40.0 as bigint)),(cast('2018-08-08' as date),cast(2284.0 as bigint),cast(9.0 as bigint),cast(8.0 as bigint)),(cast('2019-06-12' as date),cast(1739.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-09-18' as date),cast(6779.0 as bigint),cast(10.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-13' as date),cast(2148.0 as bigint),cast(28.0 as bigint),cast(11.0 as bigint)),(cast('2019-02-09' as date),cast(532.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-19' as date),cast(6295.0 as bigint),cast(3.0 as bigint),cast(44.0 as bigint)),(cast('2019-03-23' as date),cast(3339.0 as bigint),cast(22.0 as bigint),cast(38.0 as bigint)),(cast('2019-03-23' as date),cast(435.0 as bigint),cast(7.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-13' as date),cast(124.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-10' as date),cast(3734.0 as bigint),cast(4.0 as bigint),cast(25.0 as bigint)),(cast('2019-01-09' as date),cast(6860.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-26' as date),cast(5687.0 as bigint),cast(13.0 as bigint),cast(11.0 as bigint)),(cast('2018-07-18' as date),cast(6248.0 as bigint),cast(4.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-22' as date),cast(2307.0 as bigint),cast(4.0 as bigint),cast(6.0 as bigint)),(cast('2018-12-18' as date),cast(3678.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-31' as date),cast(83.0 as bigint),cast(25.0 as bigint),cast(3.0 as bigint)),(cast('2019-01-02' as date),cast(2357.0 as bigint),cast(14.0 as bigint),cast(60.0 as bigint)),(cast('2019-01-23' as date),cast(4573.0 as bigint),cast(2.0 as bigint),cast(3.0 as bigint)),(cast('2019-12-02' as date),cast(820.0 as bigint),cast(30.0 as bigint),cast(8.0 as bigint)),(cast('2019-03-05' as date),cast(6933.0 as bigint),cast(25.0 as bigint),cast(34.0 as bigint)),(cast('2019-07-14' as date),cast(1672.0 as bigint),cast(11.0 as bigint),cast(5.0 as bigint)),(cast('2018-12-16' as date),cast(4595.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-14' as date),cast(2002.0 as bigint),cast(1.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-01' as date),cast(5738.0 as bigint),cast(13.0 as bigint),cast(22.0 as bigint)),(cast('2019-01-25' as date),cast(2876.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-18' as date),cast(585.0 as bigint),cast(17.0 as bigint),cast(25.0 as bigint)),(cast('2019-10-11' as date),cast(2381.0 as bigint),cast(18.0 as bigint),cast(23.0 as bigint)),(cast('2019-08-10' as date),cast(1005.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-12' as date),cast(2837.0 as bigint),cast(18.0 as bigint),cast(149.0 as bigint)),(cast('2018-09-30' as date),cast(1935.0 as bigint),cast(2.0 as bigint),cast(48.0 as bigint)),(cast('2019-11-28' as date),cast(820.0 as bigint),cast(30.0 as bigint),cast(6.0 as bigint)),(cast('2018-12-27' as date),cast(2367.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2018-07-24' as date),cast(4306.0 as bigint),cast(14.0 as bigint),cast(11.0 as bigint)),(cast('2019-07-09' as date),cast(1935.0 as bigint),cast(2.0 as bigint),cast(37.0 as bigint)),(cast('2019-02-02' as date),cast(2897.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-19' as date),cast(4075.0 as bigint),cast(18.0 as bigint),cast(25.0 as bigint)),(cast('2018-10-25' as date),cast(2911.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-04' as date),cast(7526.0 as bigint),cast(14.0 as bigint),cast(5.0 as bigint)),(cast('2019-10-21' as date),cast(2524.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-05-04' as date),cast(4508.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-19' as date),cast(2271.0 as bigint),cast(3.0 as bigint),cast(28.0 as bigint)),(cast('2018-12-16' as date),cast(7034.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-06' as date),cast(7300.0 as bigint),cast(9.0 as bigint),cast(46.0 as bigint)),(cast('2019-10-25' as date),cast(107.0 as bigint),cast(4.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-25' as date),cast(6435.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-19' as date),cast(2307.0 as bigint),cast(4.0 as bigint),cast(9.0 as bigint)),(cast('2019-10-13' as date),cast(149.0 as bigint),cast(14.0 as bigint),cast(37.0 as bigint)),(cast('2019-04-18' as date),cast(5119.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-31' as date),cast(7508.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2018-11-05' as date),cast(4347.0 as bigint),cast(25.0 as bigint),cast(131.0 as bigint)),(cast('2018-12-03' as date),cast(639.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-12' as date),cast(841.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-26' as date),cast(4207.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-20' as date),cast(1081.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-23' as date),cast(5970.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-31' as date),cast(1341.0 as bigint),cast(13.0 as bigint),cast(8.0 as bigint)),(cast('2018-09-07' as date),cast(6478.0 as bigint),cast(2.0 as bigint),cast(2.0 as bigint)),(cast('2019-05-17' as date),cast(6309.0 as bigint),cast(29.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-11' as date),cast(3179.0 as bigint),cast(22.0 as bigint),cast(16.0 as bigint)),(cast('2018-10-10' as date),cast(6302.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-01' as date),cast(836.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-20' as date),cast(1670.0 as bigint),cast(26.0 as bigint),cast(15.0 as bigint)),(cast('2018-09-07' as date),cast(1191.0 as bigint),cast(13.0 as bigint),cast(47.0 as bigint)),(cast('2019-08-02' as date),cast(664.0 as bigint),cast(24.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-16' as date),cast(1361.0 as bigint),cast(20.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-16' as date),cast(3553.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-22' as date),cast(7430.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-07' as date),cast(7288.0 as bigint),cast(14.0 as bigint),cast(5.0 as bigint)),(cast('2019-07-05' as date),cast(5970.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-24' as date),cast(6717.0 as bigint),cast(3.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-14' as date),cast(5670.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-12' as date),cast(637.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-09' as date),cast(4944.0 as bigint),cast(26.0 as bigint),cast(9.0 as bigint)),(cast('2019-11-01' as date),cast(6487.0 as bigint),cast(30.0 as bigint),cast(6.0 as bigint)),(cast('2019-05-27' as date),cast(6072.0 as bigint),cast(26.0 as bigint),cast(60.0 as bigint)),(cast('2018-07-14' as date),cast(4183.0 as bigint),cast(22.0 as bigint),cast(8.0 as bigint)),(cast('2019-11-11' as date),cast(2746.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-20' as date),cast(6336.0 as bigint),cast(23.0 as bigint),cast(13.0 as bigint)),(cast('2019-09-13' as date),cast(5012.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-18' as date),cast(3098.0 as bigint),cast(28.0 as bigint),cast(6.0 as bigint)),(cast('2019-08-15' as date),cast(5770.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-15' as date),cast(890.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-20' as date),cast(4847.0 as bigint),cast(26.0 as bigint),cast(9.0 as bigint)),(cast('2019-10-11' as date),cast(983.0 as bigint),cast(25.0 as bigint),cast(45.0 as bigint)),(cast('2019-08-04' as date),cast(2830.0 as bigint),cast(14.0 as bigint),cast(21.0 as bigint)),(cast('2018-12-31' as date),cast(1985.0 as bigint),cast(14.0 as bigint),cast(45.0 as bigint)),(cast('2019-11-21' as date),cast(7224.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-31' as date),cast(4382.0 as bigint),cast(23.0 as bigint),cast(5.0 as bigint)),(cast('2019-02-15' as date),cast(2906.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-04' as date),cast(963.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-21' as date),cast(873.0 as bigint),cast(25.0 as bigint),cast(16.0 as bigint)),(cast('2019-07-24' as date),cast(6115.0 as bigint),cast(22.0 as bigint),cast(29.0 as bigint)),(cast('2019-10-14' as date),cast(4192.0 as bigint),cast(14.0 as bigint),cast(59.0 as bigint)),(cast('2019-06-28' as date),cast(5430.0 as bigint),cast(14.0 as bigint),cast(7.0 as bigint)),(cast('2019-01-18' as date),cast(621.0 as bigint),cast(22.0 as bigint),cast(25.0 as bigint)),(cast('2018-12-07' as date),cast(1933.0 as bigint),cast(21.0 as bigint),cast(17.0 as bigint)),(cast('2019-03-24' as date),cast(4523.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-30' as date),cast(3532.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2018-12-23' as date),cast(7078.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2018-11-05' as date),cast(7450.0 as bigint),cast(21.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-13' as date),cast(3860.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-15' as date),cast(1766.0 as bigint),cast(22.0 as bigint),cast(15.0 as bigint)),(cast('2018-09-08' as date),cast(5330.0 as bigint),cast(26.0 as bigint),cast(6.0 as bigint)),(cast('2018-12-04' as date),cast(1622.0 as bigint),cast(9.0 as bigint),cast(4.0 as bigint)),(cast('2019-10-12' as date),cast(4347.0 as bigint),cast(25.0 as bigint),cast(195.0 as bigint)),(cast('2019-08-02' as date),cast(5742.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-02' as date),cast(3803.0 as bigint),cast(21.0 as bigint),cast(2.0 as bigint)),(cast('2019-01-25' as date),cast(5508.0 as bigint),cast(14.0 as bigint),cast(9.0 as bigint)),(cast('2019-10-20' as date),cast(5125.0 as bigint),cast(3.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-14' as date),cast(626.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-21' as date),cast(1945.0 as bigint),cast(9.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-26' as date),cast(4895.0 as bigint),cast(29.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-13' as date),cast(6566.0 as bigint),cast(18.0 as bigint),cast(8.0 as bigint)),(cast('2018-12-11' as date),cast(4203.0 as bigint),cast(22.0 as bigint),cast(26.0 as bigint)),(cast('2018-07-14' as date),cast(1114.0 as bigint),cast(13.0 as bigint),cast(90.0 as bigint)),(cast('2019-02-14' as date),cast(7140.0 as bigint),cast(18.0 as bigint),cast(20.0 as bigint)),(cast('2019-11-15' as date),cast(5549.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-22' as date),cast(3125.0 as bigint),cast(1.0 as bigint),cast(69.0 as bigint)),(cast('2018-11-05' as date),cast(6430.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-05' as date),cast(7464.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2019-05-15' as date),cast(1896.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2019-11-01' as date),cast(3967.0 as bigint),cast(2.0 as bigint),cast(12.0 as bigint)),(cast('2019-07-25' as date),cast(2898.0 as bigint),cast(18.0 as bigint),cast(98.0 as bigint)),(cast('2019-04-04' as date),cast(5979.0 as bigint),cast(21.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-08' as date),cast(383.0 as bigint),cast(25.0 as bigint),cast(22.0 as bigint)),(cast('2018-12-22' as date),cast(711.0 as bigint),cast(30.0 as bigint),cast(3.0 as bigint)),(cast('2019-10-11' as date),cast(5116.0 as bigint),cast(14.0 as bigint),cast(32.0 as bigint)),(cast('2019-02-06' as date),cast(3835.0 as bigint),cast(9.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-16' as date),cast(1115.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-29' as date),cast(6791.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-30' as date),cast(5407.0 as bigint),cast(13.0 as bigint),cast(64.0 as bigint)),(cast('2019-02-09' as date),cast(2123.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-11' as date),cast(6941.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-20' as date),cast(5822.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2019-04-18' as date),cast(6095.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-30' as date),cast(6663.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-02' as date),cast(3247.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-21' as date),cast(2254.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2019-10-20' as date),cast(2597.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-24' as date),cast(2306.0 as bigint),cast(14.0 as bigint),cast(12.0 as bigint)),(cast('2019-06-04' as date),cast(2053.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-05' as date),cast(4733.0 as bigint),cast(12.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-09' as date),cast(7148.0 as bigint),cast(16.0 as bigint),cast(11.0 as bigint)),(cast('2019-03-16' as date),cast(3562.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-26' as date),cast(4667.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-07' as date),cast(3508.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-28' as date),cast(1225.0 as bigint),cast(13.0 as bigint),cast(40.0 as bigint)),(cast('2019-07-25' as date),cast(5371.0 as bigint),cast(22.0 as bigint),cast(15.0 as bigint)),(cast('2019-01-24' as date),cast(1881.0 as bigint),cast(14.0 as bigint),cast(14.0 as bigint)),(cast('2019-06-19' as date),cast(1232.0 as bigint),cast(14.0 as bigint),cast(8.0 as bigint)),(cast('2018-12-02' as date),cast(25.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-23' as date),cast(5280.0 as bigint),cast(23.0 as bigint),cast(8.0 as bigint)),(cast('2019-12-12' as date),cast(2585.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-06' as date),cast(2259.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-26' as date),cast(1047.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-17' as date),cast(77.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-10' as date),cast(7269.0 as bigint),cast(30.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-04' as date),cast(5953.0 as bigint),cast(13.0 as bigint),cast(34.0 as bigint)),(cast('2018-12-02' as date),cast(1403.0 as bigint),cast(29.0 as bigint),cast(3.0 as bigint)),(cast('2019-12-12' as date),cast(4968.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-30' as date),cast(6975.0 as bigint),cast(3.0 as bigint),cast(3.0 as bigint)),(cast('2019-08-03' as date),cast(4207.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-22' as date),cast(4611.0 as bigint),cast(26.0 as bigint),cast(8.0 as bigint)),(cast('2018-12-09' as date),cast(3953.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-06' as date),cast(6671.0 as bigint),cast(20.0 as bigint),cast(28.0 as bigint)),(cast('2018-07-26' as date),cast(50.0 as bigint),cast(2.0 as bigint),cast(15.0 as bigint)),(cast('2019-11-01' as date),cast(6377.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2019-04-03' as date),cast(4921.0 as bigint),cast(24.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-23' as date),cast(5482.0 as bigint),cast(25.0 as bigint),cast(7.0 as bigint)),(cast('2019-10-30' as date),cast(2416.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-18' as date),cast(3629.0 as bigint),cast(9.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-01' as date),cast(370.0 as bigint),cast(13.0 as bigint),cast(7.0 as bigint)),(cast('2019-06-13' as date),cast(2249.0 as bigint),cast(20.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-29' as date),cast(6671.0 as bigint),cast(20.0 as bigint),cast(15.0 as bigint)),(cast('2019-08-01' as date),cast(2811.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-17' as date),cast(7015.0 as bigint),cast(26.0 as bigint),cast(3.0 as bigint)),(cast('2019-07-30' as date),cast(5698.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-22' as date),cast(6007.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-31' as date),cast(4639.0 as bigint),cast(0.0 as bigint),cast(5.0 as bigint)),(cast('2019-10-17' as date),cast(3250.0 as bigint),cast(27.0 as bigint),cast(3.0 as bigint)),(cast('2019-01-22' as date),cast(6291.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-23' as date),cast(5615.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-26' as date),cast(7318.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-24' as date),cast(1140.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-29' as date),cast(2563.0 as bigint),cast(18.0 as bigint),cast(14.0 as bigint)),(cast('2018-08-24' as date),cast(4885.0 as bigint),cast(16.0 as bigint),cast(25.0 as bigint)),(cast('2019-12-08' as date),cast(2831.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2018-09-26' as date),cast(7350.0 as bigint),cast(16.0 as bigint),cast(23.0 as bigint)),(cast('2018-12-10' as date),cast(2457.0 as bigint),cast(3.0 as bigint),cast(13.0 as bigint)),(cast('2019-06-10' as date),cast(2652.0 as bigint),cast(18.0 as bigint),cast(69.0 as bigint)),(cast('2019-12-05' as date),cast(3944.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-01' as date),cast(3222.0 as bigint),cast(25.0 as bigint),cast(7.0 as bigint)),(cast('2019-01-21' as date),cast(5280.0 as bigint),cast(23.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-22' as date),cast(882.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-21' as date),cast(793.0 as bigint),cast(29.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-03' as date),cast(5917.0 as bigint),cast(2.0 as bigint),cast(59.0 as bigint)),(cast('2018-11-11' as date),cast(6656.0 as bigint),cast(26.0 as bigint),cast(10.0 as bigint)),(cast('2019-07-05' as date),cast(5115.0 as bigint),cast(2.0 as bigint),cast(121.0 as bigint)),(cast('2019-06-27' as date),cast(6756.0 as bigint),cast(17.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-04' as date),cast(5955.0 as bigint),cast(16.0 as bigint),cast(3.0 as bigint)),(cast('2019-05-29' as date),cast(2381.0 as bigint),cast(18.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-11' as date),cast(873.0 as bigint),cast(25.0 as bigint),cast(26.0 as bigint)),(cast('2019-08-15' as date),cast(3422.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-14' as date),cast(2422.0 as bigint),cast(18.0 as bigint),cast(3.0 as bigint)),(cast('2019-01-22' as date),cast(2811.0 as bigint),cast(13.0 as bigint),cast(9.0 as bigint)),(cast('2019-06-26' as date),cast(2416.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-16' as date),cast(5860.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-04' as date),cast(358.0 as bigint),cast(10.0 as bigint),cast(15.0 as bigint)),(cast('2019-08-18' as date),cast(6212.0 as bigint),cast(7.0 as bigint),cast(12.0 as bigint)),(cast('2018-12-01' as date),cast(348.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2019-04-11' as date),cast(7294.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-08' as date),cast(4195.0 as bigint),cast(26.0 as bigint),cast(8.0 as bigint)),(cast('2019-04-29' as date),cast(888.0 as bigint),cast(20.0 as bigint),cast(5.0 as bigint)),(cast('2019-04-29' as date),cast(3646.0 as bigint),cast(14.0 as bigint),cast(63.0 as bigint)),(cast('2019-11-15' as date),cast(2457.0 as bigint),cast(3.0 as bigint),cast(24.0 as bigint)),(cast('2019-12-01' as date),cast(4505.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-18' as date),cast(5795.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-18' as date),cast(2687.0 as bigint),cast(25.0 as bigint),cast(31.0 as bigint)),(cast('2018-09-18' as date),cast(5421.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-03' as date),cast(4191.0 as bigint),cast(16.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-16' as date),cast(5778.0 as bigint),cast(24.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-13' as date),cast(5639.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2018-09-27' as date),cast(4627.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-11' as date),cast(202.0 as bigint),cast(2.0 as bigint),cast(3.0 as bigint)),(cast('2018-07-22' as date),cast(2974.0 as bigint),cast(26.0 as bigint),cast(15.0 as bigint)),(cast('2019-06-28' as date),cast(5922.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-13' as date),cast(7059.0 as bigint),cast(14.0 as bigint),cast(31.0 as bigint)),(cast('2018-09-29' as date),cast(5965.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-18' as date),cast(731.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-22' as date),cast(1031.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-17' as date),cast(2589.0 as bigint),cast(20.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-16' as date),cast(1520.0 as bigint),cast(26.0 as bigint),cast(168.0 as bigint)),(cast('2018-07-16' as date),cast(5738.0 as bigint),cast(13.0 as bigint),cast(39.0 as bigint)),(cast('2019-06-26' as date),cast(2563.0 as bigint),cast(18.0 as bigint),cast(8.0 as bigint)),(cast('2019-10-30' as date),cast(6153.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2019-05-21' as date),cast(3055.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-02' as date),cast(1757.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-14' as date),cast(3197.0 as bigint),cast(17.0 as bigint),cast(27.0 as bigint)),(cast('2019-10-15' as date),cast(5386.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-05' as date),cast(2471.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-17' as date),cast(2973.0 as bigint),cast(26.0 as bigint),cast(7.0 as bigint)),(cast('2019-04-14' as date),cast(547.0 as bigint),cast(4.0 as bigint),cast(86.0 as bigint)),(cast('2018-09-21' as date),cast(5407.0 as bigint),cast(13.0 as bigint),cast(25.0 as bigint)),(cast('2019-08-05' as date),cast(6091.0 as bigint),cast(25.0 as bigint),cast(92.0 as bigint)),(cast('2018-10-18' as date),cast(4846.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-07' as date),cast(1134.0 as bigint),cast(13.0 as bigint),cast(19.0 as bigint)),(cast('2019-06-05' as date),cast(2373.0 as bigint),cast(13.0 as bigint),cast(16.0 as bigint)),(cast('2019-10-18' as date),cast(3464.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-24' as date),cast(6592.0 as bigint),cast(25.0 as bigint),cast(12.0 as bigint)),(cast('2018-07-15' as date),cast(3497.0 as bigint),cast(26.0 as bigint),cast(234.0 as bigint)),(cast('2018-12-11' as date),cast(7435.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-05' as date),cast(5708.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-19' as date),cast(5452.0 as bigint),cast(26.0 as bigint),cast(12.0 as bigint)),(cast('2018-11-24' as date),cast(2870.0 as bigint),cast(25.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-27' as date),cast(3685.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-10' as date),cast(5301.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-21' as date),cast(1933.0 as bigint),cast(21.0 as bigint),cast(19.0 as bigint)),(cast('2018-10-01' as date),cast(457.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-01-30' as date),cast(1284.0 as bigint),cast(17.0 as bigint),cast(11.0 as bigint)),(cast('2019-01-26' as date),cast(7354.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-20' as date),cast(7430.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-14' as date),cast(5941.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-19' as date),cast(2846.0 as bigint),cast(22.0 as bigint),cast(3.0 as bigint)),(cast('2019-02-09' as date),cast(5733.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-27' as date),cast(5517.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2019-10-14' as date),cast(1140.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-24' as date),cast(7450.0 as bigint),cast(21.0 as bigint),cast(4.0 as bigint)),(cast('2019-03-21' as date),cast(3220.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-12' as date),cast(6011.0 as bigint),cast(9.0 as bigint),cast(4.0 as bigint)),(cast('2018-09-21' as date),cast(3234.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-13' as date),cast(4597.0 as bigint),cast(3.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-09' as date),cast(1737.0 as bigint),cast(1.0 as bigint),cast(8.0 as bigint)),(cast('2018-10-05' as date),cast(5849.0 as bigint),cast(26.0 as bigint),cast(5.0 as bigint)),(cast('2019-12-07' as date),cast(6668.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-01' as date),cast(4568.0 as bigint),cast(13.0 as bigint),cast(138.0 as bigint)),(cast('2019-08-03' as date),cast(5823.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-15' as date),cast(7138.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-29' as date),cast(6850.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-30' as date),cast(4323.0 as bigint),cast(4.0 as bigint),cast(7.0 as bigint)),(cast('2018-11-22' as date),cast(3923.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-26' as date),cast(4601.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-08' as date),cast(1958.0 as bigint),cast(17.0 as bigint),cast(3.0 as bigint)),(cast('2018-11-11' as date),cast(6295.0 as bigint),cast(3.0 as bigint),cast(84.0 as bigint)),(cast('2018-11-01' as date),cast(1744.0 as bigint),cast(13.0 as bigint),cast(4.0 as bigint)),(cast('2019-02-15' as date),cast(957.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2018-08-10' as date),cast(6608.0 as bigint),cast(22.0 as bigint),cast(5.0 as bigint)),(cast('2019-11-04' as date),cast(7198.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-03' as date),cast(3161.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-12' as date),cast(3034.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-21' as date),cast(594.0 as bigint),cast(22.0 as bigint),cast(13.0 as bigint)),(cast('2019-05-31' as date),cast(7561.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-29' as date),cast(4065.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-11' as date),cast(6091.0 as bigint),cast(25.0 as bigint),cast(40.0 as bigint)),(cast('2018-09-01' as date),cast(7399.0 as bigint),cast(0.0 as bigint),cast(39.0 as bigint)),(cast('2018-09-05' as date),cast(6556.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-08' as date),cast(564.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-05' as date),cast(6976.0 as bigint),cast(22.0 as bigint),cast(19.0 as bigint)),(cast('2019-05-21' as date),cast(5626.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-12' as date),cast(763.0 as bigint),cast(26.0 as bigint),cast(25.0 as bigint)),(cast('2019-10-29' as date),cast(2306.0 as bigint),cast(14.0 as bigint),cast(9.0 as bigint)),(cast('2019-02-27' as date),cast(6937.0 as bigint),cast(13.0 as bigint),cast(14.0 as bigint)),(cast('2019-04-22' as date),cast(14.0 as bigint),cast(2.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-07' as date),cast(4419.0 as bigint),cast(27.0 as bigint),cast(8.0 as bigint)),(cast('2018-10-28' as date),cast(5687.0 as bigint),cast(13.0 as bigint),cast(15.0 as bigint)),(cast('2019-01-26' as date),cast(7025.0 as bigint),cast(14.0 as bigint),cast(56.0 as bigint)),(cast('2018-09-18' as date),cast(5266.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-01' as date),cast(3140.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-01' as date),cast(6599.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-25' as date),cast(3042.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-08' as date),cast(6290.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-19' as date),cast(3761.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-05' as date),cast(6543.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-29' as date),cast(146.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2019-03-19' as date),cast(7429.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-18' as date),cast(687.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-01' as date),cast(6937.0 as bigint),cast(13.0 as bigint),cast(38.0 as bigint)),(cast('2018-10-31' as date),cast(1647.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-24' as date),cast(3051.0 as bigint),cast(7.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-31' as date),cast(5544.0 as bigint),cast(25.0 as bigint),cast(3.0 as bigint)),(cast('2019-09-18' as date),cast(779.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-25' as date),cast(6215.0 as bigint),cast(22.0 as bigint),cast(8.0 as bigint)),(cast('2018-08-31' as date),cast(4867.0 as bigint),cast(9.0 as bigint),cast(5.0 as bigint)),(cast('2018-12-05' as date),cast(4038.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-27' as date),cast(6264.0 as bigint),cast(25.0 as bigint),cast(11.0 as bigint)),(cast('2019-03-04' as date),cast(1503.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-02' as date),cast(6293.0 as bigint),cast(14.0 as bigint),cast(32.0 as bigint)),(cast('2019-11-11' as date),cast(4068.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2019-11-17' as date),cast(4111.0 as bigint),cast(18.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-08' as date),cast(6483.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-24' as date),cast(3837.0 as bigint),cast(25.0 as bigint),cast(6.0 as bigint)),(cast('2018-10-06' as date),cast(5957.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-09' as date),cast(4981.0 as bigint),cast(22.0 as bigint),cast(3.0 as bigint)),(cast('2019-02-28' as date),cast(212.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-29' as date),cast(1715.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-13' as date),cast(2242.0 as bigint),cast(8.0 as bigint),cast(4.0 as bigint)),(cast('2019-04-06' as date),cast(2154.0 as bigint),cast(26.0 as bigint),cast(4.0 as bigint)),(cast('2019-06-18' as date),cast(4530.0 as bigint),cast(26.0 as bigint),cast(108.0 as bigint)),(cast('2018-12-16' as date),cast(3799.0 as bigint),cast(20.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-22' as date),cast(1917.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-18' as date),cast(7419.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-26' as date),cast(2271.0 as bigint),cast(3.0 as bigint),cast(60.0 as bigint)),(cast('2019-06-26' as date),cast(523.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-01' as date),cast(7294.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-19' as date),cast(6065.0 as bigint),cast(18.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-10' as date),cast(3582.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-03' as date),cast(7567.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-06' as date),cast(1160.0 as bigint),cast(13.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-23' as date),cast(2669.0 as bigint),cast(25.0 as bigint),cast(20.0 as bigint)),(cast('2018-11-25' as date),cast(6806.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-16' as date),cast(2393.0 as bigint),cast(27.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-02' as date),cast(5187.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2019-11-12' as date),cast(468.0 as bigint),cast(0.0 as bigint),cast(5.0 as bigint)),(cast('2018-10-21' as date),cast(7099.0 as bigint),cast(26.0 as bigint),cast(4.0 as bigint)),(cast('2019-01-04' as date),cast(3667.0 as bigint),cast(13.0 as bigint),cast(11.0 as bigint)),(cast('2019-07-06' as date),cast(2247.0 as bigint),cast(16.0 as bigint),cast(9.0 as bigint)),(cast('2019-06-05' as date),cast(5004.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2018-11-21' as date),cast(3916.0 as bigint),cast(27.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-28' as date),cast(128.0 as bigint),cast(12.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-13' as date),cast(6201.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2019-02-10' as date),cast(5290.0 as bigint),cast(3.0 as bigint),cast(8.0 as bigint)),(cast('2018-10-14' as date),cast(4269.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-07' as date),cast(4659.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2018-07-26' as date),cast(1667.0 as bigint),cast(25.0 as bigint),cast(9.0 as bigint)),(cast('2018-11-02' as date),cast(888.0 as bigint),cast(20.0 as bigint),cast(8.0 as bigint)),(cast('2019-07-24' as date),cast(1584.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2018-10-09' as date),cast(2639.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-14' as date),cast(5965.0 as bigint),cast(13.0 as bigint),cast(10.0 as bigint)),(cast('2019-04-01' as date),cast(6212.0 as bigint),cast(7.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-13' as date),cast(1944.0 as bigint),cast(11.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-16' as date),cast(498.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-07' as date),cast(2879.0 as bigint),cast(3.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-16' as date),cast(2415.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-08' as date),cast(7556.0 as bigint),cast(7.0 as bigint),cast(5.0 as bigint)),(cast('2019-10-20' as date),cast(5794.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-20' as date),cast(1932.0 as bigint),cast(18.0 as bigint),cast(6.0 as bigint)),(cast('2019-11-07' as date),cast(6531.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-15' as date),cast(4478.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-22' as date),cast(2607.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-23' as date),cast(2598.0 as bigint),cast(0.0 as bigint),cast(6.0 as bigint)),(cast('2019-08-15' as date),cast(5143.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-10' as date),cast(3081.0 as bigint),cast(30.0 as bigint),cast(5.0 as bigint)),(cast('2018-12-21' as date),cast(1557.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-20' as date),cast(1445.0 as bigint),cast(9.0 as bigint),cast(60.0 as bigint)),(cast('2018-12-23' as date),cast(1365.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-24' as date),cast(668.0 as bigint),cast(2.0 as bigint),cast(3.0 as bigint)),(cast('2019-05-27' as date),cast(7585.0 as bigint),cast(27.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-06' as date),cast(1673.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-05' as date),cast(709.0 as bigint),cast(16.0 as bigint),cast(220.0 as bigint)),(cast('2019-11-10' as date),cast(7318.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-07-15' as date),cast(3627.0 as bigint),cast(13.0 as bigint),cast(21.0 as bigint)),(cast('2019-11-11' as date),cast(888.0 as bigint),cast(20.0 as bigint),cast(44.0 as bigint)),(cast('2019-06-10' as date),cast(5728.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-18' as date),cast(6910.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-01' as date),cast(6632.0 as bigint),cast(22.0 as bigint),cast(5.0 as bigint)),(cast('2018-08-06' as date),cast(2490.0 as bigint),cast(7.0 as bigint),cast(9.0 as bigint)),(cast('2019-01-12' as date),cast(920.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-31' as date),cast(4984.0 as bigint),cast(25.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-18' as date),cast(6430.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-10' as date),cast(1603.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-21' as date),cast(6174.0 as bigint),cast(3.0 as bigint),cast(12.0 as bigint)),(cast('2018-11-30' as date),cast(5618.0 as bigint),cast(21.0 as bigint),cast(13.0 as bigint)),(cast('2019-05-03' as date),cast(2323.0 as bigint),cast(25.0 as bigint),cast(122.0 as bigint)),(cast('2019-07-07' as date),cast(4457.0 as bigint),cast(22.0 as bigint),cast(30.0 as bigint)),(cast('2018-08-30' as date),cast(7011.0 as bigint),cast(9.0 as bigint),cast(6.0 as bigint)),(cast('2019-11-11' as date),cast(5848.0 as bigint),cast(13.0 as bigint),cast(4.0 as bigint)),(cast('2019-01-03' as date),cast(2306.0 as bigint),cast(14.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-23' as date),cast(6534.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2019-10-31' as date),cast(6215.0 as bigint),cast(22.0 as bigint),cast(7.0 as bigint)),(cast('2019-04-16' as date),cast(2800.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-12' as date),cast(5058.0 as bigint),cast(2.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-25' as date),cast(1467.0 as bigint),cast(22.0 as bigint),cast(90.0 as bigint)),(cast('2019-07-26' as date),cast(6850.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-01' as date),cast(3913.0 as bigint),cast(13.0 as bigint),cast(7.0 as bigint)),(cast('2018-07-13' as date),cast(3454.0 as bigint),cast(14.0 as bigint),cast(8.0 as bigint)),(cast('2019-11-30' as date),cast(5117.0 as bigint),cast(27.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-30' as date),cast(4990.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-09' as date),cast(408.0 as bigint),cast(9.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-10' as date),cast(6095.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-17' as date),cast(2897.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-05' as date),cast(6845.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-23' as date),cast(1479.0 as bigint),cast(16.0 as bigint),cast(3.0 as bigint)),(cast('2019-08-17' as date),cast(2459.0 as bigint),cast(0.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-27' as date),cast(5968.0 as bigint),cast(13.0 as bigint),cast(11.0 as bigint)),(cast('2019-08-18' as date),cast(704.0 as bigint),cast(13.0 as bigint),cast(10.0 as bigint)),(cast('2018-12-23' as date),cast(3833.0 as bigint),cast(26.0 as bigint),cast(212.0 as bigint)),(cast('2018-12-13' as date),cast(2235.0 as bigint),cast(16.0 as bigint),cast(14.0 as bigint)),(cast('2019-07-31' as date),cast(6174.0 as bigint),cast(3.0 as bigint),cast(4.0 as bigint)),(cast('2018-11-07' as date),cast(702.0 as bigint),cast(6.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-12' as date),cast(7425.0 as bigint),cast(22.0 as bigint),cast(9.0 as bigint)),(cast('2019-02-08' as date),cast(2331.0 as bigint),cast(26.0 as bigint),cast(69.0 as bigint)),(cast('2019-08-11' as date),cast(582.0 as bigint),cast(26.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-07' as date),cast(3076.0 as bigint),cast(18.0 as bigint),cast(11.0 as bigint)),(cast('2019-11-28' as date),cast(7427.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-21' as date),cast(888.0 as bigint),cast(20.0 as bigint),cast(6.0 as bigint)),(cast('2019-07-19' as date),cast(5371.0 as bigint),cast(22.0 as bigint),cast(8.0 as bigint)),(cast('2018-11-03' as date),cast(3635.0 as bigint),cast(16.0 as bigint),cast(46.0 as bigint)),(cast('2019-02-02' as date),cast(3741.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2019-11-02' as date),cast(6369.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-30' as date),cast(4590.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-31' as date),cast(5843.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-19' as date),cast(5448.0 as bigint),cast(1.0 as bigint),cast(12.0 as bigint)),(cast('2019-08-17' as date),cast(2823.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-26' as date),cast(2958.0 as bigint),cast(21.0 as bigint),cast(5.0 as bigint)),(cast('2019-07-12' as date),cast(5393.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-17' as date),cast(4392.0 as bigint),cast(26.0 as bigint),cast(8.0 as bigint)),(cast('2018-07-23' as date),cast(154.0 as bigint),cast(26.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-01' as date),cast(7382.0 as bigint),cast(30.0 as bigint),cast(36.0 as bigint)),(cast('2018-12-06' as date),cast(586.0 as bigint),cast(28.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-17' as date),cast(630.0 as bigint),cast(10.0 as bigint),cast(12.0 as bigint)),(cast('2018-10-23' as date),cast(5361.0 as bigint),cast(28.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-09' as date),cast(5296.0 as bigint),cast(0.0 as bigint),cast(30.0 as bigint)),(cast('2018-10-03' as date),cast(3691.0 as bigint),cast(17.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-28' as date),cast(6339.0 as bigint),cast(26.0 as bigint),cast(7.0 as bigint)),(cast('2019-07-13' as date),cast(3576.0 as bigint),cast(25.0 as bigint),cast(85.0 as bigint)),(cast('2019-11-17' as date),cast(7367.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-04' as date),cast(995.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-18' as date),cast(5371.0 as bigint),cast(22.0 as bigint),cast(17.0 as bigint)),(cast('2019-06-25' as date),cast(1187.0 as bigint),cast(2.0 as bigint),cast(45.0 as bigint)),(cast('2018-11-03' as date),cast(2430.0 as bigint),cast(23.0 as bigint),cast(8.0 as bigint)),(cast('2019-03-28' as date),cast(1719.0 as bigint),cast(2.0 as bigint),cast(79.0 as bigint)),(cast('2019-06-12' as date),cast(12.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-13' as date),cast(6438.0 as bigint),cast(24.0 as bigint),cast(8.0 as bigint)),(cast('2019-12-08' as date),cast(3659.0 as bigint),cast(20.0 as bigint),cast(4.0 as bigint)),(cast('2019-02-15' as date),cast(6634.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2019-10-20' as date),cast(3271.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-06' as date),cast(6941.0 as bigint),cast(30.0 as bigint),cast(9.0 as bigint)),(cast('2019-03-22' as date),cast(1363.0 as bigint),cast(20.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-27' as date),cast(7239.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-07' as date),cast(4996.0 as bigint),cast(5.0 as bigint),cast(6.0 as bigint)),(cast('2018-07-21' as date),cast(868.0 as bigint),cast(18.0 as bigint),cast(25.0 as bigint)),(cast('2019-08-05' as date),cast(2864.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-24' as date),cast(7384.0 as bigint),cast(5.0 as bigint),cast(9.0 as bigint)),(cast('2019-03-25' as date),cast(4691.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-22' as date),cast(944.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-05' as date),cast(2807.0 as bigint),cast(26.0 as bigint),cast(24.0 as bigint)),(cast('2019-04-22' as date),cast(6933.0 as bigint),cast(25.0 as bigint),cast(43.0 as bigint)),(cast('2019-09-18' as date),cast(287.0 as bigint),cast(6.0 as bigint),cast(4.0 as bigint)),(cast('2019-03-14' as date),cast(3047.0 as bigint),cast(4.0 as bigint),cast(4.0 as bigint)),(cast('2019-06-20' as date),cast(652.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2019-01-11' as date),cast(4445.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-04' as date),cast(6695.0 as bigint),cast(9.0 as bigint),cast(5.0 as bigint)),(cast('2018-07-27' as date),cast(398.0 as bigint),cast(22.0 as bigint),cast(8.0 as bigint)),(cast('2019-04-27' as date),cast(2736.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2018-07-17' as date),cast(2430.0 as bigint),cast(23.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-15' as date),cast(5407.0 as bigint),cast(13.0 as bigint),cast(68.0 as bigint)),(cast('2019-11-23' as date),cast(4191.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-23' as date),cast(5284.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-29' as date),cast(2837.0 as bigint),cast(18.0 as bigint),cast(131.0 as bigint)),(cast('2019-11-17' as date),cast(5250.0 as bigint),cast(3.0 as bigint),cast(13.0 as bigint)),(cast('2018-07-23' as date),cast(2190.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2019-02-14' as date),cast(4627.0 as bigint),cast(26.0 as bigint),cast(5.0 as bigint)),(cast('2019-04-03' as date),cast(4635.0 as bigint),cast(22.0 as bigint),cast(5.0 as bigint)),(cast('2019-02-27' as date),cast(5363.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-02' as date),cast(4457.0 as bigint),cast(22.0 as bigint),cast(80.0 as bigint)),(cast('2019-08-17' as date),cast(6253.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-11' as date),cast(3524.0 as bigint),cast(25.0 as bigint),cast(99.0 as bigint)),(cast('2019-10-10' as date),cast(2232.0 as bigint),cast(18.0 as bigint),cast(23.0 as bigint)),(cast('2018-12-28' as date),cast(383.0 as bigint),cast(25.0 as bigint),cast(15.0 as bigint)),(cast('2019-07-09' as date),cast(6128.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-04' as date),cast(2706.0 as bigint),cast(9.0 as bigint),cast(8.0 as bigint)),(cast('2019-08-11' as date),cast(7430.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-12' as date),cast(4030.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-06' as date),cast(4809.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-18' as date),cast(4594.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2019-01-20' as date),cast(1811.0 as bigint),cast(25.0 as bigint),cast(6.0 as bigint)),(cast('2019-07-13' as date),cast(2465.0 as bigint),cast(29.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-01' as date),cast(7331.0 as bigint),cast(17.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-05' as date),cast(4018.0 as bigint),cast(13.0 as bigint),cast(6.0 as bigint)),(cast('2019-07-23' as date),cast(4870.0 as bigint),cast(16.0 as bigint),cast(21.0 as bigint)),(cast('2018-11-03' as date),cast(1404.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-14' as date),cast(3241.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-20' as date),cast(5203.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-13' as date),cast(803.0 as bigint),cast(23.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-27' as date),cast(1307.0 as bigint),cast(1.0 as bigint),cast(7.0 as bigint)),(cast('2019-12-16' as date),cast(335.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-01' as date),cast(3679.0 as bigint),cast(6.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-30' as date),cast(2542.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-10' as date),cast(3800.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-26' as date),cast(7378.0 as bigint),cast(21.0 as bigint),cast(8.0 as bigint)),(cast('2019-08-12' as date),cast(393.0 as bigint),cast(3.0 as bigint),cast(85.0 as bigint)),(cast('2019-07-20' as date),cast(6933.0 as bigint),cast(25.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-26' as date),cast(2430.0 as bigint),cast(23.0 as bigint),cast(17.0 as bigint)),(cast('2018-11-01' as date),cast(4495.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-05' as date),cast(5848.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-30' as date),cast(7175.0 as bigint),cast(24.0 as bigint),cast(7.0 as bigint)),(cast('2019-04-30' as date),cast(7510.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2019-11-02' as date),cast(398.0 as bigint),cast(22.0 as bigint),cast(12.0 as bigint)),(cast('2019-10-25' as date),cast(1527.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-14' as date),cast(2897.0 as bigint),cast(26.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-14' as date),cast(5666.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-04' as date),cast(7223.0 as bigint),cast(2.0 as bigint),cast(15.0 as bigint)),(cast('2019-04-03' as date),cast(5314.0 as bigint),cast(11.0 as bigint),cast(7.0 as bigint)),(cast('2019-07-03' as date),cast(7368.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-05' as date),cast(5363.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-27' as date),cast(7577.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-09' as date),cast(6850.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-20' as date),cast(4413.0 as bigint),cast(3.0 as bigint),cast(7.0 as bigint)),(cast('2018-09-03' as date),cast(3107.0 as bigint),cast(9.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-18' as date),cast(3904.0 as bigint),cast(1.0 as bigint),cast(9.0 as bigint)),(cast('2019-12-07' as date),cast(1564.0 as bigint),cast(13.0 as bigint),cast(96.0 as bigint)),(cast('2018-08-02' as date),cast(1943.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-10' as date),cast(1533.0 as bigint),cast(18.0 as bigint),cast(82.0 as bigint)),(cast('2018-10-31' as date),cast(2714.0 as bigint),cast(28.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-29' as date),cast(4586.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-09' as date),cast(2502.0 as bigint),cast(13.0 as bigint),cast(5.0 as bigint)),(cast('2019-02-20' as date),cast(2945.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-12' as date),cast(3247.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2018-10-09' as date),cast(6803.0 as bigint),cast(19.0 as bigint),cast(23.0 as bigint)),(cast('2019-07-24' as date),cast(7148.0 as bigint),cast(16.0 as bigint),cast(9.0 as bigint)),(cast('2019-03-24' as date),cast(5031.0 as bigint),cast(0.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-18' as date),cast(4128.0 as bigint),cast(18.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-17' as date),cast(1828.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-22' as date),cast(133.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-18' as date),cast(5428.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-13' as date),cast(5073.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-20' as date),cast(7510.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-10' as date),cast(3965.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-25' as date),cast(2504.0 as bigint),cast(2.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-12' as date),cast(3315.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2019-08-05' as date),cast(7140.0 as bigint),cast(18.0 as bigint),cast(37.0 as bigint)),(cast('2019-03-08' as date),cast(2668.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-12' as date),cast(4908.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2018-10-31' as date),cast(1307.0 as bigint),cast(1.0 as bigint),cast(3.0 as bigint)),(cast('2019-07-13' as date),cast(2457.0 as bigint),cast(3.0 as bigint),cast(25.0 as bigint)),(cast('2019-01-25' as date),cast(1613.0 as bigint),cast(28.0 as bigint),cast(6.0 as bigint)),(cast('2018-09-01' as date),cast(2264.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-01' as date),cast(6386.0 as bigint),cast(2.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-26' as date),cast(6315.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-27' as date),cast(3995.0 as bigint),cast(18.0 as bigint),cast(31.0 as bigint)),(cast('2019-03-28' as date),cast(1658.0 as bigint),cast(16.0 as bigint),cast(27.0 as bigint)),(cast('2018-11-23' as date),cast(1073.0 as bigint),cast(2.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-01' as date),cast(1484.0 as bigint),cast(3.0 as bigint),cast(19.0 as bigint)),(cast('2018-12-27' as date),cast(1935.0 as bigint),cast(2.0 as bigint),cast(62.0 as bigint)),(cast('2019-07-07' as date),cast(6640.0 as bigint),cast(26.0 as bigint),cast(48.0 as bigint)),(cast('2018-12-04' as date),cast(219.0 as bigint),cast(3.0 as bigint),cast(3.0 as bigint)),(cast('2019-01-02' as date),cast(5371.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-07' as date),cast(6801.0 as bigint),cast(3.0 as bigint),cast(7.0 as bigint)),(cast('2018-09-06' as date),cast(6716.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-14' as date),cast(2654.0 as bigint),cast(11.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-19' as date),cast(6390.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-04' as date),cast(7138.0 as bigint),cast(28.0 as bigint),cast(3.0 as bigint)),(cast('2019-02-08' as date),cast(1973.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-30' as date),cast(1931.0 as bigint),cast(0.0 as bigint),cast(57.0 as bigint)),(cast('2019-08-02' as date),cast(2051.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-19' as date),cast(1047.0 as bigint),cast(30.0 as bigint),cast(5.0 as bigint)),(cast('2019-06-21' as date),cast(4587.0 as bigint),cast(9.0 as bigint),cast(22.0 as bigint)),(cast('2018-08-07' as date),cast(5278.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-02' as date),cast(7208.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-11' as date),cast(4108.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-16' as date),cast(2999.0 as bigint),cast(7.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-23' as date),cast(4342.0 as bigint),cast(22.0 as bigint),cast(29.0 as bigint)),(cast('2019-07-26' as date),cast(4439.0 as bigint),cast(2.0 as bigint),cast(24.0 as bigint)),(cast('2018-07-17' as date),cast(2568.0 as bigint),cast(22.0 as bigint),cast(8.0 as bigint)),(cast('2018-11-10' as date),cast(6309.0 as bigint),cast(29.0 as bigint),cast(11.0 as bigint)),(cast('2019-11-17' as date),cast(88.0 as bigint),cast(24.0 as bigint),cast(13.0 as bigint)),(cast('2018-08-04' as date),cast(5389.0 as bigint),cast(24.0 as bigint),cast(2.0 as bigint)),(cast('2019-01-01' as date),cast(6533.0 as bigint),cast(17.0 as bigint),cast(5.0 as bigint)),(cast('2019-05-10' as date),cast(2137.0 as bigint),cast(2.0 as bigint),cast(10.0 as bigint)),(cast('2018-08-02' as date),cast(2238.0 as bigint),cast(22.0 as bigint),cast(5.0 as bigint)),(cast('2018-08-18' as date),cast(6492.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-24' as date),cast(1848.0 as bigint),cast(14.0 as bigint),cast(120.0 as bigint)),(cast('2019-06-21' as date),cast(7350.0 as bigint),cast(16.0 as bigint),cast(31.0 as bigint)),(cast('2018-11-05' as date),cast(5738.0 as bigint),cast(13.0 as bigint),cast(42.0 as bigint)),(cast('2018-07-20' as date),cast(7334.0 as bigint),cast(21.0 as bigint),cast(9.0 as bigint)),(cast('2019-07-12' as date),cast(5250.0 as bigint),cast(3.0 as bigint),cast(9.0 as bigint)),(cast('2019-11-04' as date),cast(1875.0 as bigint),cast(13.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-07' as date),cast(1700.0 as bigint),cast(8.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-30' as date),cast(954.0 as bigint),cast(2.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-25' as date),cast(5926.0 as bigint),cast(13.0 as bigint),cast(24.0 as bigint)),(cast('2018-09-10' as date),cast(2220.0 as bigint),cast(2.0 as bigint),cast(99.0 as bigint)),(cast('2019-10-14' as date),cast(7011.0 as bigint),cast(9.0 as bigint),cast(24.0 as bigint)),(cast('2018-12-06' as date),cast(6740.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2019-05-13' as date),cast(1980.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-17' as date),cast(5975.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-11' as date),cast(6093.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-12' as date),cast(754.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-28' as date),cast(1307.0 as bigint),cast(1.0 as bigint),cast(9.0 as bigint)),(cast('2018-11-23' as date),cast(3197.0 as bigint),cast(17.0 as bigint),cast(15.0 as bigint)),(cast('2019-04-17' as date),cast(1233.0 as bigint),cast(16.0 as bigint),cast(18.0 as bigint)),(cast('2019-11-08' as date),cast(5282.0 as bigint),cast(4.0 as bigint),cast(6.0 as bigint)),(cast('2018-09-08' as date),cast(547.0 as bigint),cast(4.0 as bigint),cast(19.0 as bigint)),(cast('2019-06-11' as date),cast(5436.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-01' as date),cast(888.0 as bigint),cast(20.0 as bigint),cast(14.0 as bigint)),(cast('2019-04-18' as date),cast(5320.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-14' as date),cast(460.0 as bigint),cast(18.0 as bigint),cast(4.0 as bigint)),(cast('2018-11-13' as date),cast(2845.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-19' as date),cast(2426.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-03' as date),cast(3783.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-17' as date),cast(7526.0 as bigint),cast(14.0 as bigint),cast(12.0 as bigint)),(cast('2019-06-22' as date),cast(354.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-02' as date),cast(6399.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-23' as date),cast(528.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-08' as date),cast(5486.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-18' as date),cast(1406.0 as bigint),cast(14.0 as bigint),cast(26.0 as bigint)),(cast('2018-12-25' as date),cast(27.0 as bigint),cast(10.0 as bigint),cast(41.0 as bigint)),(cast('2019-02-03' as date),cast(5022.0 as bigint),cast(2.0 as bigint),cast(43.0 as bigint)),(cast('2019-02-20' as date),cast(438.0 as bigint),cast(22.0 as bigint),cast(28.0 as bigint)),(cast('2018-10-28' as date),cast(3034.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-12' as date),cast(5780.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-01' as date),cast(4146.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-08' as date),cast(1062.0 as bigint),cast(13.0 as bigint),cast(22.0 as bigint)),(cast('2018-10-23' as date),cast(785.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-08' as date),cast(255.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-06' as date),cast(5521.0 as bigint),cast(7.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-07' as date),cast(487.0 as bigint),cast(26.0 as bigint),cast(14.0 as bigint)),(cast('2019-03-03' as date),cast(1503.0 as bigint),cast(21.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-15' as date),cast(6371.0 as bigint),cast(7.0 as bigint),cast(22.0 as bigint))
      ' with 4a889cd8-b191-4aab-a0f5-385bfefc344f
2025-08-06 09:07:04,657 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 4a889cd8-b191-4aab-a0f5-385bfefc344f
2025-08-06 09:07:05,104 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 3: get_database: global_temp
2025-08-06 09:07:05,105 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore.audit - ugi=airflow	ip=unknown-ip-addr	cmd=get_database: global_temp	
2025-08-06 09:07:05,119 [HiveServer2-Background-Pool: Thread-120] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.jdbc.timeout does not exist
2025-08-06 09:07:05,120 [HiveServer2-Background-Pool: Thread-120] WARN  org.apache.hadoop.hive.conf.HiveConf - HiveConf of name hive.stats.retries.wait does not exist
2025-08-06 09:07:05,120 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.hadoop.hive.metastore.HiveMetaStore - 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-06 09:07:05,121 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.hadoop.hive.metastore.ObjectStore - ObjectStore, initialize called
2025-08-06 09:07:05,133 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.hadoop.hive.metastore.MetaStoreDirectSql - Using direct SQL, underlying DB is DERBY
2025-08-06 09:07:05,133 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.hadoop.hive.metastore.ObjectStore - Initialized ObjectStore
2025-08-06 09:07:05,137 [HiveServer2-Background-Pool: Thread-120] WARN  org.apache.hadoop.hive.metastore.ObjectStore - Failed to get database global_temp, returning NoSuchObjectException
2025-08-06 09:07:05,548 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.541015 ms
2025-08-06 09:07:05,679 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 127.2 MiB)
2025-08-06 09:07:05,726 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 127.1 MiB)
2025-08-06 09:07:05,729 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on c15f4bd07d87:41285 (size: 29.5 KiB, free: 127.2 MiB)
2025-08-06 09:07:05,736 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.spark.SparkContext - Created broadcast 0 from broadcast at SparkWrite.java:193
2025-08-06 09:07:05,739 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.spark.sql.execution.datasources.v2.AppendDataExec - Start processing data source write support: IcebergBatchWrite(table=hive_catalog.default.orders, format=PARQUET). The input RDD has 2 partitions.
2025-08-06 09:07:05,766 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.spark.SparkContext - Starting job: run at AccessController.java:712
2025-08-06 09:07:05,783 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (run at AccessController.java:712) with 2 output partitions
2025-08-06 09:07:05,784 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (run at AccessController.java:712)
2025-08-06 09:07:05,784 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-08-06 09:07:05,785 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2025-08-06 09:07:05,790 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[1] at run at AccessController.java:712), which has no missing parents
2025-08-06 09:07:05,832 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.0 KiB, free 127.1 MiB)
2025-08-06 09:07:05,835 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 127.1 MiB)
2025-08-06 09:07:05,836 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on c15f4bd07d87:41285 (size: 4.5 KiB, free: 127.2 MiB)
2025-08-06 09:07:05,837 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1535
2025-08-06 09:07:05,852 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at run at AccessController.java:712) (first 15 tasks are for partitions Vector(0, 1))
2025-08-06 09:07:05,854 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 2 tasks resource profile 0
2025-08-06 09:07:06,850 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor added: app-20250806090436-0000/1 on worker-20250806090434-172.18.0.11-33083 (172.18.0.11:33083) with 2 core(s)
2025-08-06 09:07:06,851 [spark-dynamic-executor-allocation] INFO  org.apache.spark.ExecutorAllocationManager - Requesting 1 new executor because tasks are backlogged (new desired total will be 1 for resource profile id: 0)
2025-08-06 09:07:06,851 [dispatcher-event-loop-6] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Granted executor ID app-20250806090436-0000/1 on hostPort 172.18.0.11:33083 with 2 core(s), 1024.0 MiB RAM
2025-08-06 09:07:06,984 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor updated: app-20250806090436-0000/1 is now RUNNING
2025-08-06 09:07:10,300 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.11:50454) with ID 1,  ResourceProfileId 0
2025-08-06 09:07:10,301 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - New executor 1 has registered (new total is 1)
2025-08-06 09:07:10,394 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 172.18.0.11:39111 with 434.4 MiB RAM, BlockManagerId(1, 172.18.0.11, 39111, None)
2025-08-06 09:07:10,460 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (172.18.0.11, executor 1, partition 0, PROCESS_LOCAL, 36006 bytes) 
2025-08-06 09:07:10,466 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1) (172.18.0.11, executor 1, partition 1, PROCESS_LOCAL, 36006 bytes) 
2025-08-06 09:07:10,748 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on 172.18.0.11:39111 (size: 4.5 KiB, free: 434.4 MiB)
2025-08-06 09:07:11,014 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 172.18.0.11:39111 (size: 29.5 KiB, free: 434.4 MiB)
2025-08-06 09:07:13,889 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 3425 ms on 172.18.0.11 (executor 1) (1/2)
2025-08-06 09:07:13,891 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 3444 ms on 172.18.0.11 (executor 1) (2/2)
2025-08-06 09:07:13,892 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2025-08-06 09:07:13,897 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (run at AccessController.java:712) finished in 8.093 s
2025-08-06 09:07:13,900 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
2025-08-06 09:07:13,900 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
2025-08-06 09:07:13,902 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.spark.scheduler.DAGScheduler - Job 0 finished: run at AccessController.java:712, took 8.135603 s
2025-08-06 09:07:13,905 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.spark.sql.execution.datasources.v2.AppendDataExec - Data source write support IcebergBatchWrite(table=hive_catalog.default.orders, format=PARQUET) is committing.
2025-08-06 09:07:13,940 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.iceberg.spark.source.SparkWrite - Committing append with 2 new data files to table hive_catalog.default.orders
2025-08-06 09:07:14,521 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.iceberg.hive.HiveTableOperations - Committed to table hive_catalog.default.orders with the new metadata location s3a://iceberg-warehouse/orders/metadata/00001-8d716bb6-31aa-4998-b64e-2ed4d09b6df3.metadata.json
2025-08-06 09:07:14,522 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table hive_catalog.default.orders in 225 ms
2025-08-06 09:07:14,522 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.iceberg.SnapshotProducer - Committed snapshot 3352891837780608816 (MergeAppend)
2025-08-06 09:07:14,620 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/orders/metadata/00001-8d716bb6-31aa-4998-b64e-2ed4d09b6df3.metadata.json
2025-08-06 09:07:14,655 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.iceberg.metrics.LoggingMetricsReporter - Received metrics report: CommitReport{tableName=hive_catalog.default.orders, snapshotId=3352891837780608816, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.643005958S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=2}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=2}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, addedDVs=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, removedDVs=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=1000}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=1000}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=9504}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=9504}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}, manifestsCreated=null, manifestsReplaced=null, manifestsKept=null, manifestEntriesProcessed=null}, metadata={engine-version=3.4.1, app-id=app-20250806090436-0000, engine-name=spark, iceberg-version=Apache Iceberg 1.9.2 (commit 071d5606bc6199a0be9b3f274ec7fbf111d88821)}}
2025-08-06 09:07:14,704 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.iceberg.spark.source.SparkWrite - Committed in 763 ms
2025-08-06 09:07:14,705 [HiveServer2-Background-Pool: Thread-120] INFO  org.apache.spark.sql.execution.datasources.v2.AppendDataExec - Data source write support IcebergBatchWrite(table=hive_catalog.default.orders, format=PARQUET) committed.
2025-08-06 09:07:14,752 [HiveServer2-Background-Pool: Thread-120] WARN  org.apache.spark.sql.catalyst.util.package - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
2025-08-06 09:07:14,806 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 4a889cd8-b191-4aab-a0f5-385bfefc344f
2025-08-06 09:07:14,806 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 4a889cd8-b191-4aab-a0f5-385bfefc344f
2025-08-06 09:07:14,808 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 7361d1be-7379-4d94-b5d9-ffde7f58468d
2025-08-06 09:07:14,808 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 7361d1be-7379-4d94-b5d9-ffde7f58468d
2025-08-06 09:07:14,816 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 09:07:14,817 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 09:07:14,818 [HiveServer2-Handler-Pool: Thread-99] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 09:07:14,819 [HiveServer2-Handler-Pool: Thread-99] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:07:14,830 [HiveServer2-Handler-Pool: Thread-136] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:07:14,834 [HiveServer2-Handler-Pool: Thread-136] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/2f446716-97aa-4612-9425-ccfd03afcedc
2025-08-06 09:07:14,839 [HiveServer2-Handler-Pool: Thread-136] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with 49cdf7d7-28c5-476c-adf7-f0c7b906beb1
2025-08-06 09:07:14,840 [HiveServer2-Handler-Pool: Thread-136] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 49cdf7d7-28c5-476c-adf7-f0c7b906beb1
2025-08-06 09:07:14,887 [HiveServer2-Handler-Pool: Thread-136] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 49cdf7d7-28c5-476c-adf7-f0c7b906beb1
2025-08-06 09:07:14,887 [HiveServer2-Handler-Pool: Thread-136] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 49cdf7d7-28c5-476c-adf7-f0c7b906beb1
2025-08-06 09:07:14,896 [HiveServer2-Handler-Pool: Thread-136] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:07:20,452 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:07:20,455 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/91e6f82a-da0d-41eb-ae31-f3bf7bf3dca0
2025-08-06 09:07:20,459 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with ba9b1a45-beb7-4d94-8fff-c4685696673a
2025-08-06 09:07:20,459 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with ba9b1a45-beb7-4d94-8fff-c4685696673a
2025-08-06 09:07:20,487 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group ba9b1a45-beb7-4d94-8fff-c4685696673a
2025-08-06 09:07:20,487 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with ba9b1a45-beb7-4d94-8fff-c4685696673a
2025-08-06 09:07:20,491 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_schemas"} */

    show databases
  ' with fa525799-b9d2-4ed6-8c2d-451a924d9401
2025-08-06 09:07:20,492 [HiveServer2-Background-Pool: Thread-138] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with fa525799-b9d2-4ed6-8c2d-451a924d9401
2025-08-06 09:07:20,532 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<namespace: STRING>
2025-08-06 09:07:20,537 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group fa525799-b9d2-4ed6-8c2d-451a924d9401
2025-08-06 09:07:20,542 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with fa525799-b9d2-4ed6-8c2d-451a924d9401
2025-08-06 09:07:20,548 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:07:20,568 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:07:20,571 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/1dd077f2-0641-43bb-a95a-5cfefa7322fb
2025-08-06 09:07:20,576 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with e7ae2118-bfb4-4821-9e11-c9d43d1e7559
2025-08-06 09:07:20,577 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with e7ae2118-bfb4-4821-9e11-c9d43d1e7559
2025-08-06 09:07:20,612 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group e7ae2118-bfb4-4821-9e11-c9d43d1e7559
2025-08-06 09:07:20,613 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with e7ae2118-bfb4-4821-9e11-c9d43d1e7559
2025-08-06 09:07:20,619 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
show table extended in default like '*'
  ' with 64fb0e6f-ea3b-4947-818e-f61ce0a6ff3d
2025-08-06 09:07:20,622 [HiveServer2-Background-Pool: Thread-139] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 64fb0e6f-ea3b-4947-818e-f61ce0a6ff3d
2025-08-06 09:07:20,628 [HiveServer2-Background-Pool: Thread-139] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 64fb0e6f-ea3b-4947-818e-f61ce0a6ff3d
2025-08-06 09:07:20,629 [HiveServer2-Background-Pool: Thread-139] ERROR org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Error executing query with 64fb0e6f-ea3b-4947-818e-f61ce0a6ff3d, currentState RUNNING, 
org.apache.spark.sql.AnalysisException: SHOW TABLE EXTENDED is not supported for v2 tables.;
ShowTableExtended *, [namespace#58, tableName#59, isTemporary#60, information#61]
+- ResolvedNamespace org.apache.iceberg.spark.SparkCatalog@1f76ba12, [default]

	at org.apache.spark.sql.errors.QueryCompilationErrors$.commandUnsupportedInV2TableError(QueryCompilationErrors.scala:2035) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$1(CheckAnalysis.scala:224) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$1$adapted(CheckAnalysis.scala:163) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:295) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:163) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:160) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:188) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:156) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:146) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:188) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:211) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:202) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:202) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:201) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:98) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:640) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:630) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:671) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:651) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:226) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:165) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.17.jar:?]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:79) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:63) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:40) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:165) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:160) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at java.security.AccessController.doPrivileged(AccessController.java:712) ~[?:?]
	at javax.security.auth.Subject.doAs(Subject.java:439) ~[?:?]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:174) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:07:20,657 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
show tables in default like '*'
  ' with 4301a54e-4b1e-40a8-825c-078f1cf0565b
2025-08-06 09:07:20,658 [HiveServer2-Background-Pool: Thread-140] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 4301a54e-4b1e-40a8-825c-078f1cf0565b
2025-08-06 09:07:20,756 [HiveServer2-Background-Pool: Thread-140] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 17.782761 ms
2025-08-06 09:07:20,770 [HiveServer2-Background-Pool: Thread-140] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.717567 ms
2025-08-06 09:07:20,790 [HiveServer2-Background-Pool: Thread-140] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.028645 ms
2025-08-06 09:07:20,795 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<namespace: STRING, tableName: STRING, isTemporary: BOOLEAN>
2025-08-06 09:07:20,809 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
describe extended default.orders
  ' with c8371502-a355-4cd7-8730-d2cc38af4c0e
2025-08-06 09:07:20,810 [HiveServer2-Background-Pool: Thread-141] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with c8371502-a355-4cd7-8730-d2cc38af4c0e
2025-08-06 09:07:20,837 [HiveServer2-Background-Pool: Thread-141] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/orders/metadata/00001-8d716bb6-31aa-4998-b64e-2ed4d09b6df3.metadata.json
2025-08-06 09:07:20,840 [HiveServer2-Background-Pool: Thread-141] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 09:07:20,842 [HiveServer2-Background-Pool: Thread-141] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 09:07:20,843 [HiveServer2-Background-Pool: Thread-141] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 09:07:20,861 [HiveServer2-Background-Pool: Thread-141] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive_catalog.default.orders
2025-08-06 09:07:20,917 [HiveServer2-Background-Pool: Thread-141] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 18.592191 ms
2025-08-06 09:07:20,992 [HiveServer2-Background-Pool: Thread-141] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.241249 ms
2025-08-06 09:07:21,031 [HiveServer2-Background-Pool: Thread-141] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.631365 ms
2025-08-06 09:07:21,040 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<col_name: STRING COMMENT 'name of the column', data_type: STRING COMMENT 'data type of the column', comment: STRING COMMENT 'comment of the column'>
2025-08-06 09:07:21,049 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group c8371502-a355-4cd7-8730-d2cc38af4c0e
2025-08-06 09:07:21,050 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with c8371502-a355-4cd7-8730-d2cc38af4c0e
2025-08-06 09:07:21,051 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 4301a54e-4b1e-40a8-825c-078f1cf0565b
2025-08-06 09:07:21,051 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 4301a54e-4b1e-40a8-825c-078f1cf0565b
2025-08-06 09:07:21,051 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 64fb0e6f-ea3b-4947-818e-f61ce0a6ff3d
2025-08-06 09:07:21,052 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 64fb0e6f-ea3b-4947-818e-f61ce0a6ff3d
2025-08-06 09:07:21,054 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 09:07:21,055 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 09:07:21,055 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 09:07:21,056 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:07:21,105 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:07:21,108 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/95e195b4-42df-498b-bd40-55f824d9c351
2025-08-06 09:07:21,114 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with 2632d29a-056a-4f88-9121-4d7fd9847ef6
2025-08-06 09:07:21,114 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 2632d29a-056a-4f88-9121-4d7fd9847ef6
2025-08-06 09:07:21,140 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 2632d29a-056a-4f88-9121-4d7fd9847ef6
2025-08-06 09:07:21,141 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 2632d29a-056a-4f88-9121-4d7fd9847ef6
2025-08-06 09:07:21,143 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "node_id": "model.dag.orders_by_date"} */
drop table if exists default.orders_by_date' with bc930d41-51ca-4858-b7b8-30f388a0c665
2025-08-06 09:07:21,145 [HiveServer2-Background-Pool: Thread-144] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with bc930d41-51ca-4858-b7b8-30f388a0c665
2025-08-06 09:07:21,223 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "node_id": "model.dag.orders_by_date"} */

  
    
        create or replace table default.orders_by_date
      
      
    using iceberg
      
      
      
      
      
    location 's3a://iceberg-warehouse/output/orders/orders_by_date'
      

      as
      

SELECT
    date,
    COUNT(*) as order_count
FROM default.orders
WHERE date > '2018-01-01'
GROUP BY date
  ' with 242bd5a7-91e1-476b-b012-2796b01a6431
2025-08-06 09:07:21,225 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 242bd5a7-91e1-476b-b012-2796b01a6431
2025-08-06 09:07:21,281 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/orders/metadata/00001-8d716bb6-31aa-4998-b64e-2ed4d09b6df3.metadata.json
2025-08-06 09:07:21,285 [HiveServer2-Background-Pool: Thread-145] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 09:07:21,287 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 09:07:21,288 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 09:07:21,305 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive_catalog.default.orders
2025-08-06 09:07:21,495 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown - 
Pushing operators to hive_catalog.default.orders
Pushed Filters: date IS NOT NULL, date > 17532
Post-Scan Filters: isnotnull(date#109),(date#109 > 2018-01-01)
         
2025-08-06 09:07:21,541 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown - 
Output: date#109
         
2025-08-06 09:07:21,567 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.SnapshotScan - Scanning table hive_catalog.default.orders snapshot 3352891837780608816 created at 2025-08-06T09:07:14.287+00:00 with filter (date IS NOT NULL AND date > (5-digit-int))
2025-08-06 09:07:21,598 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.BaseDistributedDataScan - Planning file tasks locally for table hive_catalog.default.orders
2025-08-06 09:07:21,698 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.spark.source.SparkPartitioningAwareScan - Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.default.orders
2025-08-06 09:07:21,777 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 32.0 KiB, free 127.1 MiB)
2025-08-06 09:07:21,798 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 127.1 MiB)
2025-08-06 09:07:21,800 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on c15f4bd07d87:41285 (size: 29.6 KiB, free: 127.1 MiB)
2025-08-06 09:07:21,808 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.SparkContext - Created broadcast 2 from broadcast at SparkBatch.java:85
2025-08-06 09:07:21,864 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on c15f4bd07d87:41285 in memory (size: 4.5 KiB, free: 127.1 MiB)
2025-08-06 09:07:21,873 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_1_piece0 on 172.18.0.11:39111 in memory (size: 4.5 KiB, free: 434.4 MiB)
2025-08-06 09:07:21,886 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on c15f4bd07d87:41285 in memory (size: 29.5 KiB, free: 127.2 MiB)
2025-08-06 09:07:21,889 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_0_piece0 on 172.18.0.11:39111 in memory (size: 29.5 KiB, free: 434.4 MiB)
2025-08-06 09:07:21,892 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 127.1 MiB)
2025-08-06 09:07:21,896 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 127.1 MiB)
2025-08-06 09:07:21,897 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on c15f4bd07d87:41285 (size: 29.6 KiB, free: 127.1 MiB)
2025-08-06 09:07:21,898 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.SparkContext - Created broadcast 3 from broadcast at SparkBatch.java:85
2025-08-06 09:07:21,971 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table properties set at catalog level through catalog properties: {}
2025-08-06 09:07:21,976 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table properties enforced at catalog level through catalog properties: {}
2025-08-06 09:07:22,033 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.sql.execution.aggregate.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-08-06 09:07:22,155 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 66.674813 ms
2025-08-06 09:07:22,229 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 127.0 MiB)
2025-08-06 09:07:22,232 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 127.0 MiB)
2025-08-06 09:07:22,234 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on c15f4bd07d87:41285 (size: 29.3 KiB, free: 127.1 MiB)
2025-08-06 09:07:22,235 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.SparkContext - Created broadcast 4 from broadcast at SparkWrite.java:193
2025-08-06 09:07:22,236 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec - Start processing data source write support: IcebergBatchWrite(table=default.orders_by_date, format=PARQUET). The input RDD has 1 partitions.
2025-08-06 09:07:22,238 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.SparkContext - Starting job: run at AccessController.java:712
2025-08-06 09:07:22,239 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 1 (run at AccessController.java:712) with 1 output partitions
2025-08-06 09:07:22,240 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 1 (run at AccessController.java:712)
2025-08-06 09:07:22,240 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-08-06 09:07:22,240 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2025-08-06 09:07:22,241 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 1 (MapPartitionsRDD[4] at run at AccessController.java:712), which has no missing parents
2025-08-06 09:07:22,245 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 44.5 KiB, free 127.0 MiB)
2025-08-06 09:07:22,248 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 127.0 MiB)
2025-08-06 09:07:22,250 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on c15f4bd07d87:41285 (size: 18.9 KiB, free: 127.1 MiB)
2025-08-06 09:07:22,251 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 5 from broadcast at DAGScheduler.scala:1535
2025-08-06 09:07:22,252 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at run at AccessController.java:712) (first 15 tasks are for partitions Vector(0))
2025-08-06 09:07:22,253 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 1.0 with 1 tasks resource profile 0
2025-08-06 09:07:22,264 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 1.0 (TID 2) (172.18.0.11, executor 1, partition 0, PROCESS_LOCAL, 12779 bytes) 
2025-08-06 09:07:22,337 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_5_piece0 in memory on 172.18.0.11:39111 (size: 18.9 KiB, free: 434.4 MiB)
2025-08-06 09:07:22,854 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_4_piece0 in memory on 172.18.0.11:39111 (size: 29.3 KiB, free: 434.4 MiB)
2025-08-06 09:07:23,032 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_3_piece0 in memory on 172.18.0.11:39111 (size: 29.6 KiB, free: 434.3 MiB)
2025-08-06 09:07:23,708 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 1.0 (TID 2) in 1453 ms on 172.18.0.11 (executor 1) (1/1)
2025-08-06 09:07:23,709 [task-result-getter-2] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2025-08-06 09:07:23,710 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 1 (run at AccessController.java:712) finished in 1.468 s
2025-08-06 09:07:23,711 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
2025-08-06 09:07:23,711 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 1: Stage finished
2025-08-06 09:07:23,712 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.scheduler.DAGScheduler - Job 1 finished: run at AccessController.java:712, took 1.473384 s
2025-08-06 09:07:23,713 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec - Data source write support IcebergBatchWrite(table=default.orders_by_date, format=PARQUET) is committing.
2025-08-06 09:07:23,714 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.spark.source.SparkWrite - Committing append with 1 new data files to table default.orders_by_date
2025-08-06 09:07:23,801 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.SnapshotProducer - Committed snapshot 120886956826897363 (MergeAppend)
2025-08-06 09:07:23,813 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.metrics.LoggingMetricsReporter - Received metrics report: CommitReport{tableName=default.orders_by_date, snapshotId=120886956826897363, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.099226151S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=1}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=1}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, addedDVs=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, removedDVs=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=394}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=394}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=1840}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=1840}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}, manifestsCreated=null, manifestsReplaced=null, manifestsKept=null, manifestEntriesProcessed=null}, metadata={engine-version=3.4.1, app-id=app-20250806090436-0000, engine-name=spark, iceberg-version=Apache Iceberg 1.9.2 (commit 071d5606bc6199a0be9b3f274ec7fbf111d88821)}}
2025-08-06 09:07:23,814 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.spark.source.SparkWrite - Committed in 100 ms
2025-08-06 09:07:23,814 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec - Data source write support IcebergBatchWrite(table=default.orders_by_date, format=PARQUET) committed.
2025-08-06 09:07:23,898 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.hive.HiveTableOperations - Committed to table hive_catalog.default.orders_by_date with the new metadata location s3a://iceberg-warehouse/output/orders/orders_by_date/metadata/00000-29b320db-a5ec-4cf5-94d1-eb791d9ef335.metadata.json
2025-08-06 09:07:23,898 [HiveServer2-Background-Pool: Thread-145] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table hive_catalog.default.orders_by_date in 78 ms
2025-08-06 09:07:23,937 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 242bd5a7-91e1-476b-b012-2796b01a6431
2025-08-06 09:07:23,937 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 242bd5a7-91e1-476b-b012-2796b01a6431
2025-08-06 09:07:23,939 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group bc930d41-51ca-4858-b7b8-30f388a0c665
2025-08-06 09:07:23,939 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with bc930d41-51ca-4858-b7b8-30f388a0c665
2025-08-06 09:07:23,942 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 09:07:23,942 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 09:07:23,943 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 09:07:23,943 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:07:23,956 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:07:23,958 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/2a2f1717-476d-4444-bd91-e11c9c141e52
2025-08-06 09:07:23,961 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with f510bfa7-468d-4234-bf13-4b230d13acd2
2025-08-06 09:07:23,962 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with f510bfa7-468d-4234-bf13-4b230d13acd2
2025-08-06 09:07:23,982 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group f510bfa7-468d-4234-bf13-4b230d13acd2
2025-08-06 09:07:23,982 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with f510bfa7-468d-4234-bf13-4b230d13acd2
2025-08-06 09:07:23,988 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:08:22,830 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:08:22,833 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/f7775a46-cf00-4e31-9048-29c68395c3e9
2025-08-06 09:08:22,838 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with 006c0a2b-9f06-4344-ba35-b5e75bf9caae
2025-08-06 09:08:22,840 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 006c0a2b-9f06-4344-ba35-b5e75bf9caae
2025-08-06 09:08:22,866 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 006c0a2b-9f06-4344-ba35-b5e75bf9caae
2025-08-06 09:08:22,867 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 006c0a2b-9f06-4344-ba35-b5e75bf9caae
2025-08-06 09:08:22,869 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_schemas"} */

    show databases
  ' with 48a4ba17-6d69-457d-bff6-ce5f8e006981
2025-08-06 09:08:22,871 [HiveServer2-Background-Pool: Thread-173] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 48a4ba17-6d69-457d-bff6-ce5f8e006981
2025-08-06 09:08:22,897 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<namespace: STRING>
2025-08-06 09:08:22,904 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 48a4ba17-6d69-457d-bff6-ce5f8e006981
2025-08-06 09:08:22,904 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 48a4ba17-6d69-457d-bff6-ce5f8e006981
2025-08-06 09:08:22,907 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:08:22,924 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:08:22,926 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/550cb052-d496-46a4-9cd2-f9c3b4303143
2025-08-06 09:08:22,929 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with e9d6eb4f-878e-410b-8b47-9279c9c31562
2025-08-06 09:08:22,930 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with e9d6eb4f-878e-410b-8b47-9279c9c31562
2025-08-06 09:08:22,948 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group e9d6eb4f-878e-410b-8b47-9279c9c31562
2025-08-06 09:08:22,952 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with e9d6eb4f-878e-410b-8b47-9279c9c31562
2025-08-06 09:08:22,954 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
show table extended in default like '*'
  ' with 94097697-4a5d-4c29-8d16-6ccf13d29305
2025-08-06 09:08:22,955 [HiveServer2-Background-Pool: Thread-174] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 94097697-4a5d-4c29-8d16-6ccf13d29305
2025-08-06 09:08:22,959 [HiveServer2-Background-Pool: Thread-174] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 94097697-4a5d-4c29-8d16-6ccf13d29305
2025-08-06 09:08:22,959 [HiveServer2-Background-Pool: Thread-174] ERROR org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Error executing query with 94097697-4a5d-4c29-8d16-6ccf13d29305, currentState RUNNING, 
org.apache.spark.sql.AnalysisException: SHOW TABLE EXTENDED is not supported for v2 tables.;
ShowTableExtended *, [namespace#134, tableName#135, isTemporary#136, information#137]
+- ResolvedNamespace org.apache.iceberg.spark.SparkCatalog@c37c96, [default]

	at org.apache.spark.sql.errors.QueryCompilationErrors$.commandUnsupportedInV2TableError(QueryCompilationErrors.scala:2035) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$1(CheckAnalysis.scala:224) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$1$adapted(CheckAnalysis.scala:163) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:295) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:163) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:160) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:188) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:156) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:146) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:188) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:211) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:202) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:202) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:201) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:98) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:640) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:630) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:671) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:651) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:226) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:165) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.17.jar:?]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:79) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:63) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:40) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:165) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:160) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at java.security.AccessController.doPrivileged(AccessController.java:712) ~[?:?]
	at javax.security.auth.Subject.doAs(Subject.java:439) ~[?:?]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:174) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:08:22,973 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
show tables in default like '*'
  ' with 4c8cfac7-76bc-483b-b415-e22a142a4845
2025-08-06 09:08:22,974 [HiveServer2-Background-Pool: Thread-175] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 4c8cfac7-76bc-483b-b415-e22a142a4845
2025-08-06 09:08:23,015 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on c15f4bd07d87:41285 in memory (size: 18.9 KiB, free: 127.1 MiB)
2025-08-06 09:08:23,018 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on 172.18.0.11:39111 in memory (size: 18.9 KiB, free: 434.3 MiB)
2025-08-06 09:08:23,027 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on c15f4bd07d87:41285 in memory (size: 29.3 KiB, free: 127.1 MiB)
2025-08-06 09:08:23,031 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on 172.18.0.11:39111 in memory (size: 29.3 KiB, free: 434.4 MiB)
2025-08-06 09:08:23,036 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<namespace: STRING, tableName: STRING, isTemporary: BOOLEAN>
2025-08-06 09:08:23,038 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_2_piece0 on c15f4bd07d87:41285 in memory (size: 29.6 KiB, free: 127.2 MiB)
2025-08-06 09:08:23,044 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on c15f4bd07d87:41285 in memory (size: 29.6 KiB, free: 127.2 MiB)
2025-08-06 09:08:23,047 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on 172.18.0.11:39111 in memory (size: 29.6 KiB, free: 434.4 MiB)
2025-08-06 09:08:23,049 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
describe extended default.orders
  ' with ba444c29-e58c-4564-ae02-2504efc8cb99
2025-08-06 09:08:23,050 [HiveServer2-Background-Pool: Thread-202] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with ba444c29-e58c-4564-ae02-2504efc8cb99
2025-08-06 09:08:23,063 [HiveServer2-Background-Pool: Thread-202] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/orders/metadata/00001-8d716bb6-31aa-4998-b64e-2ed4d09b6df3.metadata.json
2025-08-06 09:08:23,068 [HiveServer2-Background-Pool: Thread-202] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 09:08:23,070 [HiveServer2-Background-Pool: Thread-202] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 09:08:23,070 [HiveServer2-Background-Pool: Thread-202] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 09:08:23,101 [HiveServer2-Background-Pool: Thread-202] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive_catalog.default.orders
2025-08-06 09:08:23,132 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<col_name: STRING COMMENT 'name of the column', data_type: STRING COMMENT 'data type of the column', comment: STRING COMMENT 'comment of the column'>
2025-08-06 09:08:23,142 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
describe extended default.orders_by_date
  ' with 8afb35fb-04e7-4138-9193-c2ea638d468d
2025-08-06 09:08:23,144 [HiveServer2-Background-Pool: Thread-207] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 8afb35fb-04e7-4138-9193-c2ea638d468d
2025-08-06 09:08:23,155 [HiveServer2-Background-Pool: Thread-207] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/output/orders/orders_by_date/metadata/00000-29b320db-a5ec-4cf5-94d1-eb791d9ef335.metadata.json
2025-08-06 09:08:23,164 [HiveServer2-Background-Pool: Thread-207] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive_catalog.default.orders_by_date
2025-08-06 09:08:23,188 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<col_name: STRING COMMENT 'name of the column', data_type: STRING COMMENT 'data type of the column', comment: STRING COMMENT 'comment of the column'>
2025-08-06 09:08:23,194 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 8afb35fb-04e7-4138-9193-c2ea638d468d
2025-08-06 09:08:23,195 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 8afb35fb-04e7-4138-9193-c2ea638d468d
2025-08-06 09:08:23,196 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group ba444c29-e58c-4564-ae02-2504efc8cb99
2025-08-06 09:08:23,196 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with ba444c29-e58c-4564-ae02-2504efc8cb99
2025-08-06 09:08:23,197 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 4c8cfac7-76bc-483b-b415-e22a142a4845
2025-08-06 09:08:23,197 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 4c8cfac7-76bc-483b-b415-e22a142a4845
2025-08-06 09:08:23,197 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 94097697-4a5d-4c29-8d16-6ccf13d29305
2025-08-06 09:08:23,198 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 94097697-4a5d-4c29-8d16-6ccf13d29305
2025-08-06 09:08:23,200 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 09:08:23,200 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 09:08:23,200 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 09:08:23,201 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:08:23,273 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:08:23,275 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/1bd15dc8-ff73-4841-96dc-5dd62b881d1d
2025-08-06 09:08:23,278 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with 0b6d0276-9238-44da-b23e-0f37a0abdf2c
2025-08-06 09:08:23,279 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 0b6d0276-9238-44da-b23e-0f37a0abdf2c
2025-08-06 09:08:23,296 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 0b6d0276-9238-44da-b23e-0f37a0abdf2c
2025-08-06 09:08:23,297 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 0b6d0276-9238-44da-b23e-0f37a0abdf2c
2025-08-06 09:08:23,299 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "node_id": "seed.dag.orders"} */
drop table if exists default.orders' with b91838ad-f2ec-4081-932a-9d284406c45f
2025-08-06 09:08:23,301 [HiveServer2-Background-Pool: Thread-208] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with b91838ad-f2ec-4081-932a-9d284406c45f
2025-08-06 09:08:23,318 [HiveServer2-Background-Pool: Thread-208] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/orders/metadata/00001-8d716bb6-31aa-4998-b64e-2ed4d09b6df3.metadata.json
2025-08-06 09:08:23,320 [HiveServer2-Background-Pool: Thread-208] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 09:08:23,322 [HiveServer2-Background-Pool: Thread-208] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 09:08:23,322 [HiveServer2-Background-Pool: Thread-208] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 09:08:23,333 [HiveServer2-Background-Pool: Thread-208] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive_catalog.default.orders
2025-08-06 09:08:23,516 [HiveServer2-Background-Pool: Thread-208] INFO  org.apache.iceberg.hive.HiveCatalog - Dropped table: default.orders
2025-08-06 09:08:23,561 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "node_id": "seed.dag.orders"} */

    create table default.orders (`date` date,`product_id` bigint,`city_id` bigint,`orders` bigint)
    
    
    
    
    
  ' with 5a91c9f9-b1af-49d3-9649-ecf18df47937
2025-08-06 09:08:23,563 [HiveServer2-Background-Pool: Thread-211] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 5a91c9f9-b1af-49d3-9649-ecf18df47937
2025-08-06 09:08:23,577 [HiveServer2-Background-Pool: Thread-211] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table properties set at catalog level through catalog properties: {}
2025-08-06 09:08:23,587 [HiveServer2-Background-Pool: Thread-211] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table properties enforced at catalog level through catalog properties: {}
2025-08-06 09:08:23,665 [HiveServer2-Background-Pool: Thread-211] INFO  org.apache.iceberg.hive.HiveTableOperations - Committed to table hive_catalog.default.orders with the new metadata location s3a://iceberg-warehouse/orders/metadata/00000-78b9496d-47ff-47f0-b99d-6765162b5816.metadata.json
2025-08-06 09:08:23,665 [HiveServer2-Background-Pool: Thread-211] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table hive_catalog.default.orders in 77 ms
2025-08-06 09:08:23,675 [HiveServer2-Background-Pool: Thread-211] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/orders/metadata/00000-78b9496d-47ff-47f0-b99d-6765162b5816.metadata.json
2025-08-06 09:08:24,164 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Requesting to kill executor(s) 1
2025-08-06 09:08:24,164 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Actual list of executor(s) to be killed is 1
2025-08-06 09:08:24,179 [spark-dynamic-executor-allocation] INFO  org.apache.spark.ExecutorAllocationManager - Executors 1 removed due to idle timeout.
2025-08-06 09:08:29,187 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '
          insert into default.orders values
          (cast('2019-12-10' as date),cast(5628.0 as bigint),cast(25.0 as bigint),cast(3.0 as bigint)),(cast('2018-08-15' as date),cast(3646.0 as bigint),cast(14.0 as bigint),cast(157.0 as bigint)),(cast('2018-10-23' as date),cast(1859.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-17' as date),cast(7292.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-06' as date),cast(4344.0 as bigint),cast(25.0 as bigint),cast(3.0 as bigint)),(cast('2018-08-23' as date),cast(1811.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2018-11-21' as date),cast(1282.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-27' as date),cast(5022.0 as bigint),cast(2.0 as bigint),cast(41.0 as bigint)),(cast('2019-06-29' as date),cast(3699.0 as bigint),cast(3.0 as bigint),cast(15.0 as bigint)),(cast('2018-08-30' as date),cast(4373.0 as bigint),cast(11.0 as bigint),cast(3.0 as bigint)),(cast('2019-10-24' as date),cast(6339.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-02' as date),cast(3311.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2019-03-15' as date),cast(5665.0 as bigint),cast(5.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-24' as date),cast(3020.0 as bigint),cast(13.0 as bigint),cast(4.0 as bigint)),(cast('2019-05-29' as date),cast(3833.0 as bigint),cast(26.0 as bigint),cast(240.0 as bigint)),(cast('2019-02-14' as date),cast(202.0 as bigint),cast(2.0 as bigint),cast(4.0 as bigint)),(cast('2019-04-10' as date),cast(977.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-24' as date),cast(2701.0 as bigint),cast(14.0 as bigint),cast(16.0 as bigint)),(cast('2019-06-12' as date),cast(5630.0 as bigint),cast(14.0 as bigint),cast(31.0 as bigint)),(cast('2019-04-13' as date),cast(7163.0 as bigint),cast(2.0 as bigint),cast(20.0 as bigint)),(cast('2019-11-30' as date),cast(1323.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-19' as date),cast(1191.0 as bigint),cast(13.0 as bigint),cast(50.0 as bigint)),(cast('2019-09-13' as date),cast(4635.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2018-08-12' as date),cast(825.0 as bigint),cast(26.0 as bigint),cast(7.0 as bigint)),(cast('2019-07-24' as date),cast(2303.0 as bigint),cast(14.0 as bigint),cast(113.0 as bigint)),(cast('2018-09-14' as date),cast(4487.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-09' as date),cast(6825.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2019-01-24' as date),cast(4152.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-20' as date),cast(5501.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-20' as date),cast(172.0 as bigint),cast(0.0 as bigint),cast(7.0 as bigint)),(cast('2019-07-24' as date),cast(2820.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2018-10-01' as date),cast(7386.0 as bigint),cast(3.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-23' as date),cast(2845.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-11' as date),cast(3121.0 as bigint),cast(17.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-09' as date),cast(4185.0 as bigint),cast(18.0 as bigint),cast(12.0 as bigint)),(cast('2019-01-20' as date),cast(2963.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2018-07-13' as date),cast(3432.0 as bigint),cast(13.0 as bigint),cast(28.0 as bigint)),(cast('2018-08-18' as date),cast(4436.0 as bigint),cast(17.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-15' as date),cast(7025.0 as bigint),cast(14.0 as bigint),cast(33.0 as bigint)),(cast('2019-05-12' as date),cast(2376.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-27' as date),cast(6900.0 as bigint),cast(14.0 as bigint),cast(14.0 as bigint)),(cast('2019-04-07' as date),cast(2898.0 as bigint),cast(18.0 as bigint),cast(45.0 as bigint)),(cast('2018-11-02' as date),cast(1439.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-04' as date),cast(2490.0 as bigint),cast(7.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-03' as date),cast(803.0 as bigint),cast(23.0 as bigint),cast(9.0 as bigint)),(cast('2019-07-01' as date),cast(1533.0 as bigint),cast(18.0 as bigint),cast(57.0 as bigint)),(cast('2018-09-23' as date),cast(2815.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-11' as date),cast(3437.0 as bigint),cast(14.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-11' as date),cast(2860.0 as bigint),cast(28.0 as bigint),cast(41.0 as bigint)),(cast('2019-07-24' as date),cast(7038.0 as bigint),cast(13.0 as bigint),cast(8.0 as bigint)),(cast('2019-06-07' as date),cast(6137.0 as bigint),cast(3.0 as bigint),cast(3.0 as bigint)),(cast('2019-08-12' as date),cast(6344.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-02' as date),cast(2844.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-04' as date),cast(5193.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-26' as date),cast(3196.0 as bigint),cast(29.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-26' as date),cast(4976.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-12' as date),cast(3667.0 as bigint),cast(13.0 as bigint),cast(20.0 as bigint)),(cast('2019-08-04' as date),cast(2837.0 as bigint),cast(18.0 as bigint),cast(370.0 as bigint)),(cast('2019-01-06' as date),cast(4618.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-25' as date),cast(4756.0 as bigint),cast(2.0 as bigint),cast(13.0 as bigint)),(cast('2018-08-05' as date),cast(3760.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-07-20' as date),cast(7025.0 as bigint),cast(14.0 as bigint),cast(22.0 as bigint)),(cast('2019-01-13' as date),cast(5033.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-29' as date),cast(2841.0 as bigint),cast(16.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-01' as date),cast(3541.0 as bigint),cast(2.0 as bigint),cast(5.0 as bigint)),(cast('2019-03-27' as date),cast(666.0 as bigint),cast(23.0 as bigint),cast(4.0 as bigint)),(cast('2019-01-26' as date),cast(1222.0 as bigint),cast(14.0 as bigint),cast(48.0 as bigint)),(cast('2018-11-18' as date),cast(3604.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2018-10-18' as date),cast(588.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-28' as date),cast(2652.0 as bigint),cast(18.0 as bigint),cast(84.0 as bigint)),(cast('2019-10-29' as date),cast(6443.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-30' as date),cast(2918.0 as bigint),cast(26.0 as bigint),cast(3.0 as bigint)),(cast('2018-08-27' as date),cast(7582.0 as bigint),cast(17.0 as bigint),cast(30.0 as bigint)),(cast('2019-07-28' as date),cast(3913.0 as bigint),cast(13.0 as bigint),cast(19.0 as bigint)),(cast('2019-11-13' as date),cast(2199.0 as bigint),cast(14.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-12' as date),cast(289.0 as bigint),cast(24.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-18' as date),cast(5973.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-02' as date),cast(5905.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-28' as date),cast(3044.0 as bigint),cast(7.0 as bigint),cast(7.0 as bigint)),(cast('2019-05-17' as date),cast(420.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-05' as date),cast(1754.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-22' as date),cast(3143.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-26' as date),cast(1985.0 as bigint),cast(14.0 as bigint),cast(13.0 as bigint)),(cast('2018-08-11' as date),cast(6300.0 as bigint),cast(22.0 as bigint),cast(5.0 as bigint)),(cast('2018-07-30' as date),cast(7350.0 as bigint),cast(16.0 as bigint),cast(76.0 as bigint)),(cast('2019-11-13' as date),cast(5288.0 as bigint),cast(18.0 as bigint),cast(7.0 as bigint)),(cast('2019-06-27' as date),cast(3904.0 as bigint),cast(1.0 as bigint),cast(29.0 as bigint)),(cast('2019-07-12' as date),cast(7042.0 as bigint),cast(3.0 as bigint),cast(5.0 as bigint)),(cast('2019-10-11' as date),cast(925.0 as bigint),cast(25.0 as bigint),cast(10.0 as bigint)),(cast('2019-07-09' as date),cast(7214.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-16' as date),cast(7491.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-18' as date),cast(923.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-30' as date),cast(5788.0 as bigint),cast(7.0 as bigint),cast(34.0 as bigint)),(cast('2019-11-12' as date),cast(7354.0 as bigint),cast(25.0 as bigint),cast(16.0 as bigint)),(cast('2019-04-10' as date),cast(300.0 as bigint),cast(14.0 as bigint),cast(462.0 as bigint)),(cast('2019-04-02' as date),cast(5383.0 as bigint),cast(11.0 as bigint),cast(24.0 as bigint)),(cast('2018-08-23' as date),cast(925.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2018-09-27' as date),cast(4690.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-03' as date),cast(4794.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2019-04-13' as date),cast(6206.0 as bigint),cast(2.0 as bigint),cast(24.0 as bigint)),(cast('2018-11-22' as date),cast(6343.0 as bigint),cast(22.0 as bigint),cast(191.0 as bigint)),(cast('2019-12-01' as date),cast(895.0 as bigint),cast(14.0 as bigint),cast(47.0 as bigint)),(cast('2018-08-30' as date),cast(3328.0 as bigint),cast(29.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-24' as date),cast(77.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2018-09-12' as date),cast(6134.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-21' as date),cast(2465.0 as bigint),cast(29.0 as bigint),cast(2.0 as bigint)),(cast('2019-01-20' as date),cast(6592.0 as bigint),cast(25.0 as bigint),cast(11.0 as bigint)),(cast('2018-12-29' as date),cast(1225.0 as bigint),cast(13.0 as bigint),cast(60.0 as bigint)),(cast('2019-10-24' as date),cast(7538.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-08' as date),cast(351.0 as bigint),cast(20.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-13' as date),cast(7059.0 as bigint),cast(14.0 as bigint),cast(11.0 as bigint)),(cast('2019-10-17' as date),cast(3597.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-21' as date),cast(5787.0 as bigint),cast(13.0 as bigint),cast(134.0 as bigint)),(cast('2018-12-15' as date),cast(6288.0 as bigint),cast(2.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-28' as date),cast(6534.0 as bigint),cast(14.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-13' as date),cast(5779.0 as bigint),cast(13.0 as bigint),cast(6.0 as bigint)),(cast('2019-04-23' as date),cast(4523.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-20' as date),cast(1556.0 as bigint),cast(17.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-12' as date),cast(2251.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-15' as date),cast(650.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-19' as date),cast(2646.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-30' as date),cast(7140.0 as bigint),cast(18.0 as bigint),cast(54.0 as bigint)),(cast('2019-12-04' as date),cast(3076.0 as bigint),cast(18.0 as bigint),cast(8.0 as bigint)),(cast('2019-07-19' as date),cast(959.0 as bigint),cast(16.0 as bigint),cast(16.0 as bigint)),(cast('2018-11-22' as date),cast(1440.0 as bigint),cast(16.0 as bigint),cast(23.0 as bigint)),(cast('2019-03-13' as date),cast(5874.0 as bigint),cast(9.0 as bigint),cast(5.0 as bigint)),(cast('2019-07-20' as date),cast(1944.0 as bigint),cast(11.0 as bigint),cast(16.0 as bigint)),(cast('2019-12-16' as date),cast(3828.0 as bigint),cast(11.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-23' as date),cast(6204.0 as bigint),cast(24.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-06' as date),cast(7413.0 as bigint),cast(13.0 as bigint),cast(6.0 as bigint)),(cast('2019-07-12' as date),cast(2242.0 as bigint),cast(8.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-16' as date),cast(7296.0 as bigint),cast(22.0 as bigint),cast(11.0 as bigint)),(cast('2018-10-08' as date),cast(4152.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-07-23' as date),cast(6564.0 as bigint),cast(18.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-17' as date),cast(6049.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-01' as date),cast(3252.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-01' as date),cast(2200.0 as bigint),cast(3.0 as bigint),cast(3.0 as bigint)),(cast('2019-03-14' as date),cast(2087.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-04' as date),cast(4635.0 as bigint),cast(22.0 as bigint),cast(12.0 as bigint)),(cast('2018-10-31' as date),cast(5508.0 as bigint),cast(14.0 as bigint),cast(8.0 as bigint)),(cast('2018-10-31' as date),cast(5112.0 as bigint),cast(10.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-17' as date),cast(1640.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-06' as date),cast(1610.0 as bigint),cast(3.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-09' as date),cast(5284.0 as bigint),cast(25.0 as bigint),cast(8.0 as bigint)),(cast('2019-10-14' as date),cast(5778.0 as bigint),cast(24.0 as bigint),cast(108.0 as bigint)),(cast('2019-04-18' as date),cast(351.0 as bigint),cast(20.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-13' as date),cast(6828.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-09' as date),cast(5290.0 as bigint),cast(3.0 as bigint),cast(139.0 as bigint)),(cast('2019-12-10' as date),cast(561.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-09' as date),cast(1024.0 as bigint),cast(10.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-10' as date),cast(7478.0 as bigint),cast(24.0 as bigint),cast(9.0 as bigint)),(cast('2019-10-15' as date),cast(5066.0 as bigint),cast(18.0 as bigint),cast(14.0 as bigint)),(cast('2019-01-25' as date),cast(7068.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-13' as date),cast(4576.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-10' as date),cast(803.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-04' as date),cast(3888.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-25' as date),cast(568.0 as bigint),cast(8.0 as bigint),cast(25.0 as bigint)),(cast('2019-02-18' as date),cast(6761.0 as bigint),cast(14.0 as bigint),cast(5.0 as bigint)),(cast('2019-12-16' as date),cast(2148.0 as bigint),cast(28.0 as bigint),cast(51.0 as bigint)),(cast('2019-11-08' as date),cast(718.0 as bigint),cast(9.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-28' as date),cast(2627.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-30' as date),cast(7140.0 as bigint),cast(18.0 as bigint),cast(26.0 as bigint)),(cast('2019-11-17' as date),cast(1775.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2018-11-12' as date),cast(2541.0 as bigint),cast(28.0 as bigint),cast(4.0 as bigint)),(cast('2019-06-26' as date),cast(6097.0 as bigint),cast(9.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-05' as date),cast(327.0 as bigint),cast(17.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-11' as date),cast(3946.0 as bigint),cast(30.0 as bigint),cast(9.0 as bigint)),(cast('2019-07-30' as date),cast(5314.0 as bigint),cast(11.0 as bigint),cast(10.0 as bigint)),(cast('2019-11-16' as date),cast(4432.0 as bigint),cast(3.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-25' as date),cast(2876.0 as bigint),cast(1.0 as bigint),cast(4.0 as bigint)),(cast('2019-03-25' as date),cast(6357.0 as bigint),cast(4.0 as bigint),cast(5.0 as bigint)),(cast('2019-01-25' as date),cast(4964.0 as bigint),cast(1.0 as bigint),cast(55.0 as bigint)),(cast('2019-06-24' as date),cast(5450.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-11' as date),cast(3543.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-03' as date),cast(718.0 as bigint),cast(9.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-04' as date),cast(3125.0 as bigint),cast(1.0 as bigint),cast(10.0 as bigint)),(cast('2018-12-16' as date),cast(1475.0 as bigint),cast(16.0 as bigint),cast(8.0 as bigint)),(cast('2019-08-10' as date),cast(585.0 as bigint),cast(17.0 as bigint),cast(13.0 as bigint)),(cast('2019-04-30' as date),cast(4776.0 as bigint),cast(16.0 as bigint),cast(100.0 as bigint)),(cast('2019-01-15' as date),cast(4571.0 as bigint),cast(22.0 as bigint),cast(3.0 as bigint)),(cast('2019-07-13' as date),cast(4180.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2019-04-12' as date),cast(1744.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-05-26' as date),cast(1135.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-08' as date),cast(4785.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2019-01-21' as date),cast(6371.0 as bigint),cast(7.0 as bigint),cast(8.0 as bigint)),(cast('2019-11-29' as date),cast(4294.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2019-05-30' as date),cast(4992.0 as bigint),cast(9.0 as bigint),cast(15.0 as bigint)),(cast('2019-05-29' as date),cast(586.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-25' as date),cast(1123.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-05' as date),cast(4400.0 as bigint),cast(27.0 as bigint),cast(9.0 as bigint)),(cast('2019-07-13' as date),cast(776.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-29' as date),cast(2228.0 as bigint),cast(5.0 as bigint),cast(3.0 as bigint)),(cast('2019-04-21' as date),cast(21.0 as bigint),cast(24.0 as bigint),cast(3.0 as bigint)),(cast('2019-05-18' as date),cast(6828.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-09' as date),cast(5.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-01' as date),cast(5470.0 as bigint),cast(16.0 as bigint),cast(23.0 as bigint)),(cast('2018-08-20' as date),cast(6215.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2018-09-14' as date),cast(3440.0 as bigint),cast(26.0 as bigint),cast(101.0 as bigint)),(cast('2018-08-28' as date),cast(685.0 as bigint),cast(25.0 as bigint),cast(29.0 as bigint)),(cast('2019-01-27' as date),cast(3817.0 as bigint),cast(28.0 as bigint),cast(4.0 as bigint)),(cast('2019-02-06' as date),cast(3449.0 as bigint),cast(28.0 as bigint),cast(5.0 as bigint)),(cast('2019-04-06' as date),cast(2357.0 as bigint),cast(14.0 as bigint),cast(104.0 as bigint)),(cast('2018-11-21' as date),cast(192.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-16' as date),cast(4033.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-07' as date),cast(820.0 as bigint),cast(30.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-05' as date),cast(5722.0 as bigint),cast(25.0 as bigint),cast(260.0 as bigint)),(cast('2019-04-24' as date),cast(6082.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-01' as date),cast(5135.0 as bigint),cast(9.0 as bigint),cast(5.0 as bigint)),(cast('2019-06-24' as date),cast(3919.0 as bigint),cast(2.0 as bigint),cast(22.0 as bigint)),(cast('2018-11-06' as date),cast(3234.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-13' as date),cast(3403.0 as bigint),cast(1.0 as bigint),cast(15.0 as bigint)),(cast('2019-01-04' as date),cast(6588.0 as bigint),cast(28.0 as bigint),cast(7.0 as bigint)),(cast('2019-10-11' as date),cast(3340.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-25' as date),cast(2562.0 as bigint),cast(18.0 as bigint),cast(133.0 as bigint)),(cast('2019-06-30' as date),cast(453.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-01' as date),cast(7266.0 as bigint),cast(19.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-13' as date),cast(3493.0 as bigint),cast(26.0 as bigint),cast(9.0 as bigint)),(cast('2018-09-14' as date),cast(3390.0 as bigint),cast(20.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-14' as date),cast(3047.0 as bigint),cast(4.0 as bigint),cast(24.0 as bigint)),(cast('2019-07-26' as date),cast(4425.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-14' as date),cast(4482.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-15' as date),cast(300.0 as bigint),cast(14.0 as bigint),cast(967.0 as bigint)),(cast('2019-01-22' as date),cast(5002.0 as bigint),cast(13.0 as bigint),cast(15.0 as bigint)),(cast('2019-07-18' as date),cast(4529.0 as bigint),cast(20.0 as bigint),cast(5.0 as bigint)),(cast('2019-11-20' as date),cast(4495.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-26' as date),cast(1503.0 as bigint),cast(21.0 as bigint),cast(12.0 as bigint)),(cast('2018-10-31' as date),cast(4036.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-30' as date),cast(4040.0 as bigint),cast(14.0 as bigint),cast(30.0 as bigint)),(cast('2019-05-15' as date),cast(6683.0 as bigint),cast(13.0 as bigint),cast(8.0 as bigint)),(cast('2019-11-29' as date),cast(4047.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2018-07-22' as date),cast(7554.0 as bigint),cast(13.0 as bigint),cast(12.0 as bigint)),(cast('2018-08-28' as date),cast(4289.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-08' as date),cast(666.0 as bigint),cast(23.0 as bigint),cast(9.0 as bigint)),(cast('2019-08-17' as date),cast(2411.0 as bigint),cast(23.0 as bigint),cast(6.0 as bigint)),(cast('2019-04-21' as date),cast(5200.0 as bigint),cast(28.0 as bigint),cast(19.0 as bigint)),(cast('2018-10-05' as date),cast(1288.0 as bigint),cast(20.0 as bigint),cast(22.0 as bigint)),(cast('2018-08-24' as date),cast(4576.0 as bigint),cast(22.0 as bigint),cast(3.0 as bigint)),(cast('2019-12-09' as date),cast(5489.0 as bigint),cast(13.0 as bigint),cast(23.0 as bigint)),(cast('2018-08-24' as date),cast(496.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-19' as date),cast(4823.0 as bigint),cast(18.0 as bigint),cast(26.0 as bigint)),(cast('2019-08-09' as date),cast(4938.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-25' as date),cast(582.0 as bigint),cast(26.0 as bigint),cast(8.0 as bigint)),(cast('2018-11-20' as date),cast(5450.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-29' as date),cast(5939.0 as bigint),cast(14.0 as bigint),cast(183.0 as bigint)),(cast('2019-11-13' as date),cast(2691.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-28' as date),cast(2185.0 as bigint),cast(13.0 as bigint),cast(6.0 as bigint)),(cast('2019-12-10' as date),cast(2253.0 as bigint),cast(13.0 as bigint),cast(46.0 as bigint)),(cast('2019-12-06' as date),cast(7148.0 as bigint),cast(16.0 as bigint),cast(29.0 as bigint)),(cast('2019-01-04' as date),cast(3614.0 as bigint),cast(29.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-14' as date),cast(2265.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-16' as date),cast(2611.0 as bigint),cast(13.0 as bigint),cast(11.0 as bigint)),(cast('2018-11-14' as date),cast(7239.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-25' as date),cast(792.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-13' as date),cast(3793.0 as bigint),cast(22.0 as bigint),cast(32.0 as bigint)),(cast('2019-05-07' as date),cast(5329.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-30' as date),cast(4794.0 as bigint),cast(14.0 as bigint),cast(5.0 as bigint)),(cast('2019-07-28' as date),cast(4814.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-03' as date),cast(1364.0 as bigint),cast(30.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-04' as date),cast(1775.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-10' as date),cast(7246.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-04' as date),cast(4483.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-10' as date),cast(3505.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2018-11-14' as date),cast(4667.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-03' as date),cast(6694.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-26' as date),cast(1182.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2019-04-28' as date),cast(2850.0 as bigint),cast(16.0 as bigint),cast(6.0 as bigint)),(cast('2019-12-11' as date),cast(972.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-18' as date),cast(2372.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-14' as date),cast(6642.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-21' as date),cast(6567.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-23' as date),cast(704.0 as bigint),cast(13.0 as bigint),cast(10.0 as bigint)),(cast('2019-10-20' as date),cast(5281.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-22' as date),cast(3995.0 as bigint),cast(18.0 as bigint),cast(58.0 as bigint)),(cast('2019-11-03' as date),cast(149.0 as bigint),cast(14.0 as bigint),cast(24.0 as bigint)),(cast('2019-01-22' as date),cast(5618.0 as bigint),cast(21.0 as bigint),cast(3.0 as bigint)),(cast('2019-01-12' as date),cast(4850.0 as bigint),cast(26.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-18' as date),cast(5004.0 as bigint),cast(25.0 as bigint),cast(21.0 as bigint)),(cast('2018-11-21' as date),cast(2017.0 as bigint),cast(11.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-08' as date),cast(5024.0 as bigint),cast(21.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-05' as date),cast(2884.0 as bigint),cast(2.0 as bigint),cast(19.0 as bigint)),(cast('2018-08-18' as date),cast(6716.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-17' as date),cast(4379.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-27' as date),cast(1517.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-17' as date),cast(390.0 as bigint),cast(9.0 as bigint),cast(5.0 as bigint)),(cast('2018-07-27' as date),cast(3635.0 as bigint),cast(16.0 as bigint),cast(48.0 as bigint)),(cast('2018-10-19' as date),cast(6619.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-10' as date),cast(2850.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-15' as date),cast(6368.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-24' as date),cast(5618.0 as bigint),cast(21.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-21' as date),cast(483.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-05' as date),cast(4254.0 as bigint),cast(16.0 as bigint),cast(37.0 as bigint)),(cast('2018-11-20' as date),cast(5009.0 as bigint),cast(28.0 as bigint),cast(12.0 as bigint)),(cast('2018-09-02' as date),cast(1455.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-12' as date),cast(3151.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-02' as date),cast(3601.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-29' as date),cast(3012.0 as bigint),cast(18.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-05' as date),cast(3601.0 as bigint),cast(9.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-02' as date),cast(5653.0 as bigint),cast(17.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-12' as date),cast(3748.0 as bigint),cast(17.0 as bigint),cast(11.0 as bigint)),(cast('2019-05-02' as date),cast(6438.0 as bigint),cast(24.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-31' as date),cast(2981.0 as bigint),cast(26.0 as bigint),cast(1004.0 as bigint)),(cast('2018-08-18' as date),cast(2301.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-05' as date),cast(2012.0 as bigint),cast(8.0 as bigint),cast(32.0 as bigint)),(cast('2019-06-01' as date),cast(1069.0 as bigint),cast(27.0 as bigint),cast(7.0 as bigint)),(cast('2018-09-15' as date),cast(438.0 as bigint),cast(22.0 as bigint),cast(12.0 as bigint)),(cast('2019-07-05' as date),cast(25.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-01' as date),cast(820.0 as bigint),cast(30.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-06' as date),cast(3034.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-07-27' as date),cast(664.0 as bigint),cast(24.0 as bigint),cast(15.0 as bigint)),(cast('2019-08-14' as date),cast(4352.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-20' as date),cast(1533.0 as bigint),cast(18.0 as bigint),cast(8.0 as bigint)),(cast('2018-10-31' as date),cast(7430.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-14' as date),cast(7011.0 as bigint),cast(9.0 as bigint),cast(11.0 as bigint)),(cast('2018-12-29' as date),cast(5118.0 as bigint),cast(13.0 as bigint),cast(125.0 as bigint)),(cast('2018-10-06' as date),cast(4845.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2018-11-10' as date),cast(3345.0 as bigint),cast(13.0 as bigint),cast(23.0 as bigint)),(cast('2019-01-24' as date),cast(4173.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-31' as date),cast(3088.0 as bigint),cast(14.0 as bigint),cast(106.0 as bigint)),(cast('2019-07-17' as date),cast(7223.0 as bigint),cast(2.0 as bigint),cast(28.0 as bigint)),(cast('2018-07-10' as date),cast(6283.0 as bigint),cast(14.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-28' as date),cast(5631.0 as bigint),cast(24.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-04' as date),cast(2981.0 as bigint),cast(26.0 as bigint),cast(461.0 as bigint)),(cast('2019-06-23' as date),cast(652.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2018-11-19' as date),cast(583.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-14' as date),cast(1238.0 as bigint),cast(13.0 as bigint),cast(7.0 as bigint)),(cast('2019-06-13' as date),cast(7057.0 as bigint),cast(2.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-29' as date),cast(1675.0 as bigint),cast(4.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-26' as date),cast(6115.0 as bigint),cast(22.0 as bigint),cast(63.0 as bigint)),(cast('2019-11-20' as date),cast(7467.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-05' as date),cast(5347.0 as bigint),cast(3.0 as bigint),cast(5.0 as bigint)),(cast('2019-03-02' as date),cast(2432.0 as bigint),cast(22.0 as bigint),cast(3.0 as bigint)),(cast('2019-10-21' as date),cast(6729.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-02' as date),cast(1467.0 as bigint),cast(22.0 as bigint),cast(63.0 as bigint)),(cast('2019-10-31' as date),cast(1494.0 as bigint),cast(25.0 as bigint),cast(71.0 as bigint)),(cast('2019-10-27' as date),cast(1130.0 as bigint),cast(14.0 as bigint),cast(48.0 as bigint)),(cast('2018-09-05' as date),cast(45.0 as bigint),cast(13.0 as bigint),cast(38.0 as bigint)),(cast('2018-11-30' as date),cast(4192.0 as bigint),cast(14.0 as bigint),cast(26.0 as bigint)),(cast('2019-07-15' as date),cast(4180.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-05' as date),cast(3862.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-05' as date),cast(6135.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-02' as date),cast(2088.0 as bigint),cast(26.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-04' as date),cast(1097.0 as bigint),cast(26.0 as bigint),cast(17.0 as bigint)),(cast('2019-07-31' as date),cast(4509.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2019-03-22' as date),cast(3064.0 as bigint),cast(8.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-22' as date),cast(7510.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2018-07-26' as date),cast(6857.0 as bigint),cast(18.0 as bigint),cast(61.0 as bigint)),(cast('2018-11-10' as date),cast(2215.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-16' as date),cast(1881.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2019-02-09' as date),cast(1848.0 as bigint),cast(14.0 as bigint),cast(135.0 as bigint)),(cast('2018-09-02' as date),cast(5819.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2019-10-26' as date),cast(1730.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-23' as date),cast(2056.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-03' as date),cast(27.0 as bigint),cast(10.0 as bigint),cast(40.0 as bigint)),(cast('2018-08-08' as date),cast(2284.0 as bigint),cast(9.0 as bigint),cast(8.0 as bigint)),(cast('2019-06-12' as date),cast(1739.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-09-18' as date),cast(6779.0 as bigint),cast(10.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-13' as date),cast(2148.0 as bigint),cast(28.0 as bigint),cast(11.0 as bigint)),(cast('2019-02-09' as date),cast(532.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-19' as date),cast(6295.0 as bigint),cast(3.0 as bigint),cast(44.0 as bigint)),(cast('2019-03-23' as date),cast(3339.0 as bigint),cast(22.0 as bigint),cast(38.0 as bigint)),(cast('2019-03-23' as date),cast(435.0 as bigint),cast(7.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-13' as date),cast(124.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-10' as date),cast(3734.0 as bigint),cast(4.0 as bigint),cast(25.0 as bigint)),(cast('2019-01-09' as date),cast(6860.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-26' as date),cast(5687.0 as bigint),cast(13.0 as bigint),cast(11.0 as bigint)),(cast('2018-07-18' as date),cast(6248.0 as bigint),cast(4.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-22' as date),cast(2307.0 as bigint),cast(4.0 as bigint),cast(6.0 as bigint)),(cast('2018-12-18' as date),cast(3678.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-31' as date),cast(83.0 as bigint),cast(25.0 as bigint),cast(3.0 as bigint)),(cast('2019-01-02' as date),cast(2357.0 as bigint),cast(14.0 as bigint),cast(60.0 as bigint)),(cast('2019-01-23' as date),cast(4573.0 as bigint),cast(2.0 as bigint),cast(3.0 as bigint)),(cast('2019-12-02' as date),cast(820.0 as bigint),cast(30.0 as bigint),cast(8.0 as bigint)),(cast('2019-03-05' as date),cast(6933.0 as bigint),cast(25.0 as bigint),cast(34.0 as bigint)),(cast('2019-07-14' as date),cast(1672.0 as bigint),cast(11.0 as bigint),cast(5.0 as bigint)),(cast('2018-12-16' as date),cast(4595.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-14' as date),cast(2002.0 as bigint),cast(1.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-01' as date),cast(5738.0 as bigint),cast(13.0 as bigint),cast(22.0 as bigint)),(cast('2019-01-25' as date),cast(2876.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-18' as date),cast(585.0 as bigint),cast(17.0 as bigint),cast(25.0 as bigint)),(cast('2019-10-11' as date),cast(2381.0 as bigint),cast(18.0 as bigint),cast(23.0 as bigint)),(cast('2019-08-10' as date),cast(1005.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-12' as date),cast(2837.0 as bigint),cast(18.0 as bigint),cast(149.0 as bigint)),(cast('2018-09-30' as date),cast(1935.0 as bigint),cast(2.0 as bigint),cast(48.0 as bigint)),(cast('2019-11-28' as date),cast(820.0 as bigint),cast(30.0 as bigint),cast(6.0 as bigint)),(cast('2018-12-27' as date),cast(2367.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2018-07-24' as date),cast(4306.0 as bigint),cast(14.0 as bigint),cast(11.0 as bigint)),(cast('2019-07-09' as date),cast(1935.0 as bigint),cast(2.0 as bigint),cast(37.0 as bigint)),(cast('2019-02-02' as date),cast(2897.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-19' as date),cast(4075.0 as bigint),cast(18.0 as bigint),cast(25.0 as bigint)),(cast('2018-10-25' as date),cast(2911.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-04' as date),cast(7526.0 as bigint),cast(14.0 as bigint),cast(5.0 as bigint)),(cast('2019-10-21' as date),cast(2524.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-05-04' as date),cast(4508.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-19' as date),cast(2271.0 as bigint),cast(3.0 as bigint),cast(28.0 as bigint)),(cast('2018-12-16' as date),cast(7034.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-06' as date),cast(7300.0 as bigint),cast(9.0 as bigint),cast(46.0 as bigint)),(cast('2019-10-25' as date),cast(107.0 as bigint),cast(4.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-25' as date),cast(6435.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-19' as date),cast(2307.0 as bigint),cast(4.0 as bigint),cast(9.0 as bigint)),(cast('2019-10-13' as date),cast(149.0 as bigint),cast(14.0 as bigint),cast(37.0 as bigint)),(cast('2019-04-18' as date),cast(5119.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-31' as date),cast(7508.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2018-11-05' as date),cast(4347.0 as bigint),cast(25.0 as bigint),cast(131.0 as bigint)),(cast('2018-12-03' as date),cast(639.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-12' as date),cast(841.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-26' as date),cast(4207.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-20' as date),cast(1081.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-23' as date),cast(5970.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-31' as date),cast(1341.0 as bigint),cast(13.0 as bigint),cast(8.0 as bigint)),(cast('2018-09-07' as date),cast(6478.0 as bigint),cast(2.0 as bigint),cast(2.0 as bigint)),(cast('2019-05-17' as date),cast(6309.0 as bigint),cast(29.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-11' as date),cast(3179.0 as bigint),cast(22.0 as bigint),cast(16.0 as bigint)),(cast('2018-10-10' as date),cast(6302.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-01' as date),cast(836.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-20' as date),cast(1670.0 as bigint),cast(26.0 as bigint),cast(15.0 as bigint)),(cast('2018-09-07' as date),cast(1191.0 as bigint),cast(13.0 as bigint),cast(47.0 as bigint)),(cast('2019-08-02' as date),cast(664.0 as bigint),cast(24.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-16' as date),cast(1361.0 as bigint),cast(20.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-16' as date),cast(3553.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-22' as date),cast(7430.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-07' as date),cast(7288.0 as bigint),cast(14.0 as bigint),cast(5.0 as bigint)),(cast('2019-07-05' as date),cast(5970.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-24' as date),cast(6717.0 as bigint),cast(3.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-14' as date),cast(5670.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-12' as date),cast(637.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-09' as date),cast(4944.0 as bigint),cast(26.0 as bigint),cast(9.0 as bigint)),(cast('2019-11-01' as date),cast(6487.0 as bigint),cast(30.0 as bigint),cast(6.0 as bigint)),(cast('2019-05-27' as date),cast(6072.0 as bigint),cast(26.0 as bigint),cast(60.0 as bigint)),(cast('2018-07-14' as date),cast(4183.0 as bigint),cast(22.0 as bigint),cast(8.0 as bigint)),(cast('2019-11-11' as date),cast(2746.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-20' as date),cast(6336.0 as bigint),cast(23.0 as bigint),cast(13.0 as bigint)),(cast('2019-09-13' as date),cast(5012.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-18' as date),cast(3098.0 as bigint),cast(28.0 as bigint),cast(6.0 as bigint)),(cast('2019-08-15' as date),cast(5770.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-15' as date),cast(890.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-20' as date),cast(4847.0 as bigint),cast(26.0 as bigint),cast(9.0 as bigint)),(cast('2019-10-11' as date),cast(983.0 as bigint),cast(25.0 as bigint),cast(45.0 as bigint)),(cast('2019-08-04' as date),cast(2830.0 as bigint),cast(14.0 as bigint),cast(21.0 as bigint)),(cast('2018-12-31' as date),cast(1985.0 as bigint),cast(14.0 as bigint),cast(45.0 as bigint)),(cast('2019-11-21' as date),cast(7224.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-31' as date),cast(4382.0 as bigint),cast(23.0 as bigint),cast(5.0 as bigint)),(cast('2019-02-15' as date),cast(2906.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-04' as date),cast(963.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-21' as date),cast(873.0 as bigint),cast(25.0 as bigint),cast(16.0 as bigint)),(cast('2019-07-24' as date),cast(6115.0 as bigint),cast(22.0 as bigint),cast(29.0 as bigint)),(cast('2019-10-14' as date),cast(4192.0 as bigint),cast(14.0 as bigint),cast(59.0 as bigint)),(cast('2019-06-28' as date),cast(5430.0 as bigint),cast(14.0 as bigint),cast(7.0 as bigint)),(cast('2019-01-18' as date),cast(621.0 as bigint),cast(22.0 as bigint),cast(25.0 as bigint)),(cast('2018-12-07' as date),cast(1933.0 as bigint),cast(21.0 as bigint),cast(17.0 as bigint)),(cast('2019-03-24' as date),cast(4523.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-30' as date),cast(3532.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2018-12-23' as date),cast(7078.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2018-11-05' as date),cast(7450.0 as bigint),cast(21.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-13' as date),cast(3860.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-15' as date),cast(1766.0 as bigint),cast(22.0 as bigint),cast(15.0 as bigint)),(cast('2018-09-08' as date),cast(5330.0 as bigint),cast(26.0 as bigint),cast(6.0 as bigint)),(cast('2018-12-04' as date),cast(1622.0 as bigint),cast(9.0 as bigint),cast(4.0 as bigint)),(cast('2019-10-12' as date),cast(4347.0 as bigint),cast(25.0 as bigint),cast(195.0 as bigint)),(cast('2019-08-02' as date),cast(5742.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-02' as date),cast(3803.0 as bigint),cast(21.0 as bigint),cast(2.0 as bigint)),(cast('2019-01-25' as date),cast(5508.0 as bigint),cast(14.0 as bigint),cast(9.0 as bigint)),(cast('2019-10-20' as date),cast(5125.0 as bigint),cast(3.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-14' as date),cast(626.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-21' as date),cast(1945.0 as bigint),cast(9.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-26' as date),cast(4895.0 as bigint),cast(29.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-13' as date),cast(6566.0 as bigint),cast(18.0 as bigint),cast(8.0 as bigint)),(cast('2018-12-11' as date),cast(4203.0 as bigint),cast(22.0 as bigint),cast(26.0 as bigint)),(cast('2018-07-14' as date),cast(1114.0 as bigint),cast(13.0 as bigint),cast(90.0 as bigint)),(cast('2019-02-14' as date),cast(7140.0 as bigint),cast(18.0 as bigint),cast(20.0 as bigint)),(cast('2019-11-15' as date),cast(5549.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-22' as date),cast(3125.0 as bigint),cast(1.0 as bigint),cast(69.0 as bigint)),(cast('2018-11-05' as date),cast(6430.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-05' as date),cast(7464.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2019-05-15' as date),cast(1896.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2019-11-01' as date),cast(3967.0 as bigint),cast(2.0 as bigint),cast(12.0 as bigint)),(cast('2019-07-25' as date),cast(2898.0 as bigint),cast(18.0 as bigint),cast(98.0 as bigint)),(cast('2019-04-04' as date),cast(5979.0 as bigint),cast(21.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-08' as date),cast(383.0 as bigint),cast(25.0 as bigint),cast(22.0 as bigint)),(cast('2018-12-22' as date),cast(711.0 as bigint),cast(30.0 as bigint),cast(3.0 as bigint)),(cast('2019-10-11' as date),cast(5116.0 as bigint),cast(14.0 as bigint),cast(32.0 as bigint)),(cast('2019-02-06' as date),cast(3835.0 as bigint),cast(9.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-16' as date),cast(1115.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-29' as date),cast(6791.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-30' as date),cast(5407.0 as bigint),cast(13.0 as bigint),cast(64.0 as bigint)),(cast('2019-02-09' as date),cast(2123.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-11' as date),cast(6941.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-20' as date),cast(5822.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2019-04-18' as date),cast(6095.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-30' as date),cast(6663.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-02' as date),cast(3247.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-21' as date),cast(2254.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2019-10-20' as date),cast(2597.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-24' as date),cast(2306.0 as bigint),cast(14.0 as bigint),cast(12.0 as bigint)),(cast('2019-06-04' as date),cast(2053.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-05' as date),cast(4733.0 as bigint),cast(12.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-09' as date),cast(7148.0 as bigint),cast(16.0 as bigint),cast(11.0 as bigint)),(cast('2019-03-16' as date),cast(3562.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-26' as date),cast(4667.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-07' as date),cast(3508.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-28' as date),cast(1225.0 as bigint),cast(13.0 as bigint),cast(40.0 as bigint)),(cast('2019-07-25' as date),cast(5371.0 as bigint),cast(22.0 as bigint),cast(15.0 as bigint)),(cast('2019-01-24' as date),cast(1881.0 as bigint),cast(14.0 as bigint),cast(14.0 as bigint)),(cast('2019-06-19' as date),cast(1232.0 as bigint),cast(14.0 as bigint),cast(8.0 as bigint)),(cast('2018-12-02' as date),cast(25.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-23' as date),cast(5280.0 as bigint),cast(23.0 as bigint),cast(8.0 as bigint)),(cast('2019-12-12' as date),cast(2585.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-06' as date),cast(2259.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-26' as date),cast(1047.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-17' as date),cast(77.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-10' as date),cast(7269.0 as bigint),cast(30.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-04' as date),cast(5953.0 as bigint),cast(13.0 as bigint),cast(34.0 as bigint)),(cast('2018-12-02' as date),cast(1403.0 as bigint),cast(29.0 as bigint),cast(3.0 as bigint)),(cast('2019-12-12' as date),cast(4968.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-30' as date),cast(6975.0 as bigint),cast(3.0 as bigint),cast(3.0 as bigint)),(cast('2019-08-03' as date),cast(4207.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-22' as date),cast(4611.0 as bigint),cast(26.0 as bigint),cast(8.0 as bigint)),(cast('2018-12-09' as date),cast(3953.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-06' as date),cast(6671.0 as bigint),cast(20.0 as bigint),cast(28.0 as bigint)),(cast('2018-07-26' as date),cast(50.0 as bigint),cast(2.0 as bigint),cast(15.0 as bigint)),(cast('2019-11-01' as date),cast(6377.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2019-04-03' as date),cast(4921.0 as bigint),cast(24.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-23' as date),cast(5482.0 as bigint),cast(25.0 as bigint),cast(7.0 as bigint)),(cast('2019-10-30' as date),cast(2416.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-18' as date),cast(3629.0 as bigint),cast(9.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-01' as date),cast(370.0 as bigint),cast(13.0 as bigint),cast(7.0 as bigint)),(cast('2019-06-13' as date),cast(2249.0 as bigint),cast(20.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-29' as date),cast(6671.0 as bigint),cast(20.0 as bigint),cast(15.0 as bigint)),(cast('2019-08-01' as date),cast(2811.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-17' as date),cast(7015.0 as bigint),cast(26.0 as bigint),cast(3.0 as bigint)),(cast('2019-07-30' as date),cast(5698.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-22' as date),cast(6007.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-31' as date),cast(4639.0 as bigint),cast(0.0 as bigint),cast(5.0 as bigint)),(cast('2019-10-17' as date),cast(3250.0 as bigint),cast(27.0 as bigint),cast(3.0 as bigint)),(cast('2019-01-22' as date),cast(6291.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-23' as date),cast(5615.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-26' as date),cast(7318.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-24' as date),cast(1140.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-29' as date),cast(2563.0 as bigint),cast(18.0 as bigint),cast(14.0 as bigint)),(cast('2018-08-24' as date),cast(4885.0 as bigint),cast(16.0 as bigint),cast(25.0 as bigint)),(cast('2019-12-08' as date),cast(2831.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2018-09-26' as date),cast(7350.0 as bigint),cast(16.0 as bigint),cast(23.0 as bigint)),(cast('2018-12-10' as date),cast(2457.0 as bigint),cast(3.0 as bigint),cast(13.0 as bigint)),(cast('2019-06-10' as date),cast(2652.0 as bigint),cast(18.0 as bigint),cast(69.0 as bigint)),(cast('2019-12-05' as date),cast(3944.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-01' as date),cast(3222.0 as bigint),cast(25.0 as bigint),cast(7.0 as bigint)),(cast('2019-01-21' as date),cast(5280.0 as bigint),cast(23.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-22' as date),cast(882.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-21' as date),cast(793.0 as bigint),cast(29.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-03' as date),cast(5917.0 as bigint),cast(2.0 as bigint),cast(59.0 as bigint)),(cast('2018-11-11' as date),cast(6656.0 as bigint),cast(26.0 as bigint),cast(10.0 as bigint)),(cast('2019-07-05' as date),cast(5115.0 as bigint),cast(2.0 as bigint),cast(121.0 as bigint)),(cast('2019-06-27' as date),cast(6756.0 as bigint),cast(17.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-04' as date),cast(5955.0 as bigint),cast(16.0 as bigint),cast(3.0 as bigint)),(cast('2019-05-29' as date),cast(2381.0 as bigint),cast(18.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-11' as date),cast(873.0 as bigint),cast(25.0 as bigint),cast(26.0 as bigint)),(cast('2019-08-15' as date),cast(3422.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-14' as date),cast(2422.0 as bigint),cast(18.0 as bigint),cast(3.0 as bigint)),(cast('2019-01-22' as date),cast(2811.0 as bigint),cast(13.0 as bigint),cast(9.0 as bigint)),(cast('2019-06-26' as date),cast(2416.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-16' as date),cast(5860.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-04' as date),cast(358.0 as bigint),cast(10.0 as bigint),cast(15.0 as bigint)),(cast('2019-08-18' as date),cast(6212.0 as bigint),cast(7.0 as bigint),cast(12.0 as bigint)),(cast('2018-12-01' as date),cast(348.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2019-04-11' as date),cast(7294.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-08' as date),cast(4195.0 as bigint),cast(26.0 as bigint),cast(8.0 as bigint)),(cast('2019-04-29' as date),cast(888.0 as bigint),cast(20.0 as bigint),cast(5.0 as bigint)),(cast('2019-04-29' as date),cast(3646.0 as bigint),cast(14.0 as bigint),cast(63.0 as bigint)),(cast('2019-11-15' as date),cast(2457.0 as bigint),cast(3.0 as bigint),cast(24.0 as bigint)),(cast('2019-12-01' as date),cast(4505.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-18' as date),cast(5795.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-18' as date),cast(2687.0 as bigint),cast(25.0 as bigint),cast(31.0 as bigint)),(cast('2018-09-18' as date),cast(5421.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-03' as date),cast(4191.0 as bigint),cast(16.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-16' as date),cast(5778.0 as bigint),cast(24.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-13' as date),cast(5639.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2018-09-27' as date),cast(4627.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-11' as date),cast(202.0 as bigint),cast(2.0 as bigint),cast(3.0 as bigint)),(cast('2018-07-22' as date),cast(2974.0 as bigint),cast(26.0 as bigint),cast(15.0 as bigint)),(cast('2019-06-28' as date),cast(5922.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-13' as date),cast(7059.0 as bigint),cast(14.0 as bigint),cast(31.0 as bigint)),(cast('2018-09-29' as date),cast(5965.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-18' as date),cast(731.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-22' as date),cast(1031.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-17' as date),cast(2589.0 as bigint),cast(20.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-16' as date),cast(1520.0 as bigint),cast(26.0 as bigint),cast(168.0 as bigint)),(cast('2018-07-16' as date),cast(5738.0 as bigint),cast(13.0 as bigint),cast(39.0 as bigint)),(cast('2019-06-26' as date),cast(2563.0 as bigint),cast(18.0 as bigint),cast(8.0 as bigint)),(cast('2019-10-30' as date),cast(6153.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2019-05-21' as date),cast(3055.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-02' as date),cast(1757.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-14' as date),cast(3197.0 as bigint),cast(17.0 as bigint),cast(27.0 as bigint)),(cast('2019-10-15' as date),cast(5386.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-05' as date),cast(2471.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-17' as date),cast(2973.0 as bigint),cast(26.0 as bigint),cast(7.0 as bigint)),(cast('2019-04-14' as date),cast(547.0 as bigint),cast(4.0 as bigint),cast(86.0 as bigint)),(cast('2018-09-21' as date),cast(5407.0 as bigint),cast(13.0 as bigint),cast(25.0 as bigint)),(cast('2019-08-05' as date),cast(6091.0 as bigint),cast(25.0 as bigint),cast(92.0 as bigint)),(cast('2018-10-18' as date),cast(4846.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-07' as date),cast(1134.0 as bigint),cast(13.0 as bigint),cast(19.0 as bigint)),(cast('2019-06-05' as date),cast(2373.0 as bigint),cast(13.0 as bigint),cast(16.0 as bigint)),(cast('2019-10-18' as date),cast(3464.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-24' as date),cast(6592.0 as bigint),cast(25.0 as bigint),cast(12.0 as bigint)),(cast('2018-07-15' as date),cast(3497.0 as bigint),cast(26.0 as bigint),cast(234.0 as bigint)),(cast('2018-12-11' as date),cast(7435.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-05' as date),cast(5708.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-19' as date),cast(5452.0 as bigint),cast(26.0 as bigint),cast(12.0 as bigint)),(cast('2018-11-24' as date),cast(2870.0 as bigint),cast(25.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-27' as date),cast(3685.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-10' as date),cast(5301.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-21' as date),cast(1933.0 as bigint),cast(21.0 as bigint),cast(19.0 as bigint)),(cast('2018-10-01' as date),cast(457.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-01-30' as date),cast(1284.0 as bigint),cast(17.0 as bigint),cast(11.0 as bigint)),(cast('2019-01-26' as date),cast(7354.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-20' as date),cast(7430.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-14' as date),cast(5941.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-19' as date),cast(2846.0 as bigint),cast(22.0 as bigint),cast(3.0 as bigint)),(cast('2019-02-09' as date),cast(5733.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-27' as date),cast(5517.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2019-10-14' as date),cast(1140.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-24' as date),cast(7450.0 as bigint),cast(21.0 as bigint),cast(4.0 as bigint)),(cast('2019-03-21' as date),cast(3220.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-12' as date),cast(6011.0 as bigint),cast(9.0 as bigint),cast(4.0 as bigint)),(cast('2018-09-21' as date),cast(3234.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-13' as date),cast(4597.0 as bigint),cast(3.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-09' as date),cast(1737.0 as bigint),cast(1.0 as bigint),cast(8.0 as bigint)),(cast('2018-10-05' as date),cast(5849.0 as bigint),cast(26.0 as bigint),cast(5.0 as bigint)),(cast('2019-12-07' as date),cast(6668.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-01' as date),cast(4568.0 as bigint),cast(13.0 as bigint),cast(138.0 as bigint)),(cast('2019-08-03' as date),cast(5823.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-15' as date),cast(7138.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-29' as date),cast(6850.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-30' as date),cast(4323.0 as bigint),cast(4.0 as bigint),cast(7.0 as bigint)),(cast('2018-11-22' as date),cast(3923.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-26' as date),cast(4601.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-08' as date),cast(1958.0 as bigint),cast(17.0 as bigint),cast(3.0 as bigint)),(cast('2018-11-11' as date),cast(6295.0 as bigint),cast(3.0 as bigint),cast(84.0 as bigint)),(cast('2018-11-01' as date),cast(1744.0 as bigint),cast(13.0 as bigint),cast(4.0 as bigint)),(cast('2019-02-15' as date),cast(957.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2018-08-10' as date),cast(6608.0 as bigint),cast(22.0 as bigint),cast(5.0 as bigint)),(cast('2019-11-04' as date),cast(7198.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-03' as date),cast(3161.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-12' as date),cast(3034.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-21' as date),cast(594.0 as bigint),cast(22.0 as bigint),cast(13.0 as bigint)),(cast('2019-05-31' as date),cast(7561.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-29' as date),cast(4065.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-11' as date),cast(6091.0 as bigint),cast(25.0 as bigint),cast(40.0 as bigint)),(cast('2018-09-01' as date),cast(7399.0 as bigint),cast(0.0 as bigint),cast(39.0 as bigint)),(cast('2018-09-05' as date),cast(6556.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-08' as date),cast(564.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-05' as date),cast(6976.0 as bigint),cast(22.0 as bigint),cast(19.0 as bigint)),(cast('2019-05-21' as date),cast(5626.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-12-12' as date),cast(763.0 as bigint),cast(26.0 as bigint),cast(25.0 as bigint)),(cast('2019-10-29' as date),cast(2306.0 as bigint),cast(14.0 as bigint),cast(9.0 as bigint)),(cast('2019-02-27' as date),cast(6937.0 as bigint),cast(13.0 as bigint),cast(14.0 as bigint)),(cast('2019-04-22' as date),cast(14.0 as bigint),cast(2.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-07' as date),cast(4419.0 as bigint),cast(27.0 as bigint),cast(8.0 as bigint)),(cast('2018-10-28' as date),cast(5687.0 as bigint),cast(13.0 as bigint),cast(15.0 as bigint)),(cast('2019-01-26' as date),cast(7025.0 as bigint),cast(14.0 as bigint),cast(56.0 as bigint)),(cast('2018-09-18' as date),cast(5266.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-01' as date),cast(3140.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-04-01' as date),cast(6599.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-25' as date),cast(3042.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-08' as date),cast(6290.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-19' as date),cast(3761.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-05' as date),cast(6543.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-29' as date),cast(146.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2019-03-19' as date),cast(7429.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-18' as date),cast(687.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-01' as date),cast(6937.0 as bigint),cast(13.0 as bigint),cast(38.0 as bigint)),(cast('2018-10-31' as date),cast(1647.0 as bigint),cast(4.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-24' as date),cast(3051.0 as bigint),cast(7.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-31' as date),cast(5544.0 as bigint),cast(25.0 as bigint),cast(3.0 as bigint)),(cast('2019-09-18' as date),cast(779.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-25' as date),cast(6215.0 as bigint),cast(22.0 as bigint),cast(8.0 as bigint)),(cast('2018-08-31' as date),cast(4867.0 as bigint),cast(9.0 as bigint),cast(5.0 as bigint)),(cast('2018-12-05' as date),cast(4038.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-27' as date),cast(6264.0 as bigint),cast(25.0 as bigint),cast(11.0 as bigint)),(cast('2019-03-04' as date),cast(1503.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-02' as date),cast(6293.0 as bigint),cast(14.0 as bigint),cast(32.0 as bigint)),(cast('2019-11-11' as date),cast(4068.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2019-11-17' as date),cast(4111.0 as bigint),cast(18.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-08' as date),cast(6483.0 as bigint),cast(28.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-24' as date),cast(3837.0 as bigint),cast(25.0 as bigint),cast(6.0 as bigint)),(cast('2018-10-06' as date),cast(5957.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-09' as date),cast(4981.0 as bigint),cast(22.0 as bigint),cast(3.0 as bigint)),(cast('2019-02-28' as date),cast(212.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-29' as date),cast(1715.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-13' as date),cast(2242.0 as bigint),cast(8.0 as bigint),cast(4.0 as bigint)),(cast('2019-04-06' as date),cast(2154.0 as bigint),cast(26.0 as bigint),cast(4.0 as bigint)),(cast('2019-06-18' as date),cast(4530.0 as bigint),cast(26.0 as bigint),cast(108.0 as bigint)),(cast('2018-12-16' as date),cast(3799.0 as bigint),cast(20.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-22' as date),cast(1917.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-18' as date),cast(7419.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-26' as date),cast(2271.0 as bigint),cast(3.0 as bigint),cast(60.0 as bigint)),(cast('2019-06-26' as date),cast(523.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-01' as date),cast(7294.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2019-03-19' as date),cast(6065.0 as bigint),cast(18.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-10' as date),cast(3582.0 as bigint),cast(26.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-03' as date),cast(7567.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-06' as date),cast(1160.0 as bigint),cast(13.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-23' as date),cast(2669.0 as bigint),cast(25.0 as bigint),cast(20.0 as bigint)),(cast('2018-11-25' as date),cast(6806.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-16' as date),cast(2393.0 as bigint),cast(27.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-02' as date),cast(5187.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2019-11-12' as date),cast(468.0 as bigint),cast(0.0 as bigint),cast(5.0 as bigint)),(cast('2018-10-21' as date),cast(7099.0 as bigint),cast(26.0 as bigint),cast(4.0 as bigint)),(cast('2019-01-04' as date),cast(3667.0 as bigint),cast(13.0 as bigint),cast(11.0 as bigint)),(cast('2019-07-06' as date),cast(2247.0 as bigint),cast(16.0 as bigint),cast(9.0 as bigint)),(cast('2019-06-05' as date),cast(5004.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2018-11-21' as date),cast(3916.0 as bigint),cast(27.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-28' as date),cast(128.0 as bigint),cast(12.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-13' as date),cast(6201.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2019-02-10' as date),cast(5290.0 as bigint),cast(3.0 as bigint),cast(8.0 as bigint)),(cast('2018-10-14' as date),cast(4269.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-07' as date),cast(4659.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2018-07-26' as date),cast(1667.0 as bigint),cast(25.0 as bigint),cast(9.0 as bigint)),(cast('2018-11-02' as date),cast(888.0 as bigint),cast(20.0 as bigint),cast(8.0 as bigint)),(cast('2019-07-24' as date),cast(1584.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2018-10-09' as date),cast(2639.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-14' as date),cast(5965.0 as bigint),cast(13.0 as bigint),cast(10.0 as bigint)),(cast('2019-04-01' as date),cast(6212.0 as bigint),cast(7.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-13' as date),cast(1944.0 as bigint),cast(11.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-16' as date),cast(498.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-07' as date),cast(2879.0 as bigint),cast(3.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-16' as date),cast(2415.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-08' as date),cast(7556.0 as bigint),cast(7.0 as bigint),cast(5.0 as bigint)),(cast('2019-10-20' as date),cast(5794.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-20' as date),cast(1932.0 as bigint),cast(18.0 as bigint),cast(6.0 as bigint)),(cast('2019-11-07' as date),cast(6531.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-15' as date),cast(4478.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-22' as date),cast(2607.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-23' as date),cast(2598.0 as bigint),cast(0.0 as bigint),cast(6.0 as bigint)),(cast('2019-08-15' as date),cast(5143.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-10' as date),cast(3081.0 as bigint),cast(30.0 as bigint),cast(5.0 as bigint)),(cast('2018-12-21' as date),cast(1557.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-20' as date),cast(1445.0 as bigint),cast(9.0 as bigint),cast(60.0 as bigint)),(cast('2018-12-23' as date),cast(1365.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-24' as date),cast(668.0 as bigint),cast(2.0 as bigint),cast(3.0 as bigint)),(cast('2019-05-27' as date),cast(7585.0 as bigint),cast(27.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-06' as date),cast(1673.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-05' as date),cast(709.0 as bigint),cast(16.0 as bigint),cast(220.0 as bigint)),(cast('2019-11-10' as date),cast(7318.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-07-15' as date),cast(3627.0 as bigint),cast(13.0 as bigint),cast(21.0 as bigint)),(cast('2019-11-11' as date),cast(888.0 as bigint),cast(20.0 as bigint),cast(44.0 as bigint)),(cast('2019-06-10' as date),cast(5728.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-18' as date),cast(6910.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-01' as date),cast(6632.0 as bigint),cast(22.0 as bigint),cast(5.0 as bigint)),(cast('2018-08-06' as date),cast(2490.0 as bigint),cast(7.0 as bigint),cast(9.0 as bigint)),(cast('2019-01-12' as date),cast(920.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-31' as date),cast(4984.0 as bigint),cast(25.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-18' as date),cast(6430.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-10' as date),cast(1603.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-21' as date),cast(6174.0 as bigint),cast(3.0 as bigint),cast(12.0 as bigint)),(cast('2018-11-30' as date),cast(5618.0 as bigint),cast(21.0 as bigint),cast(13.0 as bigint)),(cast('2019-05-03' as date),cast(2323.0 as bigint),cast(25.0 as bigint),cast(122.0 as bigint)),(cast('2019-07-07' as date),cast(4457.0 as bigint),cast(22.0 as bigint),cast(30.0 as bigint)),(cast('2018-08-30' as date),cast(7011.0 as bigint),cast(9.0 as bigint),cast(6.0 as bigint)),(cast('2019-11-11' as date),cast(5848.0 as bigint),cast(13.0 as bigint),cast(4.0 as bigint)),(cast('2019-01-03' as date),cast(2306.0 as bigint),cast(14.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-23' as date),cast(6534.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2019-10-31' as date),cast(6215.0 as bigint),cast(22.0 as bigint),cast(7.0 as bigint)),(cast('2019-04-16' as date),cast(2800.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-12' as date),cast(5058.0 as bigint),cast(2.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-25' as date),cast(1467.0 as bigint),cast(22.0 as bigint),cast(90.0 as bigint)),(cast('2019-07-26' as date),cast(6850.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-01' as date),cast(3913.0 as bigint),cast(13.0 as bigint),cast(7.0 as bigint)),(cast('2018-07-13' as date),cast(3454.0 as bigint),cast(14.0 as bigint),cast(8.0 as bigint)),(cast('2019-11-30' as date),cast(5117.0 as bigint),cast(27.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-30' as date),cast(4990.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-09' as date),cast(408.0 as bigint),cast(9.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-10' as date),cast(6095.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-17' as date),cast(2897.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-05' as date),cast(6845.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-23' as date),cast(1479.0 as bigint),cast(16.0 as bigint),cast(3.0 as bigint)),(cast('2019-08-17' as date),cast(2459.0 as bigint),cast(0.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-27' as date),cast(5968.0 as bigint),cast(13.0 as bigint),cast(11.0 as bigint)),(cast('2019-08-18' as date),cast(704.0 as bigint),cast(13.0 as bigint),cast(10.0 as bigint)),(cast('2018-12-23' as date),cast(3833.0 as bigint),cast(26.0 as bigint),cast(212.0 as bigint)),(cast('2018-12-13' as date),cast(2235.0 as bigint),cast(16.0 as bigint),cast(14.0 as bigint)),(cast('2019-07-31' as date),cast(6174.0 as bigint),cast(3.0 as bigint),cast(4.0 as bigint)),(cast('2018-11-07' as date),cast(702.0 as bigint),cast(6.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-12' as date),cast(7425.0 as bigint),cast(22.0 as bigint),cast(9.0 as bigint)),(cast('2019-02-08' as date),cast(2331.0 as bigint),cast(26.0 as bigint),cast(69.0 as bigint)),(cast('2019-08-11' as date),cast(582.0 as bigint),cast(26.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-07' as date),cast(3076.0 as bigint),cast(18.0 as bigint),cast(11.0 as bigint)),(cast('2019-11-28' as date),cast(7427.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-21' as date),cast(888.0 as bigint),cast(20.0 as bigint),cast(6.0 as bigint)),(cast('2019-07-19' as date),cast(5371.0 as bigint),cast(22.0 as bigint),cast(8.0 as bigint)),(cast('2018-11-03' as date),cast(3635.0 as bigint),cast(16.0 as bigint),cast(46.0 as bigint)),(cast('2019-02-02' as date),cast(3741.0 as bigint),cast(25.0 as bigint),cast(4.0 as bigint)),(cast('2019-11-02' as date),cast(6369.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-30' as date),cast(4590.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-31' as date),cast(5843.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-19' as date),cast(5448.0 as bigint),cast(1.0 as bigint),cast(12.0 as bigint)),(cast('2019-08-17' as date),cast(2823.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-26' as date),cast(2958.0 as bigint),cast(21.0 as bigint),cast(5.0 as bigint)),(cast('2019-07-12' as date),cast(5393.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-17' as date),cast(4392.0 as bigint),cast(26.0 as bigint),cast(8.0 as bigint)),(cast('2018-07-23' as date),cast(154.0 as bigint),cast(26.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-01' as date),cast(7382.0 as bigint),cast(30.0 as bigint),cast(36.0 as bigint)),(cast('2018-12-06' as date),cast(586.0 as bigint),cast(28.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-17' as date),cast(630.0 as bigint),cast(10.0 as bigint),cast(12.0 as bigint)),(cast('2018-10-23' as date),cast(5361.0 as bigint),cast(28.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-09' as date),cast(5296.0 as bigint),cast(0.0 as bigint),cast(30.0 as bigint)),(cast('2018-10-03' as date),cast(3691.0 as bigint),cast(17.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-28' as date),cast(6339.0 as bigint),cast(26.0 as bigint),cast(7.0 as bigint)),(cast('2019-07-13' as date),cast(3576.0 as bigint),cast(25.0 as bigint),cast(85.0 as bigint)),(cast('2019-11-17' as date),cast(7367.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-04' as date),cast(995.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-18' as date),cast(5371.0 as bigint),cast(22.0 as bigint),cast(17.0 as bigint)),(cast('2019-06-25' as date),cast(1187.0 as bigint),cast(2.0 as bigint),cast(45.0 as bigint)),(cast('2018-11-03' as date),cast(2430.0 as bigint),cast(23.0 as bigint),cast(8.0 as bigint)),(cast('2019-03-28' as date),cast(1719.0 as bigint),cast(2.0 as bigint),cast(79.0 as bigint)),(cast('2019-06-12' as date),cast(12.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-13' as date),cast(6438.0 as bigint),cast(24.0 as bigint),cast(8.0 as bigint)),(cast('2019-12-08' as date),cast(3659.0 as bigint),cast(20.0 as bigint),cast(4.0 as bigint)),(cast('2019-02-15' as date),cast(6634.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2019-10-20' as date),cast(3271.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-06' as date),cast(6941.0 as bigint),cast(30.0 as bigint),cast(9.0 as bigint)),(cast('2019-03-22' as date),cast(1363.0 as bigint),cast(20.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-27' as date),cast(7239.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-07' as date),cast(4996.0 as bigint),cast(5.0 as bigint),cast(6.0 as bigint)),(cast('2018-07-21' as date),cast(868.0 as bigint),cast(18.0 as bigint),cast(25.0 as bigint)),(cast('2019-08-05' as date),cast(2864.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-24' as date),cast(7384.0 as bigint),cast(5.0 as bigint),cast(9.0 as bigint)),(cast('2019-03-25' as date),cast(4691.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-22' as date),cast(944.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-05' as date),cast(2807.0 as bigint),cast(26.0 as bigint),cast(24.0 as bigint)),(cast('2019-04-22' as date),cast(6933.0 as bigint),cast(25.0 as bigint),cast(43.0 as bigint)),(cast('2019-09-18' as date),cast(287.0 as bigint),cast(6.0 as bigint),cast(4.0 as bigint)),(cast('2019-03-14' as date),cast(3047.0 as bigint),cast(4.0 as bigint),cast(4.0 as bigint)),(cast('2019-06-20' as date),cast(652.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2019-01-11' as date),cast(4445.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-04' as date),cast(6695.0 as bigint),cast(9.0 as bigint),cast(5.0 as bigint)),(cast('2018-07-27' as date),cast(398.0 as bigint),cast(22.0 as bigint),cast(8.0 as bigint)),(cast('2019-04-27' as date),cast(2736.0 as bigint),cast(25.0 as bigint),cast(5.0 as bigint)),(cast('2018-07-17' as date),cast(2430.0 as bigint),cast(23.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-15' as date),cast(5407.0 as bigint),cast(13.0 as bigint),cast(68.0 as bigint)),(cast('2019-11-23' as date),cast(4191.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-23' as date),cast(5284.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-29' as date),cast(2837.0 as bigint),cast(18.0 as bigint),cast(131.0 as bigint)),(cast('2019-11-17' as date),cast(5250.0 as bigint),cast(3.0 as bigint),cast(13.0 as bigint)),(cast('2018-07-23' as date),cast(2190.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2019-02-14' as date),cast(4627.0 as bigint),cast(26.0 as bigint),cast(5.0 as bigint)),(cast('2019-04-03' as date),cast(4635.0 as bigint),cast(22.0 as bigint),cast(5.0 as bigint)),(cast('2019-02-27' as date),cast(5363.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-02' as date),cast(4457.0 as bigint),cast(22.0 as bigint),cast(80.0 as bigint)),(cast('2019-08-17' as date),cast(6253.0 as bigint),cast(30.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-11' as date),cast(3524.0 as bigint),cast(25.0 as bigint),cast(99.0 as bigint)),(cast('2019-10-10' as date),cast(2232.0 as bigint),cast(18.0 as bigint),cast(23.0 as bigint)),(cast('2018-12-28' as date),cast(383.0 as bigint),cast(25.0 as bigint),cast(15.0 as bigint)),(cast('2019-07-09' as date),cast(6128.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-04' as date),cast(2706.0 as bigint),cast(9.0 as bigint),cast(8.0 as bigint)),(cast('2019-08-11' as date),cast(7430.0 as bigint),cast(1.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-12' as date),cast(4030.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2018-08-06' as date),cast(4809.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-18' as date),cast(4594.0 as bigint),cast(22.0 as bigint),cast(6.0 as bigint)),(cast('2019-01-20' as date),cast(1811.0 as bigint),cast(25.0 as bigint),cast(6.0 as bigint)),(cast('2019-07-13' as date),cast(2465.0 as bigint),cast(29.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-01' as date),cast(7331.0 as bigint),cast(17.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-05' as date),cast(4018.0 as bigint),cast(13.0 as bigint),cast(6.0 as bigint)),(cast('2019-07-23' as date),cast(4870.0 as bigint),cast(16.0 as bigint),cast(21.0 as bigint)),(cast('2018-11-03' as date),cast(1404.0 as bigint),cast(21.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-14' as date),cast(3241.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-20' as date),cast(5203.0 as bigint),cast(27.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-13' as date),cast(803.0 as bigint),cast(23.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-27' as date),cast(1307.0 as bigint),cast(1.0 as bigint),cast(7.0 as bigint)),(cast('2019-12-16' as date),cast(335.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2018-09-01' as date),cast(3679.0 as bigint),cast(6.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-30' as date),cast(2542.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-10' as date),cast(3800.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2018-12-26' as date),cast(7378.0 as bigint),cast(21.0 as bigint),cast(8.0 as bigint)),(cast('2019-08-12' as date),cast(393.0 as bigint),cast(3.0 as bigint),cast(85.0 as bigint)),(cast('2019-07-20' as date),cast(6933.0 as bigint),cast(25.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-26' as date),cast(2430.0 as bigint),cast(23.0 as bigint),cast(17.0 as bigint)),(cast('2018-11-01' as date),cast(4495.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-05' as date),cast(5848.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-30' as date),cast(7175.0 as bigint),cast(24.0 as bigint),cast(7.0 as bigint)),(cast('2019-04-30' as date),cast(7510.0 as bigint),cast(16.0 as bigint),cast(5.0 as bigint)),(cast('2019-11-02' as date),cast(398.0 as bigint),cast(22.0 as bigint),cast(12.0 as bigint)),(cast('2019-10-25' as date),cast(1527.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-14' as date),cast(2897.0 as bigint),cast(26.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-14' as date),cast(5666.0 as bigint),cast(25.0 as bigint),cast(2.0 as bigint)),(cast('2019-12-04' as date),cast(7223.0 as bigint),cast(2.0 as bigint),cast(15.0 as bigint)),(cast('2019-04-03' as date),cast(5314.0 as bigint),cast(11.0 as bigint),cast(7.0 as bigint)),(cast('2019-07-03' as date),cast(7368.0 as bigint),cast(25.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-05' as date),cast(5363.0 as bigint),cast(23.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-27' as date),cast(7577.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-09' as date),cast(6850.0 as bigint),cast(1.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-20' as date),cast(4413.0 as bigint),cast(3.0 as bigint),cast(7.0 as bigint)),(cast('2018-09-03' as date),cast(3107.0 as bigint),cast(9.0 as bigint),cast(2.0 as bigint)),(cast('2018-11-18' as date),cast(3904.0 as bigint),cast(1.0 as bigint),cast(9.0 as bigint)),(cast('2019-12-07' as date),cast(1564.0 as bigint),cast(13.0 as bigint),cast(96.0 as bigint)),(cast('2018-08-02' as date),cast(1943.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-10' as date),cast(1533.0 as bigint),cast(18.0 as bigint),cast(82.0 as bigint)),(cast('2018-10-31' as date),cast(2714.0 as bigint),cast(28.0 as bigint),cast(8.0 as bigint)),(cast('2019-05-29' as date),cast(4586.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-09' as date),cast(2502.0 as bigint),cast(13.0 as bigint),cast(5.0 as bigint)),(cast('2019-02-20' as date),cast(2945.0 as bigint),cast(22.0 as bigint),cast(2.0 as bigint)),(cast('2019-07-12' as date),cast(3247.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2018-10-09' as date),cast(6803.0 as bigint),cast(19.0 as bigint),cast(23.0 as bigint)),(cast('2019-07-24' as date),cast(7148.0 as bigint),cast(16.0 as bigint),cast(9.0 as bigint)),(cast('2019-03-24' as date),cast(5031.0 as bigint),cast(0.0 as bigint),cast(6.0 as bigint)),(cast('2019-10-18' as date),cast(4128.0 as bigint),cast(18.0 as bigint),cast(2.0 as bigint)),(cast('2019-06-17' as date),cast(1828.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-22' as date),cast(133.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2019-02-18' as date),cast(5428.0 as bigint),cast(26.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-13' as date),cast(5073.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-20' as date),cast(7510.0 as bigint),cast(16.0 as bigint),cast(2.0 as bigint)),(cast('2018-10-10' as date),cast(3965.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-04-25' as date),cast(2504.0 as bigint),cast(2.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-12' as date),cast(3315.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2019-08-05' as date),cast(7140.0 as bigint),cast(18.0 as bigint),cast(37.0 as bigint)),(cast('2019-03-08' as date),cast(2668.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-12' as date),cast(4908.0 as bigint),cast(14.0 as bigint),cast(4.0 as bigint)),(cast('2018-10-31' as date),cast(1307.0 as bigint),cast(1.0 as bigint),cast(3.0 as bigint)),(cast('2019-07-13' as date),cast(2457.0 as bigint),cast(3.0 as bigint),cast(25.0 as bigint)),(cast('2019-01-25' as date),cast(1613.0 as bigint),cast(28.0 as bigint),cast(6.0 as bigint)),(cast('2018-09-01' as date),cast(2264.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-01' as date),cast(6386.0 as bigint),cast(2.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-26' as date),cast(6315.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-27' as date),cast(3995.0 as bigint),cast(18.0 as bigint),cast(31.0 as bigint)),(cast('2019-03-28' as date),cast(1658.0 as bigint),cast(16.0 as bigint),cast(27.0 as bigint)),(cast('2018-11-23' as date),cast(1073.0 as bigint),cast(2.0 as bigint),cast(1.0 as bigint)),(cast('2018-09-01' as date),cast(1484.0 as bigint),cast(3.0 as bigint),cast(19.0 as bigint)),(cast('2018-12-27' as date),cast(1935.0 as bigint),cast(2.0 as bigint),cast(62.0 as bigint)),(cast('2019-07-07' as date),cast(6640.0 as bigint),cast(26.0 as bigint),cast(48.0 as bigint)),(cast('2018-12-04' as date),cast(219.0 as bigint),cast(3.0 as bigint),cast(3.0 as bigint)),(cast('2019-01-02' as date),cast(5371.0 as bigint),cast(22.0 as bigint),cast(4.0 as bigint)),(cast('2019-12-07' as date),cast(6801.0 as bigint),cast(3.0 as bigint),cast(7.0 as bigint)),(cast('2018-09-06' as date),cast(6716.0 as bigint),cast(16.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-14' as date),cast(2654.0 as bigint),cast(11.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-19' as date),cast(6390.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-04' as date),cast(7138.0 as bigint),cast(28.0 as bigint),cast(3.0 as bigint)),(cast('2019-02-08' as date),cast(1973.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-30' as date),cast(1931.0 as bigint),cast(0.0 as bigint),cast(57.0 as bigint)),(cast('2019-08-02' as date),cast(2051.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-19' as date),cast(1047.0 as bigint),cast(30.0 as bigint),cast(5.0 as bigint)),(cast('2019-06-21' as date),cast(4587.0 as bigint),cast(9.0 as bigint),cast(22.0 as bigint)),(cast('2018-08-07' as date),cast(5278.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2019-03-02' as date),cast(7208.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-11' as date),cast(4108.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2019-11-16' as date),cast(2999.0 as bigint),cast(7.0 as bigint),cast(1.0 as bigint)),(cast('2019-07-23' as date),cast(4342.0 as bigint),cast(22.0 as bigint),cast(29.0 as bigint)),(cast('2019-07-26' as date),cast(4439.0 as bigint),cast(2.0 as bigint),cast(24.0 as bigint)),(cast('2018-07-17' as date),cast(2568.0 as bigint),cast(22.0 as bigint),cast(8.0 as bigint)),(cast('2018-11-10' as date),cast(6309.0 as bigint),cast(29.0 as bigint),cast(11.0 as bigint)),(cast('2019-11-17' as date),cast(88.0 as bigint),cast(24.0 as bigint),cast(13.0 as bigint)),(cast('2018-08-04' as date),cast(5389.0 as bigint),cast(24.0 as bigint),cast(2.0 as bigint)),(cast('2019-01-01' as date),cast(6533.0 as bigint),cast(17.0 as bigint),cast(5.0 as bigint)),(cast('2019-05-10' as date),cast(2137.0 as bigint),cast(2.0 as bigint),cast(10.0 as bigint)),(cast('2018-08-02' as date),cast(2238.0 as bigint),cast(22.0 as bigint),cast(5.0 as bigint)),(cast('2018-08-18' as date),cast(6492.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-11-24' as date),cast(1848.0 as bigint),cast(14.0 as bigint),cast(120.0 as bigint)),(cast('2019-06-21' as date),cast(7350.0 as bigint),cast(16.0 as bigint),cast(31.0 as bigint)),(cast('2018-11-05' as date),cast(5738.0 as bigint),cast(13.0 as bigint),cast(42.0 as bigint)),(cast('2018-07-20' as date),cast(7334.0 as bigint),cast(21.0 as bigint),cast(9.0 as bigint)),(cast('2019-07-12' as date),cast(5250.0 as bigint),cast(3.0 as bigint),cast(9.0 as bigint)),(cast('2019-11-04' as date),cast(1875.0 as bigint),cast(13.0 as bigint),cast(4.0 as bigint)),(cast('2018-12-07' as date),cast(1700.0 as bigint),cast(8.0 as bigint),cast(2.0 as bigint)),(cast('2018-09-30' as date),cast(954.0 as bigint),cast(2.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-25' as date),cast(5926.0 as bigint),cast(13.0 as bigint),cast(24.0 as bigint)),(cast('2018-09-10' as date),cast(2220.0 as bigint),cast(2.0 as bigint),cast(99.0 as bigint)),(cast('2019-10-14' as date),cast(7011.0 as bigint),cast(9.0 as bigint),cast(24.0 as bigint)),(cast('2018-12-06' as date),cast(6740.0 as bigint),cast(13.0 as bigint),cast(3.0 as bigint)),(cast('2019-05-13' as date),cast(1980.0 as bigint),cast(6.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-17' as date),cast(5975.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-06-11' as date),cast(6093.0 as bigint),cast(28.0 as bigint),cast(1.0 as bigint)),(cast('2019-02-12' as date),cast(754.0 as bigint),cast(18.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-28' as date),cast(1307.0 as bigint),cast(1.0 as bigint),cast(9.0 as bigint)),(cast('2018-11-23' as date),cast(3197.0 as bigint),cast(17.0 as bigint),cast(15.0 as bigint)),(cast('2019-04-17' as date),cast(1233.0 as bigint),cast(16.0 as bigint),cast(18.0 as bigint)),(cast('2019-11-08' as date),cast(5282.0 as bigint),cast(4.0 as bigint),cast(6.0 as bigint)),(cast('2018-09-08' as date),cast(547.0 as bigint),cast(4.0 as bigint),cast(19.0 as bigint)),(cast('2019-06-11' as date),cast(5436.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-01' as date),cast(888.0 as bigint),cast(20.0 as bigint),cast(14.0 as bigint)),(cast('2019-04-18' as date),cast(5320.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-14' as date),cast(460.0 as bigint),cast(18.0 as bigint),cast(4.0 as bigint)),(cast('2018-11-13' as date),cast(2845.0 as bigint),cast(23.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-19' as date),cast(2426.0 as bigint),cast(22.0 as bigint),cast(1.0 as bigint)),(cast('2018-08-03' as date),cast(3783.0 as bigint),cast(14.0 as bigint),cast(3.0 as bigint)),(cast('2019-06-17' as date),cast(7526.0 as bigint),cast(14.0 as bigint),cast(12.0 as bigint)),(cast('2019-06-22' as date),cast(354.0 as bigint),cast(13.0 as bigint),cast(2.0 as bigint)),(cast('2019-08-02' as date),cast(6399.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-11-23' as date),cast(528.0 as bigint),cast(0.0 as bigint),cast(3.0 as bigint)),(cast('2018-12-08' as date),cast(5486.0 as bigint),cast(14.0 as bigint),cast(1.0 as bigint)),(cast('2019-08-18' as date),cast(1406.0 as bigint),cast(14.0 as bigint),cast(26.0 as bigint)),(cast('2018-12-25' as date),cast(27.0 as bigint),cast(10.0 as bigint),cast(41.0 as bigint)),(cast('2019-02-03' as date),cast(5022.0 as bigint),cast(2.0 as bigint),cast(43.0 as bigint)),(cast('2019-02-20' as date),cast(438.0 as bigint),cast(22.0 as bigint),cast(28.0 as bigint)),(cast('2018-10-28' as date),cast(3034.0 as bigint),cast(0.0 as bigint),cast(1.0 as bigint)),(cast('2019-01-12' as date),cast(5780.0 as bigint),cast(0.0 as bigint),cast(2.0 as bigint)),(cast('2019-11-01' as date),cast(4146.0 as bigint),cast(9.0 as bigint),cast(1.0 as bigint)),(cast('2019-10-08' as date),cast(1062.0 as bigint),cast(13.0 as bigint),cast(22.0 as bigint)),(cast('2018-10-23' as date),cast(785.0 as bigint),cast(16.0 as bigint),cast(1.0 as bigint)),(cast('2018-10-08' as date),cast(255.0 as bigint),cast(13.0 as bigint),cast(1.0 as bigint)),(cast('2018-12-06' as date),cast(5521.0 as bigint),cast(7.0 as bigint),cast(1.0 as bigint)),(cast('2019-05-07' as date),cast(487.0 as bigint),cast(26.0 as bigint),cast(14.0 as bigint)),(cast('2019-03-03' as date),cast(1503.0 as bigint),cast(21.0 as bigint),cast(2.0 as bigint)),(cast('2019-10-15' as date),cast(6371.0 as bigint),cast(7.0 as bigint),cast(22.0 as bigint))
      ' with f56522a4-d63f-4ae4-9f86-3244362dced6
2025-08-06 09:08:29,190 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with f56522a4-d63f-4ae4-9f86-3244362dced6
2025-08-06 09:08:29,200 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Executor 1 on 172.18.0.11 killed by driver.
2025-08-06 09:08:29,201 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Executor lost: 1 (epoch 1)
2025-08-06 09:08:29,202 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - Executor 1 is removed. Remove reason statistics: (gracefully decommissioned: 0, decommision unfinished: 0, driver killed: 2, unexpectedly exited: 0).
2025-08-06 09:08:29,202 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Trying to remove executor 1 from BlockManagerMaster.
2025-08-06 09:08:29,202 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Removing block manager BlockManagerId(1, 172.18.0.11, 39111, None)
2025-08-06 09:08:29,203 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.BlockManagerMaster - Removed 1 successfully in removeExecutor
2025-08-06 09:08:29,203 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Shuffle files lost for executor: 1 (epoch 1)
2025-08-06 09:08:29,526 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 32.0 KiB, free 127.2 MiB)
2025-08-06 09:08:29,531 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 127.1 MiB)
2025-08-06 09:08:29,534 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on c15f4bd07d87:41285 (size: 29.4 KiB, free: 127.2 MiB)
2025-08-06 09:08:29,537 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.spark.SparkContext - Created broadcast 6 from broadcast at SparkWrite.java:193
2025-08-06 09:08:29,541 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.spark.sql.execution.datasources.v2.AppendDataExec - Start processing data source write support: IcebergBatchWrite(table=hive_catalog.default.orders, format=PARQUET). The input RDD has 2 partitions.
2025-08-06 09:08:29,549 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.spark.SparkContext - Starting job: run at AccessController.java:712
2025-08-06 09:08:29,551 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 2 (run at AccessController.java:712) with 2 output partitions
2025-08-06 09:08:29,551 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 2 (run at AccessController.java:712)
2025-08-06 09:08:29,552 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-08-06 09:08:29,553 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2025-08-06 09:08:29,554 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 2 (MapPartitionsRDD[6] at run at AccessController.java:712), which has no missing parents
2025-08-06 09:08:29,559 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 8.0 KiB, free 127.1 MiB)
2025-08-06 09:08:29,563 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 127.1 MiB)
2025-08-06 09:08:29,565 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on c15f4bd07d87:41285 (size: 4.5 KiB, free: 127.2 MiB)
2025-08-06 09:08:29,567 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 7 from broadcast at DAGScheduler.scala:1535
2025-08-06 09:08:29,568 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 2 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at run at AccessController.java:712) (first 15 tasks are for partitions Vector(0, 1))
2025-08-06 09:08:29,569 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 2.0 with 2 tasks resource profile 0
2025-08-06 09:08:30,769 [spark-dynamic-executor-allocation] INFO  org.apache.spark.ExecutorAllocationManager - Requesting 1 new executor because tasks are backlogged (new desired total will be 1 for resource profile id: 0)
2025-08-06 09:08:30,769 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor added: app-20250806090436-0000/2 on worker-20250806090434-172.18.0.11-33083 (172.18.0.11:33083) with 2 core(s)
2025-08-06 09:08:30,770 [dispatcher-event-loop-10] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Granted executor ID app-20250806090436-0000/2 on hostPort 172.18.0.11:33083 with 2 core(s), 1024.0 MiB RAM
2025-08-06 09:08:30,827 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint - Executor updated: app-20250806090436-0000/2 is now RUNNING
2025-08-06 09:08:33,547 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend$StandaloneDriverEndpoint - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.18.0.11:40492) with ID 2,  ResourceProfileId 0
2025-08-06 09:08:33,549 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - New executor 2 has registered (new total is 1)
2025-08-06 09:08:33,615 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 172.18.0.11:41877 with 434.4 MiB RAM, BlockManagerId(2, 172.18.0.11, 41877, None)
2025-08-06 09:08:33,655 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 2.0 (TID 3) (172.18.0.11, executor 2, partition 0, PROCESS_LOCAL, 36006 bytes) 
2025-08-06 09:08:33,656 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 2.0 (TID 4) (172.18.0.11, executor 2, partition 1, PROCESS_LOCAL, 36006 bytes) 
2025-08-06 09:08:33,876 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_7_piece0 in memory on 172.18.0.11:41877 (size: 4.5 KiB, free: 434.4 MiB)
2025-08-06 09:08:34,116 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_6_piece0 in memory on 172.18.0.11:41877 (size: 29.4 KiB, free: 434.4 MiB)
2025-08-06 09:08:36,808 [task-result-getter-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 2.0 (TID 3) in 3154 ms on 172.18.0.11 (executor 2) (1/2)
2025-08-06 09:08:36,809 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 2.0 (TID 4) in 3154 ms on 172.18.0.11 (executor 2) (2/2)
2025-08-06 09:08:36,809 [task-result-getter-1] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2025-08-06 09:08:36,810 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 2 (run at AccessController.java:712) finished in 7.254 s
2025-08-06 09:08:36,811 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
2025-08-06 09:08:36,811 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 2: Stage finished
2025-08-06 09:08:36,812 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.spark.scheduler.DAGScheduler - Job 2 finished: run at AccessController.java:712, took 7.099120 s
2025-08-06 09:08:36,813 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.spark.sql.execution.datasources.v2.AppendDataExec - Data source write support IcebergBatchWrite(table=hive_catalog.default.orders, format=PARQUET) is committing.
2025-08-06 09:08:36,813 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.iceberg.spark.source.SparkWrite - Committing append with 2 new data files to table hive_catalog.default.orders
2025-08-06 09:08:37,010 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.iceberg.hive.HiveTableOperations - Committed to table hive_catalog.default.orders with the new metadata location s3a://iceberg-warehouse/orders/metadata/00001-7a3803c8-c2cd-4373-b18d-39e0519f462b.metadata.json
2025-08-06 09:08:37,010 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table hive_catalog.default.orders in 89 ms
2025-08-06 09:08:37,011 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.iceberg.SnapshotProducer - Committed snapshot 7217802333294063596 (MergeAppend)
2025-08-06 09:08:37,037 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/orders/metadata/00001-7a3803c8-c2cd-4373-b18d-39e0519f462b.metadata.json
2025-08-06 09:08:37,048 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.iceberg.metrics.LoggingMetricsReporter - Received metrics report: CommitReport{tableName=hive_catalog.default.orders, snapshotId=7217802333294063596, sequenceNumber=1, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.211441375S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=2}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=2}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, addedDVs=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, removedDVs=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=1000}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=1000}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=9504}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=9504}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}, manifestsCreated=null, manifestsReplaced=null, manifestsKept=null, manifestEntriesProcessed=null}, metadata={engine-version=3.4.1, app-id=app-20250806090436-0000, engine-name=spark, iceberg-version=Apache Iceberg 1.9.2 (commit 071d5606bc6199a0be9b3f274ec7fbf111d88821)}}
2025-08-06 09:08:37,049 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.iceberg.spark.source.SparkWrite - Committed in 235 ms
2025-08-06 09:08:37,049 [HiveServer2-Background-Pool: Thread-215] INFO  org.apache.spark.sql.execution.datasources.v2.AppendDataExec - Data source write support IcebergBatchWrite(table=hive_catalog.default.orders, format=PARQUET) committed.
2025-08-06 09:08:37,121 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group f56522a4-d63f-4ae4-9f86-3244362dced6
2025-08-06 09:08:37,121 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with f56522a4-d63f-4ae4-9f86-3244362dced6
2025-08-06 09:08:37,123 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 5a91c9f9-b1af-49d3-9649-ecf18df47937
2025-08-06 09:08:37,123 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 5a91c9f9-b1af-49d3-9649-ecf18df47937
2025-08-06 09:08:37,124 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group b91838ad-f2ec-4081-932a-9d284406c45f
2025-08-06 09:08:37,124 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with b91838ad-f2ec-4081-932a-9d284406c45f
2025-08-06 09:08:37,130 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 09:08:37,131 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 09:08:37,131 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 09:08:37,132 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:08:37,148 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:08:37,154 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/1bc8a4e0-ae53-480f-925c-ad0fba7b0341
2025-08-06 09:08:37,159 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with 7f7ecbbe-b7ec-4d9e-aff9-69bfce393c9e
2025-08-06 09:08:37,160 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 7f7ecbbe-b7ec-4d9e-aff9-69bfce393c9e
2025-08-06 09:08:37,204 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 7f7ecbbe-b7ec-4d9e-aff9-69bfce393c9e
2025-08-06 09:08:37,205 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 7f7ecbbe-b7ec-4d9e-aff9-69bfce393c9e
2025-08-06 09:08:37,217 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:08:43,017 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:08:43,019 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/6317524f-a421-413b-a78b-df6af3b59b69
2025-08-06 09:08:43,022 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with c1d9391c-c9e9-473b-baf3-a6715f5c73b6
2025-08-06 09:08:43,022 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with c1d9391c-c9e9-473b-baf3-a6715f5c73b6
2025-08-06 09:08:43,041 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group c1d9391c-c9e9-473b-baf3-a6715f5c73b6
2025-08-06 09:08:43,042 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with c1d9391c-c9e9-473b-baf3-a6715f5c73b6
2025-08-06 09:08:43,044 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_schemas"} */

    show databases
  ' with 5e010aee-1211-4b3c-a0f2-aea649682d49
2025-08-06 09:08:43,045 [HiveServer2-Background-Pool: Thread-230] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 5e010aee-1211-4b3c-a0f2-aea649682d49
2025-08-06 09:08:43,067 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<namespace: STRING>
2025-08-06 09:08:43,072 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 5e010aee-1211-4b3c-a0f2-aea649682d49
2025-08-06 09:08:43,073 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 5e010aee-1211-4b3c-a0f2-aea649682d49
2025-08-06 09:08:43,076 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:08:43,095 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:08:43,098 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/8748deb0-faa4-437a-9940-ea9d50b2e0f5
2025-08-06 09:08:43,101 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with 2299246f-8f12-4513-96fa-c08559ed7cee
2025-08-06 09:08:43,101 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 2299246f-8f12-4513-96fa-c08559ed7cee
2025-08-06 09:08:43,120 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 2299246f-8f12-4513-96fa-c08559ed7cee
2025-08-06 09:08:43,121 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 2299246f-8f12-4513-96fa-c08559ed7cee
2025-08-06 09:08:43,123 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
show table extended in default like '*'
  ' with 228dd453-082d-4862-8c50-ef2de0054368
2025-08-06 09:08:43,124 [HiveServer2-Background-Pool: Thread-231] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 228dd453-082d-4862-8c50-ef2de0054368
2025-08-06 09:08:43,127 [HiveServer2-Background-Pool: Thread-231] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 228dd453-082d-4862-8c50-ef2de0054368
2025-08-06 09:08:43,128 [HiveServer2-Background-Pool: Thread-231] ERROR org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Error executing query with 228dd453-082d-4862-8c50-ef2de0054368, currentState RUNNING, 
org.apache.spark.sql.AnalysisException: SHOW TABLE EXTENDED is not supported for v2 tables.;
ShowTableExtended *, [namespace#239, tableName#240, isTemporary#241, information#242]
+- ResolvedNamespace org.apache.iceberg.spark.SparkCatalog@3441a3ad, [default]

	at org.apache.spark.sql.errors.QueryCompilationErrors$.commandUnsupportedInV2TableError(QueryCompilationErrors.scala:2035) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$1(CheckAnalysis.scala:224) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$1$adapted(CheckAnalysis.scala:163) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:295) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:163) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:160) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:188) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:156) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:146) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:188) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:211) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:208) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111) ~[spark-catalyst_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:202) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:526) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:202) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:201) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:98) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:96) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:640) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:630) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:671) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:651) ~[spark-sql_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:226) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:165) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.17.jar:?]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:79) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:63) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:40) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:165) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:160) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at java.security.AccessController.doPrivileged(AccessController.java:712) ~[?:?]
	at javax.security.auth.Subject.doAs(Subject.java:439) ~[?:?]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) ~[hadoop-client-api-3.3.4.jar:?]
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:174) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:08:43,142 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
show tables in default like '*'
  ' with 5e727789-ae0c-4678-8b33-a7f147be9f1a
2025-08-06 09:08:43,144 [HiveServer2-Background-Pool: Thread-232] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 5e727789-ae0c-4678-8b33-a7f147be9f1a
2025-08-06 09:08:43,192 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<namespace: STRING, tableName: STRING, isTemporary: BOOLEAN>
2025-08-06 09:08:43,208 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
describe extended default.orders_by_date
  ' with 2cb1f6f3-26c5-4f6b-b56a-056da1906969
2025-08-06 09:08:43,210 [HiveServer2-Background-Pool: Thread-233] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 2cb1f6f3-26c5-4f6b-b56a-056da1906969
2025-08-06 09:08:43,228 [HiveServer2-Background-Pool: Thread-233] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/output/orders/orders_by_date/metadata/00000-29b320db-a5ec-4cf5-94d1-eb791d9ef335.metadata.json
2025-08-06 09:08:43,232 [HiveServer2-Background-Pool: Thread-233] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 09:08:43,233 [HiveServer2-Background-Pool: Thread-233] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 09:08:43,234 [HiveServer2-Background-Pool: Thread-233] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 09:08:43,249 [HiveServer2-Background-Pool: Thread-233] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive_catalog.default.orders_by_date
2025-08-06 09:08:43,278 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<col_name: STRING COMMENT 'name of the column', data_type: STRING COMMENT 'data type of the column', comment: STRING COMMENT 'comment of the column'>
2025-08-06 09:08:43,288 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "connection_name": "list_None_default"} */
describe extended default.orders
  ' with 176e02e8-b7e8-4cb6-8f19-0617e0fcb917
2025-08-06 09:08:43,289 [HiveServer2-Background-Pool: Thread-236] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with 176e02e8-b7e8-4cb6-8f19-0617e0fcb917
2025-08-06 09:08:43,301 [HiveServer2-Background-Pool: Thread-236] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/orders/metadata/00001-7a3803c8-c2cd-4373-b18d-39e0519f462b.metadata.json
2025-08-06 09:08:43,310 [HiveServer2-Background-Pool: Thread-236] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive_catalog.default.orders
2025-08-06 09:08:43,334 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Result Schema: STRUCT<col_name: STRING COMMENT 'name of the column', data_type: STRING COMMENT 'data type of the column', comment: STRING COMMENT 'comment of the column'>
2025-08-06 09:08:43,341 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 176e02e8-b7e8-4cb6-8f19-0617e0fcb917
2025-08-06 09:08:43,342 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 176e02e8-b7e8-4cb6-8f19-0617e0fcb917
2025-08-06 09:08:43,343 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 5e727789-ae0c-4678-8b33-a7f147be9f1a
2025-08-06 09:08:43,344 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 5e727789-ae0c-4678-8b33-a7f147be9f1a
2025-08-06 09:08:43,344 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 2cb1f6f3-26c5-4f6b-b56a-056da1906969
2025-08-06 09:08:43,344 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 2cb1f6f3-26c5-4f6b-b56a-056da1906969
2025-08-06 09:08:43,345 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group 228dd453-082d-4862-8c50-ef2de0054368
2025-08-06 09:08:43,345 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with 228dd453-082d-4862-8c50-ef2de0054368
2025-08-06 09:08:43,347 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 09:08:43,348 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 09:08:43,348 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 09:08:43,348 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:08:43,459 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:08:43,462 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/6a8e2ee8-4626-4feb-b470-c5dec166f024
2025-08-06 09:08:43,469 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with de0f817c-c5e5-4f20-8bbd-5b3c89ab2625
2025-08-06 09:08:43,470 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with de0f817c-c5e5-4f20-8bbd-5b3c89ab2625
2025-08-06 09:08:43,509 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group de0f817c-c5e5-4f20-8bbd-5b3c89ab2625
2025-08-06 09:08:43,510 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with de0f817c-c5e5-4f20-8bbd-5b3c89ab2625
2025-08-06 09:08:43,511 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on c15f4bd07d87:41285 in memory (size: 29.4 KiB, free: 127.2 MiB)
2025-08-06 09:08:43,513 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query '/* {"app": "dbt", "dbt_version": "1.9.0b2", "profile_name": "dbt_main_project", "target_name": "dev", "node_id": "model.dag.orders_by_date"} */

  
    
        create or replace table default.orders_by_date
      
      
    using iceberg
      
      
      
      
      
    location 's3a://iceberg-warehouse/output/orders/orders_by_date'
      

      as
      

SELECT
    date,
    COUNT(*) as order_count
FROM default.orders
WHERE date > '2018-01-01'
GROUP BY date
  ' with f856a9f5-5bf7-439e-a600-2a4b7ccb5feb
2025-08-06 09:08:43,515 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with f856a9f5-5bf7-439e-a600-2a4b7ccb5feb
2025-08-06 09:08:43,540 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/orders/metadata/00001-7a3803c8-c2cd-4373-b18d-39e0519f462b.metadata.json
2025-08-06 09:08:43,541 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on 172.18.0.11:41877 in memory (size: 29.4 KiB, free: 434.4 MiB)
2025-08-06 09:08:43,544 [HiveServer2-Background-Pool: Thread-242] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 09:08:43,547 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 09:08:43,548 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 09:08:43,551 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on c15f4bd07d87:41285 in memory (size: 4.5 KiB, free: 127.2 MiB)
2025-08-06 09:08:43,554 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on 172.18.0.11:41877 in memory (size: 4.5 KiB, free: 434.4 MiB)
2025-08-06 09:08:43,563 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive_catalog.default.orders
2025-08-06 09:08:43,584 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown - 
Pushing operators to hive_catalog.default.orders
Pushed Filters: date IS NOT NULL, date > 17532
Post-Scan Filters: isnotnull(date#311),(date#311 > 2018-01-01)
         
2025-08-06 09:08:43,586 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.sql.execution.datasources.v2.V2ScanRelationPushDown - 
Output: date#311
         
2025-08-06 09:08:43,587 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.SnapshotScan - Scanning table hive_catalog.default.orders snapshot 7217802333294063596 created at 2025-08-06T09:08:36.921+00:00 with filter (date IS NOT NULL AND date > (5-digit-int))
2025-08-06 09:08:43,600 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.BaseDistributedDataScan - Planning file tasks locally for table hive_catalog.default.orders
2025-08-06 09:08:43,614 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.spark.source.SparkPartitioningAwareScan - Reporting UnknownPartitioning with 1 partition(s) for table hive_catalog.default.orders
2025-08-06 09:08:43,621 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 32.0 KiB, free 127.2 MiB)
2025-08-06 09:08:43,624 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 127.1 MiB)
2025-08-06 09:08:43,626 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on c15f4bd07d87:41285 (size: 29.6 KiB, free: 127.2 MiB)
2025-08-06 09:08:43,627 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.SparkContext - Created broadcast 8 from broadcast at SparkBatch.java:85
2025-08-06 09:08:43,632 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 32.0 KiB, free 127.1 MiB)
2025-08-06 09:08:43,635 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 127.1 MiB)
2025-08-06 09:08:43,636 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on c15f4bd07d87:41285 (size: 29.6 KiB, free: 127.1 MiB)
2025-08-06 09:08:43,637 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.SparkContext - Created broadcast 9 from broadcast at SparkBatch.java:85
2025-08-06 09:08:43,654 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/output/orders/orders_by_date/metadata/00000-29b320db-a5ec-4cf5-94d1-eb791d9ef335.metadata.json
2025-08-06 09:08:43,670 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table loaded by catalog: hive_catalog.default.orders_by_date
2025-08-06 09:08:43,672 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table properties set at catalog level through catalog properties: {}
2025-08-06 09:08:43,686 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.BaseMetastoreCatalog - Table properties enforced at catalog level through catalog properties: {}
2025-08-06 09:08:43,701 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Refreshing table metadata from new version: s3a://iceberg-warehouse/output/orders/orders_by_date/metadata/00000-29b320db-a5ec-4cf5-94d1-eb791d9ef335.metadata.json
2025-08-06 09:08:43,717 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.sql.execution.aggregate.HashAggregateExec - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2025-08-06 09:08:43,731 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 32.0 KiB, free 127.0 MiB)
2025-08-06 09:08:43,739 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 127.0 MiB)
2025-08-06 09:08:43,742 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on c15f4bd07d87:41285 (size: 29.3 KiB, free: 127.1 MiB)
2025-08-06 09:08:43,743 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.SparkContext - Created broadcast 10 from broadcast at SparkWrite.java:193
2025-08-06 09:08:43,744 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec - Start processing data source write support: IcebergBatchWrite(table=default.orders_by_date, format=PARQUET). The input RDD has 1 partitions.
2025-08-06 09:08:43,746 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.SparkContext - Starting job: run at AccessController.java:712
2025-08-06 09:08:43,747 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 3 (run at AccessController.java:712) with 1 output partitions
2025-08-06 09:08:43,747 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 3 (run at AccessController.java:712)
2025-08-06 09:08:43,747 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
2025-08-06 09:08:43,748 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2025-08-06 09:08:43,748 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[9] at run at AccessController.java:712), which has no missing parents
2025-08-06 09:08:43,753 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 44.5 KiB, free 127.0 MiB)
2025-08-06 09:08:43,755 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 127.0 MiB)
2025-08-06 09:08:43,757 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on c15f4bd07d87:41285 (size: 18.9 KiB, free: 127.1 MiB)
2025-08-06 09:08:43,758 [dag-scheduler-event-loop] INFO  org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1535
2025-08-06 09:08:43,759 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at run at AccessController.java:712) (first 15 tasks are for partitions Vector(0))
2025-08-06 09:08:43,759 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
2025-08-06 09:08:43,761 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 5) (172.18.0.11, executor 2, partition 0, PROCESS_LOCAL, 12779 bytes) 
2025-08-06 09:08:43,882 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on 172.18.0.11:41877 (size: 18.9 KiB, free: 434.4 MiB)
2025-08-06 09:08:44,363 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on 172.18.0.11:41877 (size: 29.3 KiB, free: 434.4 MiB)
2025-08-06 09:08:44,549 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on 172.18.0.11:41877 (size: 29.6 KiB, free: 434.3 MiB)
2025-08-06 09:08:45,391 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 5) in 1631 ms on 172.18.0.11 (executor 2) (1/1)
2025-08-06 09:08:45,392 [task-result-getter-0] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2025-08-06 09:08:45,393 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - ResultStage 3 (run at AccessController.java:712) finished in 1.644 s
2025-08-06 09:08:45,394 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
2025-08-06 09:08:45,394 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
2025-08-06 09:08:45,395 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.scheduler.DAGScheduler - Job 3 finished: run at AccessController.java:712, took 1.649012 s
2025-08-06 09:08:45,396 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec - Data source write support IcebergBatchWrite(table=default.orders_by_date, format=PARQUET) is committing.
2025-08-06 09:08:45,397 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.spark.source.SparkWrite - Committing append with 1 new data files to table default.orders_by_date
2025-08-06 09:08:45,488 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.SnapshotProducer - Committed snapshot 5276485673453224558 (MergeAppend)
2025-08-06 09:08:45,501 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.metrics.LoggingMetricsReporter - Received metrics report: CommitReport{tableName=default.orders_by_date, snapshotId=5276485673453224558, sequenceNumber=2, operation=append, commitMetrics=CommitMetricsResult{totalDuration=TimerResult{timeUnit=NANOSECONDS, totalDuration=PT0.10310719S, count=1}, attempts=CounterResult{unit=COUNT, value=1}, addedDataFiles=CounterResult{unit=COUNT, value=1}, removedDataFiles=null, totalDataFiles=CounterResult{unit=COUNT, value=1}, addedDeleteFiles=null, addedEqualityDeleteFiles=null, addedPositionalDeleteFiles=null, addedDVs=null, removedDeleteFiles=null, removedEqualityDeleteFiles=null, removedPositionalDeleteFiles=null, removedDVs=null, totalDeleteFiles=CounterResult{unit=COUNT, value=0}, addedRecords=CounterResult{unit=COUNT, value=394}, removedRecords=null, totalRecords=CounterResult{unit=COUNT, value=394}, addedFilesSizeInBytes=CounterResult{unit=BYTES, value=1840}, removedFilesSizeInBytes=null, totalFilesSizeInBytes=CounterResult{unit=BYTES, value=1840}, addedPositionalDeletes=null, removedPositionalDeletes=null, totalPositionalDeletes=CounterResult{unit=COUNT, value=0}, addedEqualityDeletes=null, removedEqualityDeletes=null, totalEqualityDeletes=CounterResult{unit=COUNT, value=0}, manifestsCreated=null, manifestsReplaced=null, manifestsKept=null, manifestEntriesProcessed=null}, metadata={engine-version=3.4.1, app-id=app-20250806090436-0000, engine-name=spark, iceberg-version=Apache Iceberg 1.9.2 (commit 071d5606bc6199a0be9b3f274ec7fbf111d88821)}}
2025-08-06 09:08:45,501 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.spark.source.SparkWrite - Committed in 104 ms
2025-08-06 09:08:45,501 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.spark.sql.execution.datasources.v2.AtomicReplaceTableAsSelectExec - Data source write support IcebergBatchWrite(table=default.orders_by_date, format=PARQUET) committed.
2025-08-06 09:08:45,592 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.hive.HiveTableOperations - Committed to table hive_catalog.default.orders_by_date with the new metadata location s3a://iceberg-warehouse/output/orders/orders_by_date/metadata/00001-a9d6690c-6166-49e6-ba89-904af4e4032b.metadata.json
2025-08-06 09:08:45,593 [HiveServer2-Background-Pool: Thread-242] INFO  org.apache.iceberg.BaseMetastoreTableOperations - Successfully committed to table hive_catalog.default.orders_by_date in 81 ms
2025-08-06 09:08:45,629 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group f856a9f5-5bf7-439e-a600-2a4b7ccb5feb
2025-08-06 09:08:45,629 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with f856a9f5-5bf7-439e-a600-2a4b7ccb5feb
2025-08-06 09:08:45,634 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 09:08:45,635 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 09:08:45,635 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 09:08:45,636 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:08:45,645 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.thrift.ThriftCLIService - Client protocol version: HIVE_CLI_SERVICE_PROTOCOL_V6
2025-08-06 09:08:45,648 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.hive.service.cli.session.HiveSessionImpl - Operation log session directory is created: /tmp/spark/operation_logs/fdb74a4a-9eeb-4a66-8038-1f5124768530
2025-08-06 09:08:45,652 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Submitting query 'USE `default`' with d2ad6bbd-c71a-4d63-9891-325ee5cb96df
2025-08-06 09:08:45,652 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Running query with d2ad6bbd-c71a-4d63-9891-325ee5cb96df
2025-08-06 09:08:45,671 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.scheduler.DAGScheduler - Asked to cancel job group d2ad6bbd-c71a-4d63-9891-325ee5cb96df
2025-08-06 09:08:45,671 [HiveServer2-Handler-Pool: Thread-137] INFO  org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation - Close statement with d2ad6bbd-c71a-4d63-9891-325ee5cb96df
2025-08-06 09:08:45,677 [HiveServer2-Handler-Pool: Thread-137] ERROR org.apache.thrift.server.TThreadPoolServer - Thrift error occurred during processing of message.
org.apache.thrift.transport.TTransportException: null
	at org.apache.thrift.transport.TIOStreamTransport.read(TIOStreamTransport.java:132) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readLength(TSaslTransport.java:374) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.readFrame(TSaslTransport.java:451) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslTransport.read(TSaslTransport.java:433) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TSaslServerTransport.read(TSaslServerTransport.java:43) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:425) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:321) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:225) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.thrift.TBaseProcessor.process(TBaseProcessor.java:27) ~[libthrift-0.12.0.jar:0.12.0]
	at org.apache.hive.service.auth.TSetIpAddressProcessor.process(TSetIpAddressProcessor.java:52) ~[spark-hive-thriftserver_2.12-3.4.1.jar:3.4.1]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:310) ~[libthrift-0.12.0.jar:0.12.0]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635) ~[?:?]
	at java.lang.Thread.run(Thread.java:840) ~[?:?]
2025-08-06 09:09:45,795 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Requesting to kill executor(s) 2
2025-08-06 09:09:45,795 [spark-dynamic-executor-allocation] INFO  org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend - Actual list of executor(s) to be killed is 2
2025-08-06 09:09:45,805 [spark-dynamic-executor-allocation] INFO  org.apache.spark.ExecutorAllocationManager - Executors 2 removed due to idle timeout.
2025-08-06 09:09:50,835 [dispatcher-CoarseGrainedScheduler] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Executor 2 on 172.18.0.11 killed by driver.
2025-08-06 09:09:50,836 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Executor lost: 2 (epoch 2)
2025-08-06 09:09:50,836 [spark-listener-group-executorManagement] INFO  org.apache.spark.scheduler.dynalloc.ExecutorMonitor - Executor 2 is removed. Remove reason statistics: (gracefully decommissioned: 0, decommision unfinished: 0, driver killed: 3, unexpectedly exited: 0).
2025-08-06 09:09:50,836 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Trying to remove executor 2 from BlockManagerMaster.
2025-08-06 09:09:50,837 [dispatcher-BlockManagerMaster] INFO  org.apache.spark.storage.BlockManagerMasterEndpoint - Removing block manager BlockManagerId(2, 172.18.0.11, 41877, None)
2025-08-06 09:09:50,837 [dag-scheduler-event-loop] INFO  org.apache.spark.storage.BlockManagerMaster - Removed 2 successfully in removeExecutor
2025-08-06 09:09:50,837 [dag-scheduler-event-loop] INFO  org.apache.spark.scheduler.DAGScheduler - Shuffle files lost for executor: 2 (epoch 2)
