2025-08-06 08:39:57,323 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@079a944478eb
2025-08-06 08:39:57,354 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 08:39:57,358 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 08:39:57,359 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 08:39:58,060 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:39:58,062 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:39:58,065 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:39:58,077 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:39:58,080 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:39:58,525 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 08:39:59,620 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 39517.
2025-08-06 08:39:59,632 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-06 08:40:00,067 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.11:39517 with 12 cores, 6.6 GiB RAM
2025-08-06 08:40:00,081 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-06 08:40:00,086 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-06 08:40:00,143 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:40:00,145 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-06 08:40:00,147 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:40:00,236 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @6922ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 08:40:00,323 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-06 08:40:00,342 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 08:40:00,406 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @7094ms
2025-08-06 08:40:00,544 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@2843fa6a{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-06 08:40:00,545 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-06 08:40:00,633 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5caf1e93{/logPage,null,AVAILABLE,@Spark}
2025-08-06 08:40:00,641 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@939e5d1{/logPage/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:00,650 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@564f1d35{/,null,AVAILABLE,@Spark}
2025-08-06 08:40:00,658 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@354dcaf0{/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:00,693 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@785547e8{/static,null,AVAILABLE,@Spark}
2025-08-06 08:40:00,699 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@75333143{/log,null,AVAILABLE,@Spark}
2025-08-06 08:40:00,722 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://079a944478eb:8081
2025-08-06 08:40:00,730 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-06 08:40:00,771 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7f14a5db{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 08:40:00,912 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 110 ms (0 ms spent in bootstraps)
2025-08-06 08:40:01,339 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-06 08:40:02,607 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806084002-0000/0 for Thrift JDBC/ODBC Server
2025-08-06 08:40:02,644 [ExecutorRunner for app-20250806084002-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:40:02,647 [ExecutorRunner for app-20250806084002-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:40:02,647 [ExecutorRunner for app-20250806084002-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:40:02,647 [ExecutorRunner for app-20250806084002-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:40:02,648 [ExecutorRunner for app-20250806084002-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:40:02,693 [ExecutorRunner for app-20250806084002-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=39357" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@1662e5eff489:39357" "--executor-id" "0" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806084002-0000" "--worker-url" "spark://Worker@172.18.0.11:39517" "--resourceProfileId" "0"
2025-08-06 08:40:05,398 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 120@079a944478eb
2025-08-06 08:40:05,410 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 08:40:05,412 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 08:40:05,412 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 08:40:06,105 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 08:40:06,399 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:40:06,402 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:40:06,405 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:40:06,409 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:40:06,412 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:40:07,102 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 1662e5eff489/172.18.0.12:39357 after 125 ms (0 ms spent in bootstraps)
2025-08-06 08:40:07,406 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:40:07,410 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:40:07,413 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:40:07,414 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:40:07,415 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:40:07,591 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 1662e5eff489/172.18.0.12:39357 after 5 ms (0 ms spent in bootstraps)
2025-08-06 08:40:07,796 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-66c1fe8a-9d5d-4377-911f-cd38dc4e4aca/executor-6240a9d5-a574-4d16-9ddd-15f39fdad4f2/blockmgr-cb189a48-54d0-4e75-ba38-ec70fda4deb8
2025-08-06 08:40:07,886 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 08:40:08,285 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@1662e5eff489:39357
2025-08-06 08:40:08,288 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:39517
2025-08-06 08:40:08,295 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:39517 after 3 ms (0 ms spent in bootstraps)
2025-08-06 08:40:08,302 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:39517
2025-08-06 08:40:08,303 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:40:08,305 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 08:40:08,307 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:40:08,386 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 08:40:08,390 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.11
2025-08-06 08:40:08,498 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44889.
2025-08-06 08:40:08,499 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:44889
2025-08-06 08:40:08,510 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 08:40:08,533 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.11, 44889, None)
2025-08-06 08:40:08,571 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.11, 44889, None)
2025-08-06 08:40:08,573 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.11, 44889, None)
2025-08-06 08:40:08,589 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 08:41:08,760 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806084002-0000/0
2025-08-06 08:41:08,762 [ExecutorRunner for app-20250806084002-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806084002-0000/0 interrupted
2025-08-06 08:41:08,762 [ExecutorRunner for app-20250806084002-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 08:41:08,765 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 08:41:08,780 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 08:41:08,781 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 08:41:08,785 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 08:41:08,825 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806084002-0000/0 finished with state KILLED exitStatus 143
2025-08-06 08:41:08,827 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-06 08:41:08,830 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806084002-0000, execId=0)
2025-08-06 08:42:29,883 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@c45e69ed5283
2025-08-06 08:42:29,912 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 08:42:29,917 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 08:42:29,918 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 08:42:30,544 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:42:30,546 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:42:30,548 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:42:30,551 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:42:30,552 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:42:31,044 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 08:42:31,845 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 33539.
2025-08-06 08:42:31,855 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-06 08:42:32,270 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.11:33539 with 12 cores, 6.6 GiB RAM
2025-08-06 08:42:32,292 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-06 08:42:32,294 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-06 08:42:32,328 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:42:32,330 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-06 08:42:32,332 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:42:32,451 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @6590ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 08:42:32,558 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-06 08:42:32,590 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 08:42:32,632 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @6772ms
2025-08-06 08:42:32,724 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@71c1a022{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-06 08:42:32,725 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-06 08:42:32,776 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e974675{/logPage,null,AVAILABLE,@Spark}
2025-08-06 08:42:32,785 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@207596f0{/logPage/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:32,791 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@515a7c98{/,null,AVAILABLE,@Spark}
2025-08-06 08:42:32,796 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3771ce7d{/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:32,811 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4df557f0{/static,null,AVAILABLE,@Spark}
2025-08-06 08:42:32,814 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f116234{/log,null,AVAILABLE,@Spark}
2025-08-06 08:42:32,819 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://c45e69ed5283:8081
2025-08-06 08:42:32,823 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-06 08:42:32,862 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ec5a46d{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 08:42:32,934 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 63 ms (0 ms spent in bootstraps)
2025-08-06 08:42:33,389 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-06 08:42:34,639 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806084234-0000/0 for Thrift JDBC/ODBC Server
2025-08-06 08:42:34,701 [ExecutorRunner for app-20250806084234-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:42:34,702 [ExecutorRunner for app-20250806084234-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:42:34,703 [ExecutorRunner for app-20250806084234-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:42:34,703 [ExecutorRunner for app-20250806084234-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:42:34,704 [ExecutorRunner for app-20250806084234-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:42:34,747 [ExecutorRunner for app-20250806084234-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40351" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@5f55bbfe1a00:40351" "--executor-id" "0" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806084234-0000" "--worker-url" "spark://Worker@172.18.0.11:33539" "--resourceProfileId" "0"
2025-08-06 08:42:37,237 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 125@c45e69ed5283
2025-08-06 08:42:37,254 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 08:42:37,256 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 08:42:37,256 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 08:42:38,046 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 08:42:38,287 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:42:38,289 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:42:38,291 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:42:38,293 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:42:38,296 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:42:38,858 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 5f55bbfe1a00/172.18.0.12:40351 after 146 ms (0 ms spent in bootstraps)
2025-08-06 08:42:39,143 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:42:39,144 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:42:39,146 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:42:39,147 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:42:39,148 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:42:39,271 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 5f55bbfe1a00/172.18.0.12:40351 after 6 ms (0 ms spent in bootstraps)
2025-08-06 08:42:39,481 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-19ccf7c1-e887-4674-ac46-350f7a1bbe8e/executor-451ea6d2-42c0-431a-a6ce-03bd5a0936a0/blockmgr-ac978529-60d7-4c7a-8e31-347ca5bdcf49
2025-08-06 08:42:39,565 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 08:42:39,922 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@5f55bbfe1a00:40351
2025-08-06 08:42:39,924 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:33539
2025-08-06 08:42:39,933 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:33539 after 3 ms (0 ms spent in bootstraps)
2025-08-06 08:42:39,947 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:42:39,947 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:33539
2025-08-06 08:42:39,949 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 08:42:39,950 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:42:40,025 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 08:42:40,030 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.11
2025-08-06 08:42:40,128 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46627.
2025-08-06 08:42:40,129 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:46627
2025-08-06 08:42:40,137 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 08:42:40,147 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.11, 46627, None)
2025-08-06 08:42:40,172 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.11, 46627, None)
2025-08-06 08:42:40,176 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.11, 46627, None)
2025-08-06 08:42:40,200 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 08:43:40,485 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806084234-0000/0
2025-08-06 08:43:40,488 [ExecutorRunner for app-20250806084234-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806084234-0000/0 interrupted
2025-08-06 08:43:40,489 [ExecutorRunner for app-20250806084234-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 08:43:40,491 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 08:43:40,512 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 08:43:40,513 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 08:43:40,516 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 08:43:40,564 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806084234-0000/0 finished with state KILLED exitStatus 143
2025-08-06 08:43:40,571 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-06 08:43:40,576 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806084234-0000, execId=0)
2025-08-06 08:46:10,820 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806084234-0000/1 for Thrift JDBC/ODBC Server
2025-08-06 08:46:10,832 [ExecutorRunner for app-20250806084234-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:46:10,833 [ExecutorRunner for app-20250806084234-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:46:10,833 [ExecutorRunner for app-20250806084234-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:46:10,834 [ExecutorRunner for app-20250806084234-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:46:10,834 [ExecutorRunner for app-20250806084234-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:46:10,882 [ExecutorRunner for app-20250806084234-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40351" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@5f55bbfe1a00:40351" "--executor-id" "1" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806084234-0000" "--worker-url" "spark://Worker@172.18.0.11:33539" "--resourceProfileId" "0"
2025-08-06 08:46:12,249 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 209@c45e69ed5283
2025-08-06 08:46:12,255 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 08:46:12,257 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 08:46:12,257 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 08:46:12,486 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 08:46:12,562 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:46:12,563 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:46:12,564 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:46:12,565 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:46:12,566 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:46:12,764 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 5f55bbfe1a00/172.18.0.12:40351 after 43 ms (0 ms spent in bootstraps)
2025-08-06 08:46:12,844 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:46:12,845 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:46:12,846 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:46:12,846 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:46:12,846 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:46:12,902 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 5f55bbfe1a00/172.18.0.12:40351 after 1 ms (0 ms spent in bootstraps)
2025-08-06 08:46:13,006 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-19ccf7c1-e887-4674-ac46-350f7a1bbe8e/executor-451ea6d2-42c0-431a-a6ce-03bd5a0936a0/blockmgr-4142d579-9a98-401e-a169-cf22257453b6
2025-08-06 08:46:13,044 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 08:46:13,207 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@5f55bbfe1a00:40351
2025-08-06 08:46:13,208 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:33539
2025-08-06 08:46:13,211 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:33539 after 1 ms (0 ms spent in bootstraps)
2025-08-06 08:46:13,212 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:33539
2025-08-06 08:46:13,216 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:46:13,217 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 08:46:13,218 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:46:13,235 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 08:46:13,237 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.11
2025-08-06 08:46:13,266 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36539.
2025-08-06 08:46:13,267 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:36539
2025-08-06 08:46:13,269 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 08:46:13,275 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.11, 36539, None)
2025-08-06 08:46:13,283 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.11, 36539, None)
2025-08-06 08:46:13,285 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.11, 36539, None)
2025-08-06 08:46:13,289 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 08:46:13,339 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-06 08:46:13,347 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-06 08:46:13,387 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-06 08:46:13,426 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 08:46:13,467 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 5f55bbfe1a00/172.18.0.12:34529 after 1 ms (0 ms spent in bootstraps)
2025-08-06 08:46:13,539 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 434.4 MiB)
2025-08-06 08:46:13,550 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 123 ms
2025-08-06 08:46:13,603 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.0 KiB, free 434.4 MiB)
2025-08-06 08:46:14,113 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 212.8992 ms
2025-08-06 08:46:14,170 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1548 bytes result sent to driver
2025-08-06 08:47:14,581 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806084234-0000/1
2025-08-06 08:47:14,582 [ExecutorRunner for app-20250806084234-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806084234-0000/1 interrupted
2025-08-06 08:47:14,583 [ExecutorRunner for app-20250806084234-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 08:47:14,586 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 08:47:14,618 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 08:47:14,619 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 08:47:14,622 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 08:47:14,671 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806084234-0000/1 finished with state KILLED exitStatus 143
2025-08-06 08:47:14,672 [dispatcher-event-loop-6] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-06 08:47:14,672 [dispatcher-event-loop-6] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806084234-0000, execId=1)
2025-08-06 08:55:01,160 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@494e433f0a1e
2025-08-06 08:55:01,200 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 08:55:01,209 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 08:55:01,211 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 08:55:01,895 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:55:01,897 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:55:01,903 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:55:01,906 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:55:01,908 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:55:02,415 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 08:55:03,441 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 37163.
2025-08-06 08:55:03,450 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-06 08:55:03,882 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.12:37163 with 12 cores, 6.6 GiB RAM
2025-08-06 08:55:03,906 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-06 08:55:03,909 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-06 08:55:03,954 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:55:03,957 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-06 08:55:03,959 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:55:04,061 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @7934ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 08:55:04,189 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-06 08:55:04,228 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 08:55:04,274 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @8149ms
2025-08-06 08:55:04,354 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@135160f3{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-06 08:55:04,357 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-06 08:55:04,423 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@352dd6ca{/logPage,null,AVAILABLE,@Spark}
2025-08-06 08:55:04,428 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5c8220c7{/logPage/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:04,432 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d73f768{/,null,AVAILABLE,@Spark}
2025-08-06 08:55:04,439 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@25f7925d{/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:04,467 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@242446e6{/static,null,AVAILABLE,@Spark}
2025-08-06 08:55:04,480 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7bb03bc{/log,null,AVAILABLE,@Spark}
2025-08-06 08:55:04,496 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://494e433f0a1e:8081
2025-08-06 08:55:04,501 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-06 08:55:04,532 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@10321ba4{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 08:55:04,597 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 56 ms (0 ms spent in bootstraps)
2025-08-06 08:55:04,848 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-06 08:55:05,630 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806085505-0000/0 for Thrift JDBC/ODBC Server
2025-08-06 08:55:05,722 [ExecutorRunner for app-20250806085505-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:55:05,723 [ExecutorRunner for app-20250806085505-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:55:05,724 [ExecutorRunner for app-20250806085505-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:55:05,724 [ExecutorRunner for app-20250806085505-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:55:05,724 [ExecutorRunner for app-20250806085505-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:55:05,760 [ExecutorRunner for app-20250806085505-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=40913" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@f0e4b60b3686:40913" "--executor-id" "0" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250806085505-0000" "--worker-url" "spark://Worker@172.18.0.12:37163" "--resourceProfileId" "0"
2025-08-06 08:55:08,166 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 122@494e433f0a1e
2025-08-06 08:55:08,187 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 08:55:08,190 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 08:55:08,191 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 08:55:08,971 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 08:55:09,165 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:55:09,168 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:55:09,170 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:55:09,172 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:55:09,174 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:55:09,716 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to f0e4b60b3686/172.18.0.11:40913 after 161 ms (0 ms spent in bootstraps)
2025-08-06 08:55:09,942 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 08:55:09,944 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 08:55:09,946 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 08:55:09,948 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 08:55:09,950 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 08:55:10,095 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to f0e4b60b3686/172.18.0.11:40913 after 10 ms (0 ms spent in bootstraps)
2025-08-06 08:55:10,260 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-f6b8d31d-99a7-4a50-adab-5a14433e8556/executor-843a097a-91f8-4a62-acc7-ebd7019db346/blockmgr-87476572-196c-4ec9-b5a7-fe6b02bd40c0
2025-08-06 08:55:10,314 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 08:55:10,738 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:37163
2025-08-06 08:55:10,738 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@f0e4b60b3686:40913
2025-08-06 08:55:10,752 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:37163 after 7 ms (0 ms spent in bootstraps)
2025-08-06 08:55:10,757 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:37163
2025-08-06 08:55:10,762 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:55:10,768 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 08:55:10,769 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 08:55:10,851 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 08:55:10,860 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.12
2025-08-06 08:55:10,942 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35869.
2025-08-06 08:55:10,943 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:35869
2025-08-06 08:55:10,949 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 08:55:10,960 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.12, 35869, None)
2025-08-06 08:55:10,991 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.12, 35869, None)
2025-08-06 08:55:10,994 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.12, 35869, None)
2025-08-06 08:55:11,011 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 08:56:11,407 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806085505-0000/0
2025-08-06 08:56:11,412 [ExecutorRunner for app-20250806085505-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806085505-0000/0 interrupted
2025-08-06 08:56:11,414 [ExecutorRunner for app-20250806085505-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 08:56:11,419 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 08:56:11,448 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 08:56:11,449 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 08:56:11,452 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 08:56:11,507 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806085505-0000/0 finished with state KILLED exitStatus 143
2025-08-06 08:56:11,511 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-06 08:56:11,513 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806085505-0000, execId=0)
2025-08-06 09:04:31,788 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@9e76561f5a9f
2025-08-06 09:04:31,818 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 09:04:31,822 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 09:04:31,823 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 09:04:32,458 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:04:32,463 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:04:32,465 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:04:32,478 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:04:32,490 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:04:33,070 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 09:04:34,092 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 33083.
2025-08-06 09:04:34,102 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-06 09:04:34,893 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.11:33083 with 12 cores, 6.6 GiB RAM
2025-08-06 09:04:34,910 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-06 09:04:34,918 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-06 09:04:34,965 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 09:04:34,967 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-06 09:04:34,968 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 09:04:35,090 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @7500ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 09:04:35,239 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-06 09:04:35,264 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 09:04:35,299 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @7710ms
2025-08-06 09:04:35,399 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@71c1a022{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-06 09:04:35,399 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-06 09:04:35,470 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e974675{/logPage,null,AVAILABLE,@Spark}
2025-08-06 09:04:35,477 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@207596f0{/logPage/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:35,481 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@515a7c98{/,null,AVAILABLE,@Spark}
2025-08-06 09:04:35,489 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3771ce7d{/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:35,515 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4df557f0{/static,null,AVAILABLE,@Spark}
2025-08-06 09:04:35,523 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f116234{/log,null,AVAILABLE,@Spark}
2025-08-06 09:04:35,550 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://9e76561f5a9f:8081
2025-08-06 09:04:35,565 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-06 09:04:35,637 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@ec5a46d{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 09:04:35,772 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 84 ms (0 ms spent in bootstraps)
2025-08-06 09:04:36,118 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-06 09:04:37,385 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806090436-0000/0 for Thrift JDBC/ODBC Server
2025-08-06 09:04:37,442 [ExecutorRunner for app-20250806090436-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:04:37,443 [ExecutorRunner for app-20250806090436-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:04:37,444 [ExecutorRunner for app-20250806090436-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:04:37,451 [ExecutorRunner for app-20250806090436-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:04:37,451 [ExecutorRunner for app-20250806090436-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:04:37,481 [ExecutorRunner for app-20250806090436-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=43895" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@c15f4bd07d87:43895" "--executor-id" "0" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806090436-0000" "--worker-url" "spark://Worker@172.18.0.11:33083" "--resourceProfileId" "0"
2025-08-06 09:04:39,976 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 122@9e76561f5a9f
2025-08-06 09:04:39,996 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 09:04:40,002 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 09:04:40,004 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 09:04:40,875 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 09:04:41,157 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:04:41,159 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:04:41,161 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:04:41,163 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:04:41,165 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:04:41,904 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to c15f4bd07d87/172.18.0.12:43895 after 150 ms (0 ms spent in bootstraps)
2025-08-06 09:04:42,148 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:04:42,149 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:04:42,150 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:04:42,151 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:04:42,151 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:04:42,278 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to c15f4bd07d87/172.18.0.12:43895 after 10 ms (0 ms spent in bootstraps)
2025-08-06 09:04:42,449 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-5b17adb4-15b2-41b8-83c0-d90e9ad7be4b/executor-36a0682f-a288-49ff-bf95-f029f9177742/blockmgr-582678db-b92a-4950-ac33-b82830663d6e
2025-08-06 09:04:42,546 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 09:04:43,051 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@c15f4bd07d87:43895
2025-08-06 09:04:43,053 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:33083
2025-08-06 09:04:43,067 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:33083 after 9 ms (0 ms spent in bootstraps)
2025-08-06 09:04:43,074 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 09:04:43,075 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 09:04:43,077 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 09:04:43,078 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:33083
2025-08-06 09:04:43,172 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 09:04:43,177 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.11
2025-08-06 09:04:43,307 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34505.
2025-08-06 09:04:43,312 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:34505
2025-08-06 09:04:43,321 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 09:04:43,339 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.11, 34505, None)
2025-08-06 09:04:43,404 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.11, 34505, None)
2025-08-06 09:04:43,412 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.11, 34505, None)
2025-08-06 09:04:43,434 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 09:05:43,765 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806090436-0000/0
2025-08-06 09:05:43,773 [ExecutorRunner for app-20250806090436-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806090436-0000/0 interrupted
2025-08-06 09:05:43,775 [ExecutorRunner for app-20250806090436-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 09:05:43,784 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 09:05:43,832 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 09:05:43,833 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 09:05:43,841 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 09:05:43,933 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806090436-0000/0 finished with state KILLED exitStatus 143
2025-08-06 09:05:43,946 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-06 09:05:43,949 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806090436-0000, execId=0)
2025-08-06 09:07:06,868 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806090436-0000/1 for Thrift JDBC/ODBC Server
2025-08-06 09:07:06,888 [ExecutorRunner for app-20250806090436-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:07:06,888 [ExecutorRunner for app-20250806090436-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:07:06,889 [ExecutorRunner for app-20250806090436-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:07:06,889 [ExecutorRunner for app-20250806090436-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:07:06,889 [ExecutorRunner for app-20250806090436-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:07:06,964 [ExecutorRunner for app-20250806090436-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=43895" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@c15f4bd07d87:43895" "--executor-id" "1" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806090436-0000" "--worker-url" "spark://Worker@172.18.0.11:33083" "--resourceProfileId" "0"
2025-08-06 09:07:08,748 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 205@9e76561f5a9f
2025-08-06 09:07:08,769 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 09:07:08,771 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 09:07:08,771 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 09:07:09,208 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 09:07:09,334 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:07:09,335 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:07:09,335 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:07:09,336 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:07:09,337 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:07:09,682 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to c15f4bd07d87/172.18.0.12:43895 after 63 ms (0 ms spent in bootstraps)
2025-08-06 09:07:09,788 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:07:09,789 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:07:09,790 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:07:09,790 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:07:09,790 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:07:09,863 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to c15f4bd07d87/172.18.0.12:43895 after 3 ms (0 ms spent in bootstraps)
2025-08-06 09:07:09,975 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-5b17adb4-15b2-41b8-83c0-d90e9ad7be4b/executor-36a0682f-a288-49ff-bf95-f029f9177742/blockmgr-3df35e9c-957b-485a-bfb1-03be136af353
2025-08-06 09:07:10,026 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 09:07:10,246 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@c15f4bd07d87:43895
2025-08-06 09:07:10,248 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:33083
2025-08-06 09:07:10,254 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:33083 after 3 ms (0 ms spent in bootstraps)
2025-08-06 09:07:10,257 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:33083
2025-08-06 09:07:10,261 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 09:07:10,264 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 09:07:10,266 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 09:07:10,307 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 09:07:10,311 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.11
2025-08-06 09:07:10,373 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39111.
2025-08-06 09:07:10,373 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:39111
2025-08-06 09:07:10,376 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 09:07:10,385 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.11, 39111, None)
2025-08-06 09:07:10,398 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.11, 39111, None)
2025-08-06 09:07:10,399 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.11, 39111, None)
2025-08-06 09:07:10,409 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 09:07:10,488 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-06 09:07:10,497 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-06 09:07:10,504 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-06 09:07:10,504 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-08-06 09:07:10,592 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-06 09:07:10,634 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 09:07:10,675 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to c15f4bd07d87/172.18.0.12:41285 after 2 ms (0 ms spent in bootstraps)
2025-08-06 09:07:10,741 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-06 09:07:10,760 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 125 ms
2025-08-06 09:07:10,816 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-06 09:07:10,999 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 09:07:11,011 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-06 09:07:11,017 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 17 ms
2025-08-06 09:07:11,061 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 09:07:11,600 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 09:07:11,614 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 09:07:11,614 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 09:07:12,433 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 09:07:12,433 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 09:07:12,841 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-06 09:07:12,841 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 09:07:13,460 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to orders/data/00000-0-694e3a72-56fa-4c7d-9fef-fab31d1e59d1-0-00001.parquet. This is unsupported
2025-08-06 09:07:13,756 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
2025-08-06 09:07:13,756 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 1, attempt 0, stage 0.0)
2025-08-06 09:07:13,798 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 4316 bytes result sent to driver
2025-08-06 09:07:13,798 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 4316 bytes result sent to driver
2025-08-06 09:07:21,891 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 09:07:22,270 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2
2025-08-06 09:07:22,272 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 2)
2025-08-06 09:07:22,322 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 09:07:22,334 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 434.4 MiB)
2025-08-06 09:07:22,339 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 5 took 16 ms
2025-08-06 09:07:22,342 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 44.5 KiB, free 434.3 MiB)
2025-08-06 09:07:22,838 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 237.256766 ms
2025-08-06 09:07:22,842 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 09:07:22,851 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 434.3 MiB)
2025-08-06 09:07:22,856 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 4 took 12 ms
2025-08-06 09:07:22,859 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 09:07:22,863 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 09:07:22,932 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.032965 ms
2025-08-06 09:07:22,950 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.67034 ms
2025-08-06 09:07:22,969 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.859217 ms
2025-08-06 09:07:23,020 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 09:07:23,029 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 425.7 MiB)
2025-08-06 09:07:23,034 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 3 took 13 ms
2025-08-06 09:07:23,041 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 425.7 MiB)
2025-08-06 09:07:23,152 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 09:07:23,198 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 09:07:23,211 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-06 09:07:23,211 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-06 09:07:23,224 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-06 09:07:23,227 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-06 09:07:23,229 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-06 09:07:23,609 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 09:07:23,621 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 09:07:23,651 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 09:07:23,689 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 2, attempt 0, stage 1.0)
2025-08-06 09:07:23,698 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 2). 8107 bytes result sent to driver
2025-08-06 09:08:23,033 [block-manager-storage-async-thread-pool-9] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 09:08:23,045 [block-manager-storage-async-thread-pool-15] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 09:08:24,173 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806090436-0000/1
2025-08-06 09:08:24,174 [ExecutorRunner for app-20250806090436-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806090436-0000/1 interrupted
2025-08-06 09:08:24,174 [ExecutorRunner for app-20250806090436-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 09:08:24,177 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 09:08:24,197 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 09:08:24,197 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 09:08:24,200 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 09:08:24,202 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 09:08:24,202 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 09:08:24,203 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 09:08:24,248 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806090436-0000/1 finished with state KILLED exitStatus 143
2025-08-06 09:08:24,249 [dispatcher-event-loop-5] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-06 09:08:24,250 [dispatcher-event-loop-5] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806090436-0000, execId=1)
2025-08-06 09:08:30,774 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806090436-0000/2 for Thrift JDBC/ODBC Server
2025-08-06 09:08:30,779 [ExecutorRunner for app-20250806090436-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:08:30,781 [ExecutorRunner for app-20250806090436-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:08:30,781 [ExecutorRunner for app-20250806090436-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:08:30,781 [ExecutorRunner for app-20250806090436-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:08:30,781 [ExecutorRunner for app-20250806090436-0000/2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:08:30,813 [ExecutorRunner for app-20250806090436-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=43895" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@c15f4bd07d87:43895" "--executor-id" "2" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806090436-0000" "--worker-url" "spark://Worker@172.18.0.11:33083" "--resourceProfileId" "0"
2025-08-06 09:08:32,211 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 326@9e76561f5a9f
2025-08-06 09:08:32,220 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 09:08:32,222 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 09:08:32,223 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 09:08:32,621 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 09:08:32,733 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:08:32,734 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:08:32,735 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:08:32,735 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:08:32,737 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:08:33,004 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to c15f4bd07d87/172.18.0.12:43895 after 62 ms (0 ms spent in bootstraps)
2025-08-06 09:08:33,101 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 09:08:33,102 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 09:08:33,103 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 09:08:33,103 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 09:08:33,103 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 09:08:33,178 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to c15f4bd07d87/172.18.0.12:43895 after 2 ms (0 ms spent in bootstraps)
2025-08-06 09:08:33,266 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-5b17adb4-15b2-41b8-83c0-d90e9ad7be4b/executor-36a0682f-a288-49ff-bf95-f029f9177742/blockmgr-c88bfa75-9659-4e3a-972e-3a40e24212ab
2025-08-06 09:08:33,310 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 09:08:33,512 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@c15f4bd07d87:43895
2025-08-06 09:08:33,513 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:33083
2025-08-06 09:08:33,517 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:33083 after 2 ms (0 ms spent in bootstraps)
2025-08-06 09:08:33,519 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:33083
2025-08-06 09:08:33,524 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 09:08:33,525 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 09:08:33,526 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 09:08:33,556 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 09:08:33,560 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 2 on host 172.18.0.11
2025-08-06 09:08:33,598 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41877.
2025-08-06 09:08:33,599 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:41877
2025-08-06 09:08:33,602 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 09:08:33,608 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(2, 172.18.0.11, 41877, None)
2025-08-06 09:08:33,619 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(2, 172.18.0.11, 41877, None)
2025-08-06 09:08:33,621 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(2, 172.18.0.11, 41877, None)
2025-08-06 09:08:33,627 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 09:08:33,668 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3
2025-08-06 09:08:33,674 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4
2025-08-06 09:08:33,681 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 3)
2025-08-06 09:08:33,681 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 4)
2025-08-06 09:08:33,763 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 2 and clearing cache
2025-08-06 09:08:33,816 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 09:08:33,846 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to c15f4bd07d87/172.18.0.12:41285 after 1 ms (0 ms spent in bootstraps)
2025-08-06 09:08:33,871 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-06 09:08:33,881 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 7 took 64 ms
2025-08-06 09:08:33,924 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-06 09:08:34,104 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 09:08:34,112 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-06 09:08:34,118 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 6 took 13 ms
2025-08-06 09:08:34,163 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 09:08:34,755 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 09:08:34,766 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 09:08:34,767 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 09:08:35,523 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 09:08:35,523 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 09:08:35,967 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 09:08:35,967 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-06 09:08:36,586 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to orders/data/00001-4-906a4cd4-a146-4057-bc31-b3a3daea8945-0-00001.parquet. This is unsupported
2025-08-06 09:08:36,773 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 4, attempt 0, stage 2.0)
2025-08-06 09:08:36,773 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 3, attempt 0, stage 2.0)
2025-08-06 09:08:36,802 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 4). 4316 bytes result sent to driver
2025-08-06 09:08:36,802 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 3). 4316 bytes result sent to driver
2025-08-06 09:08:43,533 [block-manager-storage-async-thread-pool-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 09:08:43,763 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5
2025-08-06 09:08:43,765 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 5)
2025-08-06 09:08:43,864 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 11 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 09:08:43,876 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 434.4 MiB)
2025-08-06 09:08:43,884 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 11 took 18 ms
2025-08-06 09:08:43,886 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 44.5 KiB, free 434.3 MiB)
2025-08-06 09:08:44,345 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 258.456296 ms
2025-08-06 09:08:44,349 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 10 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 09:08:44,358 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 434.3 MiB)
2025-08-06 09:08:44,366 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 10 took 15 ms
2025-08-06 09:08:44,370 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 09:08:44,376 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 09:08:44,444 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.612176 ms
2025-08-06 09:08:44,461 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.349883 ms
2025-08-06 09:08:44,484 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.201594 ms
2025-08-06 09:08:44,536 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 09:08:44,546 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 425.7 MiB)
2025-08-06 09:08:44,551 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 9 took 14 ms
2025-08-06 09:08:44,559 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 32.0 KiB, free 425.7 MiB)
2025-08-06 09:08:44,704 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 09:08:44,761 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 09:08:44,778 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-06 09:08:44,778 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-06 09:08:44,795 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-06 09:08:44,799 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-06 09:08:44,801 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-06 09:08:45,253 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 09:08:45,264 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 09:08:45,307 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 09:08:45,370 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 5, attempt 0, stage 3.0)
2025-08-06 09:08:45,385 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 5). 8107 bytes result sent to driver
2025-08-06 09:09:45,812 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806090436-0000/2
2025-08-06 09:09:45,813 [ExecutorRunner for app-20250806090436-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806090436-0000/2 interrupted
2025-08-06 09:09:45,813 [ExecutorRunner for app-20250806090436-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 09:09:45,815 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 09:09:45,831 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 09:09:45,832 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 09:09:45,832 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 09:09:45,832 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 09:09:45,835 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 09:09:45,837 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 09:09:45,838 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 09:09:45,838 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 09:09:45,890 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806090436-0000/2 finished with state KILLED exitStatus 143
2025-08-06 09:09:45,891 [dispatcher-event-loop-4] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-08-06 09:09:45,891 [dispatcher-event-loop-4] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806090436-0000, execId=2)
2025-08-06 13:07:55,507 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@f6f2d3eda193
2025-08-06 13:07:55,534 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:07:55,538 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:07:55,539 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:07:56,074 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:07:56,076 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:07:56,078 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:07:56,080 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:07:56,082 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:07:56,600 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:07:57,716 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 34645.
2025-08-06 13:07:57,720 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-06 13:07:58,459 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.11:34645 with 12 cores, 6.6 GiB RAM
2025-08-06 13:07:58,488 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-06 13:07:58,500 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-06 13:07:58,577 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:07:58,586 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-06 13:07:58,590 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:07:58,832 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @7880ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 13:07:59,026 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-06 13:07:59,061 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 13:07:59,135 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @8198ms
2025-08-06 13:07:59,274 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@6eac1128{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-06 13:07:59,277 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-06 13:07:59,402 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@560a5f39{/logPage,null,AVAILABLE,@Spark}
2025-08-06 13:07:59,418 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ffb1f26{/logPage/json,null,AVAILABLE,@Spark}
2025-08-06 13:07:59,423 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1beee8f{/,null,AVAILABLE,@Spark}
2025-08-06 13:07:59,429 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73aa71b8{/json,null,AVAILABLE,@Spark}
2025-08-06 13:07:59,451 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d16b5fb{/static,null,AVAILABLE,@Spark}
2025-08-06 13:07:59,459 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70d3d9aa{/log,null,AVAILABLE,@Spark}
2025-08-06 13:07:59,477 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://f6f2d3eda193:8081
2025-08-06 13:07:59,494 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-06 13:07:59,549 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32a89fc2{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 13:07:59,691 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 95 ms (0 ms spent in bootstraps)
2025-08-06 13:08:00,168 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-06 13:08:02,256 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806130801-0000/0 for Thrift JDBC/ODBC Server
2025-08-06 13:08:02,314 [ExecutorRunner for app-20250806130801-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:08:02,315 [ExecutorRunner for app-20250806130801-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:08:02,315 [ExecutorRunner for app-20250806130801-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:08:02,316 [ExecutorRunner for app-20250806130801-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:08:02,318 [ExecutorRunner for app-20250806130801-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:08:02,351 [ExecutorRunner for app-20250806130801-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=38949" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@94cac0911119:38949" "--executor-id" "0" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806130801-0000" "--worker-url" "spark://Worker@172.18.0.11:34645" "--resourceProfileId" "0"
2025-08-06 13:08:04,723 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 121@f6f2d3eda193
2025-08-06 13:08:04,758 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:08:04,760 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:08:04,761 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:08:05,601 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:08:05,874 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:08:05,877 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:08:05,880 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:08:05,881 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:08:05,882 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:08:06,434 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 94cac0911119/172.18.0.12:38949 after 172 ms (0 ms spent in bootstraps)
2025-08-06 13:08:06,696 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:08:06,697 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:08:06,698 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:08:06,698 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:08:06,699 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:08:06,799 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 94cac0911119/172.18.0.12:38949 after 2 ms (0 ms spent in bootstraps)
2025-08-06 13:08:06,933 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-4e0da9d0-dc71-4dfe-967a-961726b4969e/executor-2a6f80a0-cf2c-4c9a-9e0e-5272e8e109a5/blockmgr-9e2f8568-6dec-4050-abcf-11e89c519a43
2025-08-06 13:08:07,036 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 13:08:07,619 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@94cac0911119:38949
2025-08-06 13:08:07,620 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:34645
2025-08-06 13:08:07,631 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:34645 after 7 ms (0 ms spent in bootstraps)
2025-08-06 13:08:07,635 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:34645
2025-08-06 13:08:07,645 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:08:07,648 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 13:08:07,649 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:08:07,713 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 13:08:07,717 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.11
2025-08-06 13:08:07,799 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36469.
2025-08-06 13:08:07,800 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:36469
2025-08-06 13:08:07,804 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 13:08:07,814 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.11, 36469, None)
2025-08-06 13:08:07,854 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.11, 36469, None)
2025-08-06 13:08:07,858 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.11, 36469, None)
2025-08-06 13:08:07,878 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 13:09:08,203 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806130801-0000/0
2025-08-06 13:09:08,207 [ExecutorRunner for app-20250806130801-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806130801-0000/0 interrupted
2025-08-06 13:09:08,209 [ExecutorRunner for app-20250806130801-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 13:09:08,213 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 13:09:08,238 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 13:09:08,239 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 13:09:08,241 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 13:09:08,291 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806130801-0000/0 finished with state KILLED exitStatus 143
2025-08-06 13:09:08,295 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-06 13:09:08,297 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806130801-0000, execId=0)
2025-08-06 13:14:27,503 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@3133d26c614d
2025-08-06 13:14:27,539 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:14:27,544 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:14:27,545 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:14:28,534 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:14:28,537 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:14:28,542 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:14:28,547 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:14:28,564 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:14:29,495 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:14:30,862 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 35949.
2025-08-06 13:14:30,872 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-06 13:14:31,664 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.12:35949 with 12 cores, 6.6 GiB RAM
2025-08-06 13:14:31,691 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-06 13:14:31,700 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-06 13:14:31,767 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:14:31,769 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-06 13:14:31,771 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:14:31,928 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @9734ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 13:14:32,079 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-06 13:14:32,127 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 13:14:32,191 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @9999ms
2025-08-06 13:14:32,372 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@407e9415{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-06 13:14:32,374 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-06 13:14:32,505 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@157da5bf{/logPage,null,AVAILABLE,@Spark}
2025-08-06 13:14:32,549 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3efb57c4{/logPage/json,null,AVAILABLE,@Spark}
2025-08-06 13:14:32,558 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72d5ebe1{/,null,AVAILABLE,@Spark}
2025-08-06 13:14:32,593 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5777286f{/json,null,AVAILABLE,@Spark}
2025-08-06 13:14:32,661 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3ac19d39{/static,null,AVAILABLE,@Spark}
2025-08-06 13:14:32,669 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63878c53{/log,null,AVAILABLE,@Spark}
2025-08-06 13:14:32,679 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://3133d26c614d:8081
2025-08-06 13:14:32,713 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-06 13:14:32,841 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@36e6cf1e{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 13:14:33,016 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 168 ms (0 ms spent in bootstraps)
2025-08-06 13:14:33,463 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-06 13:14:35,396 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806131434-0000/0 for Thrift JDBC/ODBC Server
2025-08-06 13:14:35,469 [ExecutorRunner for app-20250806131434-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:14:35,472 [ExecutorRunner for app-20250806131434-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:14:35,473 [ExecutorRunner for app-20250806131434-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:14:35,474 [ExecutorRunner for app-20250806131434-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:14:35,474 [ExecutorRunner for app-20250806131434-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:14:35,528 [ExecutorRunner for app-20250806131434-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=35489" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@ced4a7aa0368:35489" "--executor-id" "0" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250806131434-0000" "--worker-url" "spark://Worker@172.18.0.12:35949" "--resourceProfileId" "0"
2025-08-06 13:14:38,367 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 127@3133d26c614d
2025-08-06 13:14:38,386 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:14:38,388 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:14:38,389 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:14:39,010 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:14:39,241 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:14:39,242 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:14:39,244 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:14:39,245 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:14:39,247 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:14:39,914 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to ced4a7aa0368/172.18.0.11:35489 after 139 ms (0 ms spent in bootstraps)
2025-08-06 13:14:40,312 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:14:40,313 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:14:40,313 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:14:40,314 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:14:40,314 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:14:40,484 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to ced4a7aa0368/172.18.0.11:35489 after 6 ms (0 ms spent in bootstraps)
2025-08-06 13:14:40,702 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-3fe1eba6-a93f-4fc8-b883-9e612672daac/executor-f9e3789a-c75a-45d0-91aa-fd135818de77/blockmgr-6e77c1bb-d77c-4583-80f4-0c2cafb7df1f
2025-08-06 13:14:40,786 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 13:14:41,153 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@ced4a7aa0368:35489
2025-08-06 13:14:41,158 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:35949
2025-08-06 13:14:41,184 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:35949 after 21 ms (0 ms spent in bootstraps)
2025-08-06 13:14:41,186 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:35949
2025-08-06 13:14:41,186 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:14:41,194 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 13:14:41,197 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:14:41,288 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 13:14:41,293 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.12
2025-08-06 13:14:41,391 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38305.
2025-08-06 13:14:41,392 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:38305
2025-08-06 13:14:41,399 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 13:14:41,416 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.12, 38305, None)
2025-08-06 13:14:41,447 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.12, 38305, None)
2025-08-06 13:14:41,452 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.12, 38305, None)
2025-08-06 13:14:41,476 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 13:15:41,971 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806131434-0000/0
2025-08-06 13:15:41,977 [ExecutorRunner for app-20250806131434-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806131434-0000/0 interrupted
2025-08-06 13:15:41,979 [ExecutorRunner for app-20250806131434-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 13:15:41,989 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 13:15:42,036 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 13:15:42,037 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 13:15:42,045 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 13:15:42,133 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806131434-0000/0 finished with state KILLED exitStatus 143
2025-08-06 13:15:42,140 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-06 13:15:42,142 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806131434-0000, execId=0)
2025-08-06 13:17:28,863 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@8c7a37cd17dc
2025-08-06 13:17:28,893 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:17:28,896 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:17:28,898 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:17:29,528 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:17:29,531 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:17:29,532 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:17:29,535 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:17:29,538 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:17:30,132 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:17:31,308 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 37249.
2025-08-06 13:17:31,320 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-06 13:17:31,982 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.11:37249 with 12 cores, 6.6 GiB RAM
2025-08-06 13:17:32,006 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-06 13:17:32,016 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-06 13:17:32,069 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:17:32,072 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-06 13:17:32,074 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:17:32,172 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @7465ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 13:17:32,259 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-06 13:17:32,286 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 13:17:32,349 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @7644ms
2025-08-06 13:17:32,437 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@54c0bb6f{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-06 13:17:32,438 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-06 13:17:32,515 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@44ead3e0{/logPage,null,AVAILABLE,@Spark}
2025-08-06 13:17:32,526 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35edf1b9{/logPage/json,null,AVAILABLE,@Spark}
2025-08-06 13:17:32,535 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@44fe71e8{/,null,AVAILABLE,@Spark}
2025-08-06 13:17:32,539 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22bb8666{/json,null,AVAILABLE,@Spark}
2025-08-06 13:17:32,562 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2acba7ec{/static,null,AVAILABLE,@Spark}
2025-08-06 13:17:32,566 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@648ef3df{/log,null,AVAILABLE,@Spark}
2025-08-06 13:17:32,579 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://8c7a37cd17dc:8081
2025-08-06 13:17:32,601 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-06 13:17:32,654 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7b9226b7{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 13:17:32,806 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 124 ms (0 ms spent in bootstraps)
2025-08-06 13:17:33,357 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-06 13:17:34,520 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806131734-0000/0 for Thrift JDBC/ODBC Server
2025-08-06 13:17:34,580 [ExecutorRunner for app-20250806131734-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:17:34,583 [ExecutorRunner for app-20250806131734-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:17:34,584 [ExecutorRunner for app-20250806131734-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:17:34,585 [ExecutorRunner for app-20250806131734-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:17:34,585 [ExecutorRunner for app-20250806131734-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:17:34,644 [ExecutorRunner for app-20250806131734-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45945" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@d2eef3aa55e4:45945" "--executor-id" "0" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806131734-0000" "--worker-url" "spark://Worker@172.18.0.11:37249" "--resourceProfileId" "0"
2025-08-06 13:17:37,283 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 121@8c7a37cd17dc
2025-08-06 13:17:37,308 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:17:37,319 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:17:37,320 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:17:38,035 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:17:38,303 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:17:38,305 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:17:38,307 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:17:38,308 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:17:38,310 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:17:38,882 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to d2eef3aa55e4/172.18.0.12:45945 after 171 ms (0 ms spent in bootstraps)
2025-08-06 13:17:39,101 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:17:39,102 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:17:39,107 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:17:39,108 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:17:39,111 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:17:39,244 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to d2eef3aa55e4/172.18.0.12:45945 after 9 ms (0 ms spent in bootstraps)
2025-08-06 13:17:39,416 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-a093a574-33e8-4ddd-b666-448234dbc251/executor-c1cfe437-f4b3-488c-a94a-25335f68ad34/blockmgr-9f6abe61-b318-4587-96ee-9eec3ac4de38
2025-08-06 13:17:39,475 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 13:17:39,846 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@d2eef3aa55e4:45945
2025-08-06 13:17:39,848 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:37249
2025-08-06 13:17:39,870 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:37249 after 12 ms (0 ms spent in bootstraps)
2025-08-06 13:17:39,870 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:17:39,873 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 13:17:39,875 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:17:39,879 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:37249
2025-08-06 13:17:39,982 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 13:17:39,993 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.11
2025-08-06 13:17:40,086 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43859.
2025-08-06 13:17:40,092 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:43859
2025-08-06 13:17:40,096 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 13:17:40,113 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.11, 43859, None)
2025-08-06 13:17:40,140 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.11, 43859, None)
2025-08-06 13:17:40,142 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.11, 43859, None)
2025-08-06 13:17:40,155 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 13:18:40,599 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806131734-0000/0
2025-08-06 13:18:40,605 [ExecutorRunner for app-20250806131734-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806131734-0000/0 interrupted
2025-08-06 13:18:40,607 [ExecutorRunner for app-20250806131734-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 13:18:40,619 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 13:18:40,669 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 13:18:40,670 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 13:18:40,676 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 13:18:40,747 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806131734-0000/0 finished with state KILLED exitStatus 143
2025-08-06 13:18:40,755 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-06 13:18:40,758 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806131734-0000, execId=0)
2025-08-06 13:20:31,235 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806131734-0000/1 for Thrift JDBC/ODBC Server
2025-08-06 13:20:31,251 [ExecutorRunner for app-20250806131734-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:20:31,251 [ExecutorRunner for app-20250806131734-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:20:31,252 [ExecutorRunner for app-20250806131734-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:20:31,252 [ExecutorRunner for app-20250806131734-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:20:31,253 [ExecutorRunner for app-20250806131734-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:20:31,300 [ExecutorRunner for app-20250806131734-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45945" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@d2eef3aa55e4:45945" "--executor-id" "1" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806131734-0000" "--worker-url" "spark://Worker@172.18.0.11:37249" "--resourceProfileId" "0"
2025-08-06 13:20:33,004 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 205@8c7a37cd17dc
2025-08-06 13:20:33,013 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:20:33,014 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:20:33,014 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:20:33,388 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:20:33,493 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:20:33,494 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:20:33,495 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:20:33,497 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:20:33,497 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:20:33,793 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to d2eef3aa55e4/172.18.0.12:45945 after 70 ms (0 ms spent in bootstraps)
2025-08-06 13:20:33,900 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:20:33,900 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:20:33,901 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:20:33,901 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:20:33,902 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:20:33,969 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to d2eef3aa55e4/172.18.0.12:45945 after 2 ms (0 ms spent in bootstraps)
2025-08-06 13:20:34,072 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-a093a574-33e8-4ddd-b666-448234dbc251/executor-c1cfe437-f4b3-488c-a94a-25335f68ad34/blockmgr-979d9364-d946-4fb9-9993-90161105ea9e
2025-08-06 13:20:34,110 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 13:20:34,303 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@d2eef3aa55e4:45945
2025-08-06 13:20:34,304 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:37249
2025-08-06 13:20:34,309 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:37249 after 2 ms (0 ms spent in bootstraps)
2025-08-06 13:20:34,311 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:37249
2025-08-06 13:20:34,313 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:20:34,314 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 13:20:34,314 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:20:34,345 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 13:20:34,348 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.11
2025-08-06 13:20:34,403 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41789.
2025-08-06 13:20:34,404 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:41789
2025-08-06 13:20:34,408 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 13:20:34,417 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.11, 41789, None)
2025-08-06 13:20:34,432 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.11, 41789, None)
2025-08-06 13:20:34,433 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.11, 41789, None)
2025-08-06 13:20:34,441 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 13:20:34,514 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-06 13:20:34,519 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-06 13:20:34,526 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-08-06 13:20:34,526 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-06 13:20:34,617 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-06 13:20:34,662 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:20:34,717 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to d2eef3aa55e4/172.18.0.12:44201 after 2 ms (0 ms spent in bootstraps)
2025-08-06 13:20:34,780 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-06 13:20:34,794 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 131 ms
2025-08-06 13:20:34,865 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-06 13:20:35,084 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:20:35,093 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-06 13:20:35,099 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 14 ms
2025-08-06 13:20:35,151 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 13:20:35,946 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 13:20:35,957 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 13:20:35,958 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 13:20:36,916 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 13:20:36,916 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 13:20:37,296 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 13:20:37,296 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-06 13:20:38,079 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to orders/data/00001-1-fda24234-226c-4c7c-8c50-040ec08e1eab-0-00001.parquet. This is unsupported
2025-08-06 13:20:38,337 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 1, attempt 0, stage 0.0)
2025-08-06 13:20:38,337 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
2025-08-06 13:20:38,387 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 4316 bytes result sent to driver
2025-08-06 13:20:38,387 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 4316 bytes result sent to driver
2025-08-06 13:20:39,499 [block-manager-storage-async-thread-pool-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 13:20:47,004 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2
2025-08-06 13:20:47,005 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 2)
2025-08-06 13:20:47,069 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:20:47,080 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 434.4 MiB)
2025-08-06 13:20:47,086 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 5 took 16 ms
2025-08-06 13:20:47,088 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 44.5 KiB, free 434.3 MiB)
2025-08-06 13:20:47,529 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 258.760599 ms
2025-08-06 13:20:47,533 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:20:47,540 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 434.3 MiB)
2025-08-06 13:20:47,544 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 4 took 10 ms
2025-08-06 13:20:47,548 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 13:20:47,552 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 13:20:47,611 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.905985 ms
2025-08-06 13:20:47,629 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.327613 ms
2025-08-06 13:20:47,646 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.841201 ms
2025-08-06 13:20:47,690 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:20:47,697 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 425.7 MiB)
2025-08-06 13:20:47,703 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 3 took 12 ms
2025-08-06 13:20:47,708 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 425.7 MiB)
2025-08-06 13:20:47,813 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 13:20:47,851 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 13:20:47,863 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-06 13:20:47,863 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-06 13:20:47,876 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-06 13:20:47,879 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-06 13:20:47,881 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-06 13:20:48,360 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 13:20:48,373 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 13:20:48,413 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 13:20:48,456 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 2, attempt 0, stage 1.0)
2025-08-06 13:20:48,470 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 2). 8107 bytes result sent to driver
2025-08-06 13:21:48,937 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806131734-0000/1
2025-08-06 13:21:48,938 [ExecutorRunner for app-20250806131734-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806131734-0000/1 interrupted
2025-08-06 13:21:48,939 [ExecutorRunner for app-20250806131734-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 13:21:48,942 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 13:21:48,974 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 13:21:48,975 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 13:21:48,977 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 13:21:48,978 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 13:21:48,981 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 13:21:48,984 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 13:21:48,985 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 13:21:48,986 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 13:21:49,043 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806131734-0000/1 finished with state KILLED exitStatus 143
2025-08-06 13:21:49,044 [dispatcher-event-loop-5] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-06 13:21:49,044 [dispatcher-event-loop-5] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806131734-0000, execId=1)
2025-08-06 13:32:12,796 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806131734-0000/2 for Thrift JDBC/ODBC Server
2025-08-06 13:32:12,819 [ExecutorRunner for app-20250806131734-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:32:12,820 [ExecutorRunner for app-20250806131734-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:32:12,822 [ExecutorRunner for app-20250806131734-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:32:12,823 [ExecutorRunner for app-20250806131734-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:32:12,823 [ExecutorRunner for app-20250806131734-0000/2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:32:12,937 [ExecutorRunner for app-20250806131734-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45945" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@d2eef3aa55e4:45945" "--executor-id" "2" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806131734-0000" "--worker-url" "spark://Worker@172.18.0.11:37249" "--resourceProfileId" "0"
2025-08-06 13:32:14,504 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 314@8c7a37cd17dc
2025-08-06 13:32:14,517 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:32:14,520 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:32:14,521 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:32:14,830 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:32:14,962 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:32:14,963 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:32:14,964 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:32:14,965 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:32:14,966 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:32:15,297 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to d2eef3aa55e4/172.18.0.12:45945 after 69 ms (0 ms spent in bootstraps)
2025-08-06 13:32:15,412 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:32:15,413 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:32:15,413 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:32:15,414 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:32:15,414 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:32:15,634 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to d2eef3aa55e4/172.18.0.12:45945 after 2 ms (0 ms spent in bootstraps)
2025-08-06 13:32:15,715 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-a093a574-33e8-4ddd-b666-448234dbc251/executor-c1cfe437-f4b3-488c-a94a-25335f68ad34/blockmgr-54a8be41-d0d9-4477-8b20-6155809bad92
2025-08-06 13:32:15,748 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 13:32:15,989 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@d2eef3aa55e4:45945
2025-08-06 13:32:15,990 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:37249
2025-08-06 13:32:15,994 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:37249 after 2 ms (0 ms spent in bootstraps)
2025-08-06 13:32:15,996 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:37249
2025-08-06 13:32:16,003 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:32:16,004 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 13:32:16,005 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:32:16,035 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 13:32:16,039 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 2 on host 172.18.0.11
2025-08-06 13:32:16,131 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43659.
2025-08-06 13:32:16,132 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:43659
2025-08-06 13:32:16,140 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 13:32:16,156 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(2, 172.18.0.11, 43659, None)
2025-08-06 13:32:16,177 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(2, 172.18.0.11, 43659, None)
2025-08-06 13:32:16,182 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(2, 172.18.0.11, 43659, None)
2025-08-06 13:32:16,197 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 13:32:16,278 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3
2025-08-06 13:32:16,287 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4
2025-08-06 13:32:16,295 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 3)
2025-08-06 13:32:16,295 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 4)
2025-08-06 13:32:16,402 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 2 and clearing cache
2025-08-06 13:32:16,470 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:32:16,521 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to d2eef3aa55e4/172.18.0.12:44201 after 2 ms (0 ms spent in bootstraps)
2025-08-06 13:32:16,578 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-06 13:32:16,591 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 7 took 120 ms
2025-08-06 13:32:16,686 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-06 13:32:16,949 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:32:16,958 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-06 13:32:16,963 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 6 took 14 ms
2025-08-06 13:32:17,017 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 13:32:18,013 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 13:32:18,036 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 13:32:18,036 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 13:32:19,596 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 13:32:19,596 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 13:32:20,290 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 13:32:20,290 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-06 13:32:21,152 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to orders/data/00000-3-965a5e5b-684c-4909-95f8-cbad8d42b47a-0-00001.parquet. This is unsupported
2025-08-06 13:32:21,455 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 3, attempt 0, stage 2.0)
2025-08-06 13:32:21,455 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 4, attempt 0, stage 2.0)
2025-08-06 13:32:21,497 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 4). 4316 bytes result sent to driver
2025-08-06 13:32:21,497 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 3). 4316 bytes result sent to driver
2025-08-06 13:32:29,359 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5
2025-08-06 13:32:29,361 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 5)
2025-08-06 13:32:29,416 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 11 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:32:29,427 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 434.3 MiB)
2025-08-06 13:32:29,432 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 11 took 15 ms
2025-08-06 13:32:29,434 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 44.5 KiB, free 434.3 MiB)
2025-08-06 13:32:29,877 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 239.111353 ms
2025-08-06 13:32:29,881 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 10 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:32:29,887 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 434.2 MiB)
2025-08-06 13:32:29,891 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 10 took 10 ms
2025-08-06 13:32:29,894 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-06 13:32:29,899 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 13:32:29,968 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.63071 ms
2025-08-06 13:32:29,983 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.998072 ms
2025-08-06 13:32:30,002 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.35018 ms
2025-08-06 13:32:30,027 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:32:30,036 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 425.7 MiB)
2025-08-06 13:32:30,041 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 9 took 13 ms
2025-08-06 13:32:30,047 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 32.0 KiB, free 425.6 MiB)
2025-08-06 13:32:30,133 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 13:32:30,171 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 13:32:30,181 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-06 13:32:30,181 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-06 13:32:30,191 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-06 13:32:30,195 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-06 13:32:30,196 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-06 13:32:30,510 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 13:32:30,519 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 13:32:30,552 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 13:32:30,588 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 5, attempt 0, stage 3.0)
2025-08-06 13:32:30,599 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 5). 8107 bytes result sent to driver
2025-08-06 13:33:30,984 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806131734-0000/2
2025-08-06 13:33:30,985 [ExecutorRunner for app-20250806131734-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806131734-0000/2 interrupted
2025-08-06 13:33:30,986 [ExecutorRunner for app-20250806131734-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 13:33:30,989 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 13:33:31,009 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 13:33:31,011 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 13:33:31,012 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 13:33:31,013 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 13:33:31,013 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 13:33:31,016 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 13:33:31,019 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 13:33:31,019 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 13:33:31,020 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 13:33:31,256 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806131734-0000/2 finished with state KILLED exitStatus 143
2025-08-06 13:33:31,257 [dispatcher-event-loop-1] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-08-06 13:33:31,258 [dispatcher-event-loop-1] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806131734-0000, execId=2)
2025-08-06 13:50:02,290 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 32@97802755210f
2025-08-06 13:50:02,333 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:50:02,338 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:50:02,339 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:50:03,034 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:50:03,040 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:50:03,051 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:50:03,057 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:50:03,061 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:50:03,767 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:50:05,157 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 46645.
2025-08-06 13:50:05,161 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-06 13:50:05,669 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.11:46645 with 12 cores, 6.6 GiB RAM
2025-08-06 13:50:05,681 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-06 13:50:05,683 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-06 13:50:05,748 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:50:05,752 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-06 13:50:05,753 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:50:05,856 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @8176ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-06 13:50:05,958 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-06 13:50:05,981 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-06 13:50:06,021 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @8343ms
2025-08-06 13:50:06,104 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@407e9415{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-06 13:50:06,106 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-06 13:50:06,171 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@157da5bf{/logPage,null,AVAILABLE,@Spark}
2025-08-06 13:50:06,179 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3efb57c4{/logPage/json,null,AVAILABLE,@Spark}
2025-08-06 13:50:06,181 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@72d5ebe1{/,null,AVAILABLE,@Spark}
2025-08-06 13:50:06,183 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5777286f{/json,null,AVAILABLE,@Spark}
2025-08-06 13:50:06,218 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3ac19d39{/static,null,AVAILABLE,@Spark}
2025-08-06 13:50:06,222 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@63878c53{/log,null,AVAILABLE,@Spark}
2025-08-06 13:50:06,238 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://97802755210f:8081
2025-08-06 13:50:06,250 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-06 13:50:06,286 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@36e6cf1e{/metrics/json,null,AVAILABLE,@Spark}
2025-08-06 13:50:06,369 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 77 ms (0 ms spent in bootstraps)
2025-08-06 13:50:06,750 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-06 13:50:08,528 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806135007-0000/0 for Thrift JDBC/ODBC Server
2025-08-06 13:50:08,657 [ExecutorRunner for app-20250806135007-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:50:08,662 [ExecutorRunner for app-20250806135007-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:50:08,664 [ExecutorRunner for app-20250806135007-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:50:08,668 [ExecutorRunner for app-20250806135007-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:50:08,670 [ExecutorRunner for app-20250806135007-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:50:08,715 [ExecutorRunner for app-20250806135007-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=35955" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@20d92c75ff60:35955" "--executor-id" "0" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806135007-0000" "--worker-url" "spark://Worker@172.18.0.11:46645" "--resourceProfileId" "0"
2025-08-06 13:50:12,678 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 125@97802755210f
2025-08-06 13:50:12,724 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:50:12,745 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:50:12,747 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:50:13,700 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:50:14,006 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:50:14,012 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:50:14,017 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:50:14,019 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:50:14,021 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:50:14,789 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:35955 after 106 ms (0 ms spent in bootstraps)
2025-08-06 13:50:15,149 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:50:15,150 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:50:15,152 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:50:15,153 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:50:15,155 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:50:15,319 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:35955 after 3 ms (0 ms spent in bootstraps)
2025-08-06 13:50:15,521 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-bbb629be-3b44-45b7-aaa5-756bc7f24d7d/executor-30c10e68-9663-48a5-826d-dcc069886552/blockmgr-4bb0fa9b-d444-42cd-a069-1d787076fcd7
2025-08-06 13:50:15,608 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 13:50:16,034 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@20d92c75ff60:35955
2025-08-06 13:50:16,036 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:46645
2025-08-06 13:50:16,047 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:46645 after 8 ms (0 ms spent in bootstraps)
2025-08-06 13:50:16,060 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:50:16,063 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 13:50:16,064 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:50:16,135 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 13:50:16,144 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.11
2025-08-06 13:50:16,257 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42149.
2025-08-06 13:50:16,259 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:42149
2025-08-06 13:50:16,267 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 13:50:16,296 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.11, 42149, None)
2025-08-06 13:50:16,341 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.11, 42149, None)
2025-08-06 13:50:16,347 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.11, 42149, None)
2025-08-06 13:50:16,376 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 13:51:16,613 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806135007-0000/0
2025-08-06 13:51:16,616 [ExecutorRunner for app-20250806135007-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806135007-0000/0 interrupted
2025-08-06 13:51:16,617 [ExecutorRunner for app-20250806135007-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 13:51:16,622 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 13:51:16,656 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 13:51:16,658 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 13:51:16,662 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 13:51:16,710 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806135007-0000/0 finished with state KILLED exitStatus 143
2025-08-06 13:51:16,715 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-06 13:51:16,716 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806135007-0000, execId=0)
2025-08-06 13:54:28,886 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806135007-0000/1 for Thrift JDBC/ODBC Server
2025-08-06 13:54:28,904 [ExecutorRunner for app-20250806135007-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:54:28,904 [ExecutorRunner for app-20250806135007-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:54:28,905 [ExecutorRunner for app-20250806135007-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:54:28,905 [ExecutorRunner for app-20250806135007-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:54:28,906 [ExecutorRunner for app-20250806135007-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:54:28,970 [ExecutorRunner for app-20250806135007-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=35955" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@20d92c75ff60:35955" "--executor-id" "1" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806135007-0000" "--worker-url" "spark://Worker@172.18.0.11:46645" "--resourceProfileId" "0"
2025-08-06 13:54:30,780 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 207@97802755210f
2025-08-06 13:54:30,788 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 13:54:30,790 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 13:54:30,790 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 13:54:31,148 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 13:54:31,275 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:54:31,276 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:54:31,276 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:54:31,277 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:54:31,277 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:54:31,579 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:35955 after 62 ms (0 ms spent in bootstraps)
2025-08-06 13:54:31,694 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 13:54:31,695 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 13:54:31,695 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 13:54:31,696 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 13:54:31,696 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 13:54:31,962 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:35955 after 2 ms (0 ms spent in bootstraps)
2025-08-06 13:54:32,083 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-bbb629be-3b44-45b7-aaa5-756bc7f24d7d/executor-30c10e68-9663-48a5-826d-dcc069886552/blockmgr-767891f9-16f6-48e1-a0a2-3254b8b131ca
2025-08-06 13:54:32,125 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 13:54:32,384 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@20d92c75ff60:35955
2025-08-06 13:54:32,386 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:46645
2025-08-06 13:54:32,390 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:46645 after 2 ms (0 ms spent in bootstraps)
2025-08-06 13:54:32,392 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:46645
2025-08-06 13:54:32,395 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:54:32,396 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 13:54:32,398 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 13:54:32,421 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 13:54:32,424 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.11
2025-08-06 13:54:32,468 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41541.
2025-08-06 13:54:32,469 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:41541
2025-08-06 13:54:32,472 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 13:54:32,481 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.11, 41541, None)
2025-08-06 13:54:32,490 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.11, 41541, None)
2025-08-06 13:54:32,491 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.11, 41541, None)
2025-08-06 13:54:32,497 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 13:54:32,560 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-06 13:54:32,566 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-06 13:54:32,571 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-08-06 13:54:32,571 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-06 13:54:32,653 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-06 13:54:32,696 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:54:32,737 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:36307 after 2 ms (0 ms spent in bootstraps)
2025-08-06 13:54:32,804 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-06 13:54:32,815 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 118 ms
2025-08-06 13:54:32,885 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-06 13:54:33,078 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:54:33,088 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-06 13:54:33,094 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 15 ms
2025-08-06 13:54:33,140 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 13:54:33,682 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 13:54:33,694 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 13:54:33,694 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 13:54:34,434 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 13:54:34,434 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 13:54:34,796 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-06 13:54:34,796 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 13:54:35,432 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to orders/data/00001-1-22650c89-3ada-4608-b2f4-32e24006f0b2-0-00001.parquet. This is unsupported
2025-08-06 13:54:35,645 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 1, attempt 0, stage 0.0)
2025-08-06 13:54:35,645 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
2025-08-06 13:54:35,674 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 4316 bytes result sent to driver
2025-08-06 13:54:35,674 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 4316 bytes result sent to driver
2025-08-06 13:54:44,167 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2
2025-08-06 13:54:44,168 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 2)
2025-08-06 13:54:44,215 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:54:44,224 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 434.3 MiB)
2025-08-06 13:54:44,229 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 5 took 13 ms
2025-08-06 13:54:44,231 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 44.5 KiB, free 434.3 MiB)
2025-08-06 13:54:44,754 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 300.049683 ms
2025-08-06 13:54:44,759 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:54:44,769 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 434.2 MiB)
2025-08-06 13:54:44,776 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 4 took 16 ms
2025-08-06 13:54:44,780 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-06 13:54:44,787 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 13:54:44,883 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.354293 ms
2025-08-06 13:54:44,905 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.353805 ms
2025-08-06 13:54:44,924 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.585401 ms
2025-08-06 13:54:44,973 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 13:54:44,981 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 425.7 MiB)
2025-08-06 13:54:44,986 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 3 took 12 ms
2025-08-06 13:54:44,993 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 425.7 MiB)
2025-08-06 13:54:45,101 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 13:54:45,163 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 13:54:45,175 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-06 13:54:45,176 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-06 13:54:45,188 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-06 13:54:45,192 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-06 13:54:45,194 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-06 13:54:45,565 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 13:54:45,577 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 13:54:45,608 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 13:54:45,649 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 2, attempt 0, stage 1.0)
2025-08-06 13:54:45,654 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 2). 8064 bytes result sent to driver
2025-08-06 13:55:46,137 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806135007-0000/1
2025-08-06 13:55:46,138 [ExecutorRunner for app-20250806135007-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806135007-0000/1 interrupted
2025-08-06 13:55:46,138 [ExecutorRunner for app-20250806135007-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 13:55:46,142 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 13:55:46,172 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 13:55:46,175 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 13:55:46,179 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 13:55:46,182 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 13:55:46,183 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 13:55:46,187 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 13:55:46,191 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 13:55:46,192 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 13:55:46,193 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 13:55:46,260 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806135007-0000/1 finished with state KILLED exitStatus 143
2025-08-06 13:55:46,261 [dispatcher-event-loop-11] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-06 13:55:46,262 [dispatcher-event-loop-11] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806135007-0000, execId=1)
2025-08-06 14:03:22,465 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806135007-0000/2 for Thrift JDBC/ODBC Server
2025-08-06 14:03:22,471 [ExecutorRunner for app-20250806135007-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 14:03:22,472 [ExecutorRunner for app-20250806135007-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 14:03:22,472 [ExecutorRunner for app-20250806135007-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 14:03:22,473 [ExecutorRunner for app-20250806135007-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 14:03:22,473 [ExecutorRunner for app-20250806135007-0000/2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 14:03:22,509 [ExecutorRunner for app-20250806135007-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=35955" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@20d92c75ff60:35955" "--executor-id" "2" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806135007-0000" "--worker-url" "spark://Worker@172.18.0.11:46645" "--resourceProfileId" "0"
2025-08-06 14:03:23,884 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 314@97802755210f
2025-08-06 14:03:23,891 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 14:03:23,892 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 14:03:23,892 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 14:03:24,170 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 14:03:24,255 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 14:03:24,255 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 14:03:24,256 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 14:03:24,257 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 14:03:24,257 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 14:03:24,505 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:35955 after 61 ms (0 ms spent in bootstraps)
2025-08-06 14:03:24,700 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 14:03:24,700 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 14:03:24,701 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 14:03:24,701 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 14:03:24,701 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 14:03:24,750 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:35955 after 2 ms (0 ms spent in bootstraps)
2025-08-06 14:03:24,853 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-bbb629be-3b44-45b7-aaa5-756bc7f24d7d/executor-30c10e68-9663-48a5-826d-dcc069886552/blockmgr-331f85ee-609c-4035-9624-3b76cd91a11d
2025-08-06 14:03:24,884 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 14:03:25,115 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@20d92c75ff60:35955
2025-08-06 14:03:25,116 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:46645
2025-08-06 14:03:25,119 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:46645 after 1 ms (0 ms spent in bootstraps)
2025-08-06 14:03:25,122 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:46645
2025-08-06 14:03:25,126 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 14:03:25,127 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 14:03:25,128 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 14:03:25,156 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 14:03:25,159 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 2 on host 172.18.0.11
2025-08-06 14:03:25,207 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37887.
2025-08-06 14:03:25,207 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:37887
2025-08-06 14:03:25,210 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 14:03:25,217 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(2, 172.18.0.11, 37887, None)
2025-08-06 14:03:25,230 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(2, 172.18.0.11, 37887, None)
2025-08-06 14:03:25,231 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(2, 172.18.0.11, 37887, None)
2025-08-06 14:03:25,240 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 14:03:25,295 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3
2025-08-06 14:03:25,303 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4
2025-08-06 14:03:25,309 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 4)
2025-08-06 14:03:25,309 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 3)
2025-08-06 14:03:25,408 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 2 and clearing cache
2025-08-06 14:03:25,458 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:03:25,504 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:36307 after 2 ms (0 ms spent in bootstraps)
2025-08-06 14:03:25,572 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-06 14:03:25,588 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 7 took 129 ms
2025-08-06 14:03:25,655 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-06 14:03:25,887 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:03:25,897 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-06 14:03:25,903 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 6 took 15 ms
2025-08-06 14:03:25,955 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 14:03:26,725 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 14:03:26,739 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 14:03:26,740 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 14:03:27,451 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 14:03:27,451 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 14:03:27,810 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-06 14:03:27,810 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 14:03:28,423 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to orders/data/00001-4-867ec0e7-0dcb-4928-ba69-8f80d29b45d2-0-00001.parquet. This is unsupported
2025-08-06 14:03:28,594 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 4, attempt 0, stage 2.0)
2025-08-06 14:03:28,594 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 3, attempt 0, stage 2.0)
2025-08-06 14:03:28,622 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 4). 4316 bytes result sent to driver
2025-08-06 14:03:28,622 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 3). 4316 bytes result sent to driver
2025-08-06 14:03:36,015 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5
2025-08-06 14:03:36,017 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 5)
2025-08-06 14:03:36,094 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 11 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:03:36,103 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 434.3 MiB)
2025-08-06 14:03:36,109 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 11 took 14 ms
2025-08-06 14:03:36,111 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 44.5 KiB, free 434.3 MiB)
2025-08-06 14:03:36,574 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 237.829919 ms
2025-08-06 14:03:36,578 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 10 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:03:36,585 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 434.2 MiB)
2025-08-06 14:03:36,589 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 10 took 11 ms
2025-08-06 14:03:36,593 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-06 14:03:36,596 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 14:03:36,658 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.568389 ms
2025-08-06 14:03:36,677 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.901334 ms
2025-08-06 14:03:36,695 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.033721 ms
2025-08-06 14:03:36,747 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:03:36,760 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 425.7 MiB)
2025-08-06 14:03:36,764 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 9 took 16 ms
2025-08-06 14:03:36,770 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 32.0 KiB, free 425.7 MiB)
2025-08-06 14:03:36,873 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 14:03:36,917 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 14:03:36,930 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-06 14:03:36,931 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-06 14:03:36,943 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-06 14:03:36,947 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-06 14:03:36,949 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-06 14:03:37,378 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 14:03:37,390 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 14:03:37,423 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 14:03:37,479 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 5, attempt 0, stage 3.0)
2025-08-06 14:03:37,489 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 5). 8107 bytes result sent to driver
2025-08-06 14:04:37,902 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806135007-0000/2
2025-08-06 14:04:37,903 [ExecutorRunner for app-20250806135007-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806135007-0000/2 interrupted
2025-08-06 14:04:37,904 [ExecutorRunner for app-20250806135007-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 14:04:37,906 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 14:04:37,921 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 14:04:37,924 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 14:04:37,924 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 14:04:37,925 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 14:04:37,925 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 14:04:37,928 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 14:04:37,931 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 14:04:37,931 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 14:04:37,931 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 14:04:37,972 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806135007-0000/2 finished with state KILLED exitStatus 143
2025-08-06 14:04:37,973 [dispatcher-event-loop-6] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-08-06 14:04:37,973 [dispatcher-event-loop-6] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806135007-0000, execId=2)
2025-08-06 14:05:44,969 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250806135007-0000/3 for Thrift JDBC/ODBC Server
2025-08-06 14:05:44,972 [ExecutorRunner for app-20250806135007-0000/3] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 14:05:44,974 [ExecutorRunner for app-20250806135007-0000/3] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 14:05:44,974 [ExecutorRunner for app-20250806135007-0000/3] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 14:05:44,975 [ExecutorRunner for app-20250806135007-0000/3] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 14:05:44,975 [ExecutorRunner for app-20250806135007-0000/3] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 14:05:45,005 [ExecutorRunner for app-20250806135007-0000/3] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=35955" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@20d92c75ff60:35955" "--executor-id" "3" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250806135007-0000" "--worker-url" "spark://Worker@172.18.0.11:46645" "--resourceProfileId" "0"
2025-08-06 14:05:46,220 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 422@97802755210f
2025-08-06 14:05:46,228 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-06 14:05:46,230 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-06 14:05:46,231 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-06 14:05:46,551 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-06 14:05:46,647 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 14:05:46,648 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 14:05:46,649 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 14:05:46,649 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 14:05:46,650 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 14:05:46,924 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:35955 after 53 ms (0 ms spent in bootstraps)
2025-08-06 14:05:47,019 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-06 14:05:47,020 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-06 14:05:47,020 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-06 14:05:47,021 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-06 14:05:47,021 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-06 14:05:47,077 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:35955 after 2 ms (0 ms spent in bootstraps)
2025-08-06 14:05:47,146 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-bbb629be-3b44-45b7-aaa5-756bc7f24d7d/executor-30c10e68-9663-48a5-826d-dcc069886552/blockmgr-bd6a48c4-196a-48e8-9384-36e4df9d725d
2025-08-06 14:05:47,179 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-06 14:05:47,359 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@20d92c75ff60:35955
2025-08-06 14:05:47,361 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:46645
2025-08-06 14:05:47,364 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:46645 after 2 ms (0 ms spent in bootstraps)
2025-08-06 14:05:47,367 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:46645
2025-08-06 14:05:47,374 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 14:05:47,376 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-06 14:05:47,377 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-06 14:05:47,401 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-06 14:05:47,404 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 3 on host 172.18.0.11
2025-08-06 14:05:47,439 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41679.
2025-08-06 14:05:47,440 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:41679
2025-08-06 14:05:47,443 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-06 14:05:47,449 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(3, 172.18.0.11, 41679, None)
2025-08-06 14:05:47,459 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(3, 172.18.0.11, 41679, None)
2025-08-06 14:05:47,461 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(3, 172.18.0.11, 41679, None)
2025-08-06 14:05:47,468 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-06 14:05:47,508 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6
2025-08-06 14:05:47,514 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7
2025-08-06 14:05:47,519 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 6)
2025-08-06 14:05:47,519 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 7)
2025-08-06 14:05:47,592 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 3 and clearing cache
2025-08-06 14:05:47,636 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 13 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:05:47,667 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 20d92c75ff60/172.18.0.12:36307 after 1 ms (0 ms spent in bootstraps)
2025-08-06 14:05:47,693 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-06 14:05:47,703 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 13 took 66 ms
2025-08-06 14:05:47,763 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-06 14:05:47,934 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 12 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:05:47,942 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-06 14:05:47,948 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 12 took 13 ms
2025-08-06 14:05:47,997 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 14:05:48,563 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-06 14:05:48,574 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-06 14:05:48,575 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-06 14:05:49,298 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 14:05:49,298 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 14:05:49,675 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 14:05:49,675 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-06 14:05:50,236 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to orders/data/00001-7-4f3d6375-649a-4d55-b88c-ec83e2de4f6a-0-00001.parquet. This is unsupported
2025-08-06 14:05:50,463 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 6, attempt 0, stage 4.0)
2025-08-06 14:05:50,463 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 7, attempt 0, stage 4.0)
2025-08-06 14:05:50,488 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 6). 4316 bytes result sent to driver
2025-08-06 14:05:50,488 [Executor task launch worker for task 1.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 7). 4316 bytes result sent to driver
2025-08-06 14:05:56,968 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8
2025-08-06 14:05:56,969 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 8)
2025-08-06 14:05:56,993 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 14:05:57,027 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 17 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:05:57,035 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_17_piece0 stored as bytes in memory (estimated size 18.9 KiB, free 434.4 MiB)
2025-08-06 14:05:57,040 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 17 took 12 ms
2025-08-06 14:05:57,042 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_17 stored as values in memory (estimated size 44.5 KiB, free 434.3 MiB)
2025-08-06 14:05:57,511 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 265.556326 ms
2025-08-06 14:05:57,516 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 16 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:05:57,525 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 434.3 MiB)
2025-08-06 14:05:57,530 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 16 took 13 ms
2025-08-06 14:05:57,535 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-06 14:05:57,539 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 14:05:57,604 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.974832 ms
2025-08-06 14:05:57,628 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.852824 ms
2025-08-06 14:05:57,651 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.313936 ms
2025-08-06 14:05:57,726 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 15 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:05:57,737 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 425.7 MiB)
2025-08-06 14:05:57,743 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 15 took 16 ms
2025-08-06 14:05:57,751 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 32.0 KiB, free 425.7 MiB)
2025-08-06 14:05:57,864 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 14:05:57,908 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 14:05:57,925 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-06 14:05:57,926 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-06 14:05:57,945 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-06 14:05:57,950 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-06 14:05:57,953 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-06 14:05:58,365 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 14:05:58,381 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 14:05:58,442 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 14:05:58,488 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 8, attempt 0, stage 5.0)
2025-08-06 14:05:58,498 [Executor task launch worker for task 0.0 in stage 5.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 8). 8107 bytes result sent to driver
2025-08-06 14:06:04,799 [block-manager-storage-async-thread-pool-9] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 14:06:04,958 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9
2025-08-06 14:06:04,958 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 9)
2025-08-06 14:06:04,966 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 21 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:06:04,975 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 20.8 KiB, free 434.3 MiB)
2025-08-06 14:06:04,981 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 21 took 15 ms
2025-08-06 14:06:04,983 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_21 stored as values in memory (estimated size 49.8 KiB, free 434.3 MiB)
2025-08-06 14:06:05,060 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.253278 ms
2025-08-06 14:06:05,118 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 47.162916 ms
2025-08-06 14:06:05,162 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 19 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:06:05,185 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 425.7 MiB)
2025-08-06 14:06:05,192 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 19 took 29 ms
2025-08-06 14:06:05,195 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_19 stored as values in memory (estimated size 32.0 KiB, free 425.7 MiB)
2025-08-06 14:06:05,216 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-06 14:06:05,225 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-06 14:06:05,240 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 20 with 1 pieces (estimated total size 4.0 MiB)
2025-08-06 14:06:05,247 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 29.3 KiB, free 434.2 MiB)
2025-08-06 14:06:05,252 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 20 took 10 ms
2025-08-06 14:06:05,254 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_20 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-06 14:06:05,258 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-06 14:06:05,262 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-06 14:06:05,291 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 9, attempt 0, stage 6.0)
2025-08-06 14:06:05,299 [Executor task launch worker for task 0.0 in stage 6.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 9). 9690 bytes result sent to driver
2025-08-06 14:07:05,695 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250806135007-0000/3
2025-08-06 14:07:05,696 [ExecutorRunner for app-20250806135007-0000/3] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250806135007-0000/3 interrupted
2025-08-06 14:07:05,696 [ExecutorRunner for app-20250806135007-0000/3] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-06 14:07:05,699 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-06 14:07:05,716 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 14:07:05,716 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 14:07:05,717 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-06 14:07:05,717 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-06 14:07:05,717 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-06 14:07:05,720 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-06 14:07:05,722 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-06 14:07:05,723 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-06 14:07:05,723 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-06 14:07:05,789 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250806135007-0000/3 finished with state KILLED exitStatus 143
2025-08-06 14:07:05,791 [dispatcher-event-loop-2] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 3
2025-08-06 14:07:05,791 [dispatcher-event-loop-2] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250806135007-0000, execId=3)
2025-08-08 08:46:43,218 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@7f45f0e9a1da
2025-08-08 08:46:43,323 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 08:46:43,354 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 08:46:43,368 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 08:46:44,735 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 08:46:44,737 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 08:46:44,740 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 08:46:44,751 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 08:46:44,754 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 08:46:45,621 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 08:46:47,320 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 33639.
2025-08-08 08:46:47,328 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-08 08:46:48,146 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.11:33639 with 12 cores, 6.6 GiB RAM
2025-08-08 08:46:48,168 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-08 08:46:48,171 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-08 08:46:48,237 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 08:46:48,240 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-08 08:46:48,248 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 08:46:48,392 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @11849ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-08 08:46:48,511 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-08 08:46:48,559 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-08 08:46:48,627 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @12086ms
2025-08-08 08:46:48,722 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@1352a2bc{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-08 08:46:48,722 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-08 08:46:48,807 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@76522809{/logPage,null,AVAILABLE,@Spark}
2025-08-08 08:46:48,814 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@69089c94{/logPage/json,null,AVAILABLE,@Spark}
2025-08-08 08:46:48,821 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6733b664{/,null,AVAILABLE,@Spark}
2025-08-08 08:46:48,828 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@786a2c05{/json,null,AVAILABLE,@Spark}
2025-08-08 08:46:48,863 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b2c3ae3{/static,null,AVAILABLE,@Spark}
2025-08-08 08:46:48,871 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@abc70bf{/log,null,AVAILABLE,@Spark}
2025-08-08 08:46:48,884 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://7f45f0e9a1da:8081
2025-08-08 08:46:48,905 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-08 08:46:48,987 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3818c53b{/metrics/json,null,AVAILABLE,@Spark}
2025-08-08 08:46:49,091 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 83 ms (0 ms spent in bootstraps)
2025-08-08 08:46:49,524 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-08 08:46:51,523 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808084650-0000/0 for Thrift JDBC/ODBC Server
2025-08-08 08:46:51,606 [ExecutorRunner for app-20250808084650-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 08:46:51,608 [ExecutorRunner for app-20250808084650-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 08:46:51,609 [ExecutorRunner for app-20250808084650-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 08:46:51,610 [ExecutorRunner for app-20250808084650-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 08:46:51,611 [ExecutorRunner for app-20250808084650-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 08:46:51,659 [ExecutorRunner for app-20250808084650-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45905" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@90fd01a25c90:45905" "--executor-id" "0" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808084650-0000" "--worker-url" "spark://Worker@172.18.0.11:33639" "--resourceProfileId" "0"
2025-08-08 08:46:54,621 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 114@7f45f0e9a1da
2025-08-08 08:46:54,636 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 08:46:54,639 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 08:46:54,639 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 08:46:55,497 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 08:46:55,929 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 08:46:55,933 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 08:46:55,943 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 08:46:55,951 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 08:46:55,954 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 08:46:56,786 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 90fd01a25c90/172.18.0.12:45905 after 162 ms (0 ms spent in bootstraps)
2025-08-08 08:46:57,080 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 08:46:57,081 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 08:46:57,082 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 08:46:57,083 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 08:46:57,083 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 08:46:57,273 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 90fd01a25c90/172.18.0.12:45905 after 4 ms (0 ms spent in bootstraps)
2025-08-08 08:46:57,561 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-fc7cfe9c-aec1-4a4f-b4c2-1452021018b8/executor-38683e17-f556-4106-bc4d-3a77cee2a565/blockmgr-4450dffb-e0d7-42d0-b44b-df846bb6ead5
2025-08-08 08:46:57,638 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 08:46:58,004 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@90fd01a25c90:45905
2025-08-08 08:46:58,005 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:33639
2025-08-08 08:46:58,011 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:33639 after 2 ms (0 ms spent in bootstraps)
2025-08-08 08:46:58,019 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:33639
2025-08-08 08:46:58,029 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 08:46:58,034 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 08:46:58,041 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 08:46:58,115 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 08:46:58,122 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.11
2025-08-08 08:46:58,211 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37425.
2025-08-08 08:46:58,216 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:37425
2025-08-08 08:46:58,223 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 08:46:58,244 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.11, 37425, None)
2025-08-08 08:46:58,276 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.11, 37425, None)
2025-08-08 08:46:58,281 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.11, 37425, None)
2025-08-08 08:46:58,293 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 08:47:58,486 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808084650-0000/0
2025-08-08 08:47:58,493 [ExecutorRunner for app-20250808084650-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808084650-0000/0 interrupted
2025-08-08 08:47:58,495 [ExecutorRunner for app-20250808084650-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 08:47:58,499 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 08:47:58,530 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 08:47:58,531 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 08:47:58,537 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 08:47:58,621 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808084650-0000/0 finished with state KILLED exitStatus 143
2025-08-08 08:47:58,628 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-08 08:47:58,629 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808084650-0000, execId=0)
2025-08-08 08:50:11,882 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808084650-0000/1 for Thrift JDBC/ODBC Server
2025-08-08 08:50:11,888 [ExecutorRunner for app-20250808084650-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 08:50:11,888 [ExecutorRunner for app-20250808084650-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 08:50:11,888 [ExecutorRunner for app-20250808084650-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 08:50:11,889 [ExecutorRunner for app-20250808084650-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 08:50:11,889 [ExecutorRunner for app-20250808084650-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 08:50:11,908 [ExecutorRunner for app-20250808084650-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45905" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@90fd01a25c90:45905" "--executor-id" "1" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808084650-0000" "--worker-url" "spark://Worker@172.18.0.11:33639" "--resourceProfileId" "0"
2025-08-08 08:50:13,360 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 189@7f45f0e9a1da
2025-08-08 08:50:13,369 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 08:50:13,371 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 08:50:13,372 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 08:50:13,820 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 08:50:13,941 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 08:50:13,942 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 08:50:13,943 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 08:50:13,944 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 08:50:13,945 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 08:50:14,222 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 90fd01a25c90/172.18.0.12:45905 after 56 ms (0 ms spent in bootstraps)
2025-08-08 08:50:14,350 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 08:50:14,351 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 08:50:14,351 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 08:50:14,352 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 08:50:14,352 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 08:50:14,411 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 90fd01a25c90/172.18.0.12:45905 after 2 ms (0 ms spent in bootstraps)
2025-08-08 08:50:14,525 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-fc7cfe9c-aec1-4a4f-b4c2-1452021018b8/executor-38683e17-f556-4106-bc4d-3a77cee2a565/blockmgr-8d946994-16eb-4c73-89cf-531b4f63b2d1
2025-08-08 08:50:14,571 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 08:50:14,796 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@90fd01a25c90:45905
2025-08-08 08:50:14,798 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:33639
2025-08-08 08:50:14,803 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:33639 after 3 ms (0 ms spent in bootstraps)
2025-08-08 08:50:14,806 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:33639
2025-08-08 08:50:14,812 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 08:50:14,813 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 08:50:14,814 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 08:50:14,863 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 08:50:14,866 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.11
2025-08-08 08:50:14,920 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44449.
2025-08-08 08:50:14,921 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:44449
2025-08-08 08:50:14,924 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 08:50:14,932 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.11, 44449, None)
2025-08-08 08:50:14,943 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.11, 44449, None)
2025-08-08 08:50:14,945 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.11, 44449, None)
2025-08-08 08:50:14,956 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 08:50:15,011 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-08 08:50:15,016 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-08 08:50:15,022 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-08-08 08:50:15,022 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-08 08:50:15,116 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-08 08:50:15,170 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 08:50:15,217 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 90fd01a25c90/172.18.0.12:45807 after 2 ms (0 ms spent in bootstraps)
2025-08-08 08:50:15,292 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-08 08:50:15,309 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 138 ms
2025-08-08 08:50:15,395 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-08 08:50:15,635 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 08:50:15,644 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-08 08:50:15,650 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 14 ms
2025-08-08 08:50:15,711 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 08:50:16,443 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 08:50:16,459 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 08:50:16,460 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 08:50:17,362 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 08:50:17,362 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 08:50:17,789 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 08:50:17,789 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 08:50:18,488 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to t24_branch/data/00000-0-23824106-6b5a-45d2-8da9-862f7d62c596-0-00001.parquet. This is unsupported
2025-08-08 08:50:18,699 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
2025-08-08 08:50:18,699 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 1, attempt 0, stage 0.0)
2025-08-08 08:50:18,729 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 4437 bytes result sent to driver
2025-08-08 08:50:18,729 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 4437 bytes result sent to driver
2025-08-08 08:50:52,394 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 08:50:53,412 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2
2025-08-08 08:50:53,413 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 2)
2025-08-08 08:50:53,451 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 08:50:53,460 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.4 MiB)
2025-08-08 08:50:53,465 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 5 took 13 ms
2025-08-08 08:50:53,467 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 20.3 KiB, free 434.4 MiB)
2025-08-08 08:50:53,762 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 175.925589 ms
2025-08-08 08:50:53,767 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 08:50:53,774 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.3 MiB)
2025-08-08 08:50:53,778 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 4 took 11 ms
2025-08-08 08:50:53,782 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 08:50:53,786 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 08:50:53,796 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 08:50:53,803 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 08:50:53,808 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 3 took 12 ms
2025-08-08 08:50:53,815 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 08:50:53,908 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 08:50:53,924 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-08 08:50:53,924 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-08 08:50:53,935 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-08 08:50:53,938 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-08 08:50:53,939 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-08 08:50:54,057 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 08:50:54,269 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 08:50:54,277 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 08:50:54,284 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 08:50:54,323 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 2, attempt 0, stage 1.0)
2025-08-08 08:50:54,327 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 2). 7738 bytes result sent to driver
2025-08-08 08:51:54,643 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808084650-0000/1
2025-08-08 08:51:54,644 [ExecutorRunner for app-20250808084650-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808084650-0000/1 interrupted
2025-08-08 08:51:54,644 [ExecutorRunner for app-20250808084650-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 08:51:54,647 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 08:51:54,674 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 08:51:54,675 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 08:51:54,676 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 08:51:54,677 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 08:51:54,681 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 08:51:54,683 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 08:51:54,684 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 08:51:54,685 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 08:51:54,749 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808084650-0000/1 finished with state KILLED exitStatus 143
2025-08-08 08:51:54,750 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-08 08:51:54,753 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808084650-0000, execId=1)
2025-08-08 08:51:58,174 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808084650-0000/2 for Thrift JDBC/ODBC Server
2025-08-08 08:51:58,178 [ExecutorRunner for app-20250808084650-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 08:51:58,179 [ExecutorRunner for app-20250808084650-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 08:51:58,179 [ExecutorRunner for app-20250808084650-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 08:51:58,179 [ExecutorRunner for app-20250808084650-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 08:51:58,180 [ExecutorRunner for app-20250808084650-0000/2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 08:51:58,215 [ExecutorRunner for app-20250808084650-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=45905" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@90fd01a25c90:45905" "--executor-id" "2" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808084650-0000" "--worker-url" "spark://Worker@172.18.0.11:33639" "--resourceProfileId" "0"
2025-08-08 08:51:59,532 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 299@7f45f0e9a1da
2025-08-08 08:51:59,540 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 08:51:59,541 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 08:51:59,541 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 08:51:59,874 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 08:51:59,961 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 08:51:59,962 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 08:51:59,962 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 08:51:59,963 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 08:51:59,963 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 08:52:00,226 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 90fd01a25c90/172.18.0.12:45905 after 64 ms (0 ms spent in bootstraps)
2025-08-08 08:52:00,319 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 08:52:00,320 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 08:52:00,320 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 08:52:00,320 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 08:52:00,321 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 08:52:00,378 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 90fd01a25c90/172.18.0.12:45905 after 2 ms (0 ms spent in bootstraps)
2025-08-08 08:52:00,450 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-fc7cfe9c-aec1-4a4f-b4c2-1452021018b8/executor-38683e17-f556-4106-bc4d-3a77cee2a565/blockmgr-cbf58f85-6526-4f2b-a570-dfd14f361755
2025-08-08 08:52:00,495 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 08:52:00,660 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@90fd01a25c90:45905
2025-08-08 08:52:00,662 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:33639
2025-08-08 08:52:00,666 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:33639 after 2 ms (0 ms spent in bootstraps)
2025-08-08 08:52:00,668 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:33639
2025-08-08 08:52:00,672 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 08:52:00,673 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 08:52:00,674 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 08:52:00,696 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 08:52:00,699 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 2 on host 172.18.0.11
2025-08-08 08:52:00,733 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33779.
2025-08-08 08:52:00,734 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:33779
2025-08-08 08:52:00,736 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 08:52:00,741 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(2, 172.18.0.11, 33779, None)
2025-08-08 08:52:00,751 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(2, 172.18.0.11, 33779, None)
2025-08-08 08:52:00,753 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(2, 172.18.0.11, 33779, None)
2025-08-08 08:52:00,760 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 08:52:00,795 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3
2025-08-08 08:52:00,801 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4
2025-08-08 08:52:00,807 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 3)
2025-08-08 08:52:00,807 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 4)
2025-08-08 08:52:00,877 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-08 08:52:00,922 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 08:52:00,955 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 90fd01a25c90/172.18.0.12:45807 after 2 ms (0 ms spent in bootstraps)
2025-08-08 08:52:00,982 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-08 08:52:00,993 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 7 took 70 ms
2025-08-08 08:52:01,036 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-08 08:52:01,210 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 08:52:01,220 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-08 08:52:01,224 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 6 took 13 ms
2025-08-08 08:52:01,274 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 08:52:01,794 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 08:52:01,807 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 08:52:01,808 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 08:52:02,707 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 08:52:02,707 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 08:52:03,062 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 08:52:03,062 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 08:52:03,633 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to t24_branch/data/00001-4-77339f83-1291-4dfa-9658-0f56358c4390-0-00001.parquet. This is unsupported
2025-08-08 08:52:03,817 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 3, attempt 0, stage 2.0)
2025-08-08 08:52:03,817 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 4, attempt 0, stage 2.0)
2025-08-08 08:52:03,843 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 4). 4437 bytes result sent to driver
2025-08-08 08:52:03,843 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 3). 4437 bytes result sent to driver
2025-08-08 08:53:04,205 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808084650-0000/2
2025-08-08 08:53:04,208 [ExecutorRunner for app-20250808084650-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808084650-0000/2 interrupted
2025-08-08 08:53:04,208 [ExecutorRunner for app-20250808084650-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 08:53:04,210 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 08:53:04,233 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 08:53:04,236 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 08:53:04,238 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 08:53:04,242 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 08:53:04,245 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 08:53:04,246 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 08:53:04,246 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 08:53:04,311 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808084650-0000/2 finished with state KILLED exitStatus 143
2025-08-08 08:53:04,312 [dispatcher-event-loop-11] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-08-08 08:53:04,314 [dispatcher-event-loop-11] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808084650-0000, execId=2)
2025-08-08 09:33:13,671 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 34@8ff1a0ac03e8
2025-08-08 09:33:13,691 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 09:33:13,696 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 09:33:13,699 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 09:33:14,190 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:33:14,195 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:33:14,198 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:33:14,208 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:33:14,219 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:33:14,851 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 09:33:15,906 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 40593.
2025-08-08 09:33:15,917 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-08 09:33:16,571 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.11:40593 with 12 cores, 6.6 GiB RAM
2025-08-08 09:33:16,597 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-08 09:33:16,601 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-08 09:33:16,636 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:33:16,638 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-08 09:33:16,640 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:33:16,750 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @6364ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-08 09:33:16,843 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-08 09:33:16,881 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-08 09:33:16,942 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @6559ms
2025-08-08 09:33:17,033 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@6eac1128{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-08 09:33:17,037 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-08 09:33:17,138 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@560a5f39{/logPage,null,AVAILABLE,@Spark}
2025-08-08 09:33:17,147 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ffb1f26{/logPage/json,null,AVAILABLE,@Spark}
2025-08-08 09:33:17,156 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1beee8f{/,null,AVAILABLE,@Spark}
2025-08-08 09:33:17,171 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73aa71b8{/json,null,AVAILABLE,@Spark}
2025-08-08 09:33:17,199 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d16b5fb{/static,null,AVAILABLE,@Spark}
2025-08-08 09:33:17,206 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70d3d9aa{/log,null,AVAILABLE,@Spark}
2025-08-08 09:33:17,213 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://8ff1a0ac03e8:8081
2025-08-08 09:33:17,220 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-08 09:33:17,299 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32a89fc2{/metrics/json,null,AVAILABLE,@Spark}
2025-08-08 09:33:17,451 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 127 ms (0 ms spent in bootstraps)
2025-08-08 09:33:17,767 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-08 09:33:19,278 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808093318-0000/0 for Thrift JDBC/ODBC Server
2025-08-08 09:33:19,370 [ExecutorRunner for app-20250808093318-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:33:19,372 [ExecutorRunner for app-20250808093318-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:33:19,375 [ExecutorRunner for app-20250808093318-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:33:19,377 [ExecutorRunner for app-20250808093318-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:33:19,378 [ExecutorRunner for app-20250808093318-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:33:19,430 [ExecutorRunner for app-20250808093318-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46139" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3b133379d565:46139" "--executor-id" "0" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808093318-0000" "--worker-url" "spark://Worker@172.18.0.11:40593" "--resourceProfileId" "0"
2025-08-08 09:33:21,740 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 124@8ff1a0ac03e8
2025-08-08 09:33:21,751 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 09:33:21,753 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 09:33:21,754 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 09:33:22,380 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 09:33:22,625 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:33:22,636 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:33:22,642 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:33:22,648 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:33:22,650 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:33:23,429 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 214 ms (0 ms spent in bootstraps)
2025-08-08 09:33:23,699 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:33:23,700 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:33:23,701 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:33:23,702 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:33:23,702 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:33:23,865 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 8 ms (0 ms spent in bootstraps)
2025-08-08 09:33:24,068 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-d72e3a66-cb73-4f67-8558-7618373c80c3/executor-63c3aaa1-ceaa-4399-b2eb-f993797d0f8c/blockmgr-0408496c-61b7-48b5-a74b-4610aa07ea38
2025-08-08 09:33:24,122 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 09:33:24,381 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3b133379d565:46139
2025-08-08 09:33:24,389 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:40593
2025-08-08 09:33:24,395 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:40593 after 2 ms (0 ms spent in bootstraps)
2025-08-08 09:33:24,406 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:40593
2025-08-08 09:33:24,411 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:33:24,414 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 09:33:24,417 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:33:24,485 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 09:33:24,499 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.11
2025-08-08 09:33:24,583 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35315.
2025-08-08 09:33:24,584 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:35315
2025-08-08 09:33:24,587 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 09:33:24,596 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.11, 35315, None)
2025-08-08 09:33:24,622 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.11, 35315, None)
2025-08-08 09:33:24,626 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.11, 35315, None)
2025-08-08 09:33:24,652 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 09:34:24,896 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808093318-0000/0
2025-08-08 09:34:24,897 [ExecutorRunner for app-20250808093318-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808093318-0000/0 interrupted
2025-08-08 09:34:24,898 [ExecutorRunner for app-20250808093318-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 09:34:24,901 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 09:34:24,948 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 09:34:24,949 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 09:34:24,953 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 09:34:25,010 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808093318-0000/0 finished with state KILLED exitStatus 143
2025-08-08 09:34:25,013 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-08 09:34:25,014 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808093318-0000, execId=0)
2025-08-08 09:39:00,662 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808093318-0000/1 for Thrift JDBC/ODBC Server
2025-08-08 09:39:00,668 [ExecutorRunner for app-20250808093318-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:39:00,668 [ExecutorRunner for app-20250808093318-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:39:00,669 [ExecutorRunner for app-20250808093318-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:39:00,669 [ExecutorRunner for app-20250808093318-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:39:00,669 [ExecutorRunner for app-20250808093318-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:39:00,696 [ExecutorRunner for app-20250808093318-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46139" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3b133379d565:46139" "--executor-id" "1" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808093318-0000" "--worker-url" "spark://Worker@172.18.0.11:40593" "--resourceProfileId" "0"
2025-08-08 09:39:02,409 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 205@8ff1a0ac03e8
2025-08-08 09:39:02,426 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 09:39:02,430 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 09:39:02,431 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 09:39:03,079 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 09:39:03,205 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:39:03,208 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:39:03,211 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:39:03,213 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:39:03,214 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:39:03,600 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 70 ms (0 ms spent in bootstraps)
2025-08-08 09:39:03,695 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:39:03,698 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:39:03,699 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:39:03,699 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:39:03,700 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:39:03,774 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 2 ms (0 ms spent in bootstraps)
2025-08-08 09:39:03,900 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-d72e3a66-cb73-4f67-8558-7618373c80c3/executor-63c3aaa1-ceaa-4399-b2eb-f993797d0f8c/blockmgr-4d1279fd-1c0b-41f5-ad06-4b7d4ca8d5c8
2025-08-08 09:39:03,941 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 09:39:04,152 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3b133379d565:46139
2025-08-08 09:39:04,154 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:40593
2025-08-08 09:39:04,162 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:40593 after 4 ms (0 ms spent in bootstraps)
2025-08-08 09:39:04,165 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:40593
2025-08-08 09:39:04,169 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:39:04,170 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 09:39:04,171 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:39:04,202 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 09:39:04,205 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.11
2025-08-08 09:39:04,249 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41981.
2025-08-08 09:39:04,250 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:41981
2025-08-08 09:39:04,253 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 09:39:04,259 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.11, 41981, None)
2025-08-08 09:39:04,269 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.11, 41981, None)
2025-08-08 09:39:04,271 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.11, 41981, None)
2025-08-08 09:39:04,277 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 09:39:04,340 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-08 09:39:04,348 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-08 09:39:04,355 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-08-08 09:39:04,355 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-08 09:39:04,437 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-08 09:39:04,524 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:39:04,605 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:37515 after 2 ms (0 ms spent in bootstraps)
2025-08-08 09:39:04,673 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-08 09:39:04,694 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 168 ms
2025-08-08 09:39:04,802 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-08 09:39:05,010 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:39:05,018 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-08 09:39:05,022 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 11 ms
2025-08-08 09:39:05,063 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 09:39:05,635 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 09:39:05,647 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 09:39:05,648 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 09:39:06,293 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:39:06,293 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:39:06,629 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 09:39:06,629 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 09:39:07,316 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to t24_branch/data/00000-0-6bc89726-0ab9-4c3e-b92a-979f63921918-0-00001.parquet. This is unsupported
2025-08-08 09:39:07,595 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 1, attempt 0, stage 0.0)
2025-08-08 09:39:07,595 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
2025-08-08 09:39:07,629 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 4437 bytes result sent to driver
2025-08-08 09:39:07,629 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 4439 bytes result sent to driver
2025-08-08 09:39:30,852 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:40:08,221 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808093318-0000/1
2025-08-08 09:40:08,222 [ExecutorRunner for app-20250808093318-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808093318-0000/1 interrupted
2025-08-08 09:40:08,223 [ExecutorRunner for app-20250808093318-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 09:40:08,225 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 09:40:08,243 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 09:40:08,244 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 09:40:08,246 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 09:40:08,248 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 09:40:08,249 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 09:40:08,249 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 09:40:08,296 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808093318-0000/1 finished with state KILLED exitStatus 143
2025-08-08 09:40:08,297 [dispatcher-event-loop-6] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-08 09:40:08,298 [dispatcher-event-loop-6] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808093318-0000, execId=1)
2025-08-08 09:45:15,401 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808093318-0000/2 for Thrift JDBC/ODBC Server
2025-08-08 09:45:15,404 [ExecutorRunner for app-20250808093318-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:45:15,404 [ExecutorRunner for app-20250808093318-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:45:15,405 [ExecutorRunner for app-20250808093318-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:45:15,405 [ExecutorRunner for app-20250808093318-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:45:15,405 [ExecutorRunner for app-20250808093318-0000/2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:45:15,423 [ExecutorRunner for app-20250808093318-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46139" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3b133379d565:46139" "--executor-id" "2" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808093318-0000" "--worker-url" "spark://Worker@172.18.0.11:40593" "--resourceProfileId" "0"
2025-08-08 09:45:16,498 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 302@8ff1a0ac03e8
2025-08-08 09:45:16,504 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 09:45:16,505 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 09:45:16,506 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 09:45:16,764 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 09:45:16,843 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:45:16,844 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:45:16,845 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:45:16,845 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:45:16,846 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:45:17,054 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 43 ms (0 ms spent in bootstraps)
2025-08-08 09:45:17,126 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:45:17,126 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:45:17,127 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:45:17,127 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:45:17,128 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:45:17,176 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 1 ms (0 ms spent in bootstraps)
2025-08-08 09:45:17,234 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-d72e3a66-cb73-4f67-8558-7618373c80c3/executor-63c3aaa1-ceaa-4399-b2eb-f993797d0f8c/blockmgr-b87697b4-5589-4763-9dc8-dd804aafbbb3
2025-08-08 09:45:17,262 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 09:45:17,426 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3b133379d565:46139
2025-08-08 09:45:17,427 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:40593
2025-08-08 09:45:17,431 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:40593 after 2 ms (0 ms spent in bootstraps)
2025-08-08 09:45:17,432 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:40593
2025-08-08 09:45:17,435 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:45:17,436 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 09:45:17,436 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:45:17,455 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 09:45:17,458 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 2 on host 172.18.0.11
2025-08-08 09:45:17,492 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38081.
2025-08-08 09:45:17,493 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:38081
2025-08-08 09:45:17,496 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 09:45:17,502 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(2, 172.18.0.11, 38081, None)
2025-08-08 09:45:17,511 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(2, 172.18.0.11, 38081, None)
2025-08-08 09:45:17,513 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(2, 172.18.0.11, 38081, None)
2025-08-08 09:45:17,519 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 09:45:17,561 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2
2025-08-08 09:45:17,570 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 2)
2025-08-08 09:45:17,989 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 2 and clearing cache
2025-08-08 09:45:18,027 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:18,061 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:37515 after 1 ms (0 ms spent in bootstraps)
2025-08-08 09:45:18,090 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)
2025-08-08 09:45:18,099 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 5 took 71 ms
2025-08-08 09:45:18,138 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 19.6 KiB, free 434.4 MiB)
2025-08-08 09:45:18,548 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 170.134601 ms
2025-08-08 09:45:18,565 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:18,573 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.3 MiB)
2025-08-08 09:45:18,578 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 4 took 11 ms
2025-08-08 09:45:18,615 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 09:45:18,807 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 09:45:18,822 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 09:45:18,823 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 09:45:19,370 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:45:19,701 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:19,709 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 09:45:19,713 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 3 took 11 ms
2025-08-08 09:45:19,718 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 09:45:19,892 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:20,193 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-08 09:45:20,193 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-08 09:45:20,211 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-08 09:45:20,214 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-08 09:45:20,216 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-08 09:45:20,343 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:20,555 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:20,564 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:20,571 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 09:45:20,696 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to dim_branch/data/00000-2-2fe74ea7-b3d8-4a15-aa34-8a3b5ac2a989-0-00001.parquet. This is unsupported
2025-08-08 09:45:20,822 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 2, attempt 0, stage 1.0)
2025-08-08 09:45:20,861 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 2). 7819 bytes result sent to driver
2025-08-08 09:45:21,265 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:45:21,282 [block-manager-storage-async-thread-pool-9] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:45:49,682 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3
2025-08-08 09:45:49,684 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 3)
2025-08-08 09:45:49,693 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4
2025-08-08 09:45:49,695 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 4)
2025-08-08 09:45:49,720 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 24 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:49,720 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 25 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:49,729 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_24_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.4 MiB)
2025-08-08 09:45:49,735 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 434.4 MiB)
2025-08-08 09:45:49,735 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 24 took 14 ms
2025-08-08 09:45:49,737 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_24 stored as values in memory (estimated size 16.1 KiB, free 434.4 MiB)
2025-08-08 09:45:49,742 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 25 took 16 ms
2025-08-08 09:45:49,744 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_25 stored as values in memory (estimated size 13.7 KiB, free 434.4 MiB)
2025-08-08 09:45:49,812 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.184493 ms
2025-08-08 09:45:49,818 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 23 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:49,826 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 25.932593 ms
2025-08-08 09:45:49,829 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_23_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-08 09:45:49,829 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 16 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:49,835 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 23 took 14 ms
2025-08-08 09:45:49,837 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 09:45:49,841 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_23 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 09:45:49,843 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 16 took 13 ms
2025-08-08 09:45:49,846 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 09:45:49,860 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:49,861 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:49,896 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:49,896 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:49,915 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 4). 4765 bytes result sent to driver
2025-08-08 09:45:49,925 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:49,937 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:49,948 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 3). 5827 bytes result sent to driver
2025-08-08 09:45:50,380 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5
2025-08-08 09:45:50,381 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6
2025-08-08 09:45:50,381 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 5)
2025-08-08 09:45:50,382 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 4.0 (TID 6)
2025-08-08 09:45:50,394 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 39 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:50,406 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_39_piece0 stored as bytes in memory (estimated size 36.4 KiB, free 434.2 MiB)
2025-08-08 09:45:50,410 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 39 took 13 ms
2025-08-08 09:45:50,412 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_39 stored as values in memory (estimated size 108.3 KiB, free 434.1 MiB)
2025-08-08 09:45:50,563 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 29.817828 ms
2025-08-08 09:45:50,564 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 30.221637 ms
2025-08-08 09:45:50,565 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 27 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:50,573 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_27_piece0 stored as bytes in memory (estimated size 1706.0 B, free 434.1 MiB)
2025-08-08 09:45:50,578 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 27 took 11 ms
2025-08-08 09:45:50,590 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_27 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-08 09:45:50,592 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 38 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:50,598 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_38_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.1 MiB)
2025-08-08 09:45:50,602 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 38 took 9 ms
2025-08-08 09:45:50,604 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_38 stored as values in memory (estimated size 32.0 KiB, free 426.1 MiB)
2025-08-08 09:45:50,607 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:45:50,608 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:45:50,610 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 34 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:50,610 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 33 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:50,617 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_34_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.0 MiB)
2025-08-08 09:45:50,617 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_33_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.0 MiB)
2025-08-08 09:45:50,621 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 34 took 11 ms
2025-08-08 09:45:50,622 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 33 took 12 ms
2025-08-08 09:45:50,624 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_34 stored as values in memory (estimated size 32.0 KiB, free 426.0 MiB)
2025-08-08 09:45:50,624 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_33 stored as values in memory (estimated size 32.0 KiB, free 426.0 MiB)
2025-08-08 09:45:50,639 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:50,639 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:50,655 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:50,655 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:50,666 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 09:45:50,666 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 09:45:50,682 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 6, attempt 0, stage 4.0)
2025-08-08 09:45:50,682 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 5, attempt 0, stage 4.0)
2025-08-08 09:45:50,687 [Executor task launch worker for task 1.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 4.0 (TID 6). 18002 bytes result sent to driver
2025-08-08 09:45:50,688 [Executor task launch worker for task 0.0 in stage 4.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 5). 18002 bytes result sent to driver
2025-08-08 09:45:50,695 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7
2025-08-08 09:45:50,696 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 4.0 (TID 7)
2025-08-08 09:45:50,696 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8
2025-08-08 09:45:50,698 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 4.0 (TID 8)
2025-08-08 09:45:50,724 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 18.554428 ms
2025-08-08 09:45:50,726 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 26 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:50,729 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 23.322256 ms
2025-08-08 09:45:50,735 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_26_piece0 stored as bytes in memory (estimated size 492.0 B, free 426.0 MiB)
2025-08-08 09:45:50,739 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 26 took 12 ms
2025-08-08 09:45:50,743 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_26 stored as values in memory (estimated size 8.0 MiB, free 418.0 MiB)
2025-08-08 09:45:50,746 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:45:50,754 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 37 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:50,761 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_37_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 417.9 MiB)
2025-08-08 09:45:50,766 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 37 took 10 ms
2025-08-08 09:45:50,768 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_37 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-08 09:45:50,787 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:50,795 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:50,807 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.692156 ms
2025-08-08 09:45:50,812 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:50,821 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:50,825 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 3 is committing.
2025-08-08 09:45:50,834 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 3 (task 8, attempt 0, stage 4.0)
2025-08-08 09:45:50,837 [Executor task launch worker for task 3.0 in stage 4.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 4.0 (TID 8). 18045 bytes result sent to driver
2025-08-08 09:45:50,850 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.212439 ms
2025-08-08 09:45:50,879 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 17.914481 ms
2025-08-08 09:45:50,914 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 25.130684 ms
2025-08-08 09:45:50,920 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:45:50,924 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 35 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:50,932 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_35_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.7 MiB)
2025-08-08 09:45:50,937 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 35 took 12 ms
2025-08-08 09:45:50,940 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_35 stored as values in memory (estimated size 32.0 KiB, free 417.7 MiB)
2025-08-08 09:45:50,956 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:50,967 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:50,989 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 36 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:45:50,997 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_36_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.7 MiB)
2025-08-08 09:45:51,001 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 36 took 10 ms
2025-08-08 09:45:51,003 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_36 stored as values in memory (estimated size 32.0 KiB, free 409.6 MiB)
2025-08-08 09:45:51,019 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:45:51,027 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:45:51,041 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 2 is committing.
2025-08-08 09:45:51,065 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 2 (task 7, attempt 0, stage 4.0)
2025-08-08 09:45:51,068 [Executor task launch worker for task 2.0 in stage 4.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 4.0 (TID 7). 21221 bytes result sent to driver
2025-08-08 09:46:39,489 [block-manager-storage-async-thread-pool-36] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:46:39,969 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9
2025-08-08 09:46:39,971 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10
2025-08-08 09:46:39,971 [Executor task launch worker for task 0.0 in stage 5.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 9)
2025-08-08 09:46:39,972 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 5.0 (TID 10)
2025-08-08 09:46:39,977 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 41 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:40,005 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_41_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 418.0 MiB)
2025-08-08 09:46:40,015 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 41 took 33 ms
2025-08-08 09:46:40,018 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_41 stored as values in memory (estimated size 8.1 KiB, free 418.0 MiB)
2025-08-08 09:46:40,022 [block-manager-storage-async-thread-pool-48] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:46:40,029 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 40 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:40,039 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_40_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 426.0 MiB)
2025-08-08 09:46:40,043 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 40 took 14 ms
2025-08-08 09:46:40,046 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_40 stored as values in memory (estimated size 32.0 KiB, free 426.0 MiB)
2025-08-08 09:46:40,050 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:46:40,050 [Executor task launch worker for task 0.0 in stage 5.0 (TID 9)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:46:40,052 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 09:46:40,052 [Executor task launch worker for task 0.0 in stage 5.0 (TID 9)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 09:46:40,062 [block-manager-storage-async-thread-pool-60] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:46:40,073 [block-manager-storage-async-thread-pool-63] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:46:40,080 [block-manager-storage-async-thread-pool-66] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:46:40,086 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 10, attempt 0, stage 5.0)
2025-08-08 09:46:40,087 [Executor task launch worker for task 0.0 in stage 5.0 (TID 9)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 9, attempt 0, stage 5.0)
2025-08-08 09:46:40,098 [Executor task launch worker for task 0.0 in stage 5.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 9). 4437 bytes result sent to driver
2025-08-08 09:46:40,098 [Executor task launch worker for task 1.0 in stage 5.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 5.0 (TID 10). 4438 bytes result sent to driver
2025-08-08 09:46:40,105 [block-manager-storage-async-thread-pool-69] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:46:40,130 [block-manager-storage-async-thread-pool-72] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:46:40,146 [block-manager-storage-async-thread-pool-78] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:46:47,767 [block-manager-storage-async-thread-pool-14] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:46:48,369 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 11
2025-08-08 09:46:48,370 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 11)
2025-08-08 09:46:48,375 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 60 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,384 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 12
2025-08-08 09:46:48,384 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_60_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 434.4 MiB)
2025-08-08 09:46:48,386 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 12)
2025-08-08 09:46:48,389 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 61 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,390 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 60 took 14 ms
2025-08-08 09:46:48,392 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_60 stored as values in memory (estimated size 13.7 KiB, free 434.4 MiB)
2025-08-08 09:46:48,396 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 59 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,397 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_61_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.4 MiB)
2025-08-08 09:46:48,401 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 61 took 11 ms
2025-08-08 09:46:48,403 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_61 stored as values in memory (estimated size 16.1 KiB, free 434.4 MiB)
2025-08-08 09:46:48,404 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_59_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-08 09:46:48,408 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 52 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,409 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 59 took 12 ms
2025-08-08 09:46:48,412 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_59 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 09:46:48,416 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_52_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 09:46:48,422 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 52 took 12 ms
2025-08-08 09:46:48,425 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_52 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 09:46:48,429 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:48,438 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:48,438 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:48,447 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:48,452 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:48,460 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:48,461 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:48,468 [Executor task launch worker for task 0.0 in stage 6.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 11). 4773 bytes result sent to driver
2025-08-08 09:46:48,474 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:48,494 [Executor task launch worker for task 0.0 in stage 7.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 12). 5838 bytes result sent to driver
2025-08-08 09:46:48,723 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 13
2025-08-08 09:46:48,724 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 14
2025-08-08 09:46:48,724 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 13)
2025-08-08 09:46:48,724 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 8.0 (TID 14)
2025-08-08 09:46:48,728 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 75 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,735 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_75_piece0 stored as bytes in memory (estimated size 36.5 KiB, free 434.2 MiB)
2025-08-08 09:46:48,738 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 75 took 9 ms
2025-08-08 09:46:48,740 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_75 stored as values in memory (estimated size 108.6 KiB, free 434.1 MiB)
2025-08-08 09:46:48,746 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 65 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,753 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_65_piece0 stored as bytes in memory (estimated size 1726.0 B, free 434.1 MiB)
2025-08-08 09:46:48,758 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 65 took 12 ms
2025-08-08 09:46:48,762 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_65 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-08 09:46:48,763 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 17.524944 ms
2025-08-08 09:46:48,764 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 74 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,772 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_74_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.1 MiB)
2025-08-08 09:46:48,777 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 74 took 13 ms
2025-08-08 09:46:48,781 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_74 stored as values in memory (estimated size 32.0 KiB, free 426.1 MiB)
2025-08-08 09:46:48,784 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:46:48,784 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:46:48,787 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 69 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,787 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 70 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,795 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_70_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.0 MiB)
2025-08-08 09:46:48,795 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_69_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.0 MiB)
2025-08-08 09:46:48,800 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 69 took 12 ms
2025-08-08 09:46:48,800 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 70 took 12 ms
2025-08-08 09:46:48,804 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_70 stored as values in memory (estimated size 32.0 KiB, free 426.0 MiB)
2025-08-08 09:46:48,804 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_69 stored as values in memory (estimated size 32.0 KiB, free 426.0 MiB)
2025-08-08 09:46:48,819 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:48,819 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:48,828 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:48,828 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:48,852 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:48,852 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:48,860 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:48,860 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:48,870 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 09:46:48,870 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 09:46:48,899 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 13, attempt 0, stage 8.0)
2025-08-08 09:46:48,899 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 14, attempt 0, stage 8.0)
2025-08-08 09:46:48,903 [Executor task launch worker for task 1.0 in stage 8.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 8.0 (TID 14). 21158 bytes result sent to driver
2025-08-08 09:46:48,903 [Executor task launch worker for task 0.0 in stage 8.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 13). 21183 bytes result sent to driver
2025-08-08 09:46:48,909 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 15
2025-08-08 09:46:48,910 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 8.0 (TID 15)
2025-08-08 09:46:48,911 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 16
2025-08-08 09:46:48,912 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 8.0 (TID 16)
2025-08-08 09:46:48,931 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.482717 ms
2025-08-08 09:46:48,932 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:46:48,933 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 62 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,935 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 71 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,940 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_62_piece0 stored as bytes in memory (estimated size 827.0 B, free 425.8 MiB)
2025-08-08 09:46:48,942 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_71_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 425.8 MiB)
2025-08-08 09:46:48,945 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 62 took 10 ms
2025-08-08 09:46:48,946 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 71 took 10 ms
2025-08-08 09:46:48,949 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_71 stored as values in memory (estimated size 32.0 KiB, free 425.8 MiB)
2025-08-08 09:46:48,949 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_62 stored as values in memory (estimated size 8.0 MiB, free 417.8 MiB)
2025-08-08 09:46:48,952 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:46:48,954 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 73 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:48,961 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_73_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 417.7 MiB)
2025-08-08 09:46:48,963 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:48,965 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 73 took 10 ms
2025-08-08 09:46:48,969 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_73 stored as values in memory (estimated size 32.0 KiB, free 417.7 MiB)
2025-08-08 09:46:48,976 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:48,985 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:48,994 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:48,998 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:49,006 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:49,009 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:49,017 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:49,017 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 72 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:46:49,022 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 3 is committing.
2025-08-08 09:46:49,025 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_72_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.7 MiB)
2025-08-08 09:46:49,029 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 72 took 11 ms
2025-08-08 09:46:49,031 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_72 stored as values in memory (estimated size 32.0 KiB, free 409.6 MiB)
2025-08-08 09:46:49,042 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:49,050 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:49,051 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 3 (task 16, attempt 0, stage 8.0)
2025-08-08 09:46:49,054 [Executor task launch worker for task 3.0 in stage 8.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 8.0 (TID 16). 21164 bytes result sent to driver
2025-08-08 09:46:49,070 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:46:49,078 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:46:49,091 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 2 is committing.
2025-08-08 09:46:49,115 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 2 (task 15, attempt 0, stage 8.0)
2025-08-08 09:46:49,121 [Executor task launch worker for task 2.0 in stage 8.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 8.0 (TID 15). 21263 bytes result sent to driver
2025-08-08 09:47:49,584 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808093318-0000/2
2025-08-08 09:47:49,584 [ExecutorRunner for app-20250808093318-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808093318-0000/2 interrupted
2025-08-08 09:47:49,585 [ExecutorRunner for app-20250808093318-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 09:47:49,587 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 09:47:49,608 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:47:49,608 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:47:49,608 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:47:49,608 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:47:49,609 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:47:49,609 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:47:49,609 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:47:49,609 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:47:49,609 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 09:47:49,610 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 09:47:49,612 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 09:47:49,615 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 09:47:49,615 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 09:47:49,615 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 09:47:49,666 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808093318-0000/2 finished with state KILLED exitStatus 143
2025-08-08 09:47:49,668 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-08-08 09:47:49,669 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808093318-0000, execId=2)
2025-08-08 09:51:52,699 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808093318-0000/3 for Thrift JDBC/ODBC Server
2025-08-08 09:51:52,703 [ExecutorRunner for app-20250808093318-0000/3] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:51:52,703 [ExecutorRunner for app-20250808093318-0000/3] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:51:52,703 [ExecutorRunner for app-20250808093318-0000/3] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:51:52,704 [ExecutorRunner for app-20250808093318-0000/3] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:51:52,704 [ExecutorRunner for app-20250808093318-0000/3] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:51:52,730 [ExecutorRunner for app-20250808093318-0000/3] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46139" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3b133379d565:46139" "--executor-id" "3" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808093318-0000" "--worker-url" "spark://Worker@172.18.0.11:40593" "--resourceProfileId" "0"
2025-08-08 09:51:53,903 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 530@8ff1a0ac03e8
2025-08-08 09:51:53,909 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 09:51:53,911 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 09:51:53,911 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 09:51:54,193 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 09:51:54,275 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:51:54,275 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:51:54,276 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:51:54,277 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:51:54,277 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:51:54,486 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 50 ms (0 ms spent in bootstraps)
2025-08-08 09:51:54,564 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:51:54,564 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:51:54,565 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:51:54,565 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:51:54,565 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:51:54,616 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 1 ms (0 ms spent in bootstraps)
2025-08-08 09:51:54,670 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-d72e3a66-cb73-4f67-8558-7618373c80c3/executor-63c3aaa1-ceaa-4399-b2eb-f993797d0f8c/blockmgr-d9b451b1-f368-4e59-87c8-d47c9ce303a9
2025-08-08 09:51:54,696 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 09:51:54,837 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3b133379d565:46139
2025-08-08 09:51:54,838 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:40593
2025-08-08 09:51:54,842 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:40593 after 2 ms (0 ms spent in bootstraps)
2025-08-08 09:51:54,845 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:40593
2025-08-08 09:51:54,847 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:51:54,849 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 09:51:54,850 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:51:54,872 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 09:51:54,875 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 3 on host 172.18.0.11
2025-08-08 09:51:54,905 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40615.
2025-08-08 09:51:54,906 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:40615
2025-08-08 09:51:54,908 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 09:51:54,913 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(3, 172.18.0.11, 40615, None)
2025-08-08 09:51:54,921 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(3, 172.18.0.11, 40615, None)
2025-08-08 09:51:54,923 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(3, 172.18.0.11, 40615, None)
2025-08-08 09:51:54,928 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 09:51:54,959 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 17
2025-08-08 09:51:54,963 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 18
2025-08-08 09:51:54,968 [Executor task launch worker for task 0.0 in stage 9.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 17)
2025-08-08 09:51:54,968 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 9.0 (TID 18)
2025-08-08 09:51:55,030 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 3 and clearing cache
2025-08-08 09:51:55,069 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 77 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:51:55,097 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:37515 after 1 ms (0 ms spent in bootstraps)
2025-08-08 09:51:55,124 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_77_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-08 09:51:55,133 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 77 took 62 ms
2025-08-08 09:51:55,180 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_77 stored as values in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-08 09:51:55,350 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 76 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:51:55,357 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_76_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-08 09:51:55,361 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 76 took 10 ms
2025-08-08 09:51:55,407 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_76 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 09:51:55,873 [Executor task launch worker for task 0.0 in stage 9.0 (TID 17)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 09:51:55,883 [Executor task launch worker for task 0.0 in stage 9.0 (TID 17)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 09:51:55,883 [Executor task launch worker for task 0.0 in stage 9.0 (TID 17)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 09:51:56,636 [Executor task launch worker for task 0.0 in stage 9.0 (TID 17)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:51:56,636 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:51:57,153 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 09:51:57,153 [Executor task launch worker for task 0.0 in stage 9.0 (TID 17)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 09:51:57,724 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to t24_branch/data/00001-18-ee6c5802-da17-4461-9d15-9b8f23337c4f-0-00001.parquet. This is unsupported
2025-08-08 09:51:57,899 [Executor task launch worker for task 0.0 in stage 9.0 (TID 17)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 17, attempt 0, stage 9.0)
2025-08-08 09:51:57,899 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 18, attempt 0, stage 9.0)
2025-08-08 09:51:57,923 [Executor task launch worker for task 0.0 in stage 9.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 17). 4438 bytes result sent to driver
2025-08-08 09:51:57,923 [Executor task launch worker for task 1.0 in stage 9.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 9.0 (TID 18). 4438 bytes result sent to driver
2025-08-08 09:52:04,939 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:52:05,316 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 19
2025-08-08 09:52:05,318 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 20
2025-08-08 09:52:05,319 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 19)
2025-08-08 09:52:05,319 [Executor task launch worker for task 1.0 in stage 10.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 10.0 (TID 20)
2025-08-08 09:52:05,366 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 96 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:05,372 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_96_piece0 stored as bytes in memory (estimated size 5.6 KiB, free 434.4 MiB)
2025-08-08 09:52:05,376 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 96 took 9 ms
2025-08-08 09:52:05,378 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_96 stored as values in memory (estimated size 13.7 KiB, free 434.4 MiB)
2025-08-08 09:52:05,671 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 154.952139 ms
2025-08-08 09:52:05,682 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 95 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:05,688 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_95_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.4 MiB)
2025-08-08 09:52:05,691 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 95 took 9 ms
2025-08-08 09:52:05,697 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_95 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 09:52:05,786 [Executor task launch worker for task 1.0 in stage 10.0 (TID 20)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:05,786 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:05,824 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-08 09:52:05,825 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-08 09:52:05,834 [Executor task launch worker for task 1.0 in stage 10.0 (TID 20)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-08 09:52:05,837 [Executor task launch worker for task 1.0 in stage 10.0 (TID 20)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-08 09:52:05,838 [Executor task launch worker for task 1.0 in stage 10.0 (TID 20)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-08 09:52:05,951 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:05,951 [Executor task launch worker for task 1.0 in stage 10.0 (TID 20)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,142 [Executor task launch worker for task 1.0 in stage 10.0 (TID 20)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,142 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,151 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,151 [Executor task launch worker for task 1.0 in stage 10.0 (TID 20)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,167 [Executor task launch worker for task 1.0 in stage 10.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 10.0 (TID 20). 4832 bytes result sent to driver
2025-08-08 09:52:06,174 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 21
2025-08-08 09:52:06,184 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,184 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 21)
2025-08-08 09:52:06,190 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 97 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:06,196 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,200 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_97_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.3 MiB)
2025-08-08 09:52:06,205 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 97 took 12 ms
2025-08-08 09:52:06,207 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_97 stored as values in memory (estimated size 16.1 KiB, free 434.3 MiB)
2025-08-08 09:52:06,211 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,220 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,229 [Executor task launch worker for task 0.0 in stage 10.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 19). 4781 bytes result sent to driver
2025-08-08 09:52:06,231 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 21.047121 ms
2025-08-08 09:52:06,234 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 88 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:06,249 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_88_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 09:52:06,253 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 88 took 19 ms
2025-08-08 09:52:06,260 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_88 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 09:52:06,282 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,292 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,309 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,316 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,326 [Executor task launch worker for task 0.0 in stage 11.0 (TID 21)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 21). 5825 bytes result sent to driver
2025-08-08 09:52:06,450 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 22
2025-08-08 09:52:06,451 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 23
2025-08-08 09:52:06,451 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 12.0 (TID 22)
2025-08-08 09:52:06,452 [Executor task launch worker for task 1.0 in stage 12.0 (TID 23)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 12.0 (TID 23)
2025-08-08 09:52:06,473 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 114 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:06,482 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_114_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.3 MiB)
2025-08-08 09:52:06,488 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 114 took 14 ms
2025-08-08 09:52:06,490 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_114 stored as values in memory (estimated size 21.6 KiB, free 434.3 MiB)
2025-08-08 09:52:06,520 [Executor task launch worker for task 1.0 in stage 12.0 (TID 23)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 24.966297 ms
2025-08-08 09:52:06,521 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 104 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:06,527 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_104_piece0 stored as bytes in memory (estimated size 1706.0 B, free 434.2 MiB)
2025-08-08 09:52:06,530 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 104 took 8 ms
2025-08-08 09:52:06,545 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_104 stored as values in memory (estimated size 8.0 MiB, free 426.2 MiB)
2025-08-08 09:52:06,547 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 92 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:06,557 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_92_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.2 MiB)
2025-08-08 09:52:06,564 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 92 took 15 ms
2025-08-08 09:52:06,567 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_92 stored as values in memory (estimated size 32.0 KiB, free 426.2 MiB)
2025-08-08 09:52:06,582 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,582 [Executor task launch worker for task 1.0 in stage 12.0 (TID 23)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,597 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,597 [Executor task launch worker for task 1.0 in stage 12.0 (TID 23)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,610 [Executor task launch worker for task 1.0 in stage 12.0 (TID 23)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 12.0 (TID 23). 4638 bytes result sent to driver
2025-08-08 09:52:06,624 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,633 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,650 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,658 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,673 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,678 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,690 [Executor task launch worker for task 0.0 in stage 12.0 (TID 22)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 12.0 (TID 22). 4670 bytes result sent to driver
2025-08-08 09:52:06,819 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 24
2025-08-08 09:52:06,820 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 25
2025-08-08 09:52:06,820 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 13.0 (TID 24)
2025-08-08 09:52:06,821 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 13.0 (TID 25)
2025-08-08 09:52:06,825 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 121 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:06,830 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_121_piece0 stored as bytes in memory (estimated size 17.1 KiB, free 426.2 MiB)
2025-08-08 09:52:06,834 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 121 took 9 ms
2025-08-08 09:52:06,836 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_121 stored as values in memory (estimated size 62.8 KiB, free 426.1 MiB)
2025-08-08 09:52:06,865 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.959991 ms
2025-08-08 09:52:06,867 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 120 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:06,874 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_120_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.1 MiB)
2025-08-08 09:52:06,878 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 120 took 10 ms
2025-08-08 09:52:06,881 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_120 stored as values in memory (estimated size 32.0 KiB, free 426.0 MiB)
2025-08-08 09:52:06,884 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:52:06,884 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:52:06,890 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 87 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:06,898 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_87_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.0 MiB)
2025-08-08 09:52:06,905 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 87 took 13 ms
2025-08-08 09:52:06,908 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_87 stored as values in memory (estimated size 32.0 KiB, free 426.0 MiB)
2025-08-08 09:52:06,923 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,923 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,933 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,933 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,944 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 09:52:06,952 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:06,957 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 25, attempt 0, stage 13.0)
2025-08-08 09:52:06,963 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:06,965 [Executor task launch worker for task 1.0 in stage 13.0 (TID 25)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 13.0 (TID 25). 12278 bytes result sent to driver
2025-08-08 09:52:06,972 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 26
2025-08-08 09:52:06,973 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 13.0 (TID 26)
2025-08-08 09:52:06,992 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,000 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,006 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 20.739346 ms
2025-08-08 09:52:07,009 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:52:07,016 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 90 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:07,022 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_90_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.0 MiB)
2025-08-08 09:52:07,023 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,026 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 90 took 9 ms
2025-08-08 09:52:07,029 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_90 stored as values in memory (estimated size 32.0 KiB, free 425.9 MiB)
2025-08-08 09:52:07,031 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,039 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 09:52:07,042 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,050 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,068 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 24, attempt 0, stage 13.0)
2025-08-08 09:52:07,068 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,071 [Executor task launch worker for task 0.0 in stage 13.0 (TID 24)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 13.0 (TID 24). 15423 bytes result sent to driver
2025-08-08 09:52:07,075 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 27
2025-08-08 09:52:07,076 [Executor task launch worker for task 3.0 in stage 13.0 (TID 27)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 13.0 (TID 27)
2025-08-08 09:52:07,077 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,084 [Executor task launch worker for task 3.0 in stage 13.0 (TID 27)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:52:07,096 [Executor task launch worker for task 3.0 in stage 13.0 (TID 27)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,096 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,104 [Executor task launch worker for task 3.0 in stage 13.0 (TID 27)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,104 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,108 [Executor task launch worker for task 3.0 in stage 13.0 (TID 27)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 3 is committing.
2025-08-08 09:52:07,117 [Executor task launch worker for task 3.0 in stage 13.0 (TID 27)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 3 (task 27, attempt 0, stage 13.0)
2025-08-08 09:52:07,120 [Executor task launch worker for task 3.0 in stage 13.0 (TID 27)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 13.0 (TID 27). 12192 bytes result sent to driver
2025-08-08 09:52:07,124 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,126 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 28
2025-08-08 09:52:07,127 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 13.0 (TID 28)
2025-08-08 09:52:07,134 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,142 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 2 is committing.
2025-08-08 09:52:07,152 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.715445 ms
2025-08-08 09:52:07,154 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 115 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:07,162 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_115_piece0 stored as bytes in memory (estimated size 188.0 B, free 425.9 MiB)
2025-08-08 09:52:07,166 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 115 took 11 ms
2025-08-08 09:52:07,176 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_115 stored as values in memory (estimated size 8.0 MiB, free 417.9 MiB)
2025-08-08 09:52:07,177 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 2 (task 26, attempt 0, stage 13.0)
2025-08-08 09:52:07,179 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:52:07,181 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 91 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:07,181 [Executor task launch worker for task 2.0 in stage 13.0 (TID 26)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 13.0 (TID 26). 15391 bytes result sent to driver
2025-08-08 09:52:07,187 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 29
2025-08-08 09:52:07,188 [Executor task launch worker for task 5.0 in stage 13.0 (TID 29)] INFO  org.apache.spark.executor.Executor - Running task 5.0 in stage 13.0 (TID 29)
2025-08-08 09:52:07,190 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_91_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.9 MiB)
2025-08-08 09:52:07,194 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 91 took 13 ms
2025-08-08 09:52:07,196 [Executor task launch worker for task 5.0 in stage 13.0 (TID 29)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:52:07,201 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_91 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-08 09:52:07,213 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,213 [Executor task launch worker for task 5.0 in stage 13.0 (TID 29)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,221 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,221 [Executor task launch worker for task 5.0 in stage 13.0 (TID 29)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,233 [Executor task launch worker for task 5.0 in stage 13.0 (TID 29)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 5 is committing.
2025-08-08 09:52:07,241 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,248 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,258 [Executor task launch worker for task 5.0 in stage 13.0 (TID 29)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 5 (task 29, attempt 0, stage 13.0)
2025-08-08 09:52:07,262 [Executor task launch worker for task 5.0 in stage 13.0 (TID 29)] INFO  org.apache.spark.executor.Executor - Finished task 5.0 in stage 13.0 (TID 29). 15410 bytes result sent to driver
2025-08-08 09:52:07,267 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 30
2025-08-08 09:52:07,268 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,268 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.executor.Executor - Running task 6.0 in stage 13.0 (TID 30)
2025-08-08 09:52:07,275 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,287 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.983823 ms
2025-08-08 09:52:07,290 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 98 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:07,293 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,296 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_98_piece0 stored as bytes in memory (estimated size 1421.0 B, free 417.9 MiB)
2025-08-08 09:52:07,299 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 98 took 8 ms
2025-08-08 09:52:07,304 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,306 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_98 stored as values in memory (estimated size 8.0 MiB, free 409.9 MiB)
2025-08-08 09:52:07,309 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:52:07,314 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 94 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:52:07,314 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 4 is committing.
2025-08-08 09:52:07,321 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_94_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.8 MiB)
2025-08-08 09:52:07,331 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 94 took 16 ms
2025-08-08 09:52:07,334 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_94 stored as values in memory (estimated size 32.0 KiB, free 409.8 MiB)
2025-08-08 09:52:07,347 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,348 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 4 (task 28, attempt 0, stage 13.0)
2025-08-08 09:52:07,355 [Executor task launch worker for task 4.0 in stage 13.0 (TID 28)] INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 13.0 (TID 28). 15453 bytes result sent to driver
2025-08-08 09:52:07,358 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,381 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:52:07,387 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:52:07,391 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 6 is committing.
2025-08-08 09:52:07,397 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 6 (task 30, attempt 0, stage 13.0)
2025-08-08 09:52:07,402 [Executor task launch worker for task 6.0 in stage 13.0 (TID 30)] INFO  org.apache.spark.executor.Executor - Finished task 6.0 in stage 13.0 (TID 30). 12278 bytes result sent to driver
2025-08-08 09:53:07,849 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808093318-0000/3
2025-08-08 09:53:07,851 [ExecutorRunner for app-20250808093318-0000/3] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808093318-0000/3 interrupted
2025-08-08 09:53:07,852 [ExecutorRunner for app-20250808093318-0000/3] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 09:53:07,854 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 09:53:07,871 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:53:07,872 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:53:07,872 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:53:07,872 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:53:07,873 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:53:07,873 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:53:07,873 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:53:07,873 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:53:07,874 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 09:53:07,874 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 09:53:07,876 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 09:53:07,878 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 09:53:07,879 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 09:53:07,879 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 09:53:07,926 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808093318-0000/3 finished with state KILLED exitStatus 143
2025-08-08 09:53:07,926 [dispatcher-event-loop-1] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 3
2025-08-08 09:53:07,927 [dispatcher-event-loop-1] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808093318-0000, execId=3)
2025-08-08 09:55:52,210 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808093318-0000/4 for Thrift JDBC/ODBC Server
2025-08-08 09:55:52,213 [ExecutorRunner for app-20250808093318-0000/4] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:55:52,214 [ExecutorRunner for app-20250808093318-0000/4] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:55:52,214 [ExecutorRunner for app-20250808093318-0000/4] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:55:52,215 [ExecutorRunner for app-20250808093318-0000/4] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:55:52,215 [ExecutorRunner for app-20250808093318-0000/4] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:55:52,251 [ExecutorRunner for app-20250808093318-0000/4] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46139" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3b133379d565:46139" "--executor-id" "4" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808093318-0000" "--worker-url" "spark://Worker@172.18.0.11:40593" "--resourceProfileId" "0"
2025-08-08 09:55:53,408 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 678@8ff1a0ac03e8
2025-08-08 09:55:53,416 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 09:55:53,417 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 09:55:53,417 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 09:55:53,697 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 09:55:53,785 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:55:53,786 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:55:53,786 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:55:53,787 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:55:53,787 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:55:54,008 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 53 ms (0 ms spent in bootstraps)
2025-08-08 09:55:54,083 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 09:55:54,084 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 09:55:54,084 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 09:55:54,084 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 09:55:54,084 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 09:55:54,137 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 2 ms (0 ms spent in bootstraps)
2025-08-08 09:55:54,200 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-d72e3a66-cb73-4f67-8558-7618373c80c3/executor-63c3aaa1-ceaa-4399-b2eb-f993797d0f8c/blockmgr-53f1c0aa-b249-4061-941c-cfa5fd830f83
2025-08-08 09:55:54,228 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 09:55:54,363 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3b133379d565:46139
2025-08-08 09:55:54,363 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:40593
2025-08-08 09:55:54,367 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:40593 after 1 ms (0 ms spent in bootstraps)
2025-08-08 09:55:54,368 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:40593
2025-08-08 09:55:54,373 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:55:54,374 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 09:55:54,375 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 09:55:54,394 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 09:55:54,396 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 4 on host 172.18.0.11
2025-08-08 09:55:54,427 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43279.
2025-08-08 09:55:54,428 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:43279
2025-08-08 09:55:54,430 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 09:55:54,435 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(4, 172.18.0.11, 43279, None)
2025-08-08 09:55:54,443 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(4, 172.18.0.11, 43279, None)
2025-08-08 09:55:54,444 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(4, 172.18.0.11, 43279, None)
2025-08-08 09:55:54,452 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 09:55:54,483 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 31
2025-08-08 09:55:54,493 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 14.0 (TID 31)
2025-08-08 09:55:54,901 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 4 and clearing cache
2025-08-08 09:55:54,945 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 125 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:55:54,978 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:37515 after 1 ms (0 ms spent in bootstraps)
2025-08-08 09:55:55,001 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_125_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)
2025-08-08 09:55:55,010 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 125 took 65 ms
2025-08-08 09:55:55,051 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_125 stored as values in memory (estimated size 19.6 KiB, free 434.4 MiB)
2025-08-08 09:55:55,480 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 177.64969 ms
2025-08-08 09:55:55,499 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 124 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:55:55,506 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_124_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.3 MiB)
2025-08-08 09:55:55,510 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 124 took 10 ms
2025-08-08 09:55:55,548 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_124 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 09:55:55,756 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 09:55:55,769 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 09:55:55,770 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 09:55:56,463 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:55:56,775 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 123 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:55:56,781 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_123_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 09:55:56,786 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 123 took 10 ms
2025-08-08 09:55:56,794 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_123 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 09:55:56,983 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:55:57,266 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-08 09:55:57,266 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-08 09:55:57,279 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-08 09:55:57,283 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-08 09:55:57,284 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-08 09:55:57,480 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:55:57,685 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:55:57,693 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:55:57,701 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 09:55:57,802 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to dim_branch/data/00000-31-40f86b0f-20c4-4bd1-b925-5095313a93c8-0-00001.parquet. This is unsupported
2025-08-08 09:55:57,903 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 31, attempt 0, stage 14.0)
2025-08-08 09:55:57,921 [Executor task launch worker for task 0.0 in stage 14.0 (TID 31)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 14.0 (TID 31). 7818 bytes result sent to driver
2025-08-08 09:56:43,215 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 32
2025-08-08 09:56:43,216 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 33
2025-08-08 09:56:43,216 [Executor task launch worker for task 0.0 in stage 15.0 (TID 32)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 15.0 (TID 32)
2025-08-08 09:56:43,218 [Executor task launch worker for task 1.0 in stage 15.0 (TID 33)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 15.0 (TID 33)
2025-08-08 09:56:43,246 [Executor task launch worker for task 0.0 in stage 15.0 (TID 32)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 127 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:43,255 [Executor task launch worker for task 0.0 in stage 15.0 (TID 32)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_127_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.2 MiB)
2025-08-08 09:56:43,260 [Executor task launch worker for task 0.0 in stage 15.0 (TID 32)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 127 took 13 ms
2025-08-08 09:56:43,262 [Executor task launch worker for task 0.0 in stage 15.0 (TID 32)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_127 stored as values in memory (estimated size 8.1 KiB, free 434.2 MiB)
2025-08-08 09:56:43,280 [Executor task launch worker for task 1.0 in stage 15.0 (TID 33)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 126 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:43,290 [Executor task launch worker for task 1.0 in stage 15.0 (TID 33)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_126_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.2 MiB)
2025-08-08 09:56:43,295 [Executor task launch worker for task 1.0 in stage 15.0 (TID 33)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 126 took 14 ms
2025-08-08 09:56:43,301 [Executor task launch worker for task 1.0 in stage 15.0 (TID 33)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_126 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 09:56:43,308 [Executor task launch worker for task 1.0 in stage 15.0 (TID 33)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:56:43,308 [Executor task launch worker for task 0.0 in stage 15.0 (TID 32)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:56:43,314 [Executor task launch worker for task 1.0 in stage 15.0 (TID 33)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 09:56:43,314 [Executor task launch worker for task 0.0 in stage 15.0 (TID 32)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 09:56:43,386 [Executor task launch worker for task 1.0 in stage 15.0 (TID 33)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 33, attempt 0, stage 15.0)
2025-08-08 09:56:43,394 [Executor task launch worker for task 0.0 in stage 15.0 (TID 32)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 32, attempt 0, stage 15.0)
2025-08-08 09:56:43,395 [Executor task launch worker for task 1.0 in stage 15.0 (TID 33)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 15.0 (TID 33). 4395 bytes result sent to driver
2025-08-08 09:56:43,405 [Executor task launch worker for task 0.0 in stage 15.0 (TID 32)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 15.0 (TID 32). 4395 bytes result sent to driver
2025-08-08 09:56:55,785 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:56:55,804 [block-manager-storage-async-thread-pool-9] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:56:55,824 [block-manager-storage-async-thread-pool-15] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:56:56,360 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 34
2025-08-08 09:56:56,362 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 16.0 (TID 34)
2025-08-08 09:56:56,373 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 35
2025-08-08 09:56:56,374 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 17.0 (TID 35)
2025-08-08 09:56:56,380 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 148 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:56,387 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_148_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.4 MiB)
2025-08-08 09:56:56,387 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 149 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:56,390 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 148 took 10 ms
2025-08-08 09:56:56,393 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_148 stored as values in memory (estimated size 16.1 KiB, free 434.4 MiB)
2025-08-08 09:56:56,394 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_149_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.4 MiB)
2025-08-08 09:56:56,398 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 149 took 9 ms
2025-08-08 09:56:56,399 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_149 stored as values in memory (estimated size 14.6 KiB, free 434.4 MiB)
2025-08-08 09:56:56,460 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.838541 ms
2025-08-08 09:56:56,463 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 17.103815 ms
2025-08-08 09:56:56,463 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 147 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:56,465 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 139 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:56,469 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_147_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-08 09:56:56,472 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_139_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 09:56:56,474 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 147 took 9 ms
2025-08-08 09:56:56,476 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 139 took 10 ms
2025-08-08 09:56:56,476 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_147 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 09:56:56,478 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_139 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 09:56:56,491 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:56:56,491 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:56:56,517 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:56:56,520 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:56:56,532 [Executor task launch worker for task 0.0 in stage 17.0 (TID 35)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 17.0 (TID 35). 4722 bytes result sent to driver
2025-08-08 09:56:56,539 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:56:56,548 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:56:56,557 [Executor task launch worker for task 0.0 in stage 16.0 (TID 34)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 16.0 (TID 34). 5805 bytes result sent to driver
2025-08-08 09:56:56,879 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 36
2025-08-08 09:56:56,880 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 37
2025-08-08 09:56:56,880 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 18.0 (TID 36)
2025-08-08 09:56:56,882 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 18.0 (TID 37)
2025-08-08 09:56:56,887 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 163 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:56,894 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_163_piece0 stored as bytes in memory (estimated size 39.6 KiB, free 434.2 MiB)
2025-08-08 09:56:56,897 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 163 took 9 ms
2025-08-08 09:56:56,899 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_163 stored as values in memory (estimated size 117.9 KiB, free 434.1 MiB)
2025-08-08 09:56:57,101 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 40.289827 ms
2025-08-08 09:56:57,101 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 40.755728 ms
2025-08-08 09:56:57,104 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 153 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:57,113 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_153_piece0 stored as bytes in memory (estimated size 1745.0 B, free 434.1 MiB)
2025-08-08 09:56:57,116 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 153 took 10 ms
2025-08-08 09:56:57,131 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_153 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-08 09:56:57,133 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 162 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:57,144 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_162_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.1 MiB)
2025-08-08 09:56:57,148 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 162 took 14 ms
2025-08-08 09:56:57,150 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_162 stored as values in memory (estimated size 32.0 KiB, free 426.1 MiB)
2025-08-08 09:56:57,154 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:56:57,154 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:56:57,156 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 158 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:57,156 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 157 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:57,161 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_158_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.0 MiB)
2025-08-08 09:56:57,161 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_157_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 426.0 MiB)
2025-08-08 09:56:57,164 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 158 took 8 ms
2025-08-08 09:56:57,165 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 157 took 8 ms
2025-08-08 09:56:57,167 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_158 stored as values in memory (estimated size 32.0 KiB, free 425.9 MiB)
2025-08-08 09:56:57,167 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_157 stored as values in memory (estimated size 32.0 KiB, free 425.9 MiB)
2025-08-08 09:56:57,182 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:56:57,182 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:56:57,192 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:56:57,192 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:56:57,202 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 09:56:57,204 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 09:56:57,235 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 36, attempt 0, stage 18.0)
2025-08-08 09:56:57,239 [Executor task launch worker for task 0.0 in stage 18.0 (TID 36)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 18.0 (TID 36). 21278 bytes result sent to driver
2025-08-08 09:56:57,245 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 38
2025-08-08 09:56:57,246 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 18.0 (TID 38)
2025-08-08 09:56:57,268 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 37, attempt 0, stage 18.0)
2025-08-08 09:56:57,277 [Executor task launch worker for task 1.0 in stage 18.0 (TID 37)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 18.0 (TID 37). 21300 bytes result sent to driver
2025-08-08 09:56:57,287 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 39
2025-08-08 09:56:57,288 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 18.0 (TID 39)
2025-08-08 09:56:57,300 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 43.043494 ms
2025-08-08 09:56:57,313 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.779687 ms
2025-08-08 09:56:57,315 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 150 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:57,323 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_150_piece0 stored as bytes in memory (estimated size 492.0 B, free 425.9 MiB)
2025-08-08 09:56:57,327 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 150 took 11 ms
2025-08-08 09:56:57,333 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_150 stored as values in memory (estimated size 8.0 MiB, free 417.9 MiB)
2025-08-08 09:56:57,337 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:56:57,339 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 161 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:57,347 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_161_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 417.9 MiB)
2025-08-08 09:56:57,353 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 161 took 11 ms
2025-08-08 09:56:57,356 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_161 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-08 09:56:57,378 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:56:57,380 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 16.80031 ms
2025-08-08 09:56:57,388 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:56:57,408 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:56:57,417 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:56:57,421 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 3 is committing.
2025-08-08 09:56:57,425 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.536841 ms
2025-08-08 09:56:57,445 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 3 (task 39, attempt 0, stage 18.0)
2025-08-08 09:56:57,450 [Executor task launch worker for task 3.0 in stage 18.0 (TID 39)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 18.0 (TID 39). 21214 bytes result sent to driver
2025-08-08 09:56:57,463 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 26.232479 ms
2025-08-08 09:56:57,490 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.271953 ms
2025-08-08 09:56:57,496 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 09:56:57,498 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 159 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:57,503 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_159_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.7 MiB)
2025-08-08 09:56:57,505 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 159 took 7 ms
2025-08-08 09:56:57,508 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_159 stored as values in memory (estimated size 32.0 KiB, free 417.7 MiB)
2025-08-08 09:56:57,519 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:56:57,527 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:56:57,544 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 160 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 09:56:57,550 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_160_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.7 MiB)
2025-08-08 09:56:57,553 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 160 took 8 ms
2025-08-08 09:56:57,555 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_160 stored as values in memory (estimated size 32.0 KiB, free 409.6 MiB)
2025-08-08 09:56:57,566 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 09:56:57,573 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 09:56:57,588 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 2 is committing.
2025-08-08 09:56:57,618 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 2 (task 38, attempt 0, stage 18.0)
2025-08-08 09:56:57,622 [Executor task launch worker for task 2.0 in stage 18.0 (TID 38)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 18.0 (TID 38). 21276 bytes result sent to driver
2025-08-08 09:57:58,033 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808093318-0000/4
2025-08-08 09:57:58,035 [ExecutorRunner for app-20250808093318-0000/4] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808093318-0000/4 interrupted
2025-08-08 09:57:58,035 [ExecutorRunner for app-20250808093318-0000/4] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 09:57:58,037 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 09:57:58,057 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:57:58,057 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:57:58,058 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:57:58,058 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:57:58,058 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:57:58,058 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:57:58,058 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:57:58,058 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 09:57:58,059 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 09:57:58,059 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 09:57:58,061 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 09:57:58,066 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 09:57:58,067 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 09:57:58,067 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 09:57:58,109 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808093318-0000/4 finished with state KILLED exitStatus 143
2025-08-08 09:57:58,109 [dispatcher-event-loop-5] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 4
2025-08-08 09:57:58,110 [dispatcher-event-loop-5] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808093318-0000, execId=4)
2025-08-08 10:00:20,848 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808093318-0000/5 for Thrift JDBC/ODBC Server
2025-08-08 10:00:20,851 [ExecutorRunner for app-20250808093318-0000/5] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:00:20,852 [ExecutorRunner for app-20250808093318-0000/5] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:00:20,853 [ExecutorRunner for app-20250808093318-0000/5] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:00:20,853 [ExecutorRunner for app-20250808093318-0000/5] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:00:20,853 [ExecutorRunner for app-20250808093318-0000/5] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:00:20,877 [ExecutorRunner for app-20250808093318-0000/5] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46139" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3b133379d565:46139" "--executor-id" "5" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808093318-0000" "--worker-url" "spark://Worker@172.18.0.11:40593" "--resourceProfileId" "0"
2025-08-08 10:00:22,053 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 830@8ff1a0ac03e8
2025-08-08 10:00:22,060 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 10:00:22,061 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 10:00:22,062 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 10:00:22,376 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 10:00:22,462 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:00:22,463 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:00:22,464 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:00:22,464 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:00:22,465 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:00:22,703 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 59 ms (0 ms spent in bootstraps)
2025-08-08 10:00:22,792 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:00:22,793 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:00:22,793 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:00:22,794 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:00:22,794 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:00:22,857 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:00:22,929 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-d72e3a66-cb73-4f67-8558-7618373c80c3/executor-63c3aaa1-ceaa-4399-b2eb-f993797d0f8c/blockmgr-420f4dcd-5081-4078-9603-002f8768bfd2
2025-08-08 10:00:22,965 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 10:00:23,110 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3b133379d565:46139
2025-08-08 10:00:23,110 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:40593
2025-08-08 10:00:23,114 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:40593 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:00:23,116 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:40593
2025-08-08 10:00:23,120 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 10:00:23,121 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 10:00:23,121 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 10:00:23,141 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 10:00:23,143 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 5 on host 172.18.0.11
2025-08-08 10:00:23,176 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40529.
2025-08-08 10:00:23,177 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:40529
2025-08-08 10:00:23,179 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 10:00:23,186 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(5, 172.18.0.11, 40529, None)
2025-08-08 10:00:23,194 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(5, 172.18.0.11, 40529, None)
2025-08-08 10:00:23,196 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(5, 172.18.0.11, 40529, None)
2025-08-08 10:00:23,202 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 10:00:23,235 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 40
2025-08-08 10:00:23,241 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 41
2025-08-08 10:00:23,246 [Executor task launch worker for task 0.0 in stage 19.0 (TID 40)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 19.0 (TID 40)
2025-08-08 10:00:23,246 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 19.0 (TID 41)
2025-08-08 10:00:23,314 [Executor task launch worker for task 0.0 in stage 19.0 (TID 40)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 5 and clearing cache
2025-08-08 10:00:23,356 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 165 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:00:23,385 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:37515 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:00:23,408 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_165_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-08 10:00:23,416 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 165 took 60 ms
2025-08-08 10:00:23,470 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_165 stored as values in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-08 10:00:23,648 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 164 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:00:23,656 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_164_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-08 10:00:23,661 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 164 took 12 ms
2025-08-08 10:00:23,712 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_164 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 10:00:24,259 [Executor task launch worker for task 0.0 in stage 19.0 (TID 40)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 10:00:24,272 [Executor task launch worker for task 0.0 in stage 19.0 (TID 40)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 10:00:24,273 [Executor task launch worker for task 0.0 in stage 19.0 (TID 40)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 10:00:25,005 [Executor task launch worker for task 0.0 in stage 19.0 (TID 40)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:00:25,005 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:00:25,405 [Executor task launch worker for task 0.0 in stage 19.0 (TID 40)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 10:00:25,405 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 10:00:25,903 [Executor task launch worker for task 0.0 in stage 19.0 (TID 40)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to t24_branch/data/00000-40-c4cfb2a0-253c-423d-b170-4b7d4497a87b-0-00001.parquet. This is unsupported
2025-08-08 10:00:26,069 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 41, attempt 0, stage 19.0)
2025-08-08 10:00:26,069 [Executor task launch worker for task 0.0 in stage 19.0 (TID 40)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 40, attempt 0, stage 19.0)
2025-08-08 10:00:26,095 [Executor task launch worker for task 0.0 in stage 19.0 (TID 40)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 19.0 (TID 40). 4438 bytes result sent to driver
2025-08-08 10:00:26,095 [Executor task launch worker for task 1.0 in stage 19.0 (TID 41)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 19.0 (TID 41). 4438 bytes result sent to driver
2025-08-08 10:00:35,980 [block-manager-storage-async-thread-pool-6] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:00:36,180 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 42
2025-08-08 10:00:36,181 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 20.0 (TID 42)
2025-08-08 10:00:36,221 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 169 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:00:36,228 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_169_piece0 stored as bytes in memory (estimated size 7.9 KiB, free 434.4 MiB)
2025-08-08 10:00:36,232 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 169 took 10 ms
2025-08-08 10:00:36,235 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_169 stored as values in memory (estimated size 19.6 KiB, free 434.4 MiB)
2025-08-08 10:00:36,536 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 177.257317 ms
2025-08-08 10:00:36,540 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 168 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:00:36,550 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_168_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.3 MiB)
2025-08-08 10:00:36,555 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 168 took 13 ms
2025-08-08 10:00:36,558 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_168 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 10:00:36,563 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:00:36,593 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 167 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:00:36,604 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_167_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 10:00:36,609 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 167 took 15 ms
2025-08-08 10:00:36,616 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_167 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 10:00:36,709 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:00:36,724 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-08 10:00:36,725 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-08 10:00:36,737 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-08 10:00:36,740 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-08 10:00:36,742 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-08 10:00:36,857 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:00:37,053 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:00:37,062 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:00:37,071 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 10:00:37,123 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 42, attempt 0, stage 20.0)
2025-08-08 10:00:37,140 [Executor task launch worker for task 0.0 in stage 20.0 (TID 42)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 20.0 (TID 42). 7818 bytes result sent to driver
2025-08-08 10:01:06,021 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 43
2025-08-08 10:01:06,023 [Executor task launch worker for task 0.0 in stage 21.0 (TID 43)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 21.0 (TID 43)
2025-08-08 10:01:06,023 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 44
2025-08-08 10:01:06,024 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 21.0 (TID 44)
2025-08-08 10:01:06,028 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 171 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:06,036 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_171_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.2 MiB)
2025-08-08 10:01:06,039 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 171 took 10 ms
2025-08-08 10:01:06,041 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_171 stored as values in memory (estimated size 8.1 KiB, free 434.2 MiB)
2025-08-08 10:01:06,046 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 170 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:06,059 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_170_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.2 MiB)
2025-08-08 10:01:06,064 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 170 took 17 ms
2025-08-08 10:01:06,067 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_170 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 10:01:06,070 [Executor task launch worker for task 0.0 in stage 21.0 (TID 43)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:01:06,075 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:01:06,077 [Executor task launch worker for task 0.0 in stage 21.0 (TID 43)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 10:01:06,077 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 10:01:06,108 [Executor task launch worker for task 0.0 in stage 21.0 (TID 43)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 43, attempt 0, stage 21.0)
2025-08-08 10:01:06,115 [Executor task launch worker for task 0.0 in stage 21.0 (TID 43)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 21.0 (TID 43). 4440 bytes result sent to driver
2025-08-08 10:01:06,116 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 44, attempt 0, stage 21.0)
2025-08-08 10:01:06,121 [Executor task launch worker for task 1.0 in stage 21.0 (TID 44)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 21.0 (TID 44). 4438 bytes result sent to driver
2025-08-08 10:01:15,449 [block-manager-storage-async-thread-pool-96] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:01:15,461 [block-manager-storage-async-thread-pool-99] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:01:15,708 [block-manager-storage-async-thread-pool-8] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:01:15,877 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 45
2025-08-08 10:01:15,879 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 22.0 (TID 45)
2025-08-08 10:01:15,888 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 46
2025-08-08 10:01:15,889 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 23.0 (TID 46)
2025-08-08 10:01:15,908 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 195 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:15,918 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_195_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.4 MiB)
2025-08-08 10:01:15,919 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 194 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:15,924 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 195 took 15 ms
2025-08-08 10:01:15,928 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_195 stored as values in memory (estimated size 16.1 KiB, free 434.4 MiB)
2025-08-08 10:01:15,930 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_194_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 434.4 MiB)
2025-08-08 10:01:15,936 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 194 took 15 ms
2025-08-08 10:01:15,939 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_194 stored as values in memory (estimated size 14.6 KiB, free 434.4 MiB)
2025-08-08 10:01:16,038 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 29.723299 ms
2025-08-08 10:01:16,043 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 35.690537 ms
2025-08-08 10:01:16,047 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 184 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,048 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 191 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,058 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_184_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 10:01:16,061 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_191_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-08 10:01:16,066 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 184 took 18 ms
2025-08-08 10:01:16,069 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 191 took 20 ms
2025-08-08 10:01:16,074 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_191 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 10:01:16,074 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_184 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 10:01:16,098 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:16,098 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:16,133 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:16,137 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:16,158 [Executor task launch worker for task 0.0 in stage 22.0 (TID 45)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 22.0 (TID 45). 4765 bytes result sent to driver
2025-08-08 10:01:16,169 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:16,176 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 47
2025-08-08 10:01:16,177 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 24.0 (TID 47)
2025-08-08 10:01:16,186 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 196 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,190 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:16,196 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_196_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.2 MiB)
2025-08-08 10:01:16,206 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 196 took 19 ms
2025-08-08 10:01:16,208 [Executor task launch worker for task 0.0 in stage 23.0 (TID 46)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 23.0 (TID 46). 5847 bytes result sent to driver
2025-08-08 10:01:16,210 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_196 stored as values in memory (estimated size 16.1 KiB, free 434.2 MiB)
2025-08-08 10:01:16,219 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 48
2025-08-08 10:01:16,224 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 25.0 (TID 48)
2025-08-08 10:01:16,230 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 197 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,240 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_197_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.2 MiB)
2025-08-08 10:01:16,243 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 197 took 11 ms
2025-08-08 10:01:16,246 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_197 stored as values in memory (estimated size 13.9 KiB, free 434.2 MiB)
2025-08-08 10:01:16,248 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 30.252162 ms
2025-08-08 10:01:16,251 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 193 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,263 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_193_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.2 MiB)
2025-08-08 10:01:16,268 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 193 took 16 ms
2025-08-08 10:01:16,269 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 21.067838 ms
2025-08-08 10:01:16,272 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_193 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 10:01:16,274 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 186 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,284 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_186_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.1 MiB)
2025-08-08 10:01:16,290 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 186 took 15 ms
2025-08-08 10:01:16,292 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:16,293 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_186 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-08 10:01:16,303 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:16,313 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:16,325 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:16,325 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:16,338 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:16,342 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:16,351 [Executor task launch worker for task 0.0 in stage 24.0 (TID 47)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 24.0 (TID 47). 5847 bytes result sent to driver
2025-08-08 10:01:16,362 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:16,375 [Executor task launch worker for task 0.0 in stage 25.0 (TID 48)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 25.0 (TID 48). 4765 bytes result sent to driver
2025-08-08 10:01:16,716 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 49
2025-08-08 10:01:16,717 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 26.0 (TID 49)
2025-08-08 10:01:16,717 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 50
2025-08-08 10:01:16,718 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 26.0 (TID 50)
2025-08-08 10:01:16,724 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 223 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,734 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_223_piece0 stored as bytes in memory (estimated size 22.3 KiB, free 434.1 MiB)
2025-08-08 10:01:16,738 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 223 took 13 ms
2025-08-08 10:01:16,741 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_223 stored as values in memory (estimated size 82.2 KiB, free 434.1 MiB)
2025-08-08 10:01:16,795 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 42.351889 ms
2025-08-08 10:01:16,799 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 210 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,808 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 55.727313 ms
2025-08-08 10:01:16,809 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_210_piece0 stored as bytes in memory (estimated size 497.0 B, free 434.1 MiB)
2025-08-08 10:01:16,811 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 202 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,814 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 210 took 15 ms
2025-08-08 10:01:16,819 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_202_piece0 stored as bytes in memory (estimated size 1732.0 B, free 434.1 MiB)
2025-08-08 10:01:16,823 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 202 took 11 ms
2025-08-08 10:01:16,842 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_210 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-08 10:01:16,842 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_202 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-08 10:01:16,844 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 222 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,851 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_222_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 418.0 MiB)
2025-08-08 10:01:16,857 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 222 took 13 ms
2025-08-08 10:01:16,860 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_222 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-08 10:01:16,864 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:01:16,864 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:01:16,869 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 183 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,869 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 185 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:16,876 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_183_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.9 MiB)
2025-08-08 10:01:16,876 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_185_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.9 MiB)
2025-08-08 10:01:16,885 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 183 took 16 ms
2025-08-08 10:01:16,886 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 185 took 16 ms
2025-08-08 10:01:16,889 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_185 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-08 10:01:16,889 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_183 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-08 10:01:16,906 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:16,906 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:16,916 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:16,916 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:16,928 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 10:01:16,928 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 10:01:16,962 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 50, attempt 0, stage 26.0)
2025-08-08 10:01:16,970 [Executor task launch worker for task 1.0 in stage 26.0 (TID 50)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 26.0 (TID 50). 18088 bytes result sent to driver
2025-08-08 10:01:16,975 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 51
2025-08-08 10:01:16,976 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 26.0 (TID 51)
2025-08-08 10:01:16,989 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 49, attempt 0, stage 26.0)
2025-08-08 10:01:16,992 [Executor task launch worker for task 0.0 in stage 26.0 (TID 49)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 26.0 (TID 49). 18045 bytes result sent to driver
2025-08-08 10:01:16,998 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 52
2025-08-08 10:01:17,004 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 26.0 (TID 52)
2025-08-08 10:01:17,023 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 36.00806 ms
2025-08-08 10:01:17,027 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:01:17,034 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 22.676671 ms
2025-08-08 10:01:17,035 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 188 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:17,036 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 198 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:17,042 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_198_piece0 stored as bytes in memory (estimated size 492.0 B, free 417.8 MiB)
2025-08-08 10:01:17,042 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_188_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.8 MiB)
2025-08-08 10:01:17,047 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 198 took 10 ms
2025-08-08 10:01:17,047 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 188 took 12 ms
2025-08-08 10:01:17,054 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_188 stored as values in memory (estimated size 32.0 KiB, free 417.8 MiB)
2025-08-08 10:01:17,054 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_198 stored as values in memory (estimated size 8.0 MiB, free 409.8 MiB)
2025-08-08 10:01:17,057 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:01:17,061 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 190 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:17,066 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_190_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.8 MiB)
2025-08-08 10:01:17,067 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:17,070 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 190 took 9 ms
2025-08-08 10:01:17,073 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_190 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-08 10:01:17,078 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:17,085 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:17,087 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 2 is committing.
2025-08-08 10:01:17,093 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:17,107 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:17,113 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 2 (task 51, attempt 0, stage 26.0)
2025-08-08 10:01:17,120 [Executor task launch worker for task 2.0 in stage 26.0 (TID 51)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 26.0 (TID 51). 18062 bytes result sent to driver
2025-08-08 10:01:17,120 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:17,126 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 3 is committing.
2025-08-08 10:01:17,127 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 53
2025-08-08 10:01:17,128 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 26.0 (TID 53)
2025-08-08 10:01:17,165 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 3 (task 52, attempt 0, stage 26.0)
2025-08-08 10:01:17,173 [Executor task launch worker for task 3.0 in stage 26.0 (TID 52)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 26.0 (TID 52). 18058 bytes result sent to driver
2025-08-08 10:01:17,179 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 35.006803 ms
2025-08-08 10:01:17,183 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 211 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:17,194 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_211_piece0 stored as bytes in memory (estimated size 2.2 KiB, free 409.7 MiB)
2025-08-08 10:01:17,198 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 211 took 14 ms
2025-08-08 10:01:17,206 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_211 stored as values in memory (estimated size 8.0 MiB, free 401.7 MiB)
2025-08-08 10:01:17,210 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:01:17,212 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 192 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:01:17,219 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_192_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 401.7 MiB)
2025-08-08 10:01:17,226 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 192 took 13 ms
2025-08-08 10:01:17,229 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_192 stored as values in memory (estimated size 32.0 KiB, free 401.7 MiB)
2025-08-08 10:01:17,244 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:01:17,252 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:01:17,262 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 4 is committing.
2025-08-08 10:01:17,286 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 4 (task 53, attempt 0, stage 26.0)
2025-08-08 10:01:17,292 [Executor task launch worker for task 4.0 in stage 26.0 (TID 53)] INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 26.0 (TID 53). 18077 bytes result sent to driver
2025-08-08 10:02:17,750 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808093318-0000/5
2025-08-08 10:02:17,752 [ExecutorRunner for app-20250808093318-0000/5] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808093318-0000/5 interrupted
2025-08-08 10:02:17,753 [ExecutorRunner for app-20250808093318-0000/5] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 10:02:17,755 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 10:02:17,774 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:02:17,775 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:02:17,775 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:02:17,775 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:02:17,775 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:02:17,776 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:02:17,776 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:02:17,776 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:02:17,776 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:02:17,776 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:02:17,777 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 10:02:17,778 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 10:02:17,780 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 10:02:17,783 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 10:02:17,783 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 10:02:17,783 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 10:02:17,833 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808093318-0000/5 finished with state KILLED exitStatus 143
2025-08-08 10:02:17,834 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 5
2025-08-08 10:02:17,835 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808093318-0000, execId=5)
2025-08-08 10:03:22,289 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808093318-0000/6 for Thrift JDBC/ODBC Server
2025-08-08 10:03:22,293 [ExecutorRunner for app-20250808093318-0000/6] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:03:22,294 [ExecutorRunner for app-20250808093318-0000/6] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:03:22,295 [ExecutorRunner for app-20250808093318-0000/6] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:03:22,295 [ExecutorRunner for app-20250808093318-0000/6] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:03:22,296 [ExecutorRunner for app-20250808093318-0000/6] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:03:22,330 [ExecutorRunner for app-20250808093318-0000/6] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46139" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3b133379d565:46139" "--executor-id" "6" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808093318-0000" "--worker-url" "spark://Worker@172.18.0.11:40593" "--resourceProfileId" "0"
2025-08-08 10:03:23,536 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 1052@8ff1a0ac03e8
2025-08-08 10:03:23,544 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 10:03:23,546 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 10:03:23,546 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 10:03:23,876 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 10:03:23,964 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:03:23,965 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:03:23,965 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:03:23,966 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:03:23,966 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:03:24,198 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 59 ms (0 ms spent in bootstraps)
2025-08-08 10:03:24,277 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:03:24,278 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:03:24,278 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:03:24,279 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:03:24,279 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:03:24,327 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:03:24,406 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-d72e3a66-cb73-4f67-8558-7618373c80c3/executor-63c3aaa1-ceaa-4399-b2eb-f993797d0f8c/blockmgr-2af263cf-9eb5-47a6-8bd1-a96ada198914
2025-08-08 10:03:24,452 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 10:03:24,604 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3b133379d565:46139
2025-08-08 10:03:24,605 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:40593
2025-08-08 10:03:24,609 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:40593 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:03:24,612 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:40593
2025-08-08 10:03:24,615 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 10:03:24,616 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 10:03:24,617 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 10:03:24,638 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 10:03:24,641 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 6 on host 172.18.0.11
2025-08-08 10:03:24,676 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33425.
2025-08-08 10:03:24,677 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:33425
2025-08-08 10:03:24,680 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 10:03:24,686 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(6, 172.18.0.11, 33425, None)
2025-08-08 10:03:24,695 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(6, 172.18.0.11, 33425, None)
2025-08-08 10:03:24,698 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(6, 172.18.0.11, 33425, None)
2025-08-08 10:03:24,707 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 10:03:24,746 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 54
2025-08-08 10:03:24,752 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 55
2025-08-08 10:03:24,756 [Executor task launch worker for task 1.0 in stage 27.0 (TID 55)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 27.0 (TID 55)
2025-08-08 10:03:24,756 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 27.0 (TID 54)
2025-08-08 10:03:24,822 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 6 and clearing cache
2025-08-08 10:03:24,867 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 225 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:24,895 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:37515 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:03:24,921 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_225_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-08 10:03:24,931 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 225 took 62 ms
2025-08-08 10:03:24,979 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_225 stored as values in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-08 10:03:25,137 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 224 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:25,144 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_224_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-08 10:03:25,149 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 224 took 11 ms
2025-08-08 10:03:25,200 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_224 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 10:03:25,675 [Executor task launch worker for task 1.0 in stage 27.0 (TID 55)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 10:03:25,687 [Executor task launch worker for task 1.0 in stage 27.0 (TID 55)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 10:03:25,688 [Executor task launch worker for task 1.0 in stage 27.0 (TID 55)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 10:03:26,423 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:03:26,423 [Executor task launch worker for task 1.0 in stage 27.0 (TID 55)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:03:26,746 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 10:03:26,746 [Executor task launch worker for task 1.0 in stage 27.0 (TID 55)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 10:03:27,244 [Executor task launch worker for task 1.0 in stage 27.0 (TID 55)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to t24_branch/data/00001-55-8c63a3e3-5144-443e-b579-ae7a61b32e8e-0-00001.parquet. This is unsupported
2025-08-08 10:03:27,390 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 54, attempt 0, stage 27.0)
2025-08-08 10:03:27,390 [Executor task launch worker for task 1.0 in stage 27.0 (TID 55)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 55, attempt 0, stage 27.0)
2025-08-08 10:03:27,430 [Executor task launch worker for task 0.0 in stage 27.0 (TID 54)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 27.0 (TID 54). 4438 bytes result sent to driver
2025-08-08 10:03:27,430 [Executor task launch worker for task 1.0 in stage 27.0 (TID 55)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 27.0 (TID 55). 4438 bytes result sent to driver
2025-08-08 10:03:30,028 [block-manager-storage-async-thread-pool-72] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:03:42,441 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 56
2025-08-08 10:03:42,443 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 28.0 (TID 56)
2025-08-08 10:03:42,445 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 57
2025-08-08 10:03:42,447 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 29.0 (TID 57)
2025-08-08 10:03:42,503 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 249 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:42,503 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 248 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:42,509 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_248_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 434.4 MiB)
2025-08-08 10:03:42,509 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_249_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.4 MiB)
2025-08-08 10:03:42,512 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 248 took 9 ms
2025-08-08 10:03:42,513 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 249 took 9 ms
2025-08-08 10:03:42,514 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_248 stored as values in memory (estimated size 14.6 KiB, free 434.4 MiB)
2025-08-08 10:03:42,514 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_249 stored as values in memory (estimated size 16.1 KiB, free 434.4 MiB)
2025-08-08 10:03:42,841 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 188.566958 ms
2025-08-08 10:03:42,841 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 188.565728 ms
2025-08-08 10:03:42,852 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 245 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:42,852 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 238 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:42,860 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_238_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 10:03:42,860 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_245_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-08 10:03:42,866 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 245 took 13 ms
2025-08-08 10:03:42,867 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 238 took 14 ms
2025-08-08 10:03:42,887 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_245 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 10:03:42,887 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_238 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 10:03:42,984 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:42,984 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:43,015 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-08 10:03:43,016 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-08 10:03:43,016 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:43,025 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-08 10:03:43,028 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-08 10:03:43,030 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-08 10:03:43,149 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:43,351 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:43,351 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:43,359 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:43,359 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:43,377 [Executor task launch worker for task 0.0 in stage 29.0 (TID 57)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 29.0 (TID 57). 5894 bytes result sent to driver
2025-08-08 10:03:43,380 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:43,394 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 58
2025-08-08 10:03:43,395 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 30.0 (TID 58)
2025-08-08 10:03:43,404 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 250 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:43,409 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:43,413 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_250_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.2 MiB)
2025-08-08 10:03:43,417 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 250 took 12 ms
2025-08-08 10:03:43,420 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_250 stored as values in memory (estimated size 13.9 KiB, free 434.2 MiB)
2025-08-08 10:03:43,428 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:43,437 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:43,437 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.247966 ms
2025-08-08 10:03:43,439 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 240 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:43,453 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_240_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.2 MiB)
2025-08-08 10:03:43,456 [Executor task launch worker for task 0.0 in stage 28.0 (TID 56)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 28.0 (TID 56). 4777 bytes result sent to driver
2025-08-08 10:03:43,457 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 240 took 16 ms
2025-08-08 10:03:43,462 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_240 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 10:03:43,466 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 59
2025-08-08 10:03:43,477 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808093318-0000/7 for Thrift JDBC/ODBC Server
2025-08-08 10:03:43,480 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 31.0 (TID 59)
2025-08-08 10:03:43,484 [ExecutorRunner for app-20250808093318-0000/7] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:03:43,486 [ExecutorRunner for app-20250808093318-0000/7] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:03:43,488 [ExecutorRunner for app-20250808093318-0000/7] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:03:43,489 [ExecutorRunner for app-20250808093318-0000/7] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:03:43,490 [ExecutorRunner for app-20250808093318-0000/7] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:03:43,497 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 251 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:43,511 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:43,511 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_251_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.2 MiB)
2025-08-08 10:03:43,516 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 251 took 18 ms
2025-08-08 10:03:43,519 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_251 stored as values in memory (estimated size 16.1 KiB, free 434.1 MiB)
2025-08-08 10:03:43,525 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:43,539 [ExecutorRunner for app-20250808093318-0000/7] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46139" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3b133379d565:46139" "--executor-id" "7" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808093318-0000" "--worker-url" "spark://Worker@172.18.0.11:40593" "--resourceProfileId" "0"
2025-08-08 10:03:43,544 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:43,552 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 25.992287 ms
2025-08-08 10:03:43,555 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 247 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:43,557 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:43,568 [Executor task launch worker for task 0.0 in stage 30.0 (TID 58)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 30.0 (TID 58). 4722 bytes result sent to driver
2025-08-08 10:03:43,568 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_247_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.1 MiB)
2025-08-08 10:03:43,572 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 247 took 16 ms
2025-08-08 10:03:43,577 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_247 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-08 10:03:43,596 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:43,609 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:43,628 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:43,640 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:43,648 [Executor task launch worker for task 0.0 in stage 31.0 (TID 59)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 31.0 (TID 59). 5851 bytes result sent to driver
2025-08-08 10:03:43,884 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 60
2025-08-08 10:03:43,885 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 32.0 (TID 60)
2025-08-08 10:03:43,885 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 61
2025-08-08 10:03:43,886 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 32.0 (TID 61)
2025-08-08 10:03:43,892 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 282 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:43,898 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_282_piece0 stored as bytes in memory (estimated size 22.5 KiB, free 434.1 MiB)
2025-08-08 10:03:43,902 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 282 took 10 ms
2025-08-08 10:03:43,905 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_282 stored as values in memory (estimated size 82.5 KiB, free 434.1 MiB)
2025-08-08 10:03:43,954 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 39.433184 ms
2025-08-08 10:03:43,957 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 269 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:43,958 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 43.145931 ms
2025-08-08 10:03:43,961 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 252 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:43,965 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_269_piece0 stored as bytes in memory (estimated size 497.0 B, free 434.1 MiB)
2025-08-08 10:03:43,969 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_252_piece0 stored as bytes in memory (estimated size 1742.0 B, free 434.1 MiB)
2025-08-08 10:03:43,970 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 269 took 12 ms
2025-08-08 10:03:43,974 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 252 took 11 ms
2025-08-08 10:03:43,990 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_269 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-08 10:03:43,991 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 281 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:43,991 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_252 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-08 10:03:43,997 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_281_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 418.0 MiB)
2025-08-08 10:03:44,001 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 281 took 9 ms
2025-08-08 10:03:44,004 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_281 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-08 10:03:44,009 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:03:44,009 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:03:44,018 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 239 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:44,018 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 237 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:44,023 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_239_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.9 MiB)
2025-08-08 10:03:44,023 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_237_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.9 MiB)
2025-08-08 10:03:44,026 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 239 took 8 ms
2025-08-08 10:03:44,027 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 237 took 8 ms
2025-08-08 10:03:44,030 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_239 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-08 10:03:44,030 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_237 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-08 10:03:44,047 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,047 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,056 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,056 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,076 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,076 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,087 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,087 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,107 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,107 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,119 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,119 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,137 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,137 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,146 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,146 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,154 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 10:03:44,154 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 10:03:44,182 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 60, attempt 0, stage 32.0)
2025-08-08 10:03:44,190 [Executor task launch worker for task 0.0 in stage 32.0 (TID 60)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 32.0 (TID 60). 18090 bytes result sent to driver
2025-08-08 10:03:44,195 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 62
2025-08-08 10:03:44,196 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 32.0 (TID 62)
2025-08-08 10:03:44,219 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 61, attempt 0, stage 32.0)
2025-08-08 10:03:44,226 [Executor task launch worker for task 1.0 in stage 32.0 (TID 61)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 32.0 (TID 61). 18088 bytes result sent to driver
2025-08-08 10:03:44,232 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 63
2025-08-08 10:03:44,233 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 32.0 (TID 63)
2025-08-08 10:03:44,249 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 37.926611 ms
2025-08-08 10:03:44,252 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:03:44,254 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 242 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:44,259 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 16.122246 ms
2025-08-08 10:03:44,261 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_242_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.8 MiB)
2025-08-08 10:03:44,261 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 262 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:44,264 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 242 took 9 ms
2025-08-08 10:03:44,266 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_262_piece0 stored as bytes in memory (estimated size 712.0 B, free 417.8 MiB)
2025-08-08 10:03:44,266 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_242 stored as values in memory (estimated size 32.0 KiB, free 417.8 MiB)
2025-08-08 10:03:44,269 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 262 took 7 ms
2025-08-08 10:03:44,276 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_262 stored as values in memory (estimated size 8.0 MiB, free 409.8 MiB)
2025-08-08 10:03:44,278 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:03:44,285 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 244 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:44,287 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,290 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_244_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.8 MiB)
2025-08-08 10:03:44,293 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 244 took 7 ms
2025-08-08 10:03:44,296 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_244 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-08 10:03:44,298 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,309 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,316 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,318 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,326 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,333 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,340 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,342 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,344 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 3 is committing.
2025-08-08 10:03:44,349 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,359 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 3 (task 63, attempt 0, stage 32.0)
2025-08-08 10:03:44,363 [Executor task launch worker for task 3.0 in stage 32.0 (TID 63)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 32.0 (TID 63). 14859 bytes result sent to driver
2025-08-08 10:03:44,365 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,369 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 64
2025-08-08 10:03:44,370 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.executor.Executor - Running task 4.0 in stage 32.0 (TID 64)
2025-08-08 10:03:44,376 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,388 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 2 is committing.
2025-08-08 10:03:44,406 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 29.40415 ms
2025-08-08 10:03:44,409 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 275 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:44,416 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_275_piece0 stored as bytes in memory (estimated size 2.2 KiB, free 409.7 MiB)
2025-08-08 10:03:44,420 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 2 (task 62, attempt 0, stage 32.0)
2025-08-08 10:03:44,420 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 275 took 11 ms
2025-08-08 10:03:44,423 [Executor task launch worker for task 2.0 in stage 32.0 (TID 62)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 32.0 (TID 62). 18019 bytes result sent to driver
2025-08-08 10:03:44,425 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_275 stored as values in memory (estimated size 8.0 MiB, free 401.7 MiB)
2025-08-08 10:03:44,429 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:03:44,432 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 246 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:03:44,439 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_246_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 401.7 MiB)
2025-08-08 10:03:44,443 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 246 took 9 ms
2025-08-08 10:03:44,446 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_246 stored as values in memory (estimated size 32.0 KiB, free 401.7 MiB)
2025-08-08 10:03:44,460 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,472 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,499 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,508 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,528 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,537 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,554 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:03:44,562 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:03:44,573 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 4 is committing.
2025-08-08 10:03:44,603 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 4 (task 64, attempt 0, stage 32.0)
2025-08-08 10:03:44,606 [Executor task launch worker for task 4.0 in stage 32.0 (TID 64)] INFO  org.apache.spark.executor.Executor - Finished task 4.0 in stage 32.0 (TID 64). 17982 bytes result sent to driver
2025-08-08 10:03:44,979 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 1250@8ff1a0ac03e8
2025-08-08 10:03:44,987 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 10:03:44,989 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 10:03:44,989 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 10:03:45,238 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 10:03:45,310 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:03:45,311 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:03:45,311 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:03:45,312 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:03:45,312 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:03:45,515 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 47 ms (0 ms spent in bootstraps)
2025-08-08 10:03:45,591 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:03:45,591 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:03:45,592 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:03:45,592 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:03:45,592 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:03:45,634 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:03:45,701 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-d72e3a66-cb73-4f67-8558-7618373c80c3/executor-63c3aaa1-ceaa-4399-b2eb-f993797d0f8c/blockmgr-cea0ec8d-09bb-4515-8753-184362c06625
2025-08-08 10:03:45,730 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 10:03:45,886 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3b133379d565:46139
2025-08-08 10:03:45,887 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:40593
2025-08-08 10:03:45,891 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:40593 after 1 ms (0 ms spent in bootstraps)
2025-08-08 10:03:45,893 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:40593
2025-08-08 10:03:45,897 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 10:03:45,898 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 10:03:45,899 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 10:03:45,919 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 10:03:45,922 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 7 on host 172.18.0.11
2025-08-08 10:03:45,956 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37543.
2025-08-08 10:03:45,956 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:37543
2025-08-08 10:03:45,960 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 10:03:45,966 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(7, 172.18.0.11, 37543, None)
2025-08-08 10:03:45,973 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(7, 172.18.0.11, 37543, None)
2025-08-08 10:03:45,977 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(7, 172.18.0.11, 37543, None)
2025-08-08 10:03:45,986 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 10:04:45,007 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808093318-0000/6
2025-08-08 10:04:45,008 [ExecutorRunner for app-20250808093318-0000/6] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808093318-0000/6 interrupted
2025-08-08 10:04:45,009 [ExecutorRunner for app-20250808093318-0000/6] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 10:04:45,011 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 10:04:45,028 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:04:45,028 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:04:45,028 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:04:45,029 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:04:45,029 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:04:45,029 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:04:45,029 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:04:45,029 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:04:45,030 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:04:45,030 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:04:45,030 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 10:04:45,031 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 10:04:45,033 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 10:04:45,035 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 10:04:45,035 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 10:04:45,036 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 10:04:45,089 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808093318-0000/6 finished with state KILLED exitStatus 143
2025-08-08 10:04:45,091 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 6
2025-08-08 10:04:45,092 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808093318-0000, execId=6)
2025-08-08 10:04:46,318 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808093318-0000/7
2025-08-08 10:04:46,319 [ExecutorRunner for app-20250808093318-0000/7] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808093318-0000/7 interrupted
2025-08-08 10:04:46,320 [ExecutorRunner for app-20250808093318-0000/7] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 10:04:46,322 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 10:04:46,336 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 10:04:46,336 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 10:04:46,339 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 10:04:46,374 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808093318-0000/7 finished with state KILLED exitStatus 143
2025-08-08 10:04:46,375 [dispatcher-event-loop-0] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 7
2025-08-08 10:04:46,376 [dispatcher-event-loop-0] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808093318-0000, execId=7)
2025-08-08 10:39:28,124 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808093318-0000/8 for Thrift JDBC/ODBC Server
2025-08-08 10:39:28,128 [ExecutorRunner for app-20250808093318-0000/8] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:39:28,130 [ExecutorRunner for app-20250808093318-0000/8] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:39:28,130 [ExecutorRunner for app-20250808093318-0000/8] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:39:28,130 [ExecutorRunner for app-20250808093318-0000/8] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:39:28,131 [ExecutorRunner for app-20250808093318-0000/8] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:39:28,162 [ExecutorRunner for app-20250808093318-0000/8] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46139" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3b133379d565:46139" "--executor-id" "8" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808093318-0000" "--worker-url" "spark://Worker@172.18.0.11:40593" "--resourceProfileId" "0"
2025-08-08 10:39:29,544 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 1344@8ff1a0ac03e8
2025-08-08 10:39:29,552 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 10:39:29,553 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 10:39:29,554 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 10:39:29,857 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 10:39:29,950 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:39:29,951 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:39:29,952 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:39:29,952 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:39:29,953 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:39:30,199 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 57 ms (0 ms spent in bootstraps)
2025-08-08 10:39:30,295 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:39:30,296 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:39:30,296 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:39:30,297 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:39:30,297 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:39:30,362 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:39:30,426 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-d72e3a66-cb73-4f67-8558-7618373c80c3/executor-63c3aaa1-ceaa-4399-b2eb-f993797d0f8c/blockmgr-daecee62-42b5-4982-93b0-b5a17bc16248
2025-08-08 10:39:30,459 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 10:39:30,609 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3b133379d565:46139
2025-08-08 10:39:30,610 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:40593
2025-08-08 10:39:30,614 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:40593 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:39:30,617 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:40593
2025-08-08 10:39:30,622 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 10:39:30,623 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 10:39:30,624 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 10:39:30,650 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 10:39:30,653 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 8 on host 172.18.0.11
2025-08-08 10:39:30,684 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36781.
2025-08-08 10:39:30,685 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:36781
2025-08-08 10:39:30,688 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 10:39:30,693 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(8, 172.18.0.11, 36781, None)
2025-08-08 10:39:30,703 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(8, 172.18.0.11, 36781, None)
2025-08-08 10:39:30,705 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(8, 172.18.0.11, 36781, None)
2025-08-08 10:39:30,710 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 10:39:30,745 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 65
2025-08-08 10:39:30,752 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 66
2025-08-08 10:39:30,758 [Executor task launch worker for task 0.0 in stage 33.0 (TID 65)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 33.0 (TID 65)
2025-08-08 10:39:30,758 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 33.0 (TID 66)
2025-08-08 10:39:30,831 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 8 and clearing cache
2025-08-08 10:39:30,879 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 284 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:39:30,913 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:37515 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:39:30,941 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_284_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-08 10:39:30,950 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 284 took 71 ms
2025-08-08 10:39:31,016 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_284 stored as values in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-08 10:39:31,228 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 283 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:39:31,238 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_283_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-08 10:39:31,241 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 283 took 13 ms
2025-08-08 10:39:31,284 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_283 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 10:39:31,770 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 10:39:31,781 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 10:39:31,782 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 10:39:32,472 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:39:32,472 [Executor task launch worker for task 0.0 in stage 33.0 (TID 65)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:39:32,810 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 10:39:32,810 [Executor task launch worker for task 0.0 in stage 33.0 (TID 65)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 10:39:33,342 [Executor task launch worker for task 0.0 in stage 33.0 (TID 65)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to t24_branch/data/00000-65-2de4dd01-026e-4462-beee-d9d341734118-0-00001.parquet. This is unsupported
2025-08-08 10:39:33,510 [Executor task launch worker for task 0.0 in stage 33.0 (TID 65)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 65, attempt 0, stage 33.0)
2025-08-08 10:39:33,510 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 66, attempt 0, stage 33.0)
2025-08-08 10:39:33,534 [Executor task launch worker for task 1.0 in stage 33.0 (TID 66)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 33.0 (TID 66). 4438 bytes result sent to driver
2025-08-08 10:39:33,534 [Executor task launch worker for task 0.0 in stage 33.0 (TID 65)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 33.0 (TID 65). 4440 bytes result sent to driver
2025-08-08 10:40:34,159 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808093318-0000/8
2025-08-08 10:40:34,159 [ExecutorRunner for app-20250808093318-0000/8] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808093318-0000/8 interrupted
2025-08-08 10:40:34,160 [ExecutorRunner for app-20250808093318-0000/8] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 10:40:34,162 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 10:40:34,187 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:40:34,190 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 10:40:34,191 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 10:40:34,193 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 10:40:34,195 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 10:40:34,195 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 10:40:34,196 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 10:40:34,251 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808093318-0000/8 finished with state KILLED exitStatus 143
2025-08-08 10:40:34,252 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 8
2025-08-08 10:40:34,252 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808093318-0000, execId=8)
2025-08-08 10:52:27,300 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808093318-0000/9 for Thrift JDBC/ODBC Server
2025-08-08 10:52:27,306 [ExecutorRunner for app-20250808093318-0000/9] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:52:27,310 [ExecutorRunner for app-20250808093318-0000/9] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:52:27,310 [ExecutorRunner for app-20250808093318-0000/9] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:52:27,311 [ExecutorRunner for app-20250808093318-0000/9] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:52:27,311 [ExecutorRunner for app-20250808093318-0000/9] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:52:27,338 [ExecutorRunner for app-20250808093318-0000/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=46139" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3b133379d565:46139" "--executor-id" "9" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808093318-0000" "--worker-url" "spark://Worker@172.18.0.11:40593" "--resourceProfileId" "0"
2025-08-08 10:52:28,598 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 1435@8ff1a0ac03e8
2025-08-08 10:52:28,607 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 10:52:28,608 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 10:52:28,609 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 10:52:28,945 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 10:52:29,040 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:52:29,041 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:52:29,042 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:52:29,042 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:52:29,044 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:52:29,292 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 51 ms (0 ms spent in bootstraps)
2025-08-08 10:52:29,357 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 10:52:29,358 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 10:52:29,358 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 10:52:29,358 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 10:52:29,359 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 10:52:29,405 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:46139 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:52:29,511 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-d72e3a66-cb73-4f67-8558-7618373c80c3/executor-63c3aaa1-ceaa-4399-b2eb-f993797d0f8c/blockmgr-4ad60367-d189-4305-b7eb-33d4d5723f5b
2025-08-08 10:52:29,553 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 10:52:29,714 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3b133379d565:46139
2025-08-08 10:52:29,715 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:40593
2025-08-08 10:52:29,718 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:40593 after 1 ms (0 ms spent in bootstraps)
2025-08-08 10:52:29,723 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 10:52:29,721 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:40593
2025-08-08 10:52:29,725 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 10:52:29,726 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 10:52:29,750 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 10:52:29,756 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 9 on host 172.18.0.11
2025-08-08 10:52:29,805 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39809.
2025-08-08 10:52:29,806 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:39809
2025-08-08 10:52:29,812 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 10:52:29,819 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(9, 172.18.0.11, 39809, None)
2025-08-08 10:52:29,833 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(9, 172.18.0.11, 39809, None)
2025-08-08 10:52:29,835 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(9, 172.18.0.11, 39809, None)
2025-08-08 10:52:29,846 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 10:52:29,907 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 67
2025-08-08 10:52:29,921 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 34.0 (TID 67)
2025-08-08 10:52:30,397 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 9 and clearing cache
2025-08-08 10:52:30,440 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 288 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:52:30,481 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3b133379d565/172.18.0.12:37515 after 2 ms (0 ms spent in bootstraps)
2025-08-08 10:52:30,509 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_288_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.4 MiB)
2025-08-08 10:52:30,519 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 288 took 78 ms
2025-08-08 10:52:30,563 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_288 stored as values in memory (estimated size 20.6 KiB, free 434.4 MiB)
2025-08-08 10:52:31,001 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 190.741958 ms
2025-08-08 10:52:31,019 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 287 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:52:31,027 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_287_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.3 MiB)
2025-08-08 10:52:31,033 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 287 took 13 ms
2025-08-08 10:52:31,074 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_287 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 10:52:31,292 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 10:52:31,307 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 10:52:31,308 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 10:52:31,921 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 10:52:32,232 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 286 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 10:52:32,238 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_286_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 10:52:32,241 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 286 took 8 ms
2025-08-08 10:52:32,249 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_286 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 10:52:32,471 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:52:32,865 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-08 10:52:32,866 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-08 10:52:32,880 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-08 10:52:32,884 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-08 10:52:32,886 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-08 10:52:33,033 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:52:33,276 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 10:52:33,284 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 10:52:33,292 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 10:52:33,398 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to snapshots.db/dim_branch_snapshot/data/00000-67-a90a5ee2-3744-41b3-9bb9-b0875119334d-0-00001.parquet. This is unsupported
2025-08-08 10:52:33,514 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 67, attempt 0, stage 34.0)
2025-08-08 10:52:33,533 [Executor task launch worker for task 0.0 in stage 34.0 (TID 67)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 34.0 (TID 67). 7847 bytes result sent to driver
2025-08-08 10:53:33,984 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808093318-0000/9
2025-08-08 10:53:33,985 [ExecutorRunner for app-20250808093318-0000/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808093318-0000/9 interrupted
2025-08-08 10:53:33,986 [ExecutorRunner for app-20250808093318-0000/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 10:53:33,989 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 10:53:34,007 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:53:34,009 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 10:53:34,010 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 10:53:34,011 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 10:53:34,013 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 10:53:34,017 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 10:53:34,018 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 10:53:34,019 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 10:53:34,075 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808093318-0000/9 finished with state KILLED exitStatus 143
2025-08-08 10:53:34,075 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 9
2025-08-08 10:53:34,075 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808093318-0000, execId=9)
2025-08-08 11:05:00,999 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@524c53b22c53
2025-08-08 11:05:01,035 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 11:05:01,039 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 11:05:01,040 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 11:05:01,619 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:05:01,626 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:05:01,630 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:05:01,634 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:05:01,636 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:05:02,032 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 11:05:02,868 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 37613.
2025-08-08 11:05:02,879 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-08 11:05:03,340 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.11:37613 with 12 cores, 6.6 GiB RAM
2025-08-08 11:05:03,373 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-08 11:05:03,375 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-08 11:05:03,430 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:05:03,432 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-08 11:05:03,435 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:05:03,527 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @6762ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-08 11:05:03,619 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-08 11:05:03,667 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-08 11:05:03,717 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @6954ms
2025-08-08 11:05:03,854 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@54c0bb6f{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-08 11:05:03,857 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-08 11:05:03,947 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@44ead3e0{/logPage,null,AVAILABLE,@Spark}
2025-08-08 11:05:03,961 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35edf1b9{/logPage/json,null,AVAILABLE,@Spark}
2025-08-08 11:05:03,965 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@44fe71e8{/,null,AVAILABLE,@Spark}
2025-08-08 11:05:03,969 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22bb8666{/json,null,AVAILABLE,@Spark}
2025-08-08 11:05:03,993 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2acba7ec{/static,null,AVAILABLE,@Spark}
2025-08-08 11:05:03,996 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@648ef3df{/log,null,AVAILABLE,@Spark}
2025-08-08 11:05:04,001 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://524c53b22c53:8081
2025-08-08 11:05:04,006 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-08 11:05:04,051 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7b9226b7{/metrics/json,null,AVAILABLE,@Spark}
2025-08-08 11:05:04,195 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 117 ms (0 ms spent in bootstraps)
2025-08-08 11:05:04,849 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-08 11:05:06,539 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808110505-0000/0 for Thrift JDBC/ODBC Server
2025-08-08 11:05:06,608 [ExecutorRunner for app-20250808110505-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:05:06,610 [ExecutorRunner for app-20250808110505-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:05:06,614 [ExecutorRunner for app-20250808110505-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:05:06,617 [ExecutorRunner for app-20250808110505-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:05:06,619 [ExecutorRunner for app-20250808110505-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:05:06,702 [ExecutorRunner for app-20250808110505-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42127" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@19450efa36e6:42127" "--executor-id" "0" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808110505-0000" "--worker-url" "spark://Worker@172.18.0.11:37613" "--resourceProfileId" "0"
2025-08-08 11:05:09,096 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 120@524c53b22c53
2025-08-08 11:05:09,115 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 11:05:09,118 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 11:05:09,120 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 11:05:09,670 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 11:05:09,876 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:05:09,883 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:05:09,888 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:05:09,890 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:05:09,893 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:05:10,530 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 19450efa36e6/172.18.0.12:42127 after 136 ms (0 ms spent in bootstraps)
2025-08-08 11:05:10,757 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:05:10,758 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:05:10,759 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:05:10,759 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:05:10,760 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:05:10,893 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 19450efa36e6/172.18.0.12:42127 after 15 ms (0 ms spent in bootstraps)
2025-08-08 11:05:11,126 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-e63ef0af-28dd-4d50-9a07-3bb615936d14/executor-64d56299-ef07-44b8-af34-644b05023012/blockmgr-a24493e1-167f-4135-af38-d72ae7d8a312
2025-08-08 11:05:11,196 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 11:05:11,522 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@19450efa36e6:42127
2025-08-08 11:05:11,526 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:37613
2025-08-08 11:05:11,540 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:37613 after 3 ms (0 ms spent in bootstraps)
2025-08-08 11:05:11,541 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:05:11,542 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 11:05:11,544 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:05:11,547 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:37613
2025-08-08 11:05:11,631 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 11:05:11,638 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.11
2025-08-08 11:05:11,734 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43073.
2025-08-08 11:05:11,736 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:43073
2025-08-08 11:05:11,741 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 11:05:11,755 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.11, 43073, None)
2025-08-08 11:05:11,798 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.11, 43073, None)
2025-08-08 11:05:11,803 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.11, 43073, None)
2025-08-08 11:05:11,824 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 11:06:12,534 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808110505-0000/0
2025-08-08 11:06:12,535 [ExecutorRunner for app-20250808110505-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808110505-0000/0 interrupted
2025-08-08 11:06:12,536 [ExecutorRunner for app-20250808110505-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 11:06:12,540 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 11:06:12,561 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 11:06:12,562 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 11:06:12,566 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 11:06:12,617 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808110505-0000/0 finished with state KILLED exitStatus 143
2025-08-08 11:06:12,619 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-08 11:06:12,620 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808110505-0000, execId=0)
2025-08-08 11:06:19,286 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808110505-0000/1 for Thrift JDBC/ODBC Server
2025-08-08 11:06:19,289 [ExecutorRunner for app-20250808110505-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:06:19,290 [ExecutorRunner for app-20250808110505-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:06:19,290 [ExecutorRunner for app-20250808110505-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:06:19,290 [ExecutorRunner for app-20250808110505-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:06:19,291 [ExecutorRunner for app-20250808110505-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:06:19,303 [ExecutorRunner for app-20250808110505-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42127" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@19450efa36e6:42127" "--executor-id" "1" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808110505-0000" "--worker-url" "spark://Worker@172.18.0.11:37613" "--resourceProfileId" "0"
2025-08-08 11:06:20,995 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 202@524c53b22c53
2025-08-08 11:06:21,003 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 11:06:21,005 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 11:06:21,005 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 11:06:21,276 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 11:06:21,365 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:06:21,366 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:06:21,367 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:06:21,367 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:06:21,368 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:06:21,603 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 19450efa36e6/172.18.0.12:42127 after 47 ms (0 ms spent in bootstraps)
2025-08-08 11:06:21,678 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:06:21,678 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:06:21,679 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:06:21,679 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:06:21,679 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:06:21,740 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 19450efa36e6/172.18.0.12:42127 after 1 ms (0 ms spent in bootstraps)
2025-08-08 11:06:21,817 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-e63ef0af-28dd-4d50-9a07-3bb615936d14/executor-64d56299-ef07-44b8-af34-644b05023012/blockmgr-11f27a94-46c7-4693-b2ac-f634113dea17
2025-08-08 11:06:21,848 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 11:06:22,003 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@19450efa36e6:42127
2025-08-08 11:06:22,004 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:37613
2025-08-08 11:06:22,007 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:37613 after 1 ms (0 ms spent in bootstraps)
2025-08-08 11:06:22,010 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:37613
2025-08-08 11:06:22,013 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:06:22,013 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 11:06:22,014 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:06:22,034 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 11:06:22,036 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.11
2025-08-08 11:06:22,065 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41643.
2025-08-08 11:06:22,065 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:41643
2025-08-08 11:06:22,067 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 11:06:22,073 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.11, 41643, None)
2025-08-08 11:06:22,081 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.11, 41643, None)
2025-08-08 11:06:22,082 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.11, 41643, None)
2025-08-08 11:06:22,089 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 11:06:22,137 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-08 11:06:22,142 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-08 11:06:22,146 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-08 11:06:22,146 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-08-08 11:06:22,208 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-08 11:06:22,248 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:06:22,281 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 19450efa36e6/172.18.0.12:36377 after 1 ms (0 ms spent in bootstraps)
2025-08-08 11:06:22,319 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-08 11:06:22,331 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 83 ms
2025-08-08 11:06:22,377 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-08 11:06:22,552 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:06:22,561 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-08 11:06:22,566 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 13 ms
2025-08-08 11:06:22,604 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:06:23,085 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 11:06:23,099 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 11:06:23,099 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 11:06:23,901 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:06:23,901 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:06:24,326 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 11:06:24,326 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 11:06:24,994 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to t24_branch/data/00001-1-ffafd0c1-598c-4993-9372-ee033919feed-0-00001.parquet. This is unsupported
2025-08-08 11:06:25,172 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
2025-08-08 11:06:25,172 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 1, attempt 0, stage 0.0)
2025-08-08 11:06:25,201 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 4439 bytes result sent to driver
2025-08-08 11:06:25,201 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 4437 bytes result sent to driver
2025-08-08 11:06:36,331 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:06:36,523 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2
2025-08-08 11:06:36,524 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 2)
2025-08-08 11:06:36,563 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:06:36,571 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.4 MiB)
2025-08-08 11:06:36,575 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 5 took 12 ms
2025-08-08 11:06:36,577 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 20.6 KiB, free 434.4 MiB)
2025-08-08 11:06:36,900 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 204.452549 ms
2025-08-08 11:06:36,904 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:06:36,915 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.3 MiB)
2025-08-08 11:06:36,919 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 4 took 14 ms
2025-08-08 11:06:36,922 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:06:36,927 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:06:36,939 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:06:36,948 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 11:06:36,953 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 3 took 13 ms
2025-08-08 11:06:36,960 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:06:37,052 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 11:06:37,067 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-08 11:06:37,067 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-08 11:06:37,080 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-08 11:06:37,084 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-08 11:06:37,086 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-08 11:06:37,219 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 11:06:37,494 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 11:06:37,504 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 11:06:37,511 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 11:06:37,563 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 2, attempt 0, stage 1.0)
2025-08-08 11:06:37,566 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 2). 7803 bytes result sent to driver
2025-08-08 11:07:38,413 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808110505-0000/1
2025-08-08 11:07:38,414 [ExecutorRunner for app-20250808110505-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808110505-0000/1 interrupted
2025-08-08 11:07:38,415 [ExecutorRunner for app-20250808110505-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 11:07:38,418 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 11:07:38,442 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:07:38,442 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:07:38,442 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 11:07:38,443 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 11:07:38,446 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 11:07:38,448 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 11:07:38,449 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 11:07:38,449 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 11:07:38,510 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808110505-0000/1 finished with state KILLED exitStatus 143
2025-08-08 11:07:38,510 [dispatcher-event-loop-11] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-08 11:07:38,511 [dispatcher-event-loop-11] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808110505-0000, execId=1)
2025-08-08 11:07:57,171 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808110505-0000/2 for Thrift JDBC/ODBC Server
2025-08-08 11:07:57,174 [ExecutorRunner for app-20250808110505-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:07:57,175 [ExecutorRunner for app-20250808110505-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:07:57,175 [ExecutorRunner for app-20250808110505-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:07:57,176 [ExecutorRunner for app-20250808110505-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:07:57,176 [ExecutorRunner for app-20250808110505-0000/2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:07:57,189 [ExecutorRunner for app-20250808110505-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42127" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@19450efa36e6:42127" "--executor-id" "2" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250808110505-0000" "--worker-url" "spark://Worker@172.18.0.11:37613" "--resourceProfileId" "0"
2025-08-08 11:07:58,629 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 308@524c53b22c53
2025-08-08 11:07:58,636 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 11:07:58,638 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 11:07:58,638 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 11:07:58,948 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 11:07:59,041 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:07:59,042 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:07:59,043 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:07:59,043 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:07:59,044 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:07:59,304 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 19450efa36e6/172.18.0.12:42127 after 64 ms (0 ms spent in bootstraps)
2025-08-08 11:07:59,410 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:07:59,411 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:07:59,412 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:07:59,412 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:07:59,413 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:07:59,463 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 19450efa36e6/172.18.0.12:42127 after 2 ms (0 ms spent in bootstraps)
2025-08-08 11:07:59,526 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-e63ef0af-28dd-4d50-9a07-3bb615936d14/executor-64d56299-ef07-44b8-af34-644b05023012/blockmgr-325341a9-f26c-40c8-bfb5-3f3a703821d1
2025-08-08 11:07:59,563 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 11:07:59,733 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@19450efa36e6:42127
2025-08-08 11:07:59,737 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:37613
2025-08-08 11:07:59,743 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:37613 after 2 ms (0 ms spent in bootstraps)
2025-08-08 11:07:59,746 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:37613
2025-08-08 11:07:59,749 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:07:59,750 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 11:07:59,750 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:07:59,772 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 11:07:59,775 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 2 on host 172.18.0.11
2025-08-08 11:07:59,816 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43703.
2025-08-08 11:07:59,817 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:43703
2025-08-08 11:07:59,819 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 11:07:59,825 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(2, 172.18.0.11, 43703, None)
2025-08-08 11:07:59,838 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(2, 172.18.0.11, 43703, None)
2025-08-08 11:07:59,841 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(2, 172.18.0.11, 43703, None)
2025-08-08 11:07:59,849 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 11:07:59,890 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3
2025-08-08 11:07:59,901 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 3)
2025-08-08 11:08:00,377 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 2 and clearing cache
2025-08-08 11:08:00,434 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:08:00,485 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 19450efa36e6/172.18.0.12:36377 after 2 ms (0 ms spent in bootstraps)
2025-08-08 11:08:00,523 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-08 11:08:00,536 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 9 took 100 ms
2025-08-08 11:08:00,585 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 21.3 KiB, free 434.4 MiB)
2025-08-08 11:08:01,068 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 195.186139 ms
2025-08-08 11:08:01,087 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 8 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:08:01,097 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.3 MiB)
2025-08-08 11:08:01,102 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 8 took 14 ms
2025-08-08 11:08:01,141 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:08:01,553 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 11:08:01,565 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 11:08:01,566 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 11:08:02,222 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:08:02,648 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:08:02,655 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-08 11:08:02,660 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 7 took 11 ms
2025-08-08 11:08:02,668 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:08:02,864 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 11:08:03,239 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-08 11:08:03,239 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-08 11:08:03,250 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-08 11:08:03,254 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-08 11:08:03,255 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-08 11:08:03,383 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 11:08:03,601 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 11:08:03,712 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] WARN  org.apache.hadoop.fs.s3a.S3ABlockOutputStream - Application invoked the Syncable API against stream writing to dim_branch/data/00000-3-e2c5c6a0-a405-43ea-b69a-15118d0b1d4f-0-00001.parquet. This is unsupported
2025-08-08 11:08:03,825 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 3, attempt 0, stage 2.0)
2025-08-08 11:08:03,846 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 3). 7880 bytes result sent to driver
2025-08-08 11:08:50,108 [block-manager-storage-async-thread-pool-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:08:50,130 [block-manager-storage-async-thread-pool-6] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:08:50,137 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4
2025-08-08 11:08:50,138 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 4)
2025-08-08 11:08:50,138 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5
2025-08-08 11:08:50,139 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 3.0 (TID 5)
2025-08-08 11:08:50,155 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 11 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:08:50,164 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-08 11:08:50,169 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 11 took 12 ms
2025-08-08 11:08:50,170 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-08 11:08:50,182 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 10 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:08:50,188 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-08 11:08:50,193 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 10 took 10 ms
2025-08-08 11:08:50,198 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:08:50,204 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:08:50,204 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:08:50,217 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 11:08:50,217 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 11:08:50,248 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 5, attempt 0, stage 3.0)
2025-08-08 11:08:50,260 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 3.0 (TID 5). 4437 bytes result sent to driver
2025-08-08 11:08:50,288 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 4, attempt 0, stage 3.0)
2025-08-08 11:08:50,295 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 4). 4438 bytes result sent to driver
2025-08-08 11:09:23,105 [block-manager-storage-async-thread-pool-15] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:09:51,223 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808110505-0000/2
2025-08-08 11:09:51,224 [ExecutorRunner for app-20250808110505-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808110505-0000/2 interrupted
2025-08-08 11:09:51,224 [ExecutorRunner for app-20250808110505-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 11:09:51,226 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 11:09:51,241 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 11:09:51,242 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 11:09:51,244 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 11:09:51,247 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 11:09:51,247 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 11:09:51,248 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 11:09:51,303 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808110505-0000/2 finished with state KILLED exitStatus 143
2025-08-08 11:09:51,303 [dispatcher-event-loop-3] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-08-08 11:09:51,304 [dispatcher-event-loop-3] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808110505-0000, execId=2)
2025-08-08 11:23:24,807 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@bb2a1e26def0
2025-08-08 11:23:24,829 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 11:23:24,836 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 11:23:24,838 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 11:23:25,343 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:23:25,345 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:23:25,348 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:23:25,356 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:23:25,358 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:23:26,156 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 11:23:27,622 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 45873.
2025-08-08 11:23:27,628 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-08 11:23:28,239 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.12:45873 with 12 cores, 6.6 GiB RAM
2025-08-08 11:23:28,258 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-08 11:23:28,260 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-08 11:23:28,324 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:23:28,329 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-08 11:23:28,331 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:23:28,477 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @7336ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-08 11:23:28,645 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-08 11:23:28,683 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-08 11:23:28,757 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @7617ms
2025-08-08 11:23:28,880 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@6eac1128{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-08 11:23:28,888 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-08 11:23:28,955 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@560a5f39{/logPage,null,AVAILABLE,@Spark}
2025-08-08 11:23:28,970 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ffb1f26{/logPage/json,null,AVAILABLE,@Spark}
2025-08-08 11:23:28,977 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1beee8f{/,null,AVAILABLE,@Spark}
2025-08-08 11:23:28,982 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73aa71b8{/json,null,AVAILABLE,@Spark}
2025-08-08 11:23:29,010 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d16b5fb{/static,null,AVAILABLE,@Spark}
2025-08-08 11:23:29,023 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70d3d9aa{/log,null,AVAILABLE,@Spark}
2025-08-08 11:23:29,085 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://bb2a1e26def0:8081
2025-08-08 11:23:29,109 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-08 11:23:29,179 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32a89fc2{/metrics/json,null,AVAILABLE,@Spark}
2025-08-08 11:23:29,326 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 129 ms (0 ms spent in bootstraps)
2025-08-08 11:23:29,736 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-08 11:23:32,273 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808112331-0000/0 for Thrift JDBC/ODBC Server
2025-08-08 11:23:32,342 [ExecutorRunner for app-20250808112331-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:23:32,342 [ExecutorRunner for app-20250808112331-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:23:32,344 [ExecutorRunner for app-20250808112331-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:23:32,344 [ExecutorRunner for app-20250808112331-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:23:32,345 [ExecutorRunner for app-20250808112331-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:23:32,411 [ExecutorRunner for app-20250808112331-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42249" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@caa95fed3650:42249" "--executor-id" "0" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250808112331-0000" "--worker-url" "spark://Worker@172.18.0.12:45873" "--resourceProfileId" "0"
2025-08-08 11:23:35,042 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 123@bb2a1e26def0
2025-08-08 11:23:35,103 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 11:23:35,114 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 11:23:35,122 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 11:23:36,362 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 11:23:36,744 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:23:36,749 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:23:36,751 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:23:36,754 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:23:36,760 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:23:37,578 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to caa95fed3650/172.18.0.11:42249 after 113 ms (0 ms spent in bootstraps)
2025-08-08 11:23:37,884 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:23:37,887 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:23:37,892 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:23:37,893 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:23:37,893 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:23:38,018 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to caa95fed3650/172.18.0.11:42249 after 3 ms (0 ms spent in bootstraps)
2025-08-08 11:23:38,211 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-02b3f970-c1cf-41ad-90be-7c6279b28253/executor-1aea72ef-2875-4c9e-96d2-a1faecec8580/blockmgr-0a63d398-46d0-401f-8431-60e219894949
2025-08-08 11:23:38,310 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 11:23:38,834 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@caa95fed3650:42249
2025-08-08 11:23:38,841 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:45873
2025-08-08 11:23:38,866 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:45873 after 16 ms (0 ms spent in bootstraps)
2025-08-08 11:23:38,880 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:45873
2025-08-08 11:23:38,904 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:23:38,908 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 11:23:38,914 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:23:38,983 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 11:23:38,992 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.12
2025-08-08 11:23:39,086 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43159.
2025-08-08 11:23:39,087 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:43159
2025-08-08 11:23:39,091 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 11:23:39,104 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.12, 43159, None)
2025-08-08 11:23:39,130 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.12, 43159, None)
2025-08-08 11:23:39,143 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.12, 43159, None)
2025-08-08 11:23:39,189 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 11:24:40,390 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808112331-0000/0
2025-08-08 11:24:40,391 [ExecutorRunner for app-20250808112331-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808112331-0000/0 interrupted
2025-08-08 11:24:40,393 [ExecutorRunner for app-20250808112331-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 11:24:40,398 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 11:24:40,439 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 11:24:40,440 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 11:24:40,443 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 11:24:40,486 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808112331-0000/0 finished with state KILLED exitStatus 143
2025-08-08 11:24:40,488 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-08 11:24:40,489 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808112331-0000, execId=0)
2025-08-08 11:25:02,955 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808112331-0000/1 for Thrift JDBC/ODBC Server
2025-08-08 11:25:02,958 [ExecutorRunner for app-20250808112331-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:25:02,958 [ExecutorRunner for app-20250808112331-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:25:02,959 [ExecutorRunner for app-20250808112331-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:25:02,959 [ExecutorRunner for app-20250808112331-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:25:02,959 [ExecutorRunner for app-20250808112331-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:25:02,971 [ExecutorRunner for app-20250808112331-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42249" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@caa95fed3650:42249" "--executor-id" "1" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250808112331-0000" "--worker-url" "spark://Worker@172.18.0.12:45873" "--resourceProfileId" "0"
2025-08-08 11:25:04,714 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 207@bb2a1e26def0
2025-08-08 11:25:04,721 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 11:25:04,723 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 11:25:04,723 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 11:25:05,032 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 11:25:05,170 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:25:05,171 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:25:05,172 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:25:05,172 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:25:05,173 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:25:05,484 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to caa95fed3650/172.18.0.11:42249 after 62 ms (0 ms spent in bootstraps)
2025-08-08 11:25:05,587 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:25:05,588 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:25:05,589 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:25:05,589 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:25:05,590 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:25:05,661 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to caa95fed3650/172.18.0.11:42249 after 1 ms (0 ms spent in bootstraps)
2025-08-08 11:25:05,800 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-02b3f970-c1cf-41ad-90be-7c6279b28253/executor-1aea72ef-2875-4c9e-96d2-a1faecec8580/blockmgr-9d23ca50-7eaf-4ab1-ba06-9fba99c7fd8e
2025-08-08 11:25:05,857 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 11:25:06,064 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@caa95fed3650:42249
2025-08-08 11:25:06,065 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:45873
2025-08-08 11:25:06,069 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:45873 after 2 ms (0 ms spent in bootstraps)
2025-08-08 11:25:06,071 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:45873
2025-08-08 11:25:06,077 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:25:06,079 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 11:25:06,080 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:25:06,107 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 11:25:06,111 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.12
2025-08-08 11:25:06,155 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39131.
2025-08-08 11:25:06,156 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:39131
2025-08-08 11:25:06,159 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 11:25:06,172 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.12, 39131, None)
2025-08-08 11:25:06,183 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.12, 39131, None)
2025-08-08 11:25:06,186 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.12, 39131, None)
2025-08-08 11:25:06,197 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 11:25:06,256 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-08 11:25:06,261 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-08 11:25:06,265 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-08-08 11:25:06,265 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-08 11:25:06,333 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-08 11:25:06,375 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:25:06,409 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to caa95fed3650/172.18.0.11:46653 after 2 ms (0 ms spent in bootstraps)
2025-08-08 11:25:06,454 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 434.4 MiB)
2025-08-08 11:25:06,469 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 94 ms
2025-08-08 11:25:06,542 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-08 11:25:06,773 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:25:06,782 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-08 11:25:06,787 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 13 ms
2025-08-08 11:25:06,822 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:25:07,324 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 11:25:07,336 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 11:25:07,336 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 11:25:08,179 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:25:08,179 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:25:08,475 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 11:25:08,475 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 11:25:09,246 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
2025-08-08 11:25:09,246 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 1, attempt 0, stage 0.0)
2025-08-08 11:25:09,281 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 4158 bytes result sent to driver
2025-08-08 11:25:09,281 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 4156 bytes result sent to driver
2025-08-08 11:25:55,651 [block-manager-storage-async-thread-pool-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:25:56,359 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2
2025-08-08 11:25:56,361 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 2)
2025-08-08 11:25:56,405 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:25:56,414 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-08 11:25:56,420 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 5 took 14 ms
2025-08-08 11:25:56,422 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 20.2 KiB, free 434.4 MiB)
2025-08-08 11:25:56,780 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 213.337541 ms
2025-08-08 11:25:56,785 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:25:56,792 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.3 MiB)
2025-08-08 11:25:56,797 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 4 took 12 ms
2025-08-08 11:25:56,801 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:25:56,806 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:25:56,818 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:25:56,825 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-08 11:25:56,831 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 3 took 13 ms
2025-08-08 11:25:56,839 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:25:56,944 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 11:25:56,961 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-08 11:25:56,961 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-08 11:25:56,973 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-08 11:25:56,976 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-08 11:25:56,978 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-08 11:25:57,134 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 11:25:57,414 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 11:25:57,424 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 11:25:57,433 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 11:25:57,478 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 2, attempt 0, stage 1.0)
2025-08-08 11:25:57,482 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 2). 7564 bytes result sent to driver
2025-08-08 11:26:07,641 [block-manager-storage-async-thread-pool-9] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:26:07,811 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3
2025-08-08 11:26:07,812 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 3)
2025-08-08 11:26:07,823 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 9 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:26:07,830 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 434.3 MiB)
2025-08-08 11:26:07,836 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 9 took 12 ms
2025-08-08 11:26:07,838 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 20.8 KiB, free 434.3 MiB)
2025-08-08 11:26:07,861 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.252573 ms
2025-08-08 11:26:07,863 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 8 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:26:07,870 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.3 MiB)
2025-08-08 11:26:07,874 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 8 took 10 ms
2025-08-08 11:26:07,878 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:26:07,885 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:26:07,888 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:26:07,895 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.2 MiB)
2025-08-08 11:26:07,899 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 7 took 10 ms
2025-08-08 11:26:07,901 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-08 11:26:07,916 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-08 11:26:07,942 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-08 11:26:07,955 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 11:26:07,981 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 3, attempt 0, stage 2.0)
2025-08-08 11:26:07,984 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 3). 7512 bytes result sent to driver
2025-08-08 11:27:02,060 [block-manager-storage-async-thread-pool-15] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:27:08,899 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808112331-0000/1
2025-08-08 11:27:08,900 [ExecutorRunner for app-20250808112331-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808112331-0000/1 interrupted
2025-08-08 11:27:08,901 [ExecutorRunner for app-20250808112331-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 11:27:08,903 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 11:27:08,921 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:27:08,921 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:27:08,922 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 11:27:08,922 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 11:27:08,924 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 11:27:08,927 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 11:27:08,927 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 11:27:08,928 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 11:27:08,985 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808112331-0000/1 finished with state KILLED exitStatus 143
2025-08-08 11:27:08,986 [dispatcher-event-loop-3] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-08 11:27:08,986 [dispatcher-event-loop-3] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808112331-0000, execId=1)
2025-08-08 11:27:29,273 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250808112331-0000/2 for Thrift JDBC/ODBC Server
2025-08-08 11:27:29,277 [ExecutorRunner for app-20250808112331-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:27:29,278 [ExecutorRunner for app-20250808112331-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:27:29,278 [ExecutorRunner for app-20250808112331-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:27:29,278 [ExecutorRunner for app-20250808112331-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:27:29,278 [ExecutorRunner for app-20250808112331-0000/2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:27:29,305 [ExecutorRunner for app-20250808112331-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42249" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@caa95fed3650:42249" "--executor-id" "2" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250808112331-0000" "--worker-url" "spark://Worker@172.18.0.12:45873" "--resourceProfileId" "0"
2025-08-08 11:27:30,335 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 336@bb2a1e26def0
2025-08-08 11:27:30,344 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-08 11:27:30,346 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-08 11:27:30,346 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-08 11:27:30,628 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-08 11:27:30,722 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:27:30,723 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:27:30,724 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:27:30,725 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:27:30,726 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:27:30,934 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to caa95fed3650/172.18.0.11:42249 after 45 ms (0 ms spent in bootstraps)
2025-08-08 11:27:31,013 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-08 11:27:31,014 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-08 11:27:31,014 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-08 11:27:31,015 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-08 11:27:31,015 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-08 11:27:31,079 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to caa95fed3650/172.18.0.11:42249 after 1 ms (0 ms spent in bootstraps)
2025-08-08 11:27:31,161 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-02b3f970-c1cf-41ad-90be-7c6279b28253/executor-1aea72ef-2875-4c9e-96d2-a1faecec8580/blockmgr-ec2756b9-5b3b-48da-a450-acd72d2677e0
2025-08-08 11:27:31,204 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-08 11:27:31,329 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@caa95fed3650:42249
2025-08-08 11:27:31,330 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:45873
2025-08-08 11:27:31,334 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:45873 after 2 ms (0 ms spent in bootstraps)
2025-08-08 11:27:31,335 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:45873
2025-08-08 11:27:31,339 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:27:31,340 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-08 11:27:31,341 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-08 11:27:31,361 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-08 11:27:31,364 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 2 on host 172.18.0.12
2025-08-08 11:27:31,396 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35127.
2025-08-08 11:27:31,397 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:35127
2025-08-08 11:27:31,400 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-08 11:27:31,408 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(2, 172.18.0.12, 35127, None)
2025-08-08 11:27:31,417 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(2, 172.18.0.12, 35127, None)
2025-08-08 11:27:31,419 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(2, 172.18.0.12, 35127, None)
2025-08-08 11:27:31,425 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-08 11:27:31,460 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4
2025-08-08 11:27:31,466 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5
2025-08-08 11:27:31,470 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 3.0 (TID 5)
2025-08-08 11:27:31,470 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 4)
2025-08-08 11:27:31,528 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 2 and clearing cache
2025-08-08 11:27:31,565 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 11 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:27:31,595 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to caa95fed3650/172.18.0.11:46653 after 2 ms (0 ms spent in bootstraps)
2025-08-08 11:27:31,621 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-08 11:27:31,632 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 11 took 65 ms
2025-08-08 11:27:31,678 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-08 11:27:31,838 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 10 with 1 pieces (estimated total size 4.0 MiB)
2025-08-08 11:27:31,850 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-08 11:27:31,856 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 10 took 17 ms
2025-08-08 11:27:31,916 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-08 11:27:32,406 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-08 11:27:32,417 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-08 11:27:32,417 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-08 11:27:33,138 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:27:33,138 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-08 11:27:33,485 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-08 11:27:33,485 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-08 11:27:34,357 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 5, attempt 0, stage 3.0)
2025-08-08 11:27:34,358 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 4, attempt 0, stage 3.0)
2025-08-08 11:27:34,383 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 3.0 (TID 5). 4156 bytes result sent to driver
2025-08-08 11:27:34,383 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 4). 4158 bytes result sent to driver
2025-08-08 11:27:42,725 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-08 11:28:35,339 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250808112331-0000/2
2025-08-08 11:28:35,340 [ExecutorRunner for app-20250808112331-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250808112331-0000/2 interrupted
2025-08-08 11:28:35,340 [ExecutorRunner for app-20250808112331-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-08 11:28:35,344 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-08 11:28:35,764 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-08 11:28:35,764 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-08 11:28:35,767 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-08 11:28:35,770 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-08 11:28:35,770 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-08 11:28:35,771 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-08 11:28:35,834 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250808112331-0000/2 finished with state KILLED exitStatus 143
2025-08-08 11:28:35,837 [dispatcher-event-loop-7] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-08-08 11:28:35,839 [dispatcher-event-loop-7] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250808112331-0000, execId=2)
2025-08-09 04:48:28,310 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@cb9deef6c154
2025-08-09 04:48:28,328 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 04:48:28,331 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 04:48:28,333 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 04:48:28,928 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 04:48:28,940 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 04:48:28,945 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 04:48:28,950 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 04:48:28,957 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 04:48:29,544 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 04:48:31,378 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 44005.
2025-08-09 04:48:31,390 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-09 04:48:32,026 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.12:44005 with 12 cores, 6.6 GiB RAM
2025-08-09 04:48:32,048 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-09 04:48:32,056 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-09 04:48:32,111 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 04:48:32,114 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-09 04:48:32,116 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 04:48:32,218 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @7126ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-09 04:48:32,333 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-09 04:48:32,362 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-09 04:48:32,420 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @7332ms
2025-08-09 04:48:32,510 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@4dc4c33e{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-09 04:48:32,511 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-09 04:48:32,573 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3261cf5e{/logPage,null,AVAILABLE,@Spark}
2025-08-09 04:48:32,583 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46c3ec44{/logPage/json,null,AVAILABLE,@Spark}
2025-08-09 04:48:32,589 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@233f489e{/,null,AVAILABLE,@Spark}
2025-08-09 04:48:32,595 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e8c8dcb{/json,null,AVAILABLE,@Spark}
2025-08-09 04:48:32,625 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@34bcce52{/static,null,AVAILABLE,@Spark}
2025-08-09 04:48:32,632 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3dcf247b{/log,null,AVAILABLE,@Spark}
2025-08-09 04:48:32,637 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://cb9deef6c154:8081
2025-08-09 04:48:32,646 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-09 04:48:32,697 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6b35b15d{/metrics/json,null,AVAILABLE,@Spark}
2025-08-09 04:48:32,888 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 148 ms (0 ms spent in bootstraps)
2025-08-09 04:48:33,360 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-09 04:48:34,855 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250809044834-0000/0 for Thrift JDBC/ODBC Server
2025-08-09 04:48:34,936 [ExecutorRunner for app-20250809044834-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 04:48:34,937 [ExecutorRunner for app-20250809044834-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 04:48:34,937 [ExecutorRunner for app-20250809044834-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 04:48:34,938 [ExecutorRunner for app-20250809044834-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 04:48:34,938 [ExecutorRunner for app-20250809044834-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 04:48:34,975 [ExecutorRunner for app-20250809044834-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42323" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@921e2d5918c8:42323" "--executor-id" "0" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250809044834-0000" "--worker-url" "spark://Worker@172.18.0.12:44005" "--resourceProfileId" "0"
2025-08-09 04:48:37,099 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 119@cb9deef6c154
2025-08-09 04:48:37,121 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 04:48:37,122 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 04:48:37,123 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 04:48:37,802 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 04:48:38,024 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 04:48:38,028 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 04:48:38,030 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 04:48:38,033 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 04:48:38,039 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 04:48:38,620 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 921e2d5918c8/172.18.0.11:42323 after 119 ms (0 ms spent in bootstraps)
2025-08-09 04:48:38,780 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 04:48:38,781 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 04:48:38,782 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 04:48:38,783 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 04:48:38,783 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 04:48:38,900 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 921e2d5918c8/172.18.0.11:42323 after 2 ms (0 ms spent in bootstraps)
2025-08-09 04:48:39,060 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-28868e1b-0c6c-469c-9148-c1e3a2d30cdd/executor-6056289b-89e1-4e23-a472-2feb952f62dc/blockmgr-6773dad2-9053-4d2d-b01d-4d956287b614
2025-08-09 04:48:39,125 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-09 04:48:39,430 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@921e2d5918c8:42323
2025-08-09 04:48:39,433 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:44005
2025-08-09 04:48:39,447 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:44005 after 6 ms (0 ms spent in bootstraps)
2025-08-09 04:48:39,448 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:44005
2025-08-09 04:48:39,449 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 04:48:39,451 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-09 04:48:39,452 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 04:48:39,509 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-09 04:48:39,521 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.12
2025-08-09 04:48:39,593 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34293.
2025-08-09 04:48:39,594 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:34293
2025-08-09 04:48:39,597 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-09 04:48:39,609 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.12, 34293, None)
2025-08-09 04:48:39,641 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.12, 34293, None)
2025-08-09 04:48:39,645 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.12, 34293, None)
2025-08-09 04:48:39,655 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-09 04:49:41,051 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250809044834-0000/0
2025-08-09 04:49:41,053 [ExecutorRunner for app-20250809044834-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250809044834-0000/0 interrupted
2025-08-09 04:49:41,054 [ExecutorRunner for app-20250809044834-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-09 04:49:41,061 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-09 04:49:41,086 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-09 04:49:41,088 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-09 04:49:41,091 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-09 04:49:41,148 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250809044834-0000/0 finished with state KILLED exitStatus 143
2025-08-09 04:49:41,151 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-09 04:49:41,152 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250809044834-0000, execId=0)
2025-08-09 04:51:46,169 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250809044834-0000/1 for Thrift JDBC/ODBC Server
2025-08-09 04:51:46,179 [ExecutorRunner for app-20250809044834-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 04:51:46,179 [ExecutorRunner for app-20250809044834-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 04:51:46,180 [ExecutorRunner for app-20250809044834-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 04:51:46,180 [ExecutorRunner for app-20250809044834-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 04:51:46,180 [ExecutorRunner for app-20250809044834-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 04:51:46,223 [ExecutorRunner for app-20250809044834-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42323" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@921e2d5918c8:42323" "--executor-id" "1" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250809044834-0000" "--worker-url" "spark://Worker@172.18.0.12:44005" "--resourceProfileId" "0"
2025-08-09 04:51:47,679 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 197@cb9deef6c154
2025-08-09 04:51:47,687 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 04:51:47,688 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 04:51:47,689 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 04:51:47,969 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 04:51:48,045 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 04:51:48,046 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 04:51:48,047 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 04:51:48,047 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 04:51:48,047 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 04:51:48,274 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 921e2d5918c8/172.18.0.11:42323 after 48 ms (0 ms spent in bootstraps)
2025-08-09 04:51:48,356 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 04:51:48,357 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 04:51:48,357 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 04:51:48,357 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 04:51:48,358 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 04:51:48,397 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 921e2d5918c8/172.18.0.11:42323 after 1 ms (0 ms spent in bootstraps)
2025-08-09 04:51:48,474 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-28868e1b-0c6c-469c-9148-c1e3a2d30cdd/executor-6056289b-89e1-4e23-a472-2feb952f62dc/blockmgr-6fea0403-8ef6-4d95-ab37-4f6b258fcbcf
2025-08-09 04:51:48,506 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-09 04:51:48,653 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@921e2d5918c8:42323
2025-08-09 04:51:48,654 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:44005
2025-08-09 04:51:48,658 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:44005 after 2 ms (0 ms spent in bootstraps)
2025-08-09 04:51:48,659 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:44005
2025-08-09 04:51:48,664 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 04:51:48,664 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-09 04:51:48,665 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 04:51:48,683 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-09 04:51:48,686 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.12
2025-08-09 04:51:48,715 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43725.
2025-08-09 04:51:48,715 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:43725
2025-08-09 04:51:48,717 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-09 04:51:48,722 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.12, 43725, None)
2025-08-09 04:51:48,730 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.12, 43725, None)
2025-08-09 04:51:48,732 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.12, 43725, None)
2025-08-09 04:51:48,737 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-09 04:51:48,785 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-09 04:51:48,793 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-09 04:51:48,831 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-09 04:51:48,867 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 04:51:48,905 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 921e2d5918c8/172.18.0.11:39227 after 1 ms (0 ms spent in bootstraps)
2025-08-09 04:51:48,945 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 434.4 MiB)
2025-08-09 04:51:48,954 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 86 ms
2025-08-09 04:51:48,996 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 7.0 KiB, free 434.4 MiB)
2025-08-09 04:51:49,447 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 175.597734 ms
2025-08-09 04:51:49,500 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1505 bytes result sent to driver
2025-08-09 04:52:20,984 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-09 04:52:20,985 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2
2025-08-09 04:52:20,985 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 1)
2025-08-09 04:52:20,986 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 1.0 (TID 2)
2025-08-09 04:52:20,992 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 04:52:21,000 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-09 04:52:21,009 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 2 took 16 ms
2025-08-09 04:52:21,011 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-09 04:52:21,085 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 04:52:21,096 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-09 04:52:21,101 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 15 ms
2025-08-09 04:52:21,152 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-09 04:52:21,653 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-09 04:52:21,667 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-09 04:52:21,667 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-09 04:52:22,260 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-09 04:52:22,260 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-09 04:52:22,559 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-09 04:52:22,559 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-09 04:52:23,206 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 2, attempt 0, stage 1.0)
2025-08-09 04:52:23,206 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 1, attempt 0, stage 1.0)
2025-08-09 04:52:23,215 [Executor task launch worker for task 1.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 1.0 (TID 2). 4156 bytes result sent to driver
2025-08-09 04:52:23,215 [Executor task launch worker for task 0.0 in stage 1.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 1). 4158 bytes result sent to driver
2025-08-09 04:52:55,592 [block-manager-storage-async-thread-pool-6] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-09 04:52:56,715 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3
2025-08-09 04:52:56,716 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 3)
2025-08-09 04:52:56,761 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 04:52:56,772 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.1 KiB, free 434.4 MiB)
2025-08-09 04:52:56,778 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 6 took 16 ms
2025-08-09 04:52:56,781 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 20.2 KiB, free 434.4 MiB)
2025-08-09 04:52:56,847 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 39.314298 ms
2025-08-09 04:52:56,850 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 04:52:56,858 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.3 MiB)
2025-08-09 04:52:56,864 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 5 took 13 ms
2025-08-09 04:52:56,867 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-09 04:52:56,874 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-09 04:52:56,890 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 04:52:56,899 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-09 04:52:56,905 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 4 took 15 ms
2025-08-09 04:52:56,913 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-09 04:52:57,057 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-09 04:52:57,074 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-09 04:52:57,074 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-09 04:52:57,087 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-09 04:52:57,091 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-09 04:52:57,093 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-09 04:52:57,226 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-09 04:52:57,422 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-09 04:52:57,431 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-09 04:52:57,437 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-09 04:52:57,485 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 3, attempt 0, stage 2.0)
2025-08-09 04:52:57,488 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 3). 7521 bytes result sent to driver
2025-08-09 04:53:59,192 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250809044834-0000/1
2025-08-09 04:53:59,192 [ExecutorRunner for app-20250809044834-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250809044834-0000/1 interrupted
2025-08-09 04:53:59,192 [ExecutorRunner for app-20250809044834-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-09 04:53:59,197 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-09 04:53:59,217 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-09 04:53:59,217 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-09 04:53:59,218 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-09 04:53:59,218 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-09 04:53:59,221 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-09 04:53:59,223 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-09 04:53:59,223 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-09 04:53:59,224 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-09 04:53:59,275 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250809044834-0000/1 finished with state KILLED exitStatus 143
2025-08-09 04:53:59,278 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-09 04:53:59,278 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250809044834-0000, execId=1)
2025-08-09 04:54:02,716 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250809044834-0000/2 for Thrift JDBC/ODBC Server
2025-08-09 04:54:02,718 [ExecutorRunner for app-20250809044834-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 04:54:02,719 [ExecutorRunner for app-20250809044834-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 04:54:02,719 [ExecutorRunner for app-20250809044834-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 04:54:02,719 [ExecutorRunner for app-20250809044834-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 04:54:02,719 [ExecutorRunner for app-20250809044834-0000/2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 04:54:02,729 [ExecutorRunner for app-20250809044834-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42323" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@921e2d5918c8:42323" "--executor-id" "2" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250809044834-0000" "--worker-url" "spark://Worker@172.18.0.12:44005" "--resourceProfileId" "0"
2025-08-09 04:54:03,944 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 313@cb9deef6c154
2025-08-09 04:54:03,958 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 04:54:03,960 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 04:54:03,961 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 04:54:04,289 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 04:54:04,378 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 04:54:04,379 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 04:54:04,380 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 04:54:04,380 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 04:54:04,381 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 04:54:04,621 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 921e2d5918c8/172.18.0.11:42323 after 59 ms (0 ms spent in bootstraps)
2025-08-09 04:54:04,720 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 04:54:04,720 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 04:54:04,721 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 04:54:04,721 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 04:54:04,721 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 04:54:04,786 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 921e2d5918c8/172.18.0.11:42323 after 1 ms (0 ms spent in bootstraps)
2025-08-09 04:54:04,863 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-28868e1b-0c6c-469c-9148-c1e3a2d30cdd/executor-6056289b-89e1-4e23-a472-2feb952f62dc/blockmgr-c354dd6c-d09b-4b6c-b8c0-0d155ecee0f0
2025-08-09 04:54:04,892 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-09 04:54:05,072 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@921e2d5918c8:42323
2025-08-09 04:54:05,074 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:44005
2025-08-09 04:54:05,077 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:44005 after 2 ms (0 ms spent in bootstraps)
2025-08-09 04:54:05,080 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:44005
2025-08-09 04:54:05,083 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 04:54:05,084 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-09 04:54:05,085 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 04:54:05,109 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-09 04:54:05,112 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 2 on host 172.18.0.12
2025-08-09 04:54:05,149 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39307.
2025-08-09 04:54:05,149 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:39307
2025-08-09 04:54:05,152 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-09 04:54:05,160 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(2, 172.18.0.12, 39307, None)
2025-08-09 04:54:05,170 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(2, 172.18.0.12, 39307, None)
2025-08-09 04:54:05,172 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(2, 172.18.0.12, 39307, None)
2025-08-09 04:54:05,179 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-09 04:54:05,220 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4
2025-08-09 04:54:05,226 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5
2025-08-09 04:54:05,231 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 4)
2025-08-09 04:54:05,231 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 3.0 (TID 5)
2025-08-09 04:54:05,302 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-09 04:54:05,345 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 8 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 04:54:05,375 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 921e2d5918c8/172.18.0.11:39227 after 2 ms (0 ms spent in bootstraps)
2025-08-09 04:54:05,402 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-09 04:54:05,412 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 8 took 66 ms
2025-08-09 04:54:05,465 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-09 04:54:05,625 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 04:54:05,633 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-09 04:54:05,637 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 7 took 11 ms
2025-08-09 04:54:05,677 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-09 04:54:06,142 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-09 04:54:06,153 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-09 04:54:06,153 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-09 04:54:06,883 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-09 04:54:06,883 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-09 04:54:07,183 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-09 04:54:07,183 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-09 04:54:07,788 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 4, attempt 0, stage 3.0)
2025-08-09 04:54:07,788 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 5, attempt 0, stage 3.0)
2025-08-09 04:54:07,814 [Executor task launch worker for task 0.0 in stage 3.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 4). 4158 bytes result sent to driver
2025-08-09 04:54:07,814 [Executor task launch worker for task 1.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 3.0 (TID 5). 4156 bytes result sent to driver
2025-08-09 04:54:17,716 [block-manager-storage-async-thread-pool-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-09 04:55:09,462 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250809044834-0000/2
2025-08-09 04:55:09,463 [ExecutorRunner for app-20250809044834-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250809044834-0000/2 interrupted
2025-08-09 04:55:09,463 [ExecutorRunner for app-20250809044834-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-09 04:55:09,477 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-09 04:55:09,495 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-09 04:55:09,496 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-09 04:55:09,498 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-09 04:55:09,501 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-09 04:55:09,501 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-09 04:55:09,502 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-09 04:55:09,554 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250809044834-0000/2 finished with state KILLED exitStatus 143
2025-08-09 04:55:09,554 [dispatcher-event-loop-11] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-08-09 04:55:09,555 [dispatcher-event-loop-11] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250809044834-0000, execId=2)
2025-08-09 05:00:47,801 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@811c7b2ddddd
2025-08-09 05:00:47,839 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 05:00:47,844 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 05:00:47,847 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 05:00:48,451 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 05:00:48,453 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 05:00:48,456 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 05:00:48,468 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 05:00:48,474 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 05:00:48,875 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 05:00:50,609 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 41893.
2025-08-09 05:00:50,615 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-09 05:00:51,102 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.12:41893 with 12 cores, 6.6 GiB RAM
2025-08-09 05:00:51,122 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-09 05:00:51,123 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-09 05:00:51,163 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 05:00:51,168 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-09 05:00:51,172 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 05:00:51,290 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @6241ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-09 05:00:51,376 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-09 05:00:51,413 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-09 05:00:51,493 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @6446ms
2025-08-09 05:00:51,580 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@6eac1128{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-09 05:00:51,581 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-09 05:00:51,640 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@560a5f39{/logPage,null,AVAILABLE,@Spark}
2025-08-09 05:00:51,651 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ffb1f26{/logPage/json,null,AVAILABLE,@Spark}
2025-08-09 05:00:51,655 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1beee8f{/,null,AVAILABLE,@Spark}
2025-08-09 05:00:51,668 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73aa71b8{/json,null,AVAILABLE,@Spark}
2025-08-09 05:00:51,692 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d16b5fb{/static,null,AVAILABLE,@Spark}
2025-08-09 05:00:51,697 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70d3d9aa{/log,null,AVAILABLE,@Spark}
2025-08-09 05:00:51,705 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://811c7b2ddddd:8081
2025-08-09 05:00:51,717 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-09 05:00:51,789 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32a89fc2{/metrics/json,null,AVAILABLE,@Spark}
2025-08-09 05:00:51,872 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 78 ms (0 ms spent in bootstraps)
2025-08-09 05:00:52,289 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-09 05:00:53,748 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250809050053-0000/0 for Thrift JDBC/ODBC Server
2025-08-09 05:00:53,823 [ExecutorRunner for app-20250809050053-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 05:00:53,824 [ExecutorRunner for app-20250809050053-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 05:00:53,830 [ExecutorRunner for app-20250809050053-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 05:00:53,831 [ExecutorRunner for app-20250809050053-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 05:00:53,832 [ExecutorRunner for app-20250809050053-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 05:00:53,883 [ExecutorRunner for app-20250809050053-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42669" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@f9886d40251d:42669" "--executor-id" "0" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250809050053-0000" "--worker-url" "spark://Worker@172.18.0.12:41893" "--resourceProfileId" "0"
2025-08-09 05:00:56,083 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 121@811c7b2ddddd
2025-08-09 05:00:56,097 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 05:00:56,099 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 05:00:56,100 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 05:00:56,705 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 05:00:56,925 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 05:00:56,927 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 05:00:56,929 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 05:00:56,931 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 05:00:56,934 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 05:00:57,477 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to f9886d40251d/172.18.0.11:42669 after 74 ms (0 ms spent in bootstraps)
2025-08-09 05:00:57,694 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 05:00:57,696 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 05:00:57,696 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 05:00:57,697 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 05:00:57,698 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 05:00:57,807 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to f9886d40251d/172.18.0.11:42669 after 3 ms (0 ms spent in bootstraps)
2025-08-09 05:00:57,922 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-86ed0a08-a1a0-4b10-9158-7302f2f6a9c5/executor-ad0832cd-05a2-4578-a457-a32c86dfc535/blockmgr-2dfe5a81-4812-4272-9586-a42e3f707d12
2025-08-09 05:00:57,987 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-09 05:00:58,298 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@f9886d40251d:42669
2025-08-09 05:00:58,300 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:41893
2025-08-09 05:00:58,305 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:41893 after 2 ms (0 ms spent in bootstraps)
2025-08-09 05:00:58,309 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:41893
2025-08-09 05:00:58,321 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 05:00:58,323 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-09 05:00:58,324 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 05:00:58,388 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-09 05:00:58,394 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.12
2025-08-09 05:00:58,496 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34283.
2025-08-09 05:00:58,498 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:34283
2025-08-09 05:00:58,506 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-09 05:00:58,521 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.12, 34283, None)
2025-08-09 05:00:58,579 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.12, 34283, None)
2025-08-09 05:00:58,581 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.12, 34283, None)
2025-08-09 05:00:58,593 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-09 05:02:00,228 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250809050053-0000/0
2025-08-09 05:02:00,229 [ExecutorRunner for app-20250809050053-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250809050053-0000/0 interrupted
2025-08-09 05:02:00,230 [ExecutorRunner for app-20250809050053-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-09 05:02:00,234 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-09 05:02:00,260 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-09 05:02:00,261 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-09 05:02:00,264 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-09 05:02:00,311 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250809050053-0000/0 finished with state KILLED exitStatus 143
2025-08-09 05:02:00,313 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-09 05:02:00,314 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250809050053-0000, execId=0)
2025-08-09 05:03:23,553 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250809050053-0000/1 for Thrift JDBC/ODBC Server
2025-08-09 05:03:23,556 [ExecutorRunner for app-20250809050053-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 05:03:23,556 [ExecutorRunner for app-20250809050053-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 05:03:23,557 [ExecutorRunner for app-20250809050053-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 05:03:23,557 [ExecutorRunner for app-20250809050053-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 05:03:23,557 [ExecutorRunner for app-20250809050053-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 05:03:23,575 [ExecutorRunner for app-20250809050053-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=42669" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@f9886d40251d:42669" "--executor-id" "1" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250809050053-0000" "--worker-url" "spark://Worker@172.18.0.12:41893" "--resourceProfileId" "0"
2025-08-09 05:03:25,820 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 204@811c7b2ddddd
2025-08-09 05:03:25,829 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 05:03:25,831 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 05:03:25,832 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 05:03:26,082 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 05:03:26,157 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 05:03:26,158 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 05:03:26,158 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 05:03:26,159 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 05:03:26,159 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 05:03:26,390 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to f9886d40251d/172.18.0.11:42669 after 52 ms (0 ms spent in bootstraps)
2025-08-09 05:03:26,476 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 05:03:26,477 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 05:03:26,477 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 05:03:26,478 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 05:03:26,478 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 05:03:26,526 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to f9886d40251d/172.18.0.11:42669 after 1 ms (0 ms spent in bootstraps)
2025-08-09 05:03:26,597 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-86ed0a08-a1a0-4b10-9158-7302f2f6a9c5/executor-ad0832cd-05a2-4578-a457-a32c86dfc535/blockmgr-7300212b-1def-4191-9b13-92515b82e335
2025-08-09 05:03:26,626 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-09 05:03:26,787 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@f9886d40251d:42669
2025-08-09 05:03:26,787 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:41893
2025-08-09 05:03:26,791 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:41893 after 2 ms (0 ms spent in bootstraps)
2025-08-09 05:03:26,793 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:41893
2025-08-09 05:03:26,796 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 05:03:26,797 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-09 05:03:26,798 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 05:03:26,817 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-09 05:03:26,819 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.12
2025-08-09 05:03:26,864 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33625.
2025-08-09 05:03:26,865 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:33625
2025-08-09 05:03:26,870 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-09 05:03:26,877 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.12, 33625, None)
2025-08-09 05:03:26,886 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.12, 33625, None)
2025-08-09 05:03:26,888 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.12, 33625, None)
2025-08-09 05:03:26,895 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-09 05:03:26,962 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-09 05:03:26,970 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-09 05:03:26,974 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-09 05:03:26,974 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-08-09 05:03:27,040 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-09 05:03:27,081 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 05:03:27,121 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to f9886d40251d/172.18.0.11:38533 after 2 ms (0 ms spent in bootstraps)
2025-08-09 05:03:27,167 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-09 05:03:27,180 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 98 ms
2025-08-09 05:03:27,228 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-09 05:03:27,402 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 05:03:27,411 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-09 05:03:27,416 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 13 ms
2025-08-09 05:03:27,456 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-09 05:03:28,037 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-09 05:03:28,050 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-09 05:03:28,051 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-09 05:03:28,681 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-09 05:03:28,681 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-09 05:03:28,995 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-09 05:03:28,995 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-09 05:03:29,631 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 1, attempt 0, stage 0.0)
2025-08-09 05:03:29,631 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
2025-08-09 05:03:29,656 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 4156 bytes result sent to driver
2025-08-09 05:03:29,656 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 4158 bytes result sent to driver
2025-08-09 05:04:31,590 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250809050053-0000/1
2025-08-09 05:04:31,591 [ExecutorRunner for app-20250809050053-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250809050053-0000/1 interrupted
2025-08-09 05:04:31,592 [ExecutorRunner for app-20250809050053-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-09 05:04:31,594 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-09 05:04:31,615 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-09 05:04:31,618 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-09 05:04:31,618 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-09 05:04:31,621 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-09 05:04:31,624 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-09 05:04:31,624 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-09 05:04:31,625 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-09 05:04:31,679 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250809050053-0000/1 finished with state KILLED exitStatus 143
2025-08-09 05:04:31,680 [dispatcher-event-loop-3] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-09 05:04:31,681 [dispatcher-event-loop-3] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250809050053-0000, execId=1)
2025-08-09 11:09:55,680 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@01ed9f2d60b8
2025-08-09 11:09:55,712 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 11:09:55,715 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 11:09:55,716 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 11:09:56,279 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 11:09:56,283 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 11:09:56,288 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 11:09:56,291 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 11:09:56,296 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 11:09:56,720 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 11:09:57,810 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 46537.
2025-08-09 11:09:57,815 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-09 11:09:58,236 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.12:46537 with 12 cores, 6.6 GiB RAM
2025-08-09 11:09:58,250 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-09 11:09:58,252 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-09 11:09:58,296 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 11:09:58,298 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-09 11:09:58,300 [dispatcher-event-loop-1] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 11:09:58,380 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.util.log - Logging initialized @7677ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-09 11:09:58,446 [dispatcher-event-loop-1] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-09 11:09:58,481 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-09 11:09:58,582 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.Server - Started @7880ms
2025-08-09 11:09:58,752 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@6eac1128{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-09 11:09:58,755 [dispatcher-event-loop-1] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-09 11:09:58,832 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@560a5f39{/logPage,null,AVAILABLE,@Spark}
2025-08-09 11:09:58,838 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ffb1f26{/logPage/json,null,AVAILABLE,@Spark}
2025-08-09 11:09:58,842 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1beee8f{/,null,AVAILABLE,@Spark}
2025-08-09 11:09:58,846 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73aa71b8{/json,null,AVAILABLE,@Spark}
2025-08-09 11:09:58,864 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d16b5fb{/static,null,AVAILABLE,@Spark}
2025-08-09 11:09:58,867 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70d3d9aa{/log,null,AVAILABLE,@Spark}
2025-08-09 11:09:58,873 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://01ed9f2d60b8:8081
2025-08-09 11:09:58,878 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-09 11:09:58,939 [dispatcher-event-loop-1] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32a89fc2{/metrics/json,null,AVAILABLE,@Spark}
2025-08-09 11:09:59,032 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.6:7077 after 88 ms (0 ms spent in bootstraps)
2025-08-09 11:09:59,301 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-09 11:10:00,957 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250809111000-0000/0 for Thrift JDBC/ODBC Server
2025-08-09 11:10:01,007 [ExecutorRunner for app-20250809111000-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 11:10:01,008 [ExecutorRunner for app-20250809111000-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 11:10:01,009 [ExecutorRunner for app-20250809111000-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 11:10:01,011 [ExecutorRunner for app-20250809111000-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 11:10:01,015 [ExecutorRunner for app-20250809111000-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 11:10:01,059 [ExecutorRunner for app-20250809111000-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41181" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dcba52d7f0ba:41181" "--executor-id" "0" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250809111000-0000" "--worker-url" "spark://Worker@172.18.0.12:46537" "--resourceProfileId" "0"
2025-08-09 11:10:02,900 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 122@01ed9f2d60b8
2025-08-09 11:10:02,908 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 11:10:02,909 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 11:10:02,909 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 11:10:03,392 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 11:10:03,598 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 11:10:03,600 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 11:10:03,602 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 11:10:03,604 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 11:10:03,605 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 11:10:04,447 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to dcba52d7f0ba/172.18.0.11:41181 after 182 ms (0 ms spent in bootstraps)
2025-08-09 11:10:04,701 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 11:10:04,702 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 11:10:04,702 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 11:10:04,703 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 11:10:04,704 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 11:10:04,785 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to dcba52d7f0ba/172.18.0.11:41181 after 3 ms (0 ms spent in bootstraps)
2025-08-09 11:10:04,881 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-74e0fabb-6cb0-43ce-b456-89d6bf3b839d/executor-15d5ec15-16e1-4547-adc2-57617dfacac2/blockmgr-915ebc49-268b-4839-a70c-25060bce0eb2
2025-08-09 11:10:04,933 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-09 11:10:05,170 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@dcba52d7f0ba:41181
2025-08-09 11:10:05,171 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:46537
2025-08-09 11:10:05,181 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:46537 after 3 ms (0 ms spent in bootstraps)
2025-08-09 11:10:05,185 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:46537
2025-08-09 11:10:05,185 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 11:10:05,187 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-09 11:10:05,188 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 11:10:05,267 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-09 11:10:05,273 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.12
2025-08-09 11:10:05,349 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36485.
2025-08-09 11:10:05,350 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:36485
2025-08-09 11:10:05,353 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-09 11:10:05,365 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.12, 36485, None)
2025-08-09 11:10:05,419 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.12, 36485, None)
2025-08-09 11:10:05,422 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.12, 36485, None)
2025-08-09 11:10:05,433 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-09 11:11:07,733 [dispatcher-event-loop-4] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250809111000-0000/0
2025-08-09 11:11:07,735 [ExecutorRunner for app-20250809111000-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250809111000-0000/0 interrupted
2025-08-09 11:11:07,735 [ExecutorRunner for app-20250809111000-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-09 11:11:07,739 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-09 11:11:07,768 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-09 11:11:07,769 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-09 11:11:07,772 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-09 11:11:07,812 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250809111000-0000/0 finished with state KILLED exitStatus 143
2025-08-09 11:11:07,814 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-09 11:11:07,815 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250809111000-0000, execId=0)
2025-08-09 11:23:38,067 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250809111000-0000/1 for Thrift JDBC/ODBC Server
2025-08-09 11:23:38,082 [ExecutorRunner for app-20250809111000-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 11:23:38,082 [ExecutorRunner for app-20250809111000-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 11:23:38,083 [ExecutorRunner for app-20250809111000-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 11:23:38,083 [ExecutorRunner for app-20250809111000-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 11:23:38,086 [ExecutorRunner for app-20250809111000-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 11:23:38,130 [ExecutorRunner for app-20250809111000-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41181" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dcba52d7f0ba:41181" "--executor-id" "1" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250809111000-0000" "--worker-url" "spark://Worker@172.18.0.12:46537" "--resourceProfileId" "0"
2025-08-09 11:23:40,010 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 203@01ed9f2d60b8
2025-08-09 11:23:40,018 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 11:23:40,020 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 11:23:40,021 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 11:23:40,284 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 11:23:40,363 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 11:23:40,364 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 11:23:40,365 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 11:23:40,366 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 11:23:40,366 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 11:23:40,579 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to dcba52d7f0ba/172.18.0.11:41181 after 45 ms (0 ms spent in bootstraps)
2025-08-09 11:23:40,654 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 11:23:40,655 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 11:23:40,656 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 11:23:40,656 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 11:23:40,656 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 11:23:40,716 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to dcba52d7f0ba/172.18.0.11:41181 after 2 ms (0 ms spent in bootstraps)
2025-08-09 11:23:40,839 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-74e0fabb-6cb0-43ce-b456-89d6bf3b839d/executor-15d5ec15-16e1-4547-adc2-57617dfacac2/blockmgr-4bc36a32-d20b-4998-ab01-be6a64c9fead
2025-08-09 11:23:40,893 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-09 11:23:41,052 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@dcba52d7f0ba:41181
2025-08-09 11:23:41,053 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:46537
2025-08-09 11:23:41,056 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:46537 after 1 ms (0 ms spent in bootstraps)
2025-08-09 11:23:41,058 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:46537
2025-08-09 11:23:41,061 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 11:23:41,062 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-09 11:23:41,062 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 11:23:41,086 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-09 11:23:41,088 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.12
2025-08-09 11:23:41,119 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38051.
2025-08-09 11:23:41,120 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:38051
2025-08-09 11:23:41,122 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-09 11:23:41,128 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.12, 38051, None)
2025-08-09 11:23:41,138 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.12, 38051, None)
2025-08-09 11:23:41,139 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.12, 38051, None)
2025-08-09 11:23:41,145 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-09 11:23:41,200 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-09 11:23:41,205 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-09 11:23:41,209 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-08-09 11:23:41,209 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-09 11:23:41,277 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-09 11:23:41,318 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 11:23:41,354 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to dcba52d7f0ba/172.18.0.11:36469 after 2 ms (0 ms spent in bootstraps)
2025-08-09 11:23:41,404 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-09 11:23:41,418 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 99 ms
2025-08-09 11:23:41,464 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-09 11:23:41,619 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 11:23:41,627 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-09 11:23:41,632 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 12 ms
2025-08-09 11:23:41,676 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-09 11:23:42,229 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-09 11:23:42,243 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-09 11:23:42,244 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-09 11:23:43,041 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-09 11:23:43,041 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-09 11:23:43,479 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-09 11:23:43,479 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-09 11:23:44,386 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 1, attempt 0, stage 0.0)
2025-08-09 11:23:44,386 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
2025-08-09 11:23:44,420 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 4158 bytes result sent to driver
2025-08-09 11:23:44,420 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 4156 bytes result sent to driver
2025-08-09 11:24:47,003 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250809111000-0000/1
2025-08-09 11:24:47,005 [ExecutorRunner for app-20250809111000-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250809111000-0000/1 interrupted
2025-08-09 11:24:47,005 [ExecutorRunner for app-20250809111000-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-09 11:24:47,008 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-09 11:24:47,029 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-09 11:24:47,032 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-09 11:24:47,032 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-09 11:24:47,035 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-09 11:24:47,037 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-09 11:24:47,037 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-09 11:24:47,040 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-09 11:24:47,092 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250809111000-0000/1 finished with state KILLED exitStatus 143
2025-08-09 11:24:47,093 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-09 11:24:47,093 [dispatcher-event-loop-9] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250809111000-0000, execId=1)
2025-08-09 11:35:33,495 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250809111000-0000/2 for Thrift JDBC/ODBC Server
2025-08-09 11:35:33,522 [ExecutorRunner for app-20250809111000-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 11:35:33,522 [ExecutorRunner for app-20250809111000-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 11:35:33,523 [ExecutorRunner for app-20250809111000-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 11:35:33,523 [ExecutorRunner for app-20250809111000-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 11:35:33,523 [ExecutorRunner for app-20250809111000-0000/2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 11:35:33,589 [ExecutorRunner for app-20250809111000-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41181" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@dcba52d7f0ba:41181" "--executor-id" "2" "--hostname" "172.18.0.12" "--cores" "2" "--app-id" "app-20250809111000-0000" "--worker-url" "spark://Worker@172.18.0.12:46537" "--resourceProfileId" "0"
2025-08-09 11:35:35,395 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 298@01ed9f2d60b8
2025-08-09 11:35:35,409 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-09 11:35:35,412 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-09 11:35:35,413 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-09 11:35:35,870 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-09 11:35:36,023 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 11:35:36,024 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 11:35:36,025 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 11:35:36,026 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 11:35:36,028 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 11:35:36,348 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to dcba52d7f0ba/172.18.0.11:41181 after 69 ms (0 ms spent in bootstraps)
2025-08-09 11:35:36,477 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-09 11:35:36,478 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-09 11:35:36,479 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-09 11:35:36,480 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-09 11:35:36,480 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-09 11:35:36,560 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to dcba52d7f0ba/172.18.0.11:41181 after 3 ms (0 ms spent in bootstraps)
2025-08-09 11:35:36,669 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-74e0fabb-6cb0-43ce-b456-89d6bf3b839d/executor-15d5ec15-16e1-4547-adc2-57617dfacac2/blockmgr-439eac3f-aecc-40db-95fe-8ba398b8ab7e
2025-08-09 11:35:36,717 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-09 11:35:36,940 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@dcba52d7f0ba:41181
2025-08-09 11:35:36,941 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.12:46537
2025-08-09 11:35:36,945 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.12:46537 after 2 ms (0 ms spent in bootstraps)
2025-08-09 11:35:36,948 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.12:46537
2025-08-09 11:35:36,950 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 11:35:36,951 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-09 11:35:36,951 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-09 11:35:36,981 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-09 11:35:36,985 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 2 on host 172.18.0.12
2025-08-09 11:35:37,041 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41163.
2025-08-09 11:35:37,041 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.12:41163
2025-08-09 11:35:37,045 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-09 11:35:37,055 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(2, 172.18.0.12, 41163, None)
2025-08-09 11:35:37,067 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(2, 172.18.0.12, 41163, None)
2025-08-09 11:35:37,068 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(2, 172.18.0.12, 41163, None)
2025-08-09 11:35:37,077 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-09 11:35:37,123 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2
2025-08-09 11:35:37,139 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 2)
2025-08-09 11:35:37,197 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 2 and clearing cache
2025-08-09 11:35:37,258 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 2 with 1 pieces (estimated total size 4.0 MiB)
2025-08-09 11:35:37,306 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to dcba52d7f0ba/172.18.0.11:36469 after 2 ms (0 ms spent in bootstraps)
2025-08-09 11:35:37,350 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.6 KiB, free 434.4 MiB)
2025-08-09 11:35:37,361 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 2 took 102 ms
2025-08-09 11:35:37,419 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 7.0 KiB, free 434.4 MiB)
2025-08-09 11:35:38,184 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 369.294637 ms
2025-08-09 11:35:38,315 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 2). 1505 bytes result sent to driver
2025-08-09 11:36:40,714 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250809111000-0000/2
2025-08-09 11:36:40,716 [ExecutorRunner for app-20250809111000-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250809111000-0000/2 interrupted
2025-08-09 11:36:40,716 [ExecutorRunner for app-20250809111000-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-09 11:36:40,719 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-09 11:36:40,739 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-09 11:36:40,739 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-09 11:36:40,742 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-09 11:36:40,776 [dispatcher-event-loop-5] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250809111000-0000/2 finished with state KILLED exitStatus 143
2025-08-09 11:36:40,777 [dispatcher-event-loop-5] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-08-09 11:36:40,778 [dispatcher-event-loop-5] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250809111000-0000, execId=2)
2025-08-09 15:52:58,471 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Master with url spark://spark-master:7077 requested this worker to reconnect.
2025-08-09 15:52:58,503 [worker-register-master-threadpool-1] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-09 15:52:58,598 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-10 07:57:30,336 [main] INFO  org.apache.spark.deploy.worker.Worker - Started daemon with process name: 33@661307a8e8bd
2025-08-10 07:57:30,363 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-10 07:57:30,368 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-10 07:57:30,369 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-10 07:57:31,155 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 07:57:31,159 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 07:57:31,163 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 07:57:31,167 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 07:57:31,172 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 07:57:31,842 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-10 07:57:33,245 [main] INFO  org.apache.spark.util.Utils - Successfully started service 'sparkWorker' on port 44407.
2025-08-10 07:57:33,251 [main] INFO  org.apache.spark.deploy.worker.Worker - Worker decommissioning not enabled.
2025-08-10 07:57:34,146 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker 172.18.0.11:44407 with 12 cores, 6.6 GiB RAM
2025-08-10 07:57:34,173 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Running Spark version 3.4.1
2025-08-10 07:57:34,182 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /opt/bitnami/spark
2025-08-10 07:57:34,309 [dispatcher-event-loop-0] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 07:57:34,318 [dispatcher-event-loop-0] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.worker.
2025-08-10 07:57:34,323 [dispatcher-event-loop-0] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 07:57:34,584 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.util.log - Logging initialized @9569ms to org.sparkproject.jetty.util.log.Slf4jLog
2025-08-10 07:57:34,725 [dispatcher-event-loop-0] INFO  org.apache.spark.ui.JettyUtils - Start Jetty 0.0.0.0:8081 for WorkerUI
2025-08-10 07:57:34,763 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.server.Server - jetty-9.4.50.v20221201; built: 2022-12-01T22:07:03.915Z; git: da9a0b30691a45daf90a9f17b5defa2f1434f882; jvm 17.0.9+11-LTS
2025-08-10 07:57:34,864 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.server.Server - Started @9852ms
2025-08-10 07:57:35,020 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@6eac1128{HTTP/1.1, (http/1.1)}{0.0.0.0:8081}
2025-08-10 07:57:35,022 [dispatcher-event-loop-0] INFO  org.apache.spark.util.Utils - Successfully started service 'WorkerUI' on port 8081.
2025-08-10 07:57:35,082 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@560a5f39{/logPage,null,AVAILABLE,@Spark}
2025-08-10 07:57:35,100 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ffb1f26{/logPage/json,null,AVAILABLE,@Spark}
2025-08-10 07:57:35,111 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1beee8f{/,null,AVAILABLE,@Spark}
2025-08-10 07:57:35,117 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73aa71b8{/json,null,AVAILABLE,@Spark}
2025-08-10 07:57:35,154 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6d16b5fb{/static,null,AVAILABLE,@Spark}
2025-08-10 07:57:35,163 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@70d3d9aa{/log,null,AVAILABLE,@Spark}
2025-08-10 07:57:35,177 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Bound WorkerWebUI to 0.0.0.0, and started at http://661307a8e8bd:8081
2025-08-10 07:57:35,192 [worker-register-master-threadpool-0] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark-master:7077...
2025-08-10 07:57:35,253 [dispatcher-event-loop-0] INFO  org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@32a89fc2{/metrics/json,null,AVAILABLE,@Spark}
2025-08-10 07:57:35,561 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to spark-master/172.18.0.9:7077 after 230 ms (0 ms spent in bootstraps)
2025-08-10 07:57:36,186 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://spark-master:7077
2025-08-10 07:57:38,394 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250810075737-0000/0 for Thrift JDBC/ODBC Server
2025-08-10 07:57:38,467 [ExecutorRunner for app-20250810075737-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 07:57:38,468 [ExecutorRunner for app-20250810075737-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 07:57:38,469 [ExecutorRunner for app-20250810075737-0000/0] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 07:57:38,470 [ExecutorRunner for app-20250810075737-0000/0] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 07:57:38,471 [ExecutorRunner for app-20250810075737-0000/0] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 07:57:38,522 [ExecutorRunner for app-20250810075737-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41435" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3c3beacd57f0:41435" "--executor-id" "0" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250810075737-0000" "--worker-url" "spark://Worker@172.18.0.11:44407" "--resourceProfileId" "0"
2025-08-10 07:57:41,219 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 124@661307a8e8bd
2025-08-10 07:57:41,239 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-10 07:57:41,241 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-10 07:57:41,242 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-10 07:57:41,987 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-10 07:57:42,248 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 07:57:42,250 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 07:57:42,252 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 07:57:42,254 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 07:57:42,256 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 07:57:43,002 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 239 ms (0 ms spent in bootstraps)
2025-08-10 07:57:43,311 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 07:57:43,312 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 07:57:43,314 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 07:57:43,315 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 07:57:43,316 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 07:57:43,424 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 2 ms (0 ms spent in bootstraps)
2025-08-10 07:57:43,612 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-40702174-4f13-4067-a184-4956d5932ca1/executor-03c5b1f9-784d-4cb3-b3f5-31b8e233e3c5/blockmgr-cb5d5421-d46b-4deb-878a-2e4b07cc8188
2025-08-10 07:57:43,736 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-10 07:57:44,254 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3c3beacd57f0:41435
2025-08-10 07:57:44,257 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:44407
2025-08-10 07:57:44,265 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:44407 after 4 ms (0 ms spent in bootstraps)
2025-08-10 07:57:44,270 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:44407
2025-08-10 07:57:44,301 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 07:57:44,308 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-10 07:57:44,317 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 07:57:44,452 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-10 07:57:44,466 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 0 on host 172.18.0.11
2025-08-10 07:57:44,569 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35161.
2025-08-10 07:57:44,571 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:35161
2025-08-10 07:57:44,581 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-10 07:57:44,601 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(0, 172.18.0.11, 35161, None)
2025-08-10 07:57:44,673 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(0, 172.18.0.11, 35161, None)
2025-08-10 07:57:44,678 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(0, 172.18.0.11, 35161, None)
2025-08-10 07:57:44,713 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-10 07:58:44,650 [dispatcher-event-loop-7] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250810075737-0000/0
2025-08-10 07:58:44,651 [ExecutorRunner for app-20250810075737-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250810075737-0000/0 interrupted
2025-08-10 07:58:44,653 [ExecutorRunner for app-20250810075737-0000/0] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-10 07:58:44,659 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-10 07:58:44,692 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-10 07:58:44,693 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-10 07:58:44,696 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-10 07:58:44,745 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250810075737-0000/0 finished with state KILLED exitStatus 143
2025-08-10 07:58:44,749 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 0
2025-08-10 07:58:44,750 [dispatcher-event-loop-8] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250810075737-0000, execId=0)
2025-08-10 07:59:06,981 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250810075737-0000/1 for Thrift JDBC/ODBC Server
2025-08-10 07:59:06,984 [ExecutorRunner for app-20250810075737-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 07:59:06,985 [ExecutorRunner for app-20250810075737-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 07:59:06,985 [ExecutorRunner for app-20250810075737-0000/1] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 07:59:06,986 [ExecutorRunner for app-20250810075737-0000/1] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 07:59:06,986 [ExecutorRunner for app-20250810075737-0000/1] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 07:59:06,998 [ExecutorRunner for app-20250810075737-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41435" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3c3beacd57f0:41435" "--executor-id" "1" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250810075737-0000" "--worker-url" "spark://Worker@172.18.0.11:44407" "--resourceProfileId" "0"
2025-08-10 07:59:08,386 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 206@661307a8e8bd
2025-08-10 07:59:08,400 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-10 07:59:08,402 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-10 07:59:08,402 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-10 07:59:08,714 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-10 07:59:08,801 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 07:59:08,802 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 07:59:08,803 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 07:59:08,803 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 07:59:08,804 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 07:59:09,054 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 54 ms (0 ms spent in bootstraps)
2025-08-10 07:59:09,147 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 07:59:09,148 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 07:59:09,149 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 07:59:09,149 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 07:59:09,150 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 07:59:09,209 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 2 ms (0 ms spent in bootstraps)
2025-08-10 07:59:09,291 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-40702174-4f13-4067-a184-4956d5932ca1/executor-03c5b1f9-784d-4cb3-b3f5-31b8e233e3c5/blockmgr-4405924f-501a-4419-9a91-15701bef7fd7
2025-08-10 07:59:09,331 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-10 07:59:09,500 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3c3beacd57f0:41435
2025-08-10 07:59:09,501 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:44407
2025-08-10 07:59:09,504 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:44407 after 2 ms (0 ms spent in bootstraps)
2025-08-10 07:59:09,506 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:44407
2025-08-10 07:59:09,511 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 07:59:09,512 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-10 07:59:09,513 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 07:59:09,538 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-10 07:59:09,541 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 1 on host 172.18.0.11
2025-08-10 07:59:09,580 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43777.
2025-08-10 07:59:09,581 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:43777
2025-08-10 07:59:09,584 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-10 07:59:09,592 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(1, 172.18.0.11, 43777, None)
2025-08-10 07:59:09,603 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(1, 172.18.0.11, 43777, None)
2025-08-10 07:59:09,604 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(1, 172.18.0.11, 43777, None)
2025-08-10 07:59:09,610 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-10 07:59:09,671 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 0
2025-08-10 07:59:09,677 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1
2025-08-10 07:59:09,683 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
2025-08-10 07:59:09,683 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
2025-08-10 07:59:09,755 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-10 07:59:09,804 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 07:59:09,840 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:45089 after 2 ms (0 ms spent in bootstraps)
2025-08-10 07:59:09,890 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KiB, free 434.4 MiB)
2025-08-10 07:59:09,901 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1 took 97 ms
2025-08-10 07:59:09,957 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-10 07:59:10,154 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 0 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 07:59:10,163 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 29.5 KiB, free 434.4 MiB)
2025-08-10 07:59:10,168 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 0 took 13 ms
2025-08-10 07:59:10,214 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 07:59:10,794 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-10 07:59:10,807 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-10 07:59:10,807 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-10 07:59:11,646 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 07:59:11,646 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 07:59:12,015 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 07:59:12,015 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 07:59:12,844 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 1, attempt 0, stage 0.0)
2025-08-10 07:59:12,844 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
2025-08-10 07:59:12,903 [Executor task launch worker for task 1.0 in stage 0.0 (TID 1)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 4156 bytes result sent to driver
2025-08-10 07:59:12,903 [Executor task launch worker for task 0.0 in stage 0.0 (TID 0)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 4158 bytes result sent to driver
2025-08-10 08:00:12,049 [block-manager-storage-async-thread-pool-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:00:13,092 [dispatcher-event-loop-8] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250810075737-0000/1
2025-08-10 08:00:13,094 [ExecutorRunner for app-20250810075737-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250810075737-0000/1 interrupted
2025-08-10 08:00:13,094 [ExecutorRunner for app-20250810075737-0000/1] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-10 08:00:13,098 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-10 08:00:13,127 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-10 08:00:13,128 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-10 08:00:13,131 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-10 08:00:13,135 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-10 08:00:13,135 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-10 08:00:13,136 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-10 08:00:13,192 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250810075737-0000/1 finished with state KILLED exitStatus 143
2025-08-10 08:00:13,192 [dispatcher-event-loop-11] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 1
2025-08-10 08:00:13,193 [dispatcher-event-loop-11] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250810075737-0000, execId=1)
2025-08-10 08:00:14,518 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250810075737-0000/2 for Thrift JDBC/ODBC Server
2025-08-10 08:00:14,521 [ExecutorRunner for app-20250810075737-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:00:14,522 [ExecutorRunner for app-20250810075737-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:00:14,522 [ExecutorRunner for app-20250810075737-0000/2] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:00:14,522 [ExecutorRunner for app-20250810075737-0000/2] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:00:14,523 [ExecutorRunner for app-20250810075737-0000/2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:00:14,535 [ExecutorRunner for app-20250810075737-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41435" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3c3beacd57f0:41435" "--executor-id" "2" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250810075737-0000" "--worker-url" "spark://Worker@172.18.0.11:44407" "--resourceProfileId" "0"
2025-08-10 08:00:16,057 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 304@661307a8e8bd
2025-08-10 08:00:16,066 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-10 08:00:16,067 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-10 08:00:16,068 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-10 08:00:16,428 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-10 08:00:16,572 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:00:16,573 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:00:16,574 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:00:16,574 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:00:16,575 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:00:16,863 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 61 ms (0 ms spent in bootstraps)
2025-08-10 08:00:16,957 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:00:16,957 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:00:16,958 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:00:16,958 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:00:16,958 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:00:17,027 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 2 ms (0 ms spent in bootstraps)
2025-08-10 08:00:17,120 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-40702174-4f13-4067-a184-4956d5932ca1/executor-03c5b1f9-784d-4cb3-b3f5-31b8e233e3c5/blockmgr-14faa291-411b-43ec-9ebd-a69aabaab520
2025-08-10 08:00:17,151 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-10 08:00:17,305 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3c3beacd57f0:41435
2025-08-10 08:00:17,307 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:44407
2025-08-10 08:00:17,312 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:44407 after 2 ms (0 ms spent in bootstraps)
2025-08-10 08:00:17,314 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:44407
2025-08-10 08:00:17,318 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 08:00:17,319 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-10 08:00:17,320 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 08:00:17,346 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-10 08:00:17,350 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 2 on host 172.18.0.11
2025-08-10 08:00:17,394 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38695.
2025-08-10 08:00:17,394 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:38695
2025-08-10 08:00:17,398 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-10 08:00:17,405 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(2, 172.18.0.11, 38695, None)
2025-08-10 08:00:17,415 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(2, 172.18.0.11, 38695, None)
2025-08-10 08:00:17,417 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(2, 172.18.0.11, 38695, None)
2025-08-10 08:00:17,426 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-10 08:00:17,479 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2
2025-08-10 08:00:17,488 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 1.0 (TID 2)
2025-08-10 08:00:17,961 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2025-08-10 08:00:18,008 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 5 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:00:18,065 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:45089 after 4 ms (0 ms spent in bootstraps)
2025-08-10 08:00:18,107 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5_piece0 stored as bytes in memory (estimated size 18.0 KiB, free 434.4 MiB)
2025-08-10 08:00:18,121 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 5 took 112 ms
2025-08-10 08:00:18,194 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_5 stored as values in memory (estimated size 42.0 KiB, free 434.3 MiB)
2025-08-10 08:00:18,911 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 252.719818 ms
2025-08-10 08:00:19,015 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.663658 ms
2025-08-10 08:00:19,070 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 18.053335 ms
2025-08-10 08:00:19,132 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.011999 ms
2025-08-10 08:00:19,142 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.755752 ms
2025-08-10 08:00:19,151 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 3 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:00:19,161 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.2 MiB)
2025-08-10 08:00:19,166 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 3 took 14 ms
2025-08-10 08:00:19,217 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_3 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:00:19,501 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-10 08:00:19,519 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-10 08:00:19,519 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-10 08:00:20,338 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:00:20,761 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-10 08:00:20,762 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-10 08:00:20,774 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-10 08:00:20,780 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-10 08:00:20,782 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-10 08:00:21,000 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:00:21,553 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:00:21,564 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:00:21,609 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.819123 ms
2025-08-10 08:00:21,637 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.143866 ms
2025-08-10 08:00:21,647 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.60638 ms
2025-08-10 08:00:21,668 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.38255 ms
2025-08-10 08:00:21,680 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.872049 ms
2025-08-10 08:00:21,691 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.212172 ms
2025-08-10 08:00:21,695 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 4 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:00:21,705 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 426.1 MiB)
2025-08-10 08:00:21,711 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 4 took 15 ms
2025-08-10 08:00:21,715 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_4 stored as values in memory (estimated size 32.0 KiB, free 426.1 MiB)
2025-08-10 08:00:21,813 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:00:21,948 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:00:22,222 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 2, attempt 0, stage 1.0)
2025-08-10 08:00:22,246 [Executor task launch worker for task 0.0 in stage 1.0 (TID 2)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 1.0 (TID 2). 8058 bytes result sent to driver
2025-08-10 08:01:22,371 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250810075737-0000/2
2025-08-10 08:01:22,372 [ExecutorRunner for app-20250810075737-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250810075737-0000/2 interrupted
2025-08-10 08:01:22,372 [ExecutorRunner for app-20250810075737-0000/2] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-10 08:01:22,374 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-10 08:01:22,393 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:01:22,395 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:01:22,395 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-10 08:01:22,395 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-10 08:01:22,398 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-10 08:01:22,401 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-10 08:01:22,401 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-10 08:01:22,402 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-10 08:01:22,440 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250810075737-0000/2 finished with state KILLED exitStatus 143
2025-08-10 08:01:22,442 [dispatcher-event-loop-3] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 2
2025-08-10 08:01:22,443 [dispatcher-event-loop-3] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250810075737-0000, execId=2)
2025-08-10 08:06:52,972 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250810075737-0000/3 for Thrift JDBC/ODBC Server
2025-08-10 08:06:52,976 [ExecutorRunner for app-20250810075737-0000/3] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:06:52,976 [ExecutorRunner for app-20250810075737-0000/3] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:06:52,977 [ExecutorRunner for app-20250810075737-0000/3] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:06:52,977 [ExecutorRunner for app-20250810075737-0000/3] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:06:52,978 [ExecutorRunner for app-20250810075737-0000/3] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:06:52,994 [ExecutorRunner for app-20250810075737-0000/3] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41435" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3c3beacd57f0:41435" "--executor-id" "3" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250810075737-0000" "--worker-url" "spark://Worker@172.18.0.11:44407" "--resourceProfileId" "0"
2025-08-10 08:06:54,489 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 398@661307a8e8bd
2025-08-10 08:06:54,495 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-10 08:06:54,497 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-10 08:06:54,497 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-10 08:06:54,811 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-10 08:06:54,895 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:06:54,896 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:06:54,897 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:06:54,897 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:06:54,898 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:06:55,148 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 64 ms (0 ms spent in bootstraps)
2025-08-10 08:06:55,236 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:06:55,237 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:06:55,237 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:06:55,237 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:06:55,238 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:06:55,290 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 1 ms (0 ms spent in bootstraps)
2025-08-10 08:06:55,352 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-40702174-4f13-4067-a184-4956d5932ca1/executor-03c5b1f9-784d-4cb3-b3f5-31b8e233e3c5/blockmgr-c809f0ff-46e1-417f-a538-786eb76fafd6
2025-08-10 08:06:55,380 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-10 08:06:55,579 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3c3beacd57f0:41435
2025-08-10 08:06:55,580 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:44407
2025-08-10 08:06:55,584 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:44407 after 2 ms (0 ms spent in bootstraps)
2025-08-10 08:06:55,586 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:44407
2025-08-10 08:06:55,593 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 08:06:55,596 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-10 08:06:55,597 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 08:06:55,637 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-10 08:06:55,641 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 3 on host 172.18.0.11
2025-08-10 08:06:55,689 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41373.
2025-08-10 08:06:55,690 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:41373
2025-08-10 08:06:55,693 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-10 08:06:55,700 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(3, 172.18.0.11, 41373, None)
2025-08-10 08:06:55,712 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(3, 172.18.0.11, 41373, None)
2025-08-10 08:06:55,714 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(3, 172.18.0.11, 41373, None)
2025-08-10 08:06:55,721 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-10 08:06:55,769 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3
2025-08-10 08:06:55,776 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4
2025-08-10 08:06:55,782 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 2.0 (TID 4)
2025-08-10 08:06:55,782 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 2.0 (TID 3)
2025-08-10 08:06:55,863 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 3 and clearing cache
2025-08-10 08:06:55,913 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 7 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:06:55,951 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:45089 after 2 ms (0 ms spent in bootstraps)
2025-08-10 08:06:55,978 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-10 08:06:55,987 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 7 took 73 ms
2025-08-10 08:06:56,040 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_7 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-10 08:06:56,226 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 6 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:06:56,236 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-10 08:06:56,241 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 6 took 14 ms
2025-08-10 08:06:56,283 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_6 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:06:56,809 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-10 08:06:56,825 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-10 08:06:56,825 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-10 08:06:57,569 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:06:57,569 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:06:57,905 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:06:57,905 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:06:58,605 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 3, attempt 0, stage 2.0)
2025-08-10 08:06:58,605 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 4, attempt 0, stage 2.0)
2025-08-10 08:06:58,632 [Executor task launch worker for task 0.0 in stage 2.0 (TID 3)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 2.0 (TID 3). 4158 bytes result sent to driver
2025-08-10 08:06:58,632 [Executor task launch worker for task 1.0 in stage 2.0 (TID 4)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 2.0 (TID 4). 4156 bytes result sent to driver
2025-08-10 08:07:16,978 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:07:18,114 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5
2025-08-10 08:07:18,116 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 5)
2025-08-10 08:07:18,117 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6
2025-08-10 08:07:18,118 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 6)
2025-08-10 08:07:18,168 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 18 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:18,168 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 19 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:18,185 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.4 MiB)
2025-08-10 08:07:18,185 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.1 KiB, free 434.4 MiB)
2025-08-10 08:07:18,191 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 18 took 22 ms
2025-08-10 08:07:18,192 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 19 took 23 ms
2025-08-10 08:07:18,193 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_18 stored as values in memory (estimated size 16.4 KiB, free 434.4 MiB)
2025-08-10 08:07:18,193 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_19 stored as values in memory (estimated size 17.5 KiB, free 434.4 MiB)
2025-08-10 08:07:18,553 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 188.580923 ms
2025-08-10 08:07:18,553 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 188.593379 ms
2025-08-10 08:07:18,563 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 15 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:18,563 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 13 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:18,572 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_15_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:07:18,571 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_13_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:07:18,577 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 13 took 13 ms
2025-08-10 08:07:18,578 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 15 took 13 ms
2025-08-10 08:07:18,587 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_13 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:07:18,587 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_15 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:07:18,726 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:07:18,726 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:07:18,773 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:07:18,773 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:07:18,781 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-10 08:07:18,782 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-10 08:07:18,790 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-10 08:07:18,794 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-10 08:07:18,795 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-10 08:07:19,132 [Executor task launch worker for task 0.0 in stage 3.0 (TID 5)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 5). 5896 bytes result sent to driver
2025-08-10 08:07:19,133 [Executor task launch worker for task 0.0 in stage 4.0 (TID 6)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 6). 6025 bytes result sent to driver
2025-08-10 08:07:19,402 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7
2025-08-10 08:07:19,403 [Executor task launch worker for task 0.0 in stage 5.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 7)
2025-08-10 08:07:19,408 [Executor task launch worker for task 0.0 in stage 5.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 24 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:19,416 [Executor task launch worker for task 0.0 in stage 5.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.3 MiB)
2025-08-10 08:07:19,420 [Executor task launch worker for task 0.0 in stage 5.0 (TID 7)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 24 took 11 ms
2025-08-10 08:07:19,422 [Executor task launch worker for task 0.0 in stage 5.0 (TID 7)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_24 stored as values in memory (estimated size 11.7 KiB, free 434.3 MiB)
2025-08-10 08:07:19,494 [Executor task launch worker for task 0.0 in stage 5.0 (TID 7)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.534902 ms
2025-08-10 08:07:19,531 [Executor task launch worker for task 0.0 in stage 5.0 (TID 7)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 7). 1922 bytes result sent to driver
2025-08-10 08:07:19,601 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8
2025-08-10 08:07:19,603 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 7.0 (TID 8)
2025-08-10 08:07:19,606 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 4 and clearing cache
2025-08-10 08:07:19,609 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 25 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:19,616 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_25_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.3 MiB)
2025-08-10 08:07:19,620 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 25 took 10 ms
2025-08-10 08:07:19,621 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_25 stored as values in memory (estimated size 12.7 KiB, free 434.2 MiB)
2025-08-10 08:07:19,630 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 0, fetching them
2025-08-10 08:07:19,632 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:07:19,656 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:07:19,685 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:07:19,688 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 14 ms
2025-08-10 08:07:19,703 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.049594 ms
2025-08-10 08:07:19,716 [Executor task launch worker for task 0.0 in stage 7.0 (TID 8)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 7.0 (TID 8). 4002 bytes result sent to driver
2025-08-10 08:07:19,845 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9
2025-08-10 08:07:19,846 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10
2025-08-10 08:07:19,846 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 8.0 (TID 9)
2025-08-10 08:07:19,847 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 8.0 (TID 10)
2025-08-10 08:07:19,852 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 27 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:19,858 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_27_piece0 stored as bytes in memory (estimated size 27.8 KiB, free 434.2 MiB)
2025-08-10 08:07:19,867 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 27 took 14 ms
2025-08-10 08:07:19,869 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_27 stored as values in memory (estimated size 74.6 KiB, free 434.1 MiB)
2025-08-10 08:07:20,040 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 26.066958 ms
2025-08-10 08:07:20,041 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 27.053576 ms
2025-08-10 08:07:20,042 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 21 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:20,050 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_21_piece0 stored as bytes in memory (estimated size 1725.0 B, free 434.1 MiB)
2025-08-10 08:07:20,055 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 21 took 12 ms
2025-08-10 08:07:20,073 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_21 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-10 08:07:20,075 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 20 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:20,084 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_20_piece0 stored as bytes in memory (estimated size 1824.0 B, free 426.1 MiB)
2025-08-10 08:07:20,092 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 20 took 16 ms
2025-08-10 08:07:20,102 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_20 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:07:20,104 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 26 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:20,113 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_26_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 418.1 MiB)
2025-08-10 08:07:20,122 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 26 took 17 ms
2025-08-10 08:07:20,126 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_26 stored as values in memory (estimated size 32.0 KiB, free 418.1 MiB)
2025-08-10 08:07:20,127 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 18.453822 ms
2025-08-10 08:07:20,135 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:07:20,162 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 14 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:20,173 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_14_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.0 MiB)
2025-08-10 08:07:20,179 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 14 took 16 ms
2025-08-10 08:07:20,182 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_14 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:07:20,191 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.941208 ms
2025-08-10 08:07:20,198 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:07:20,208 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:07:20,226 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.458511 ms
2025-08-10 08:07:20,227 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:07:20,237 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.424282 ms
2025-08-10 08:07:20,237 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:07:20,239 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 16 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:07:20,242 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:07:20,246 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_16_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 417.9 MiB)
2025-08-10 08:07:20,251 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 16 took 11 ms
2025-08-10 08:07:20,253 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_16 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 08:07:20,258 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 9, attempt 0, stage 8.0)
2025-08-10 08:07:20,267 [Executor task launch worker for task 0.0 in stage 8.0 (TID 9)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 8.0 (TID 9). 10496 bytes result sent to driver
2025-08-10 08:07:20,273 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:07:20,284 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:07:20,301 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:07:20,309 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:07:20,342 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.565349 ms
2025-08-10 08:07:20,362 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.856346 ms
2025-08-10 08:07:20,371 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.475407 ms
2025-08-10 08:07:20,381 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.105628 ms
2025-08-10 08:07:20,384 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:07:20,385 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:07:20,393 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 10, attempt 0, stage 8.0)
2025-08-10 08:07:20,396 [Executor task launch worker for task 1.0 in stage 8.0 (TID 10)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 8.0 (TID 10). 10453 bytes result sent to driver
2025-08-10 08:08:25,682 [block-manager-storage-async-thread-pool-24] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:08:26,290 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 11
2025-08-10 08:08:26,291 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 12
2025-08-10 08:08:26,291 [Executor task launch worker for task 0.0 in stage 9.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 9.0 (TID 11)
2025-08-10 08:08:26,293 [Executor task launch worker for task 1.0 in stage 9.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 9.0 (TID 12)
2025-08-10 08:08:26,296 [Executor task launch worker for task 1.0 in stage 9.0 (TID 12)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 29 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:26,327 [Executor task launch worker for task 1.0 in stage 9.0 (TID 12)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_29_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 418.2 MiB)
2025-08-10 08:08:26,335 [Executor task launch worker for task 1.0 in stage 9.0 (TID 12)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 29 took 37 ms
2025-08-10 08:08:26,337 [Executor task launch worker for task 1.0 in stage 9.0 (TID 12)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_29 stored as values in memory (estimated size 8.0 KiB, free 426.1 MiB)
2025-08-10 08:08:26,342 [Executor task launch worker for task 0.0 in stage 9.0 (TID 11)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 28 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:26,349 [Executor task launch worker for task 0.0 in stage 9.0 (TID 11)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_28_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.1 MiB)
2025-08-10 08:08:26,356 [Executor task launch worker for task 0.0 in stage 9.0 (TID 11)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 28 took 12 ms
2025-08-10 08:08:26,359 [Executor task launch worker for task 0.0 in stage 9.0 (TID 11)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_28 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:08:26,364 [Executor task launch worker for task 1.0 in stage 9.0 (TID 12)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:08:26,365 [Executor task launch worker for task 0.0 in stage 9.0 (TID 11)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:08:26,367 [Executor task launch worker for task 0.0 in stage 9.0 (TID 11)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:08:26,367 [Executor task launch worker for task 1.0 in stage 9.0 (TID 12)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:08:26,377 [block-manager-storage-async-thread-pool-45] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:08:26,384 [block-manager-storage-async-thread-pool-48] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:08:26,409 [Executor task launch worker for task 1.0 in stage 9.0 (TID 12)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 12, attempt 0, stage 9.0)
2025-08-10 08:08:26,413 [Executor task launch worker for task 1.0 in stage 9.0 (TID 12)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 9.0 (TID 12). 4071 bytes result sent to driver
2025-08-10 08:08:26,415 [block-manager-storage-async-thread-pool-57] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:08:26,420 [Executor task launch worker for task 0.0 in stage 9.0 (TID 11)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 11, attempt 0, stage 9.0)
2025-08-10 08:08:26,423 [Executor task launch worker for task 0.0 in stage 9.0 (TID 11)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 9.0 (TID 11). 4072 bytes result sent to driver
2025-08-10 08:08:26,439 [block-manager-storage-async-thread-pool-66] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:08:34,490 [block-manager-storage-async-thread-pool-69] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:08:34,834 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 13
2025-08-10 08:08:34,835 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 10.0 (TID 13)
2025-08-10 08:08:34,839 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 40 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:34,843 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 14
2025-08-10 08:08:34,845 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 11.0 (TID 14)
2025-08-10 08:08:34,846 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_40_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
2025-08-10 08:08:34,848 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 41 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:34,851 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 40 took 11 ms
2025-08-10 08:08:34,853 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_40 stored as values in memory (estimated size 17.5 KiB, free 434.4 MiB)
2025-08-10 08:08:34,854 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_41_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.4 MiB)
2025-08-10 08:08:34,858 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 41 took 9 ms
2025-08-10 08:08:34,859 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 35 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:34,860 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_41 stored as values in memory (estimated size 16.4 KiB, free 434.4 MiB)
2025-08-10 08:08:34,864 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 37 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:34,866 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_35_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:08:34,870 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 35 took 10 ms
2025-08-10 08:08:34,871 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_37_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:08:34,872 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_35 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:08:34,875 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 37 took 10 ms
2025-08-10 08:08:34,877 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_37 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:08:34,889 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:08:34,892 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:08:34,899 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:08:34,903 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:08:34,920 [Executor task launch worker for task 0.0 in stage 10.0 (TID 13)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 10.0 (TID 13). 6025 bytes result sent to driver
2025-08-10 08:08:34,921 [Executor task launch worker for task 0.0 in stage 11.0 (TID 14)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 11.0 (TID 14). 5853 bytes result sent to driver
2025-08-10 08:08:35,030 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 15
2025-08-10 08:08:35,031 [Executor task launch worker for task 0.0 in stage 12.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 12.0 (TID 15)
2025-08-10 08:08:35,034 [Executor task launch worker for task 0.0 in stage 12.0 (TID 15)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 48 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:35,041 [Executor task launch worker for task 0.0 in stage 12.0 (TID 15)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_48_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.2 MiB)
2025-08-10 08:08:35,045 [Executor task launch worker for task 0.0 in stage 12.0 (TID 15)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 48 took 10 ms
2025-08-10 08:08:35,047 [Executor task launch worker for task 0.0 in stage 12.0 (TID 15)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_48 stored as values in memory (estimated size 11.7 KiB, free 434.2 MiB)
2025-08-10 08:08:35,057 [Executor task launch worker for task 0.0 in stage 12.0 (TID 15)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 12.0 (TID 15). 1836 bytes result sent to driver
2025-08-10 08:08:35,101 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 16
2025-08-10 08:08:35,102 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 14.0 (TID 16)
2025-08-10 08:08:35,104 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 5 and clearing cache
2025-08-10 08:08:35,107 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 49 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:35,116 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_49_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.3 MiB)
2025-08-10 08:08:35,120 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 49 took 12 ms
2025-08-10 08:08:35,122 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_49 stored as values in memory (estimated size 12.7 KiB, free 434.2 MiB)
2025-08-10 08:08:35,124 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 1, fetching them
2025-08-10 08:08:35,125 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:08:35,130 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:08:35,132 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:08:35,132 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:08:35,137 [Executor task launch worker for task 0.0 in stage 14.0 (TID 16)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 14.0 (TID 16). 3959 bytes result sent to driver
2025-08-10 08:08:35,223 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 17
2025-08-10 08:08:35,224 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 18
2025-08-10 08:08:35,225 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 15.0 (TID 17)
2025-08-10 08:08:35,226 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 15.0 (TID 18)
2025-08-10 08:08:35,229 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 51 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:35,242 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_51_piece0 stored as bytes in memory (estimated size 27.8 KiB, free 434.3 MiB)
2025-08-10 08:08:35,246 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 51 took 16 ms
2025-08-10 08:08:35,248 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_51 stored as values in memory (estimated size 74.6 KiB, free 434.2 MiB)
2025-08-10 08:08:35,260 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 43 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:35,271 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_43_piece0 stored as bytes in memory (estimated size 1725.0 B, free 434.1 MiB)
2025-08-10 08:08:35,277 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 43 took 16 ms
2025-08-10 08:08:35,284 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_43 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-10 08:08:35,286 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 42 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:35,295 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_42_piece0 stored as bytes in memory (estimated size 1824.0 B, free 426.1 MiB)
2025-08-10 08:08:35,295 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 38 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:35,300 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 42 took 13 ms
2025-08-10 08:08:35,306 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_38_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 426.1 MiB)
2025-08-10 08:08:35,307 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_42 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:08:35,308 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 50 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:35,311 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 38 took 15 ms
2025-08-10 08:08:35,314 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_38 stored as values in memory (estimated size 32.0 KiB, free 418.1 MiB)
2025-08-10 08:08:35,317 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_50_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 418.0 MiB)
2025-08-10 08:08:35,322 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 50 took 12 ms
2025-08-10 08:08:35,325 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_50 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:08:35,329 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:08:35,336 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:08:35,337 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 36 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:08:35,346 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_36_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.0 MiB)
2025-08-10 08:08:35,348 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:08:35,352 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 36 took 13 ms
2025-08-10 08:08:35,354 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_36 stored as values in memory (estimated size 32.0 KiB, free 409.9 MiB)
2025-08-10 08:08:35,370 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:08:35,370 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:08:35,379 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:08:35,379 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:08:35,400 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:08:35,407 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:08:35,410 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:08:35,412 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:08:35,414 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:08:35,452 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 18, attempt 0, stage 15.0)
2025-08-10 08:08:35,452 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 17, attempt 0, stage 15.0)
2025-08-10 08:08:35,456 [Executor task launch worker for task 1.0 in stage 15.0 (TID 18)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 15.0 (TID 18). 13382 bytes result sent to driver
2025-08-10 08:08:35,456 [Executor task launch worker for task 0.0 in stage 15.0 (TID 17)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 15.0 (TID 17). 13409 bytes result sent to driver
2025-08-10 08:10:22,533 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 19
2025-08-10 08:10:22,535 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 20
2025-08-10 08:10:22,535 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 16.0 (TID 19)
2025-08-10 08:10:22,536 [Executor task launch worker for task 1.0 in stage 16.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 16.0 (TID 20)
2025-08-10 08:10:22,539 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 53 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:22,544 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_53_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 418.0 MiB)
2025-08-10 08:10:22,547 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 53 took 7 ms
2025-08-10 08:10:22,548 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_53 stored as values in memory (estimated size 8.0 KiB, free 418.0 MiB)
2025-08-10 08:10:22,552 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 52 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:22,556 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_52_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 418.0 MiB)
2025-08-10 08:10:22,558 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 52 took 6 ms
2025-08-10 08:10:22,560 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_52 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 08:10:22,564 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:10:22,564 [Executor task launch worker for task 1.0 in stage 16.0 (TID 20)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:10:22,571 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:10:22,571 [Executor task launch worker for task 1.0 in stage 16.0 (TID 20)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:10:22,603 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 19, attempt 0, stage 16.0)
2025-08-10 08:10:22,610 [Executor task launch worker for task 0.0 in stage 16.0 (TID 19)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 16.0 (TID 19). 4158 bytes result sent to driver
2025-08-10 08:10:22,611 [Executor task launch worker for task 1.0 in stage 16.0 (TID 20)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 20, attempt 0, stage 16.0)
2025-08-10 08:10:22,612 [Executor task launch worker for task 1.0 in stage 16.0 (TID 20)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 16.0 (TID 20). 4114 bytes result sent to driver
2025-08-10 08:10:29,328 [block-manager-storage-async-thread-pool-102] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:10:29,351 [block-manager-storage-async-thread-pool-108] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:10:29,823 [block-manager-storage-async-thread-pool-111] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:10:29,830 [block-manager-storage-async-thread-pool-114] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:10:29,859 [block-manager-storage-async-thread-pool-123] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:10:29,875 [block-manager-storage-async-thread-pool-130] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:10:29,955 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 21
2025-08-10 08:10:29,956 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 17.0 (TID 21)
2025-08-10 08:10:29,960 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 64 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:29,962 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 22
2025-08-10 08:10:29,963 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 18.0 (TID 22)
2025-08-10 08:10:29,967 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 65 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:29,968 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_64_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.4 MiB)
2025-08-10 08:10:29,972 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 64 took 11 ms
2025-08-10 08:10:29,972 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_65_piece0 stored as bytes in memory (estimated size 6.2 KiB, free 434.4 MiB)
2025-08-10 08:10:29,974 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_64 stored as values in memory (estimated size 16.4 KiB, free 434.4 MiB)
2025-08-10 08:10:29,976 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 65 took 9 ms
2025-08-10 08:10:29,978 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 61 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:29,978 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_65 stored as values in memory (estimated size 17.5 KiB, free 434.4 MiB)
2025-08-10 08:10:29,980 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 59 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:29,985 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_61_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:10:29,989 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_59_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:10:29,989 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 61 took 11 ms
2025-08-10 08:10:29,992 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_61 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:10:29,992 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 59 took 10 ms
2025-08-10 08:10:29,995 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_59 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:10:30,008 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:10:30,008 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:10:30,017 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:10:30,017 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:10:30,038 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:10:30,038 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:10:30,046 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:10:30,046 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:10:30,060 [Executor task launch worker for task 0.0 in stage 18.0 (TID 22)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 18.0 (TID 22). 6023 bytes result sent to driver
2025-08-10 08:10:30,060 [Executor task launch worker for task 0.0 in stage 17.0 (TID 21)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 17.0 (TID 21). 5885 bytes result sent to driver
2025-08-10 08:10:30,145 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 23
2025-08-10 08:10:30,146 [Executor task launch worker for task 0.0 in stage 19.0 (TID 23)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 19.0 (TID 23)
2025-08-10 08:10:30,150 [Executor task launch worker for task 0.0 in stage 19.0 (TID 23)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 72 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:30,157 [Executor task launch worker for task 0.0 in stage 19.0 (TID 23)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_72_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.3 MiB)
2025-08-10 08:10:30,162 [Executor task launch worker for task 0.0 in stage 19.0 (TID 23)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 72 took 11 ms
2025-08-10 08:10:30,164 [Executor task launch worker for task 0.0 in stage 19.0 (TID 23)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_72 stored as values in memory (estimated size 11.7 KiB, free 434.3 MiB)
2025-08-10 08:10:30,171 [Executor task launch worker for task 0.0 in stage 19.0 (TID 23)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 19.0 (TID 23). 1836 bytes result sent to driver
2025-08-10 08:10:30,200 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 24
2025-08-10 08:10:30,201 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 21.0 (TID 24)
2025-08-10 08:10:30,202 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 6 and clearing cache
2025-08-10 08:10:30,209 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 73 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:30,213 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_73_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.3 MiB)
2025-08-10 08:10:30,216 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 73 took 7 ms
2025-08-10 08:10:30,217 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_73 stored as values in memory (estimated size 12.7 KiB, free 434.3 MiB)
2025-08-10 08:10:30,219 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 2, fetching them
2025-08-10 08:10:30,220 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:10:30,227 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:10:30,229 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:10:30,230 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:10:30,233 [Executor task launch worker for task 0.0 in stage 21.0 (TID 24)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 21.0 (TID 24). 3959 bytes result sent to driver
2025-08-10 08:10:30,321 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 25
2025-08-10 08:10:30,322 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 26
2025-08-10 08:10:30,322 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 22.0 (TID 25)
2025-08-10 08:10:30,322 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 22.0 (TID 26)
2025-08-10 08:10:30,325 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 75 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:30,329 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_75_piece0 stored as bytes in memory (estimated size 28.1 KiB, free 434.2 MiB)
2025-08-10 08:10:30,333 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 75 took 7 ms
2025-08-10 08:10:30,334 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_75 stored as values in memory (estimated size 75.3 KiB, free 434.2 MiB)
2025-08-10 08:10:30,362 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 22.390847 ms
2025-08-10 08:10:30,362 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 22.390691 ms
2025-08-10 08:10:30,365 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 67 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:30,371 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_67_piece0 stored as bytes in memory (estimated size 1770.0 B, free 434.1 MiB)
2025-08-10 08:10:30,374 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 67 took 8 ms
2025-08-10 08:10:30,377 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_67 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-10 08:10:30,378 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 66 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:30,382 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 62 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:30,383 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_66_piece0 stored as bytes in memory (estimated size 1884.0 B, free 426.1 MiB)
2025-08-10 08:10:30,385 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 66 took 6 ms
2025-08-10 08:10:30,387 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_62_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 426.1 MiB)
2025-08-10 08:10:30,389 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 62 took 6 ms
2025-08-10 08:10:30,390 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_66 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:10:30,391 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_62 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:10:30,392 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 74 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:30,396 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_74_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 418.0 MiB)
2025-08-10 08:10:30,401 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 74 took 8 ms
2025-08-10 08:10:30,403 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_74 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:10:30,405 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:10:30,406 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:10:30,408 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 60 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:10:30,413 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:10:30,415 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_60_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 417.9 MiB)
2025-08-10 08:10:30,418 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 60 took 9 ms
2025-08-10 08:10:30,426 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_60 stored as values in memory (estimated size 32.0 KiB, free 409.9 MiB)
2025-08-10 08:10:30,436 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:10:30,436 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:10:30,443 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:10:30,443 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:10:30,456 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:10:30,462 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.573684 ms
2025-08-10 08:10:30,463 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:10:30,464 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:10:30,466 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:10:30,466 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:10:30,492 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 26, attempt 0, stage 22.0)
2025-08-10 08:10:30,493 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 25, attempt 0, stage 22.0)
2025-08-10 08:10:30,494 [Executor task launch worker for task 1.0 in stage 22.0 (TID 26)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 22.0 (TID 26). 13391 bytes result sent to driver
2025-08-10 08:10:30,498 [Executor task launch worker for task 0.0 in stage 22.0 (TID 25)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 22.0 (TID 25). 13418 bytes result sent to driver
2025-08-10 08:14:52,747 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 27
2025-08-10 08:14:52,749 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 23.0 (TID 27)
2025-08-10 08:14:52,754 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 79 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:14:52,761 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_79_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 418.0 MiB)
2025-08-10 08:14:52,770 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 79 took 15 ms
2025-08-10 08:14:52,772 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_79 stored as values in memory (estimated size 39.2 KiB, free 417.9 MiB)
2025-08-10 08:14:52,803 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 25.515561 ms
2025-08-10 08:14:52,822 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 77 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:14:52,828 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_77_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 417.8 MiB)
2025-08-10 08:14:52,832 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 77 took 9 ms
2025-08-10 08:14:52,835 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_77 stored as values in memory (estimated size 32.0 KiB, free 417.8 MiB)
2025-08-10 08:14:52,855 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:14:52,864 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:14:52,880 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:14:52,887 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:14:52,905 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.087399 ms
2025-08-10 08:14:52,907 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 78 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:14:52,913 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_78_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 409.8 MiB)
2025-08-10 08:14:52,917 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 78 took 9 ms
2025-08-10 08:14:52,919 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_78 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 08:14:52,922 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:14:52,933 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:14:52,964 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 27, attempt 0, stage 23.0)
2025-08-10 08:14:52,967 [Executor task launch worker for task 0.0 in stage 23.0 (TID 27)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 23.0 (TID 27). 7839 bytes result sent to driver
2025-08-10 08:15:16,593 [block-manager-storage-async-thread-pool-180] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:15:16,609 [block-manager-storage-async-thread-pool-186] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:15:16,615 [block-manager-storage-async-thread-pool-189] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:15:17,136 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 28
2025-08-10 08:15:17,137 [Executor task launch worker for task 0.0 in stage 24.0 (TID 28)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 24.0 (TID 28)
2025-08-10 08:15:17,137 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 29
2025-08-10 08:15:17,139 [Executor task launch worker for task 1.0 in stage 24.0 (TID 29)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 24.0 (TID 29)
2025-08-10 08:15:17,140 [Executor task launch worker for task 0.0 in stage 24.0 (TID 28)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 81 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:15:17,147 [Executor task launch worker for task 0.0 in stage 24.0 (TID 28)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_81_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 418.1 MiB)
2025-08-10 08:15:17,151 [Executor task launch worker for task 0.0 in stage 24.0 (TID 28)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 81 took 10 ms
2025-08-10 08:15:17,153 [Executor task launch worker for task 0.0 in stage 24.0 (TID 28)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_81 stored as values in memory (estimated size 8.0 KiB, free 418.1 MiB)
2025-08-10 08:15:17,156 [Executor task launch worker for task 1.0 in stage 24.0 (TID 29)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 80 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:15:17,185 [Executor task launch worker for task 1.0 in stage 24.0 (TID 29)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_80_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 418.1 MiB)
2025-08-10 08:15:17,190 [Executor task launch worker for task 1.0 in stage 24.0 (TID 29)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 80 took 33 ms
2025-08-10 08:15:17,194 [Executor task launch worker for task 1.0 in stage 24.0 (TID 29)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_80 stored as values in memory (estimated size 32.0 KiB, free 418.1 MiB)
2025-08-10 08:15:17,199 [Executor task launch worker for task 0.0 in stage 24.0 (TID 28)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:15:17,199 [Executor task launch worker for task 1.0 in stage 24.0 (TID 29)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:15:17,209 [Executor task launch worker for task 1.0 in stage 24.0 (TID 29)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:15:17,209 [Executor task launch worker for task 0.0 in stage 24.0 (TID 28)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:15:17,225 [block-manager-storage-async-thread-pool-204] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:15:17,240 [Executor task launch worker for task 0.0 in stage 24.0 (TID 28)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 28, attempt 0, stage 24.0)
2025-08-10 08:15:17,240 [Executor task launch worker for task 1.0 in stage 24.0 (TID 29)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 29, attempt 0, stage 24.0)
2025-08-10 08:15:17,248 [Executor task launch worker for task 1.0 in stage 24.0 (TID 29)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 24.0 (TID 29). 4157 bytes result sent to driver
2025-08-10 08:15:17,248 [Executor task launch worker for task 0.0 in stage 24.0 (TID 28)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 24.0 (TID 28). 4159 bytes result sent to driver
2025-08-10 08:15:17,264 [block-manager-storage-async-thread-pool-213] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:15:17,294 [block-manager-storage-async-thread-pool-222] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:15:17,312 [block-manager-storage-async-thread-pool-228] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:15:28,277 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 30
2025-08-10 08:15:28,278 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 25.0 (TID 30)
2025-08-10 08:15:28,281 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 85 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:15:28,287 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_85_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 434.3 MiB)
2025-08-10 08:15:28,291 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 85 took 10 ms
2025-08-10 08:15:28,294 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_85 stored as values in memory (estimated size 39.2 KiB, free 434.3 MiB)
2025-08-10 08:15:28,308 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 83 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:15:28,313 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_83_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.2 MiB)
2025-08-10 08:15:28,315 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 83 took 6 ms
2025-08-10 08:15:28,317 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_83 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:15:28,327 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:15:28,334 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:15:28,347 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:15:28,354 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:15:28,363 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 84 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:15:28,368 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_84_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 426.1 MiB)
2025-08-10 08:15:28,370 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 84 took 7 ms
2025-08-10 08:15:28,372 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_84 stored as values in memory (estimated size 32.0 KiB, free 426.1 MiB)
2025-08-10 08:15:28,375 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:15:28,377 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:15:28,403 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 30, attempt 0, stage 25.0)
2025-08-10 08:15:28,407 [Executor task launch worker for task 0.0 in stage 25.0 (TID 30)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 25.0 (TID 30). 7805 bytes result sent to driver
2025-08-10 08:16:28,502 [dispatcher-event-loop-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250810075737-0000/3
2025-08-10 08:16:28,503 [ExecutorRunner for app-20250810075737-0000/3] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250810075737-0000/3 interrupted
2025-08-10 08:16:28,504 [ExecutorRunner for app-20250810075737-0000/3] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-10 08:16:28,507 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-10 08:16:28,538 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:16:28,539 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:16:28,539 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:16:28,540 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-10 08:16:28,540 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-10 08:16:28,544 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-10 08:16:28,547 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-10 08:16:28,547 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-10 08:16:28,548 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-10 08:16:28,620 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250810075737-0000/3 finished with state KILLED exitStatus 143
2025-08-10 08:16:28,622 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 3
2025-08-10 08:16:28,624 [dispatcher-event-loop-10] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250810075737-0000, execId=3)
2025-08-10 08:16:29,822 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250810075737-0000/4 for Thrift JDBC/ODBC Server
2025-08-10 08:16:29,825 [ExecutorRunner for app-20250810075737-0000/4] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:16:29,825 [ExecutorRunner for app-20250810075737-0000/4] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:16:29,826 [ExecutorRunner for app-20250810075737-0000/4] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:16:29,826 [ExecutorRunner for app-20250810075737-0000/4] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:16:29,826 [ExecutorRunner for app-20250810075737-0000/4] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:16:29,838 [ExecutorRunner for app-20250810075737-0000/4] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41435" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3c3beacd57f0:41435" "--executor-id" "4" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250810075737-0000" "--worker-url" "spark://Worker@172.18.0.11:44407" "--resourceProfileId" "0"
2025-08-10 08:16:31,314 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 773@661307a8e8bd
2025-08-10 08:16:31,321 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-10 08:16:31,322 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-10 08:16:31,323 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-10 08:16:31,661 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-10 08:16:31,759 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:16:31,760 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:16:31,761 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:16:31,761 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:16:31,762 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:16:31,984 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 49 ms (0 ms spent in bootstraps)
2025-08-10 08:16:32,065 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:16:32,066 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:16:32,066 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:16:32,066 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:16:32,067 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:16:32,123 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 2 ms (0 ms spent in bootstraps)
2025-08-10 08:16:32,192 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-40702174-4f13-4067-a184-4956d5932ca1/executor-03c5b1f9-784d-4cb3-b3f5-31b8e233e3c5/blockmgr-f5ddb016-836f-4ca8-811e-69681c4dc566
2025-08-10 08:16:32,223 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-10 08:16:32,356 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3c3beacd57f0:41435
2025-08-10 08:16:32,356 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:44407
2025-08-10 08:16:32,360 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:44407 after 1 ms (0 ms spent in bootstraps)
2025-08-10 08:16:32,361 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:44407
2025-08-10 08:16:32,365 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 08:16:32,366 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-10 08:16:32,366 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 08:16:32,387 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-10 08:16:32,389 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 4 on host 172.18.0.11
2025-08-10 08:16:32,434 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36167.
2025-08-10 08:16:32,435 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:36167
2025-08-10 08:16:32,438 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-10 08:16:32,446 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(4, 172.18.0.11, 36167, None)
2025-08-10 08:16:32,456 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(4, 172.18.0.11, 36167, None)
2025-08-10 08:16:32,457 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(4, 172.18.0.11, 36167, None)
2025-08-10 08:16:32,463 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-10 08:16:32,497 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 31
2025-08-10 08:16:32,503 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 32
2025-08-10 08:16:32,507 [Executor task launch worker for task 0.0 in stage 26.0 (TID 31)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 26.0 (TID 31)
2025-08-10 08:16:32,507 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 26.0 (TID 32)
2025-08-10 08:16:32,581 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 6 and clearing cache
2025-08-10 08:16:32,622 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 87 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:16:32,651 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:45089 after 2 ms (0 ms spent in bootstraps)
2025-08-10 08:16:32,675 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_87_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-10 08:16:32,684 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 87 took 61 ms
2025-08-10 08:16:32,727 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_87 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-10 08:16:32,893 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 86 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:16:32,900 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_86_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-10 08:16:32,905 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 86 took 10 ms
2025-08-10 08:16:32,945 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_86 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:16:33,445 [Executor task launch worker for task 0.0 in stage 26.0 (TID 31)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-10 08:16:33,458 [Executor task launch worker for task 0.0 in stage 26.0 (TID 31)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-10 08:16:33,458 [Executor task launch worker for task 0.0 in stage 26.0 (TID 31)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-10 08:16:34,241 [Executor task launch worker for task 0.0 in stage 26.0 (TID 31)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:16:34,241 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:16:34,643 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:16:34,643 [Executor task launch worker for task 0.0 in stage 26.0 (TID 31)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:16:35,340 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 32, attempt 0, stage 26.0)
2025-08-10 08:16:35,340 [Executor task launch worker for task 0.0 in stage 26.0 (TID 31)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 31, attempt 0, stage 26.0)
2025-08-10 08:16:35,366 [Executor task launch worker for task 0.0 in stage 26.0 (TID 31)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 26.0 (TID 31). 4159 bytes result sent to driver
2025-08-10 08:16:35,366 [Executor task launch worker for task 1.0 in stage 26.0 (TID 32)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 26.0 (TID 32). 4157 bytes result sent to driver
2025-08-10 08:16:44,370 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:16:44,459 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 33
2025-08-10 08:16:44,461 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 27.0 (TID 33)
2025-08-10 08:16:44,533 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 7 and clearing cache
2025-08-10 08:16:44,560 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 91 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:16:44,575 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_91_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 434.4 MiB)
2025-08-10 08:16:44,587 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 91 took 26 ms
2025-08-10 08:16:44,592 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_91 stored as values in memory (estimated size 39.2 KiB, free 434.3 MiB)
2025-08-10 08:16:45,461 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 358.54117 ms
2025-08-10 08:16:45,542 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.757905 ms
2025-08-10 08:16:45,578 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.918653 ms
2025-08-10 08:16:45,652 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 37.358394 ms
2025-08-10 08:16:45,666 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.869362 ms
2025-08-10 08:16:45,681 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 89 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:16:45,699 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_89_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-10 08:16:45,711 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 89 took 28 ms
2025-08-10 08:16:45,722 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_89 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:16:45,854 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:16:45,875 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-10 08:16:45,875 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-10 08:16:45,885 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-10 08:16:45,888 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-10 08:16:45,890 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-10 08:16:46,037 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:16:46,319 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:16:46,328 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:16:46,363 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.681398 ms
2025-08-10 08:16:46,387 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.452932 ms
2025-08-10 08:16:46,397 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.785857 ms
2025-08-10 08:16:46,412 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.11849 ms
2025-08-10 08:16:46,414 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 90 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:16:46,421 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_90_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 426.2 MiB)
2025-08-10 08:16:46,426 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 90 took 11 ms
2025-08-10 08:16:46,429 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_90 stored as values in memory (estimated size 32.0 KiB, free 426.2 MiB)
2025-08-10 08:16:46,432 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:16:46,450 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:16:46,492 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 33, attempt 0, stage 27.0)
2025-08-10 08:16:46,496 [Executor task launch worker for task 0.0 in stage 27.0 (TID 33)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 27.0 (TID 33). 7848 bytes result sent to driver
2025-08-10 08:17:24,269 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 34
2025-08-10 08:17:24,271 [Executor task launch worker for task 0.0 in stage 28.0 (TID 34)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 28.0 (TID 34)
2025-08-10 08:17:24,276 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 35
2025-08-10 08:17:24,277 [Executor task launch worker for task 1.0 in stage 28.0 (TID 35)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 28.0 (TID 35)
2025-08-10 08:17:24,278 [Executor task launch worker for task 0.0 in stage 28.0 (TID 34)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 93 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:17:24,286 [Executor task launch worker for task 0.0 in stage 28.0 (TID 34)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_93_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.2 MiB)
2025-08-10 08:17:24,291 [Executor task launch worker for task 0.0 in stage 28.0 (TID 34)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 93 took 12 ms
2025-08-10 08:17:24,293 [Executor task launch worker for task 0.0 in stage 28.0 (TID 34)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_93 stored as values in memory (estimated size 8.0 KiB, free 434.2 MiB)
2025-08-10 08:17:24,298 [Executor task launch worker for task 1.0 in stage 28.0 (TID 35)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 92 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:17:24,305 [Executor task launch worker for task 1.0 in stage 28.0 (TID 35)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_92_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.2 MiB)
2025-08-10 08:17:24,309 [Executor task launch worker for task 1.0 in stage 28.0 (TID 35)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 92 took 10 ms
2025-08-10 08:17:24,312 [Executor task launch worker for task 1.0 in stage 28.0 (TID 35)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_92 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:17:24,316 [Executor task launch worker for task 0.0 in stage 28.0 (TID 34)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:17:24,317 [Executor task launch worker for task 1.0 in stage 28.0 (TID 35)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:17:24,318 [Executor task launch worker for task 0.0 in stage 28.0 (TID 34)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:17:24,318 [Executor task launch worker for task 1.0 in stage 28.0 (TID 35)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:17:24,349 [Executor task launch worker for task 0.0 in stage 28.0 (TID 34)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 34, attempt 0, stage 28.0)
2025-08-10 08:17:24,350 [Executor task launch worker for task 1.0 in stage 28.0 (TID 35)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 35, attempt 0, stage 28.0)
2025-08-10 08:17:24,354 [Executor task launch worker for task 0.0 in stage 28.0 (TID 34)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 28.0 (TID 34). 4115 bytes result sent to driver
2025-08-10 08:17:24,354 [Executor task launch worker for task 1.0 in stage 28.0 (TID 35)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 28.0 (TID 35). 4114 bytes result sent to driver
2025-08-10 08:17:31,717 [block-manager-storage-async-thread-pool-9] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:17:31,718 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 36
2025-08-10 08:17:31,720 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 29.0 (TID 36)
2025-08-10 08:17:31,723 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 97 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:17:31,724 [block-manager-storage-async-thread-pool-12] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:17:31,730 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_97_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 434.3 MiB)
2025-08-10 08:17:31,735 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 97 took 11 ms
2025-08-10 08:17:31,737 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_97 stored as values in memory (estimated size 39.2 KiB, free 434.3 MiB)
2025-08-10 08:17:31,750 [block-manager-storage-async-thread-pool-21] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:17:31,761 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 95 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:17:31,768 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_95_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-10 08:17:31,771 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 95 took 9 ms
2025-08-10 08:17:31,774 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_95 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:17:31,789 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:17:31,796 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:17:31,814 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:17:31,821 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:17:31,831 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 96 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:17:31,836 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_96_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 426.2 MiB)
2025-08-10 08:17:31,839 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 96 took 8 ms
2025-08-10 08:17:31,841 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_96 stored as values in memory (estimated size 32.0 KiB, free 426.2 MiB)
2025-08-10 08:17:31,844 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:17:31,846 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:17:31,871 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 36, attempt 0, stage 29.0)
2025-08-10 08:17:31,873 [Executor task launch worker for task 0.0 in stage 29.0 (TID 36)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 29.0 (TID 36). 7796 bytes result sent to driver
2025-08-10 08:18:31,950 [dispatcher-event-loop-11] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250810075737-0000/4
2025-08-10 08:18:31,951 [ExecutorRunner for app-20250810075737-0000/4] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250810075737-0000/4 interrupted
2025-08-10 08:18:31,952 [ExecutorRunner for app-20250810075737-0000/4] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-10 08:18:31,956 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-10 08:18:31,977 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:18:31,978 [shutdown-hook-0] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:18:31,979 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-10 08:18:31,980 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-10 08:18:31,984 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-10 08:18:31,986 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-10 08:18:31,987 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-10 08:18:31,987 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-10 08:18:32,062 [dispatcher-event-loop-2] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250810075737-0000/4 finished with state KILLED exitStatus 143
2025-08-10 08:18:32,063 [dispatcher-event-loop-2] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 4
2025-08-10 08:18:32,064 [dispatcher-event-loop-2] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250810075737-0000, execId=4)
2025-08-10 08:19:28,400 [dispatcher-event-loop-9] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250810075737-0000/5 for Thrift JDBC/ODBC Server
2025-08-10 08:19:28,402 [ExecutorRunner for app-20250810075737-0000/5] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:19:28,403 [ExecutorRunner for app-20250810075737-0000/5] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:19:28,404 [ExecutorRunner for app-20250810075737-0000/5] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:19:28,404 [ExecutorRunner for app-20250810075737-0000/5] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:19:28,404 [ExecutorRunner for app-20250810075737-0000/5] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:19:28,415 [ExecutorRunner for app-20250810075737-0000/5] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41435" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3c3beacd57f0:41435" "--executor-id" "5" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250810075737-0000" "--worker-url" "spark://Worker@172.18.0.11:44407" "--resourceProfileId" "0"
2025-08-10 08:19:29,471 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 911@661307a8e8bd
2025-08-10 08:19:29,477 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-10 08:19:29,478 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-10 08:19:29,478 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-10 08:19:29,753 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-10 08:19:29,841 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:19:29,841 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:19:29,842 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:19:29,842 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:19:29,843 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:19:30,088 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 56 ms (0 ms spent in bootstraps)
2025-08-10 08:19:30,163 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 08:19:30,164 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 08:19:30,164 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 08:19:30,164 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 08:19:30,165 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 08:19:30,218 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 2 ms (0 ms spent in bootstraps)
2025-08-10 08:19:30,310 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-40702174-4f13-4067-a184-4956d5932ca1/executor-03c5b1f9-784d-4cb3-b3f5-31b8e233e3c5/blockmgr-4b5933d5-0320-4124-887e-2eb8f29eb1ce
2025-08-10 08:19:30,359 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-10 08:19:30,544 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3c3beacd57f0:41435
2025-08-10 08:19:30,545 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:44407
2025-08-10 08:19:30,549 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:44407 after 1 ms (0 ms spent in bootstraps)
2025-08-10 08:19:30,551 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:44407
2025-08-10 08:19:30,554 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 08:19:30,555 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-10 08:19:30,556 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 08:19:30,581 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-10 08:19:30,584 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 5 on host 172.18.0.11
2025-08-10 08:19:30,620 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36495.
2025-08-10 08:19:30,622 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:36495
2025-08-10 08:19:30,625 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-10 08:19:30,632 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(5, 172.18.0.11, 36495, None)
2025-08-10 08:19:30,641 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(5, 172.18.0.11, 36495, None)
2025-08-10 08:19:30,643 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(5, 172.18.0.11, 36495, None)
2025-08-10 08:19:30,649 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-10 08:19:30,684 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 37
2025-08-10 08:19:30,690 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 38
2025-08-10 08:19:30,695 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 30.0 (TID 38)
2025-08-10 08:19:30,695 [Executor task launch worker for task 0.0 in stage 30.0 (TID 37)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 30.0 (TID 37)
2025-08-10 08:19:30,768 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 8 and clearing cache
2025-08-10 08:19:30,836 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 99 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:30,883 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:45089 after 3 ms (0 ms spent in bootstraps)
2025-08-10 08:19:30,921 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_99_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-10 08:19:30,931 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 99 took 94 ms
2025-08-10 08:19:30,996 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_99 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-10 08:19:31,211 [Executor task launch worker for task 0.0 in stage 30.0 (TID 37)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 98 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:31,234 [Executor task launch worker for task 0.0 in stage 30.0 (TID 37)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_98_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-10 08:19:31,242 [Executor task launch worker for task 0.0 in stage 30.0 (TID 37)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 98 took 29 ms
2025-08-10 08:19:31,309 [Executor task launch worker for task 0.0 in stage 30.0 (TID 37)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_98 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:19:32,303 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-10 08:19:32,322 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-10 08:19:32,322 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-10 08:19:33,148 [Executor task launch worker for task 0.0 in stage 30.0 (TID 37)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:19:33,148 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:19:33,547 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:19:33,547 [Executor task launch worker for task 0.0 in stage 30.0 (TID 37)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:19:34,288 [Executor task launch worker for task 0.0 in stage 30.0 (TID 37)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 37, attempt 0, stage 30.0)
2025-08-10 08:19:34,288 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 38, attempt 0, stage 30.0)
2025-08-10 08:19:34,332 [Executor task launch worker for task 0.0 in stage 30.0 (TID 37)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 30.0 (TID 37). 4159 bytes result sent to driver
2025-08-10 08:19:34,332 [Executor task launch worker for task 1.0 in stage 30.0 (TID 38)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 30.0 (TID 38). 4157 bytes result sent to driver
2025-08-10 08:19:54,587 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:19:55,044 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 39
2025-08-10 08:19:55,045 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 31.0 (TID 39)
2025-08-10 08:19:55,052 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 40
2025-08-10 08:19:55,053 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 32.0 (TID 40)
2025-08-10 08:19:55,096 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 118 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:55,096 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 119 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:55,101 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_119_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.4 MiB)
2025-08-10 08:19:55,101 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_118_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
2025-08-10 08:19:55,105 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 119 took 8 ms
2025-08-10 08:19:55,106 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 118 took 9 ms
2025-08-10 08:19:55,108 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_119 stored as values in memory (estimated size 14.3 KiB, free 434.4 MiB)
2025-08-10 08:19:55,108 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_118 stored as values in memory (estimated size 13.6 KiB, free 434.4 MiB)
2025-08-10 08:19:55,400 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 159.630408 ms
2025-08-10 08:19:55,400 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 159.680964 ms
2025-08-10 08:19:55,409 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 115 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:55,409 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 113 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:55,416 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_115_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:19:55,416 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_113_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-10 08:19:55,420 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 115 took 11 ms
2025-08-10 08:19:55,420 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 113 took 11 ms
2025-08-10 08:19:55,429 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_115 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:19:55,429 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_113 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:19:55,525 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:55,525 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:55,562 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:55,564 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-10 08:19:55,565 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-10 08:19:55,576 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-10 08:19:55,579 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-10 08:19:55,580 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-10 08:19:55,744 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:55,935 [Executor task launch worker for task 0.0 in stage 32.0 (TID 40)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 32.0 (TID 40). 4717 bytes result sent to driver
2025-08-10 08:19:55,940 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 41
2025-08-10 08:19:55,941 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 33.0 (TID 41)
2025-08-10 08:19:55,942 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:55,946 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 120 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:55,954 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:55,954 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_120_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.2 MiB)
2025-08-10 08:19:55,959 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 120 took 12 ms
2025-08-10 08:19:55,961 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_120 stored as values in memory (estimated size 20.5 KiB, free 434.2 MiB)
2025-08-10 08:19:55,962 [Executor task launch worker for task 0.0 in stage 31.0 (TID 39)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 31.0 (TID 39). 4679 bytes result sent to driver
2025-08-10 08:19:56,009 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 42.266414 ms
2025-08-10 08:19:56,011 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 111 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,018 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_111_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.2 MiB)
2025-08-10 08:19:56,023 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 111 took 11 ms
2025-08-10 08:19:56,027 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_111 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:19:56,043 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:56,056 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:56,090 [Executor task launch worker for task 0.0 in stage 33.0 (TID 41)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 33.0 (TID 41). 5357 bytes result sent to driver
2025-08-10 08:19:56,267 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 42
2025-08-10 08:19:56,268 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 34.0 (TID 42)
2025-08-10 08:19:56,268 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 43
2025-08-10 08:19:56,268 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 34.0 (TID 43)
2025-08-10 08:19:56,275 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 139 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,282 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_139_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 434.2 MiB)
2025-08-10 08:19:56,286 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 139 took 9 ms
2025-08-10 08:19:56,287 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_139 stored as values in memory (estimated size 37.9 KiB, free 434.1 MiB)
2025-08-10 08:19:56,370 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 21.87941 ms
2025-08-10 08:19:56,372 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 121 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,378 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_121_piece0 stored as bytes in memory (estimated size 479.0 B, free 434.1 MiB)
2025-08-10 08:19:56,380 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 31.673135 ms
2025-08-10 08:19:56,381 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 121 took 8 ms
2025-08-10 08:19:56,382 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 133 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,388 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_133_piece0 stored as bytes in memory (estimated size 1135.0 B, free 434.1 MiB)
2025-08-10 08:19:56,391 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 133 took 8 ms
2025-08-10 08:19:56,402 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_121 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:19:56,402 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_133 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:19:56,414 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 116 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,414 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 114 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,420 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_116_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.1 MiB)
2025-08-10 08:19:56,420 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_114_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.1 MiB)
2025-08-10 08:19:56,424 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 116 took 9 ms
2025-08-10 08:19:56,424 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 114 took 9 ms
2025-08-10 08:19:56,427 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_116 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:19:56,427 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_114 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:19:56,440 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:56,440 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:56,450 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:56,450 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:56,465 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:56,465 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:56,473 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:56,473 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:56,492 [Executor task launch worker for task 1.0 in stage 34.0 (TID 43)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 34.0 (TID 43). 7314 bytes result sent to driver
2025-08-10 08:19:56,499 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 44
2025-08-10 08:19:56,500 [Executor task launch worker for task 0.0 in stage 34.0 (TID 42)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 34.0 (TID 42). 7400 bytes result sent to driver
2025-08-10 08:19:56,500 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 35.0 (TID 44)
2025-08-10 08:19:56,504 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 140 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,518 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 45
2025-08-10 08:19:56,520 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 35.0 (TID 45)
2025-08-10 08:19:56,528 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_140_piece0 stored as bytes in memory (estimated size 10.3 KiB, free 418.0 MiB)
2025-08-10 08:19:56,532 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 140 took 27 ms
2025-08-10 08:19:56,534 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_140 stored as values in memory (estimated size 32.9 KiB, free 418.0 MiB)
2025-08-10 08:19:56,553 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.560944 ms
2025-08-10 08:19:56,555 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 124 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,561 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_124_piece0 stored as bytes in memory (estimated size 497.0 B, free 418.0 MiB)
2025-08-10 08:19:56,563 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 24.948934 ms
2025-08-10 08:19:56,565 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 124 took 9 ms
2025-08-10 08:19:56,565 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 110 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,572 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_124 stored as values in memory (estimated size 8.0 MiB, free 410.0 MiB)
2025-08-10 08:19:56,575 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 112 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,575 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_110_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 409.9 MiB)
2025-08-10 08:19:56,579 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 110 took 12 ms
2025-08-10 08:19:56,582 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_110 stored as values in memory (estimated size 32.0 KiB, free 409.9 MiB)
2025-08-10 08:19:56,583 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_112_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.9 MiB)
2025-08-10 08:19:56,590 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 112 took 14 ms
2025-08-10 08:19:56,592 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_112 stored as values in memory (estimated size 32.0 KiB, free 409.9 MiB)
2025-08-10 08:19:56,601 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:56,611 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:56,616 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:56,625 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:56,628 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:19:56,642 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:19:56,642 [Executor task launch worker for task 1.0 in stage 35.0 (TID 45)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 35.0 (TID 45). 7206 bytes result sent to driver
2025-08-10 08:19:56,650 [Executor task launch worker for task 0.0 in stage 35.0 (TID 44)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 35.0 (TID 44). 7206 bytes result sent to driver
2025-08-10 08:19:56,700 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 46
2025-08-10 08:19:56,700 [Executor task launch worker for task 0.0 in stage 36.0 (TID 46)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 36.0 (TID 46)
2025-08-10 08:19:56,702 [Executor task launch worker for task 0.0 in stage 36.0 (TID 46)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 9 and clearing cache
2025-08-10 08:19:56,704 [Executor task launch worker for task 0.0 in stage 36.0 (TID 46)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 143 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,710 [Executor task launch worker for task 0.0 in stage 36.0 (TID 46)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_143_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 409.8 MiB)
2025-08-10 08:19:56,713 [Executor task launch worker for task 0.0 in stage 36.0 (TID 46)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 143 took 8 ms
2025-08-10 08:19:56,715 [Executor task launch worker for task 0.0 in stage 36.0 (TID 46)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_143 stored as values in memory (estimated size 11.7 KiB, free 409.8 MiB)
2025-08-10 08:19:56,729 [Executor task launch worker for task 0.0 in stage 36.0 (TID 46)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.101941 ms
2025-08-10 08:19:56,737 [Executor task launch worker for task 0.0 in stage 36.0 (TID 46)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 36.0 (TID 46). 1922 bytes result sent to driver
2025-08-10 08:19:56,768 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 47
2025-08-10 08:19:56,769 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 38.0 (TID 47)
2025-08-10 08:19:56,772 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 10 and clearing cache
2025-08-10 08:19:56,774 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 144 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,780 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_144_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 409.8 MiB)
2025-08-10 08:19:56,783 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 144 took 8 ms
2025-08-10 08:19:56,784 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_144 stored as values in memory (estimated size 12.7 KiB, free 409.8 MiB)
2025-08-10 08:19:56,793 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 4, fetching them
2025-08-10 08:19:56,795 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:19:56,807 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:19:56,853 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:19:56,856 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 18 ms
2025-08-10 08:19:56,872 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.352375 ms
2025-08-10 08:19:56,884 [Executor task launch worker for task 0.0 in stage 38.0 (TID 47)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 38.0 (TID 47). 4002 bytes result sent to driver
2025-08-10 08:19:56,966 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 48
2025-08-10 08:19:56,966 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 40.0 (TID 48)
2025-08-10 08:19:56,969 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 146 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:56,974 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_146_piece0 stored as bytes in memory (estimated size 27.8 KiB, free 409.8 MiB)
2025-08-10 08:19:56,976 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 146 took 6 ms
2025-08-10 08:19:56,977 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_146 stored as values in memory (estimated size 69.6 KiB, free 409.7 MiB)
2025-08-10 08:19:57,164 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 3, fetching them
2025-08-10 08:19:57,165 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:19:57,176 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:19:57,178 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:19:57,179 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:19:57,194 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.09618 ms
2025-08-10 08:19:57,278 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.711042 ms
2025-08-10 08:19:57,321 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.541458 ms
2025-08-10 08:19:57,366 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.356494 ms
2025-08-10 08:19:57,378 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.815301 ms
2025-08-10 08:19:57,423 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.463912 ms
2025-08-10 08:19:57,454 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.347918 ms
2025-08-10 08:19:57,463 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.300113 ms
2025-08-10 08:19:57,475 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.719228 ms
2025-08-10 08:19:57,477 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 145 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:19:57,483 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_145_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.8 MiB)
2025-08-10 08:19:57,487 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 145 took 10 ms
2025-08-10 08:19:57,490 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_145 stored as values in memory (estimated size 32.0 KiB, free 409.8 MiB)
2025-08-10 08:19:57,492 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:19:57,511 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:19:57,553 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 48, attempt 0, stage 40.0)
2025-08-10 08:19:57,560 [Executor task launch worker for task 0.0 in stage 40.0 (TID 48)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 40.0 (TID 48). 18528 bytes result sent to driver
2025-08-10 08:20:31,313 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 49
2025-08-10 08:20:31,318 [Executor task launch worker for task 0.0 in stage 41.0 (TID 49)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 41.0 (TID 49)
2025-08-10 08:20:31,318 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 50
2025-08-10 08:20:31,319 [Executor task launch worker for task 1.0 in stage 41.0 (TID 50)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 41.0 (TID 50)
2025-08-10 08:20:31,321 [Executor task launch worker for task 0.0 in stage 41.0 (TID 49)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 148 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:31,328 [Executor task launch worker for task 0.0 in stage 41.0 (TID 49)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_148_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 409.8 MiB)
2025-08-10 08:20:31,332 [Executor task launch worker for task 0.0 in stage 41.0 (TID 49)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 148 took 9 ms
2025-08-10 08:20:31,335 [Executor task launch worker for task 0.0 in stage 41.0 (TID 49)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_148 stored as values in memory (estimated size 8.0 KiB, free 409.8 MiB)
2025-08-10 08:20:31,339 [Executor task launch worker for task 1.0 in stage 41.0 (TID 50)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 147 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:31,350 [Executor task launch worker for task 1.0 in stage 41.0 (TID 50)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_147_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 409.8 MiB)
2025-08-10 08:20:31,351 [block-manager-storage-async-thread-pool-81] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:20:31,353 [Executor task launch worker for task 1.0 in stage 41.0 (TID 50)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 147 took 11 ms
2025-08-10 08:20:31,355 [Executor task launch worker for task 1.0 in stage 41.0 (TID 50)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_147 stored as values in memory (estimated size 32.0 KiB, free 409.8 MiB)
2025-08-10 08:20:31,358 [Executor task launch worker for task 1.0 in stage 41.0 (TID 50)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:20:31,363 [Executor task launch worker for task 0.0 in stage 41.0 (TID 49)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:20:31,365 [Executor task launch worker for task 0.0 in stage 41.0 (TID 49)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:20:31,365 [Executor task launch worker for task 1.0 in stage 41.0 (TID 50)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:20:31,399 [Executor task launch worker for task 1.0 in stage 41.0 (TID 50)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 50, attempt 0, stage 41.0)
2025-08-10 08:20:31,399 [Executor task launch worker for task 0.0 in stage 41.0 (TID 49)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 49, attempt 0, stage 41.0)
2025-08-10 08:20:31,406 [Executor task launch worker for task 0.0 in stage 41.0 (TID 49)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 41.0 (TID 49). 4159 bytes result sent to driver
2025-08-10 08:20:31,406 [Executor task launch worker for task 1.0 in stage 41.0 (TID 50)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 41.0 (TID 50). 4157 bytes result sent to driver
2025-08-10 08:20:39,805 [block-manager-storage-async-thread-pool-90] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:20:39,966 [block-manager-storage-async-thread-pool-99] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:20:39,980 [block-manager-storage-async-thread-pool-4] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:20:39,993 [block-manager-storage-async-thread-pool-17] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:20:40,009 [block-manager-storage-async-thread-pool-32] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:20:40,020 [block-manager-storage-async-thread-pool-38] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:20:40,033 [block-manager-storage-async-thread-pool-50] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:20:40,041 [block-manager-storage-async-thread-pool-53] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:20:40,103 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 51
2025-08-10 08:20:40,104 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 42.0 (TID 51)
2025-08-10 08:20:40,109 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 167 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,116 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 52
2025-08-10 08:20:40,117 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 43.0 (TID 52)
2025-08-10 08:20:40,120 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_167_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.4 MiB)
2025-08-10 08:20:40,121 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 168 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,126 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 167 took 16 ms
2025-08-10 08:20:40,129 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_167 stored as values in memory (estimated size 14.3 KiB, free 434.4 MiB)
2025-08-10 08:20:40,131 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_168_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
2025-08-10 08:20:40,134 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 164 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,135 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 168 took 13 ms
2025-08-10 08:20:40,137 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_168 stored as values in memory (estimated size 13.6 KiB, free 434.4 MiB)
2025-08-10 08:20:40,141 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 162 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,142 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_164_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-10 08:20:40,146 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 164 took 10 ms
2025-08-10 08:20:40,147 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_162_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-10 08:20:40,149 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_164 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:20:40,150 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 162 took 8 ms
2025-08-10 08:20:40,153 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_162 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:20:40,167 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,168 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,178 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,178 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,190 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,194 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,200 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,207 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,209 [Executor task launch worker for task 0.0 in stage 43.0 (TID 52)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 43.0 (TID 52). 4722 bytes result sent to driver
2025-08-10 08:20:40,219 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 53
2025-08-10 08:20:40,219 [Executor task launch worker for task 0.0 in stage 42.0 (TID 51)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 42.0 (TID 51). 4724 bytes result sent to driver
2025-08-10 08:20:40,220 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 44.0 (TID 53)
2025-08-10 08:20:40,229 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 169 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,230 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 54
2025-08-10 08:20:40,231 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 45.0 (TID 54)
2025-08-10 08:20:40,236 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 170 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,241 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_169_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 434.2 MiB)
2025-08-10 08:20:40,243 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_170_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.2 MiB)
2025-08-10 08:20:40,243 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 169 took 13 ms
2025-08-10 08:20:40,245 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_169 stored as values in memory (estimated size 19.9 KiB, free 434.2 MiB)
2025-08-10 08:20:40,246 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 170 took 9 ms
2025-08-10 08:20:40,248 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_170 stored as values in memory (estimated size 20.5 KiB, free 434.2 MiB)
2025-08-10 08:20:40,276 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 27.932956 ms
2025-08-10 08:20:40,278 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 25.997701 ms
2025-08-10 08:20:40,278 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 159 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,280 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 166 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,284 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_159_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 434.2 MiB)
2025-08-10 08:20:40,286 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_166_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.1 MiB)
2025-08-10 08:20:40,296 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 159 took 16 ms
2025-08-10 08:20:40,297 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 166 took 16 ms
2025-08-10 08:20:40,299 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_159 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:20:40,300 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_166 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:20:40,318 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,318 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,330 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,330 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,353 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,357 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,363 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,383 [Executor task launch worker for task 0.0 in stage 44.0 (TID 53)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 44.0 (TID 53). 5407 bytes result sent to driver
2025-08-10 08:20:40,383 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,402 [Executor task launch worker for task 0.0 in stage 45.0 (TID 54)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 45.0 (TID 54). 5402 bytes result sent to driver
2025-08-10 08:20:40,554 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 55
2025-08-10 08:20:40,555 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 56
2025-08-10 08:20:40,555 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 46.0 (TID 55)
2025-08-10 08:20:40,556 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 46.0 (TID 56)
2025-08-10 08:20:40,559 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 193 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,566 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_193_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 434.1 MiB)
2025-08-10 08:20:40,569 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 193 took 10 ms
2025-08-10 08:20:40,571 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_193 stored as values in memory (estimated size 33.7 KiB, free 434.1 MiB)
2025-08-10 08:20:40,578 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 171 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,586 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_171_piece0 stored as bytes in memory (estimated size 497.0 B, free 434.1 MiB)
2025-08-10 08:20:40,590 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 171 took 11 ms
2025-08-10 08:20:40,594 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_171 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-10 08:20:40,596 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 161 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,599 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 22.89089 ms
2025-08-10 08:20:40,602 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 183 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,603 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_161_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 426.0 MiB)
2025-08-10 08:20:40,606 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 161 took 9 ms
2025-08-10 08:20:40,608 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_183_piece0 stored as bytes in memory (estimated size 1204.0 B, free 426.0 MiB)
2025-08-10 08:20:40,609 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_161 stored as values in memory (estimated size 32.0 KiB, free 426.0 MiB)
2025-08-10 08:20:40,612 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 183 took 9 ms
2025-08-10 08:20:40,623 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_183 stored as values in memory (estimated size 8.0 MiB, free 418.0 MiB)
2025-08-10 08:20:40,625 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 160 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,630 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,632 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_160_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 418.0 MiB)
2025-08-10 08:20:40,636 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 160 took 10 ms
2025-08-10 08:20:40,638 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_160 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 08:20:40,643 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,653 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,656 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,662 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,666 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,682 [Executor task launch worker for task 1.0 in stage 46.0 (TID 56)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 46.0 (TID 56). 7206 bytes result sent to driver
2025-08-10 08:20:40,685 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,688 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 57
2025-08-10 08:20:40,689 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 47.0 (TID 57)
2025-08-10 08:20:40,692 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 194 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,700 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,706 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_194_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 417.9 MiB)
2025-08-10 08:20:40,709 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 194 took 16 ms
2025-08-10 08:20:40,710 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_194 stored as values in memory (estimated size 37.9 KiB, free 417.9 MiB)
2025-08-10 08:20:40,720 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 172 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,720 [Executor task launch worker for task 0.0 in stage 46.0 (TID 55)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 46.0 (TID 55). 7236 bytes result sent to driver
2025-08-10 08:20:40,725 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 58
2025-08-10 08:20:40,726 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 47.0 (TID 58)
2025-08-10 08:20:40,726 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_172_piece0 stored as bytes in memory (estimated size 492.0 B, free 417.9 MiB)
2025-08-10 08:20:40,731 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 172 took 10 ms
2025-08-10 08:20:40,733 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 185 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,735 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_172 stored as values in memory (estimated size 8.0 MiB, free 409.9 MiB)
2025-08-10 08:20:40,743 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_185_piece0 stored as bytes in memory (estimated size 1198.0 B, free 409.9 MiB)
2025-08-10 08:20:40,748 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 163 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,750 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 185 took 16 ms
2025-08-10 08:20:40,754 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_163_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 401.9 MiB)
2025-08-10 08:20:40,754 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_185 stored as values in memory (estimated size 8.0 MiB, free 401.9 MiB)
2025-08-10 08:20:40,756 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 165 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,757 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 163 took 8 ms
2025-08-10 08:20:40,759 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_163 stored as values in memory (estimated size 32.0 KiB, free 401.8 MiB)
2025-08-10 08:20:40,762 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_165_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 401.8 MiB)
2025-08-10 08:20:40,765 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 165 took 7 ms
2025-08-10 08:20:40,767 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_165 stored as values in memory (estimated size 32.0 KiB, free 401.8 MiB)
2025-08-10 08:20:40,772 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,781 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,781 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,790 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,797 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,803 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,805 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:40,811 [Executor task launch worker for task 0.0 in stage 47.0 (TID 57)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 47.0 (TID 57). 7271 bytes result sent to driver
2025-08-10 08:20:40,812 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:40,820 [Executor task launch worker for task 1.0 in stage 47.0 (TID 58)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 47.0 (TID 58). 7357 bytes result sent to driver
2025-08-10 08:20:40,886 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 59
2025-08-10 08:20:40,888 [Executor task launch worker for task 0.0 in stage 48.0 (TID 59)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 48.0 (TID 59)
2025-08-10 08:20:40,890 [Executor task launch worker for task 0.0 in stage 48.0 (TID 59)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 11 and clearing cache
2025-08-10 08:20:40,893 [Executor task launch worker for task 0.0 in stage 48.0 (TID 59)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 198 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,900 [Executor task launch worker for task 0.0 in stage 48.0 (TID 59)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_198_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 401.9 MiB)
2025-08-10 08:20:40,910 [Executor task launch worker for task 0.0 in stage 48.0 (TID 59)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 198 took 16 ms
2025-08-10 08:20:40,912 [Executor task launch worker for task 0.0 in stage 48.0 (TID 59)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_198 stored as values in memory (estimated size 11.7 KiB, free 401.9 MiB)
2025-08-10 08:20:40,921 [Executor task launch worker for task 0.0 in stage 48.0 (TID 59)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 48.0 (TID 59). 1836 bytes result sent to driver
2025-08-10 08:20:40,951 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 60
2025-08-10 08:20:40,951 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 50.0 (TID 60)
2025-08-10 08:20:40,953 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 12 and clearing cache
2025-08-10 08:20:40,955 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 199 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:40,961 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_199_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 401.9 MiB)
2025-08-10 08:20:40,964 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 199 took 8 ms
2025-08-10 08:20:40,965 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_199 stored as values in memory (estimated size 12.7 KiB, free 401.9 MiB)
2025-08-10 08:20:40,967 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 6, fetching them
2025-08-10 08:20:40,968 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:20:40,973 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:20:40,976 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:20:40,976 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
2025-08-10 08:20:40,980 [Executor task launch worker for task 0.0 in stage 50.0 (TID 60)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 50.0 (TID 60). 3959 bytes result sent to driver
2025-08-10 08:20:41,058 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 61
2025-08-10 08:20:41,059 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 62
2025-08-10 08:20:41,059 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 52.0 (TID 61)
2025-08-10 08:20:41,060 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 52.0 (TID 62)
2025-08-10 08:20:41,062 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 201 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:41,067 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_201_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 401.9 MiB)
2025-08-10 08:20:41,071 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 201 took 8 ms
2025-08-10 08:20:41,072 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_201 stored as values in memory (estimated size 82.1 KiB, free 401.8 MiB)
2025-08-10 08:20:41,080 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 5, fetching them
2025-08-10 08:20:41,082 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:20:41,089 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:20:41,090 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (228.0 B) non-empty blocks including 1 (228.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:20:41,091 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:20:41,095 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.570933 ms
2025-08-10 08:20:41,097 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 195 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:41,102 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.958516 ms
2025-08-10 08:20:41,103 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_195_piece0 stored as bytes in memory (estimated size 180.0 B, free 401.8 MiB)
2025-08-10 08:20:41,106 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 195 took 8 ms
2025-08-10 08:20:41,110 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_195 stored as values in memory (estimated size 8.0 MiB, free 393.8 MiB)
2025-08-10 08:20:41,111 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 200 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:41,118 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_200_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 393.7 MiB)
2025-08-10 08:20:41,122 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 200 took 10 ms
2025-08-10 08:20:41,125 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_200 stored as values in memory (estimated size 32.0 KiB, free 385.7 MiB)
2025-08-10 08:20:41,129 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:20:41,132 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 158 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:20:41,140 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_158_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 393.7 MiB)
2025-08-10 08:20:41,146 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 158 took 13 ms
2025-08-10 08:20:41,149 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_158 stored as values in memory (estimated size 32.0 KiB, free 393.7 MiB)
2025-08-10 08:20:41,156 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.640544 ms
2025-08-10 08:20:41,165 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:20:41,167 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:20:41,171 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:41,187 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:41,211 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 61, attempt 0, stage 52.0)
2025-08-10 08:20:41,215 [Executor task launch worker for task 1.0 in stage 52.0 (TID 61)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 52.0 (TID 61). 20954 bytes result sent to driver
2025-08-10 08:20:41,230 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:20:41,242 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:20:41,247 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:20:41,280 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 62, attempt 0, stage 52.0)
2025-08-10 08:20:41,283 [Executor task launch worker for task 0.0 in stage 52.0 (TID 62)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 52.0 (TID 62). 20336 bytes result sent to driver
2025-08-10 08:23:45,552 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 63
2025-08-10 08:23:45,554 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 64
2025-08-10 08:23:45,554 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 53.0 (TID 63)
2025-08-10 08:23:45,555 [Executor task launch worker for task 1.0 in stage 53.0 (TID 64)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 53.0 (TID 64)
2025-08-10 08:23:45,557 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 203 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:45,562 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_203_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 393.7 MiB)
2025-08-10 08:23:45,564 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 203 took 6 ms
2025-08-10 08:23:45,565 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_203 stored as values in memory (estimated size 8.0 KiB, free 393.6 MiB)
2025-08-10 08:23:45,568 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 202 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:45,572 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_202_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 393.6 MiB)
2025-08-10 08:23:45,574 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 202 took 5 ms
2025-08-10 08:23:45,575 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_202 stored as values in memory (estimated size 32.0 KiB, free 393.6 MiB)
2025-08-10 08:23:45,578 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:23:45,578 [Executor task launch worker for task 1.0 in stage 53.0 (TID 64)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:23:45,579 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:23:45,579 [Executor task launch worker for task 1.0 in stage 53.0 (TID 64)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:23:45,606 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 63, attempt 0, stage 53.0)
2025-08-10 08:23:45,609 [Executor task launch worker for task 0.0 in stage 53.0 (TID 63)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 53.0 (TID 63). 4072 bytes result sent to driver
2025-08-10 08:23:45,641 [Executor task launch worker for task 1.0 in stage 53.0 (TID 64)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 64, attempt 0, stage 53.0)
2025-08-10 08:23:45,642 [Executor task launch worker for task 1.0 in stage 53.0 (TID 64)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 53.0 (TID 64). 4071 bytes result sent to driver
2025-08-10 08:23:51,554 [block-manager-storage-async-thread-pool-103] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:51,583 [block-manager-storage-async-thread-pool-112] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:52,288 [block-manager-storage-async-thread-pool-115] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:52,365 [block-manager-storage-async-thread-pool-133] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:52,372 [block-manager-storage-async-thread-pool-136] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:52,402 [block-manager-storage-async-thread-pool-148] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:52,410 [block-manager-storage-async-thread-pool-151] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:52,451 [block-manager-storage-async-thread-pool-169] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:52,466 [block-manager-storage-async-thread-pool-172] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:52,476 [block-manager-storage-async-thread-pool-175] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:52,485 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 65
2025-08-10 08:23:52,486 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 54.0 (TID 65)
2025-08-10 08:23:52,491 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 222 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,491 [block-manager-storage-async-thread-pool-184] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:23:52,497 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 66
2025-08-10 08:23:52,498 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 55.0 (TID 66)
2025-08-10 08:23:52,500 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_222_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 434.4 MiB)
2025-08-10 08:23:52,505 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 223 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,516 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 222 took 24 ms
2025-08-10 08:23:52,519 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_222 stored as values in memory (estimated size 19.9 KiB, free 434.4 MiB)
2025-08-10 08:23:52,521 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_223_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
2025-08-10 08:23:52,524 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 214 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,524 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 223 took 14 ms
2025-08-10 08:23:52,526 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_223 stored as values in memory (estimated size 13.6 KiB, free 434.4 MiB)
2025-08-10 08:23:52,532 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_214_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 434.3 MiB)
2025-08-10 08:23:52,532 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 217 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,535 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 214 took 10 ms
2025-08-10 08:23:52,538 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_214 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:23:52,539 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_217_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-10 08:23:52,543 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 217 took 10 ms
2025-08-10 08:23:52,547 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_217 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:23:52,558 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,563 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,569 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,572 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,589 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,589 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,599 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,599 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,603 [Executor task launch worker for task 0.0 in stage 55.0 (TID 66)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 55.0 (TID 66). 4674 bytes result sent to driver
2025-08-10 08:23:52,604 [Executor task launch worker for task 0.0 in stage 54.0 (TID 65)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 54.0 (TID 65). 5319 bytes result sent to driver
2025-08-10 08:23:52,609 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 67
2025-08-10 08:23:52,610 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 56.0 (TID 67)
2025-08-10 08:23:52,611 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 68
2025-08-10 08:23:52,612 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 57.0 (TID 68)
2025-08-10 08:23:52,619 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 224 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,620 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 225 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,626 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_225_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.2 MiB)
2025-08-10 08:23:52,626 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_224_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.2 MiB)
2025-08-10 08:23:52,629 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 225 took 9 ms
2025-08-10 08:23:52,629 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 224 took 10 ms
2025-08-10 08:23:52,631 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_225 stored as values in memory (estimated size 20.5 KiB, free 434.2 MiB)
2025-08-10 08:23:52,631 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_224 stored as values in memory (estimated size 14.3 KiB, free 434.2 MiB)
2025-08-10 08:23:52,633 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 221 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,634 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 219 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,639 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_221_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.2 MiB)
2025-08-10 08:23:52,639 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_219_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.1 MiB)
2025-08-10 08:23:52,643 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 221 took 8 ms
2025-08-10 08:23:52,643 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 219 took 8 ms
2025-08-10 08:23:52,645 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_219 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:23:52,645 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_221 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:23:52,657 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,657 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,667 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,667 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,680 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,680 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,690 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,690 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,713 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,713 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,724 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,724 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,748 [Executor task launch worker for task 0.0 in stage 56.0 (TID 67)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 56.0 (TID 67). 4768 bytes result sent to driver
2025-08-10 08:23:52,749 [Executor task launch worker for task 0.0 in stage 57.0 (TID 68)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 57.0 (TID 68). 5445 bytes result sent to driver
2025-08-10 08:23:52,888 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 69
2025-08-10 08:23:52,889 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 70
2025-08-10 08:23:52,889 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 58.0 (TID 69)
2025-08-10 08:23:52,890 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 58.0 (TID 70)
2025-08-10 08:23:52,892 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 243 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,899 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_243_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 434.1 MiB)
2025-08-10 08:23:52,902 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 243 took 8 ms
2025-08-10 08:23:52,904 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_243 stored as values in memory (estimated size 33.7 KiB, free 434.1 MiB)
2025-08-10 08:23:52,907 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 226 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,907 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 227 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,913 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_227_piece0 stored as bytes in memory (estimated size 1140.0 B, free 434.1 MiB)
2025-08-10 08:23:52,913 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_226_piece0 stored as bytes in memory (estimated size 479.0 B, free 434.1 MiB)
2025-08-10 08:23:52,916 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 226 took 8 ms
2025-08-10 08:23:52,916 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 227 took 8 ms
2025-08-10 08:23:52,919 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_227 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-10 08:23:52,920 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_226 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:23:52,921 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 215 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,922 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 216 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:52,927 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_215_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 418.0 MiB)
2025-08-10 08:23:52,927 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_216_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 418.0 MiB)
2025-08-10 08:23:52,930 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 215 took 8 ms
2025-08-10 08:23:52,930 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 216 took 7 ms
2025-08-10 08:23:52,932 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_216 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 08:23:52,933 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_215 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 08:23:52,943 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,943 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,951 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,951 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,964 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,970 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,971 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,980 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,988 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,994 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:52,995 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:52,999 [Executor task launch worker for task 1.0 in stage 58.0 (TID 70)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 58.0 (TID 70). 7194 bytes result sent to driver
2025-08-10 08:23:53,002 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:53,004 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 71
2025-08-10 08:23:53,004 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 59.0 (TID 71)
2025-08-10 08:23:53,007 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 244 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,009 [Executor task launch worker for task 0.0 in stage 58.0 (TID 69)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 58.0 (TID 69). 7201 bytes result sent to driver
2025-08-10 08:23:53,013 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_244_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 417.9 MiB)
2025-08-10 08:23:53,014 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 72
2025-08-10 08:23:53,014 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 59.0 (TID 72)
2025-08-10 08:23:53,016 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 244 took 7 ms
2025-08-10 08:23:53,017 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_244 stored as values in memory (estimated size 38.3 KiB, free 417.9 MiB)
2025-08-10 08:23:53,040 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 17.855785 ms
2025-08-10 08:23:53,043 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 238 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,046 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 23.968924 ms
2025-08-10 08:23:53,049 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_238_piece0 stored as bytes in memory (estimated size 513.0 B, free 417.9 MiB)
2025-08-10 08:23:53,049 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 239 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,052 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 238 took 8 ms
2025-08-10 08:23:53,056 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_239_piece0 stored as bytes in memory (estimated size 1244.0 B, free 417.9 MiB)
2025-08-10 08:23:53,057 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_238 stored as values in memory (estimated size 8.0 MiB, free 409.9 MiB)
2025-08-10 08:23:53,059 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 239 took 9 ms
2025-08-10 08:23:53,060 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 218 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,064 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_239 stored as values in memory (estimated size 8.0 MiB, free 401.9 MiB)
2025-08-10 08:23:53,065 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_218_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 401.9 MiB)
2025-08-10 08:23:53,068 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 220 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,070 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 218 took 9 ms
2025-08-10 08:23:53,072 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_218 stored as values in memory (estimated size 32.0 KiB, free 401.8 MiB)
2025-08-10 08:23:53,073 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_220_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 401.8 MiB)
2025-08-10 08:23:53,076 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 220 took 7 ms
2025-08-10 08:23:53,078 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_220 stored as values in memory (estimated size 32.0 KiB, free 401.8 MiB)
2025-08-10 08:23:53,084 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:53,091 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:53,091 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:53,100 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:53,110 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:53,114 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:53,118 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:53,125 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:53,131 [Executor task launch worker for task 0.0 in stage 59.0 (TID 71)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 59.0 (TID 71). 7228 bytes result sent to driver
2025-08-10 08:23:53,134 [Executor task launch worker for task 1.0 in stage 59.0 (TID 72)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 59.0 (TID 72). 7357 bytes result sent to driver
2025-08-10 08:23:53,186 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 73
2025-08-10 08:23:53,187 [Executor task launch worker for task 0.0 in stage 60.0 (TID 73)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 60.0 (TID 73)
2025-08-10 08:23:53,188 [Executor task launch worker for task 0.0 in stage 60.0 (TID 73)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 13 and clearing cache
2025-08-10 08:23:53,190 [Executor task launch worker for task 0.0 in stage 60.0 (TID 73)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 248 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,195 [Executor task launch worker for task 0.0 in stage 60.0 (TID 73)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_248_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 401.8 MiB)
2025-08-10 08:23:53,198 [Executor task launch worker for task 0.0 in stage 60.0 (TID 73)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 248 took 8 ms
2025-08-10 08:23:53,200 [Executor task launch worker for task 0.0 in stage 60.0 (TID 73)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_248 stored as values in memory (estimated size 11.7 KiB, free 401.8 MiB)
2025-08-10 08:23:53,206 [Executor task launch worker for task 0.0 in stage 60.0 (TID 73)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 60.0 (TID 73). 1836 bytes result sent to driver
2025-08-10 08:23:53,238 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 74
2025-08-10 08:23:53,239 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 62.0 (TID 74)
2025-08-10 08:23:53,240 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 14 and clearing cache
2025-08-10 08:23:53,241 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 249 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,247 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_249_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 401.7 MiB)
2025-08-10 08:23:53,251 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 249 took 9 ms
2025-08-10 08:23:53,252 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_249 stored as values in memory (estimated size 12.7 KiB, free 401.7 MiB)
2025-08-10 08:23:53,254 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 8, fetching them
2025-08-10 08:23:53,254 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:23:53,260 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:23:53,263 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:23:53,263 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:23:53,267 [Executor task launch worker for task 0.0 in stage 62.0 (TID 74)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 62.0 (TID 74). 3959 bytes result sent to driver
2025-08-10 08:23:53,332 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 75
2025-08-10 08:23:53,333 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 76
2025-08-10 08:23:53,333 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 64.0 (TID 75)
2025-08-10 08:23:53,334 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 64.0 (TID 76)
2025-08-10 08:23:53,336 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 251 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,342 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_251_piece0 stored as bytes in memory (estimated size 30.2 KiB, free 401.8 MiB)
2025-08-10 08:23:53,344 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 251 took 7 ms
2025-08-10 08:23:53,346 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_251 stored as values in memory (estimated size 82.1 KiB, free 401.7 MiB)
2025-08-10 08:23:53,355 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 7, fetching them
2025-08-10 08:23:53,356 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:23:53,356 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 245 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,360 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:23:53,362 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_245_piece0 stored as bytes in memory (estimated size 208.0 B, free 401.8 MiB)
2025-08-10 08:23:53,362 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (334.0 B) non-empty blocks including 1 (334.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:23:53,363 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:23:53,365 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 245 took 8 ms
2025-08-10 08:23:53,368 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_245 stored as values in memory (estimated size 8.0 MiB, free 393.8 MiB)
2025-08-10 08:23:53,369 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 250 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,374 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_250_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.7 MiB)
2025-08-10 08:23:53,377 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 250 took 7 ms
2025-08-10 08:23:53,379 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_250 stored as values in memory (estimated size 32.0 KiB, free 393.7 MiB)
2025-08-10 08:23:53,382 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:23:53,384 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 213 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:23:53,388 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_213_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 385.6 MiB)
2025-08-10 08:23:53,391 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 213 took 7 ms
2025-08-10 08:23:53,394 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_213 stored as values in memory (estimated size 32.0 KiB, free 385.6 MiB)
2025-08-10 08:23:53,403 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.440761 ms
2025-08-10 08:23:53,405 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:23:53,408 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:23:53,409 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:53,417 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:53,433 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:53,442 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:53,442 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 75, attempt 0, stage 64.0)
2025-08-10 08:23:53,446 [Executor task launch worker for task 1.0 in stage 64.0 (TID 75)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 64.0 (TID 75). 20965 bytes result sent to driver
2025-08-10 08:23:53,461 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:23:53,469 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:23:53,475 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:23:53,501 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 76, attempt 0, stage 64.0)
2025-08-10 08:23:53,504 [Executor task launch worker for task 0.0 in stage 64.0 (TID 76)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 64.0 (TID 76). 20347 bytes result sent to driver
2025-08-10 08:23:53,697 [block-manager-storage-async-thread-pool-159] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:36,351 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 77
2025-08-10 08:27:36,353 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 78
2025-08-10 08:27:36,353 [Executor task launch worker for task 0.0 in stage 65.0 (TID 77)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 65.0 (TID 77)
2025-08-10 08:27:36,353 [Executor task launch worker for task 1.0 in stage 65.0 (TID 78)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 65.0 (TID 78)
2025-08-10 08:27:36,356 [Executor task launch worker for task 1.0 in stage 65.0 (TID 78)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 253 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:27:36,361 [Executor task launch worker for task 1.0 in stage 65.0 (TID 78)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_253_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 393.8 MiB)
2025-08-10 08:27:36,363 [Executor task launch worker for task 1.0 in stage 65.0 (TID 78)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 253 took 7 ms
2025-08-10 08:27:36,365 [Executor task launch worker for task 1.0 in stage 65.0 (TID 78)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_253 stored as values in memory (estimated size 8.0 KiB, free 393.8 MiB)
2025-08-10 08:27:36,368 [Executor task launch worker for task 0.0 in stage 65.0 (TID 77)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 252 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:27:36,393 [Executor task launch worker for task 0.0 in stage 65.0 (TID 77)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_252_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 393.8 MiB)
2025-08-10 08:27:36,397 [Executor task launch worker for task 0.0 in stage 65.0 (TID 77)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 252 took 28 ms
2025-08-10 08:27:36,399 [Executor task launch worker for task 0.0 in stage 65.0 (TID 77)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_252 stored as values in memory (estimated size 32.0 KiB, free 393.8 MiB)
2025-08-10 08:27:36,403 [Executor task launch worker for task 0.0 in stage 65.0 (TID 77)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:27:36,403 [Executor task launch worker for task 1.0 in stage 65.0 (TID 78)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:27:36,405 [Executor task launch worker for task 0.0 in stage 65.0 (TID 77)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:27:36,405 [Executor task launch worker for task 1.0 in stage 65.0 (TID 78)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:27:36,433 [Executor task launch worker for task 0.0 in stage 65.0 (TID 77)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 77, attempt 0, stage 65.0)
2025-08-10 08:27:36,433 [Executor task launch worker for task 1.0 in stage 65.0 (TID 78)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 78, attempt 0, stage 65.0)
2025-08-10 08:27:36,437 [Executor task launch worker for task 0.0 in stage 65.0 (TID 77)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 65.0 (TID 77). 4073 bytes result sent to driver
2025-08-10 08:27:36,437 [Executor task launch worker for task 1.0 in stage 65.0 (TID 78)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 65.0 (TID 78). 4071 bytes result sent to driver
2025-08-10 08:27:39,356 [block-manager-storage-async-thread-pool-206] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:39,364 [block-manager-storage-async-thread-pool-209] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:39,379 [block-manager-storage-async-thread-pool-221] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:39,384 [block-manager-storage-async-thread-pool-224] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:39,389 [block-manager-storage-async-thread-pool-230] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:39,411 [block-manager-storage-async-thread-pool-246] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:39,420 [block-manager-storage-async-thread-pool-254] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:39,430 [block-manager-storage-async-thread-pool-263] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:39,436 [block-manager-storage-async-thread-pool-266] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:39,451 [block-manager-storage-async-thread-pool-278] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:27:44,479 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 79
2025-08-10 08:27:44,480 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 66.0 (TID 79)
2025-08-10 08:27:44,482 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 257 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:27:44,486 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_257_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 434.4 MiB)
2025-08-10 08:27:44,489 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 257 took 6 ms
2025-08-10 08:27:44,490 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_257 stored as values in memory (estimated size 39.2 KiB, free 434.3 MiB)
2025-08-10 08:27:44,507 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 13.070509 ms
2025-08-10 08:27:44,523 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.162499 ms
2025-08-10 08:27:44,525 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 255 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:27:44,530 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_255_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-10 08:27:44,533 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 255 took 6 ms
2025-08-10 08:27:44,535 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_255 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:27:44,545 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:27:44,551 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:27:44,570 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:27:44,580 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:27:44,602 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.522045 ms
2025-08-10 08:27:44,605 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 256 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:27:44,611 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_256_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 426.2 MiB)
2025-08-10 08:27:44,616 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 256 took 11 ms
2025-08-10 08:27:44,619 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_256 stored as values in memory (estimated size 32.0 KiB, free 426.2 MiB)
2025-08-10 08:27:44,622 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:27:44,631 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:27:44,662 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 79, attempt 0, stage 66.0)
2025-08-10 08:27:44,665 [Executor task launch worker for task 0.0 in stage 66.0 (TID 79)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 66.0 (TID 79). 7805 bytes result sent to driver
2025-08-10 08:28:04,258 [block-manager-storage-async-thread-pool-284] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:04,270 [block-manager-storage-async-thread-pool-293] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:04,402 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 80
2025-08-10 08:28:04,402 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 67.0 (TID 80)
2025-08-10 08:28:04,406 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 276 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,409 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 81
2025-08-10 08:28:04,412 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_276_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
2025-08-10 08:28:04,412 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 68.0 (TID 81)
2025-08-10 08:28:04,415 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 276 took 9 ms
2025-08-10 08:28:04,416 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 277 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,417 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_276 stored as values in memory (estimated size 13.6 KiB, free 434.4 MiB)
2025-08-10 08:28:04,421 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 271 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,421 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_277_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.4 MiB)
2025-08-10 08:28:04,424 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 277 took 8 ms
2025-08-10 08:28:04,426 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_277 stored as values in memory (estimated size 20.5 KiB, free 434.4 MiB)
2025-08-10 08:28:04,427 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_271_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-10 08:28:04,430 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 275 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,430 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 271 took 8 ms
2025-08-10 08:28:04,433 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_271 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:28:04,435 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_275_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:28:04,438 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 275 took 8 ms
2025-08-10 08:28:04,440 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_275 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:28:04,449 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,452 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,455 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,459 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,466 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,469 [Executor task launch worker for task 0.0 in stage 68.0 (TID 81)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 68.0 (TID 81). 5364 bytes result sent to driver
2025-08-10 08:28:04,473 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 82
2025-08-10 08:28:04,474 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 69.0 (TID 82)
2025-08-10 08:28:04,474 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,476 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 278 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,478 [Executor task launch worker for task 0.0 in stage 67.0 (TID 80)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 67.0 (TID 80). 4679 bytes result sent to driver
2025-08-10 08:28:04,481 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_278_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 434.2 MiB)
2025-08-10 08:28:04,482 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 83
2025-08-10 08:28:04,482 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 70.0 (TID 83)
2025-08-10 08:28:04,484 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 278 took 7 ms
2025-08-10 08:28:04,486 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 279 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,486 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_278 stored as values in memory (estimated size 19.9 KiB, free 434.2 MiB)
2025-08-10 08:28:04,489 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 268 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,491 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_279_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.2 MiB)
2025-08-10 08:28:04,494 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_268_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 434.2 MiB)
2025-08-10 08:28:04,494 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 279 took 8 ms
2025-08-10 08:28:04,495 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_279 stored as values in memory (estimated size 14.3 KiB, free 434.2 MiB)
2025-08-10 08:28:04,496 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 268 took 6 ms
2025-08-10 08:28:04,497 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 273 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,498 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_268 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:28:04,503 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_273_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.1 MiB)
2025-08-10 08:28:04,506 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 273 took 7 ms
2025-08-10 08:28:04,510 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_273 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:28:04,510 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,516 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,519 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,526 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,528 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,533 [Executor task launch worker for task 0.0 in stage 70.0 (TID 83)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 70.0 (TID 83). 4679 bytes result sent to driver
2025-08-10 08:28:04,535 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,541 [Executor task launch worker for task 0.0 in stage 69.0 (TID 82)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 69.0 (TID 82). 5364 bytes result sent to driver
2025-08-10 08:28:04,647 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 84
2025-08-10 08:28:04,649 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 85
2025-08-10 08:28:04,649 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 71.0 (TID 84)
2025-08-10 08:28:04,650 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 71.0 (TID 85)
2025-08-10 08:28:04,652 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 299 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,657 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_299_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 434.1 MiB)
2025-08-10 08:28:04,659 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 299 took 6 ms
2025-08-10 08:28:04,660 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_299 stored as values in memory (estimated size 37.9 KiB, free 434.1 MiB)
2025-08-10 08:28:04,663 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 280 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,663 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 290 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,667 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_290_piece0 stored as bytes in memory (estimated size 497.0 B, free 434.1 MiB)
2025-08-10 08:28:04,667 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_280_piece0 stored as bytes in memory (estimated size 1204.0 B, free 434.1 MiB)
2025-08-10 08:28:04,669 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 280 took 5 ms
2025-08-10 08:28:04,672 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_280 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-10 08:28:04,678 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 274 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,678 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 290 took 13 ms
2025-08-10 08:28:04,682 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_290 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:28:04,682 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_274_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.1 MiB)
2025-08-10 08:28:04,685 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 272 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,685 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 274 took 6 ms
2025-08-10 08:28:04,687 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_274 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:28:04,689 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_272_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.0 MiB)
2025-08-10 08:28:04,691 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 272 took 5 ms
2025-08-10 08:28:04,692 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_272 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:28:04,697 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,700 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,702 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,705 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,711 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,715 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,715 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,725 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,726 [Executor task launch worker for task 1.0 in stage 71.0 (TID 85)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 71.0 (TID 85). 7314 bytes result sent to driver
2025-08-10 08:28:04,730 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 86
2025-08-10 08:28:04,730 [Executor task launch worker for task 0.0 in stage 71.0 (TID 84)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 71.0 (TID 84). 7271 bytes result sent to driver
2025-08-10 08:28:04,730 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 72.0 (TID 86)
2025-08-10 08:28:04,732 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 300 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,733 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 87
2025-08-10 08:28:04,734 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 72.0 (TID 87)
2025-08-10 08:28:04,736 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_300_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 418.0 MiB)
2025-08-10 08:28:04,738 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 300 took 5 ms
2025-08-10 08:28:04,739 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_300 stored as values in memory (estimated size 33.7 KiB, free 417.9 MiB)
2025-08-10 08:28:04,742 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 282 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,742 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 292 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,745 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_292_piece0 stored as bytes in memory (estimated size 1204.0 B, free 417.9 MiB)
2025-08-10 08:28:04,745 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_282_piece0 stored as bytes in memory (estimated size 497.0 B, free 417.9 MiB)
2025-08-10 08:28:04,747 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 292 took 5 ms
2025-08-10 08:28:04,747 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 282 took 5 ms
2025-08-10 08:28:04,750 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_292 stored as values in memory (estimated size 8.0 MiB, free 409.9 MiB)
2025-08-10 08:28:04,750 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_282 stored as values in memory (estimated size 8.0 MiB, free 401.9 MiB)
2025-08-10 08:28:04,751 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 270 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,751 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 269 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,755 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_270_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 401.9 MiB)
2025-08-10 08:28:04,756 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_269_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 401.9 MiB)
2025-08-10 08:28:04,757 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 270 took 5 ms
2025-08-10 08:28:04,757 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 269 took 5 ms
2025-08-10 08:28:04,758 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_269 stored as values in memory (estimated size 32.0 KiB, free 401.8 MiB)
2025-08-10 08:28:04,758 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_270 stored as values in memory (estimated size 32.0 KiB, free 401.8 MiB)
2025-08-10 08:28:04,767 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,767 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:04,773 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,773 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:04,780 [Executor task launch worker for task 1.0 in stage 72.0 (TID 87)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 72.0 (TID 87). 7163 bytes result sent to driver
2025-08-10 08:28:04,781 [Executor task launch worker for task 0.0 in stage 72.0 (TID 86)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 72.0 (TID 86). 7163 bytes result sent to driver
2025-08-10 08:28:04,803 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 88
2025-08-10 08:28:04,804 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 73.0 (TID 88)
2025-08-10 08:28:04,805 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 15 and clearing cache
2025-08-10 08:28:04,806 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 304 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,809 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_304_piece0 stored as bytes in memory (estimated size 3.8 KiB, free 401.8 MiB)
2025-08-10 08:28:04,810 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 304 took 4 ms
2025-08-10 08:28:04,811 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_304 stored as values in memory (estimated size 6.5 KiB, free 401.8 MiB)
2025-08-10 08:28:04,813 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 303 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:04,816 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_303_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 401.8 MiB)
2025-08-10 08:28:04,818 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 303 took 5 ms
2025-08-10 08:28:04,819 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_303 stored as values in memory (estimated size 32.0 KiB, free 401.7 MiB)
2025-08-10 08:28:04,821 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:28:04,822 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:28:04,838 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 88, attempt 0, stage 73.0)
2025-08-10 08:28:04,840 [Executor task launch worker for task 0.0 in stage 73.0 (TID 88)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 73.0 (TID 88). 1168 bytes result sent to driver
2025-08-10 08:28:40,637 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 89
2025-08-10 08:28:40,638 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 90
2025-08-10 08:28:40,638 [Executor task launch worker for task 0.0 in stage 74.0 (TID 89)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 74.0 (TID 89)
2025-08-10 08:28:40,639 [Executor task launch worker for task 1.0 in stage 74.0 (TID 90)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 74.0 (TID 90)
2025-08-10 08:28:40,640 [Executor task launch worker for task 0.0 in stage 74.0 (TID 89)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 306 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:40,643 [Executor task launch worker for task 0.0 in stage 74.0 (TID 89)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_306_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 401.7 MiB)
2025-08-10 08:28:40,645 [Executor task launch worker for task 0.0 in stage 74.0 (TID 89)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 306 took 4 ms
2025-08-10 08:28:40,646 [Executor task launch worker for task 0.0 in stage 74.0 (TID 89)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_306 stored as values in memory (estimated size 8.0 KiB, free 401.7 MiB)
2025-08-10 08:28:40,647 [Executor task launch worker for task 1.0 in stage 74.0 (TID 90)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 305 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:40,651 [Executor task launch worker for task 1.0 in stage 74.0 (TID 90)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_305_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 401.7 MiB)
2025-08-10 08:28:40,653 [Executor task launch worker for task 1.0 in stage 74.0 (TID 90)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 305 took 5 ms
2025-08-10 08:28:40,655 [Executor task launch worker for task 1.0 in stage 74.0 (TID 90)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_305 stored as values in memory (estimated size 32.0 KiB, free 401.7 MiB)
2025-08-10 08:28:40,657 [Executor task launch worker for task 0.0 in stage 74.0 (TID 89)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:28:40,657 [Executor task launch worker for task 1.0 in stage 74.0 (TID 90)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:28:40,658 [Executor task launch worker for task 0.0 in stage 74.0 (TID 89)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:28:40,658 [Executor task launch worker for task 1.0 in stage 74.0 (TID 90)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:28:40,677 [Executor task launch worker for task 0.0 in stage 74.0 (TID 89)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 89, attempt 0, stage 74.0)
2025-08-10 08:28:40,679 [Executor task launch worker for task 0.0 in stage 74.0 (TID 89)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 74.0 (TID 89). 4072 bytes result sent to driver
2025-08-10 08:28:40,725 [Executor task launch worker for task 1.0 in stage 74.0 (TID 90)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 90, attempt 0, stage 74.0)
2025-08-10 08:28:40,727 [Executor task launch worker for task 1.0 in stage 74.0 (TID 90)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 74.0 (TID 90). 4071 bytes result sent to driver
2025-08-10 08:28:48,581 [block-manager-storage-async-thread-pool-306] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:48,601 [block-manager-storage-async-thread-pool-315] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:49,006 [block-manager-storage-async-thread-pool-324] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:49,016 [block-manager-storage-async-thread-pool-327] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:49,044 [block-manager-storage-async-thread-pool-336] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:49,065 [block-manager-storage-async-thread-pool-345] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:49,074 [block-manager-storage-async-thread-pool-348] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:49,083 [block-manager-storage-async-thread-pool-351] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:49,093 [block-manager-storage-async-thread-pool-357] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:49,107 [block-manager-storage-async-thread-pool-363] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:28:49,184 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 91
2025-08-10 08:28:49,185 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 75.0 (TID 91)
2025-08-10 08:28:49,189 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 325 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,194 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 92
2025-08-10 08:28:49,196 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 76.0 (TID 92)
2025-08-10 08:28:49,197 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_325_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
2025-08-10 08:28:49,199 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 326 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,202 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 325 took 12 ms
2025-08-10 08:28:49,203 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_325 stored as values in memory (estimated size 13.6 KiB, free 434.4 MiB)
2025-08-10 08:28:49,206 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_326_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 434.4 MiB)
2025-08-10 08:28:49,207 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 320 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,208 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 326 took 8 ms
2025-08-10 08:28:49,210 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_326 stored as values in memory (estimated size 19.9 KiB, free 434.4 MiB)
2025-08-10 08:28:49,213 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_320_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.3 MiB)
2025-08-10 08:28:49,215 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 317 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,217 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 320 took 9 ms
2025-08-10 08:28:49,220 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_320 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:28:49,223 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_317_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 434.3 MiB)
2025-08-10 08:28:49,227 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 317 took 11 ms
2025-08-10 08:28:49,229 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_317 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:28:49,238 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,243 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,248 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,255 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,261 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,267 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,267 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,272 [Executor task launch worker for task 0.0 in stage 75.0 (TID 91)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 75.0 (TID 91). 4674 bytes result sent to driver
2025-08-10 08:28:49,275 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,276 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 93
2025-08-10 08:28:49,277 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 77.0 (TID 93)
2025-08-10 08:28:49,281 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 327 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,283 [Executor task launch worker for task 0.0 in stage 76.0 (TID 92)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 76.0 (TID 92). 5319 bytes result sent to driver
2025-08-10 08:28:49,297 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 94
2025-08-10 08:28:49,297 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_327_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.2 MiB)
2025-08-10 08:28:49,302 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 78.0 (TID 94)
2025-08-10 08:28:49,306 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 327 took 24 ms
2025-08-10 08:28:49,306 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 328 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,307 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_327 stored as values in memory (estimated size 14.3 KiB, free 434.2 MiB)
2025-08-10 08:28:49,312 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 322 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,313 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_328_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.2 MiB)
2025-08-10 08:28:49,322 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 328 took 15 ms
2025-08-10 08:28:49,322 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_322_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.2 MiB)
2025-08-10 08:28:49,324 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_328 stored as values in memory (estimated size 20.5 KiB, free 434.2 MiB)
2025-08-10 08:28:49,330 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 322 took 16 ms
2025-08-10 08:28:49,332 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 324 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,334 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_322 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:28:49,340 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_324_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.1 MiB)
2025-08-10 08:28:49,346 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 324 took 12 ms
2025-08-10 08:28:49,350 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_324 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:28:49,351 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,360 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,364 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,369 [Executor task launch worker for task 0.0 in stage 77.0 (TID 93)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 77.0 (TID 93). 4679 bytes result sent to driver
2025-08-10 08:28:49,376 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,394 [Executor task launch worker for task 0.0 in stage 78.0 (TID 94)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 78.0 (TID 94). 5364 bytes result sent to driver
2025-08-10 08:28:49,547 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 95
2025-08-10 08:28:49,548 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 96
2025-08-10 08:28:49,548 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 79.0 (TID 95)
2025-08-10 08:28:49,549 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 79.0 (TID 96)
2025-08-10 08:28:49,552 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 346 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,557 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_346_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 434.1 MiB)
2025-08-10 08:28:49,559 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 346 took 6 ms
2025-08-10 08:28:49,560 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_346 stored as values in memory (estimated size 33.7 KiB, free 434.1 MiB)
2025-08-10 08:28:49,563 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 331 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,563 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 329 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,567 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_329_piece0 stored as bytes in memory (estimated size 479.0 B, free 434.1 MiB)
2025-08-10 08:28:49,567 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_331_piece0 stored as bytes in memory (estimated size 1140.0 B, free 434.1 MiB)
2025-08-10 08:28:49,570 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 329 took 6 ms
2025-08-10 08:28:49,570 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 331 took 7 ms
2025-08-10 08:28:49,575 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_331 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:28:49,575 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_329 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:28:49,577 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 319 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,577 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 318 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,582 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_318_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 418.1 MiB)
2025-08-10 08:28:49,582 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_319_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 418.1 MiB)
2025-08-10 08:28:49,586 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 318 took 9 ms
2025-08-10 08:28:49,587 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 319 took 9 ms
2025-08-10 08:28:49,590 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_318 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:28:49,590 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_319 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:28:49,600 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,600 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,607 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,607 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,615 [Executor task launch worker for task 1.0 in stage 79.0 (TID 96)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 79.0 (TID 96). 7194 bytes result sent to driver
2025-08-10 08:28:49,616 [Executor task launch worker for task 0.0 in stage 79.0 (TID 95)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 79.0 (TID 95). 7193 bytes result sent to driver
2025-08-10 08:28:49,619 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 97
2025-08-10 08:28:49,620 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 80.0 (TID 97)
2025-08-10 08:28:49,620 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 98
2025-08-10 08:28:49,621 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 80.0 (TID 98)
2025-08-10 08:28:49,623 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 347 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,630 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_347_piece0 stored as bytes in memory (estimated size 12.6 KiB, free 418.0 MiB)
2025-08-10 08:28:49,633 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 347 took 9 ms
2025-08-10 08:28:49,634 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_347 stored as values in memory (estimated size 37.9 KiB, free 417.9 MiB)
2025-08-10 08:28:49,639 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 337 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,639 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 340 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,643 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_340_piece0 stored as bytes in memory (estimated size 1204.0 B, free 417.9 MiB)
2025-08-10 08:28:49,643 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_337_piece0 stored as bytes in memory (estimated size 497.0 B, free 417.9 MiB)
2025-08-10 08:28:49,646 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 337 took 6 ms
2025-08-10 08:28:49,646 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 340 took 6 ms
2025-08-10 08:28:49,657 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_340 stored as values in memory (estimated size 8.0 MiB, free 409.9 MiB)
2025-08-10 08:28:49,657 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_337 stored as values in memory (estimated size 8.0 MiB, free 401.9 MiB)
2025-08-10 08:28:49,659 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 323 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,659 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 321 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,663 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_321_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 401.9 MiB)
2025-08-10 08:28:49,663 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_323_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 401.9 MiB)
2025-08-10 08:28:49,665 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 321 took 6 ms
2025-08-10 08:28:49,666 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 323 took 6 ms
2025-08-10 08:28:49,667 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_321 stored as values in memory (estimated size 32.0 KiB, free 401.8 MiB)
2025-08-10 08:28:49,667 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_323 stored as values in memory (estimated size 32.0 KiB, free 401.8 MiB)
2025-08-10 08:28:49,679 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,679 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,687 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,688 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,701 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,701 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,707 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,707 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,712 [Executor task launch worker for task 0.0 in stage 80.0 (TID 97)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 80.0 (TID 97). 7271 bytes result sent to driver
2025-08-10 08:28:49,713 [Executor task launch worker for task 1.0 in stage 80.0 (TID 98)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 80.0 (TID 98). 7400 bytes result sent to driver
2025-08-10 08:28:49,748 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 99
2025-08-10 08:28:49,749 [Executor task launch worker for task 0.0 in stage 81.0 (TID 99)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 81.0 (TID 99)
2025-08-10 08:28:49,750 [Executor task launch worker for task 0.0 in stage 81.0 (TID 99)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 16 and clearing cache
2025-08-10 08:28:49,751 [Executor task launch worker for task 0.0 in stage 81.0 (TID 99)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 351 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,754 [Executor task launch worker for task 0.0 in stage 81.0 (TID 99)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_351_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 401.8 MiB)
2025-08-10 08:28:49,756 [Executor task launch worker for task 0.0 in stage 81.0 (TID 99)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 351 took 4 ms
2025-08-10 08:28:49,757 [Executor task launch worker for task 0.0 in stage 81.0 (TID 99)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_351 stored as values in memory (estimated size 11.7 KiB, free 401.8 MiB)
2025-08-10 08:28:49,760 [Executor task launch worker for task 0.0 in stage 81.0 (TID 99)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 81.0 (TID 99). 1836 bytes result sent to driver
2025-08-10 08:28:49,779 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 100
2025-08-10 08:28:49,779 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 83.0 (TID 100)
2025-08-10 08:28:49,780 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 17 and clearing cache
2025-08-10 08:28:49,781 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 352 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,784 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_352_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 401.8 MiB)
2025-08-10 08:28:49,786 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 352 took 4 ms
2025-08-10 08:28:49,787 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_352 stored as values in memory (estimated size 12.7 KiB, free 401.8 MiB)
2025-08-10 08:28:49,788 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 11, fetching them
2025-08-10 08:28:49,789 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:28:49,792 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:28:49,793 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:28:49,793 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:28:49,795 [Executor task launch worker for task 0.0 in stage 83.0 (TID 100)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 83.0 (TID 100). 3959 bytes result sent to driver
2025-08-10 08:28:49,825 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 101
2025-08-10 08:28:49,825 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 102
2025-08-10 08:28:49,825 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 85.0 (TID 101)
2025-08-10 08:28:49,826 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 85.0 (TID 102)
2025-08-10 08:28:49,827 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 354 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,830 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_354_piece0 stored as bytes in memory (estimated size 30.1 KiB, free 401.8 MiB)
2025-08-10 08:28:49,832 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 354 took 5 ms
2025-08-10 08:28:49,833 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_354 stored as values in memory (estimated size 82.1 KiB, free 401.7 MiB)
2025-08-10 08:28:49,838 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 10, fetching them
2025-08-10 08:28:49,838 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:28:49,838 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 348 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,841 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:28:49,841 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_348_piece0 stored as bytes in memory (estimated size 197.0 B, free 401.7 MiB)
2025-08-10 08:28:49,842 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:28:49,842 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 08:28:49,843 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 348 took 4 ms
2025-08-10 08:28:49,846 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_348 stored as values in memory (estimated size 8.0 MiB, free 393.7 MiB)
2025-08-10 08:28:49,846 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 353 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,850 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_353_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.6 MiB)
2025-08-10 08:28:49,853 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 353 took 6 ms
2025-08-10 08:28:49,854 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_353 stored as values in memory (estimated size 32.0 KiB, free 393.6 MiB)
2025-08-10 08:28:49,856 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:28:49,858 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:28:49,858 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 316 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:28:49,858 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:28:49,862 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_316_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.6 MiB)
2025-08-10 08:28:49,864 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 316 took 5 ms
2025-08-10 08:28:49,865 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_316 stored as values in memory (estimated size 32.0 KiB, free 393.6 MiB)
2025-08-10 08:28:49,874 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:28:49,881 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:28:49,886 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 101, attempt 0, stage 85.0)
2025-08-10 08:28:49,887 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:28:49,888 [Executor task launch worker for task 1.0 in stage 85.0 (TID 101)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 85.0 (TID 101). 20959 bytes result sent to driver
2025-08-10 08:28:49,907 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 102, attempt 0, stage 85.0)
2025-08-10 08:28:49,909 [Executor task launch worker for task 0.0 in stage 85.0 (TID 102)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 85.0 (TID 102). 20348 bytes result sent to driver
2025-08-10 08:32:27,767 [block-manager-storage-async-thread-pool-391] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:32:28,342 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 103
2025-08-10 08:32:28,343 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 104
2025-08-10 08:32:28,343 [Executor task launch worker for task 0.0 in stage 86.0 (TID 103)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 86.0 (TID 103)
2025-08-10 08:32:28,344 [Executor task launch worker for task 1.0 in stage 86.0 (TID 104)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 86.0 (TID 104)
2025-08-10 08:32:28,346 [Executor task launch worker for task 0.0 in stage 86.0 (TID 103)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 356 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:32:28,352 [Executor task launch worker for task 0.0 in stage 86.0 (TID 103)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_356_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 393.8 MiB)
2025-08-10 08:32:28,355 [Executor task launch worker for task 0.0 in stage 86.0 (TID 103)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 356 took 8 ms
2025-08-10 08:32:28,356 [Executor task launch worker for task 0.0 in stage 86.0 (TID 103)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_356 stored as values in memory (estimated size 8.0 KiB, free 393.8 MiB)
2025-08-10 08:32:28,359 [Executor task launch worker for task 1.0 in stage 86.0 (TID 104)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 355 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:32:28,364 [Executor task launch worker for task 1.0 in stage 86.0 (TID 104)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_355_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 393.8 MiB)
2025-08-10 08:32:28,385 [Executor task launch worker for task 1.0 in stage 86.0 (TID 104)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 355 took 26 ms
2025-08-10 08:32:28,385 [block-manager-storage-async-thread-pool-415] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:32:28,388 [Executor task launch worker for task 1.0 in stage 86.0 (TID 104)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_355 stored as values in memory (estimated size 32.0 KiB, free 393.8 MiB)
2025-08-10 08:32:28,391 [Executor task launch worker for task 0.0 in stage 86.0 (TID 103)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:32:28,391 [Executor task launch worker for task 1.0 in stage 86.0 (TID 104)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:32:28,393 [Executor task launch worker for task 1.0 in stage 86.0 (TID 104)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:32:28,393 [Executor task launch worker for task 0.0 in stage 86.0 (TID 103)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:32:28,420 [block-manager-storage-async-thread-pool-433] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:32:28,426 [block-manager-storage-async-thread-pool-436] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:32:28,427 [Executor task launch worker for task 1.0 in stage 86.0 (TID 104)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 104, attempt 0, stage 86.0)
2025-08-10 08:32:28,427 [Executor task launch worker for task 0.0 in stage 86.0 (TID 103)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 103, attempt 0, stage 86.0)
2025-08-10 08:32:28,429 [Executor task launch worker for task 0.0 in stage 86.0 (TID 103)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 86.0 (TID 103). 4074 bytes result sent to driver
2025-08-10 08:32:28,429 [Executor task launch worker for task 1.0 in stage 86.0 (TID 104)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 86.0 (TID 104). 4072 bytes result sent to driver
2025-08-10 08:32:28,439 [block-manager-storage-async-thread-pool-445] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:32:28,447 [block-manager-storage-async-thread-pool-448] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:32:28,461 [block-manager-storage-async-thread-pool-451] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:32:28,495 [block-manager-storage-async-thread-pool-372] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:32:28,499 [block-manager-storage-async-thread-pool-375] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:32:28,507 [block-manager-storage-async-thread-pool-381] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:32:36,775 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 105
2025-08-10 08:32:36,775 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 87.0 (TID 105)
2025-08-10 08:32:36,777 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 360 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:32:36,780 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_360_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 434.3 MiB)
2025-08-10 08:32:36,782 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 360 took 4 ms
2025-08-10 08:32:36,782 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_360 stored as values in memory (estimated size 39.2 KiB, free 434.3 MiB)
2025-08-10 08:32:36,792 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 358 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:32:36,796 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_358_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.2 MiB)
2025-08-10 08:32:36,798 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 358 took 5 ms
2025-08-10 08:32:36,799 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_358 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:32:36,808 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:32:36,813 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:32:36,824 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:32:36,829 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:32:36,836 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 359 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:32:36,840 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_359_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 426.1 MiB)
2025-08-10 08:32:36,842 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 359 took 6 ms
2025-08-10 08:32:36,844 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_359 stored as values in memory (estimated size 32.0 KiB, free 426.1 MiB)
2025-08-10 08:32:36,846 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:32:36,849 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:32:36,868 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 105, attempt 0, stage 87.0)
2025-08-10 08:32:36,870 [Executor task launch worker for task 0.0 in stage 87.0 (TID 105)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 87.0 (TID 105). 7806 bytes result sent to driver
2025-08-10 08:32:53,164 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 106
2025-08-10 08:32:53,165 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 107
2025-08-10 08:32:53,165 [Executor task launch worker for task 0.0 in stage 88.0 (TID 106)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 88.0 (TID 106)
2025-08-10 08:32:53,166 [Executor task launch worker for task 1.0 in stage 88.0 (TID 107)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 88.0 (TID 107)
2025-08-10 08:32:53,168 [Executor task launch worker for task 0.0 in stage 88.0 (TID 106)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 362 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:32:53,173 [Executor task launch worker for task 0.0 in stage 88.0 (TID 106)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_362_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.1 MiB)
2025-08-10 08:32:53,176 [Executor task launch worker for task 0.0 in stage 88.0 (TID 106)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 362 took 7 ms
2025-08-10 08:32:53,177 [Executor task launch worker for task 0.0 in stage 88.0 (TID 106)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_362 stored as values in memory (estimated size 8.0 KiB, free 434.1 MiB)
2025-08-10 08:32:53,180 [Executor task launch worker for task 1.0 in stage 88.0 (TID 107)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 361 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:32:53,185 [Executor task launch worker for task 1.0 in stage 88.0 (TID 107)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_361_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.1 MiB)
2025-08-10 08:32:53,187 [Executor task launch worker for task 1.0 in stage 88.0 (TID 107)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 361 took 6 ms
2025-08-10 08:32:53,189 [Executor task launch worker for task 1.0 in stage 88.0 (TID 107)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_361 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:32:53,192 [Executor task launch worker for task 0.0 in stage 88.0 (TID 106)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:32:53,192 [Executor task launch worker for task 1.0 in stage 88.0 (TID 107)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:32:53,193 [Executor task launch worker for task 0.0 in stage 88.0 (TID 106)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:32:53,193 [Executor task launch worker for task 1.0 in stage 88.0 (TID 107)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:32:53,212 [Executor task launch worker for task 0.0 in stage 88.0 (TID 106)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 106, attempt 0, stage 88.0)
2025-08-10 08:32:53,213 [Executor task launch worker for task 0.0 in stage 88.0 (TID 106)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 88.0 (TID 106). 4073 bytes result sent to driver
2025-08-10 08:32:53,237 [Executor task launch worker for task 1.0 in stage 88.0 (TID 107)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 107, attempt 0, stage 88.0)
2025-08-10 08:32:53,239 [Executor task launch worker for task 1.0 in stage 88.0 (TID 107)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 88.0 (TID 107). 4072 bytes result sent to driver
2025-08-10 08:33:01,110 [block-manager-storage-async-thread-pool-396] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:33:01,123 [block-manager-storage-async-thread-pool-405] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:33:01,127 [block-manager-storage-async-thread-pool-408] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:33:01,131 [block-manager-storage-async-thread-pool-411] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:33:02,916 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 108
2025-08-10 08:33:02,918 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 89.0 (TID 108)
2025-08-10 08:33:02,920 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 445 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:02,924 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 109
2025-08-10 08:33:02,925 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_445_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.4 MiB)
2025-08-10 08:33:02,925 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 90.0 (TID 109)
2025-08-10 08:33:02,927 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 445 took 6 ms
2025-08-10 08:33:02,928 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 446 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:02,928 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_445 stored as values in memory (estimated size 14.3 KiB, free 434.4 MiB)
2025-08-10 08:33:02,932 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_446_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
2025-08-10 08:33:02,938 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 446 took 9 ms
2025-08-10 08:33:02,942 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_446 stored as values in memory (estimated size 13.6 KiB, free 434.4 MiB)
2025-08-10 08:33:02,942 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.393466 ms
2025-08-10 08:33:02,945 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 408 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:02,950 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_408_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:33:02,953 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.478147 ms
2025-08-10 08:33:02,954 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 408 took 7 ms
2025-08-10 08:33:02,956 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 401 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:02,956 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_408 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:33:02,960 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_401_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 434.3 MiB)
2025-08-10 08:33:02,962 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 401 took 6 ms
2025-08-10 08:33:02,964 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_401 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:33:02,967 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:02,974 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:02,975 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:02,982 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:02,986 [Executor task launch worker for task 0.0 in stage 89.0 (TID 108)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 89.0 (TID 108). 4679 bytes result sent to driver
2025-08-10 08:33:02,995 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:02,996 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 110
2025-08-10 08:33:02,997 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 91.0 (TID 110)
2025-08-10 08:33:03,001 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 447 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,005 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,008 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_447_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 434.2 MiB)
2025-08-10 08:33:03,010 [Executor task launch worker for task 0.0 in stage 90.0 (TID 109)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 90.0 (TID 109). 4674 bytes result sent to driver
2025-08-10 08:33:03,011 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 447 took 9 ms
2025-08-10 08:33:03,012 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_447 stored as values in memory (estimated size 19.9 KiB, free 434.2 MiB)
2025-08-10 08:33:03,015 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 111
2025-08-10 08:33:03,016 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 92.0 (TID 111)
2025-08-10 08:33:03,021 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 448 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,038 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_448_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.2 MiB)
2025-08-10 08:33:03,047 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 448 took 25 ms
2025-08-10 08:33:03,048 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_448 stored as values in memory (estimated size 20.5 KiB, free 434.2 MiB)
2025-08-10 08:33:03,049 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 34.071388 ms
2025-08-10 08:33:03,052 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 398 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,069 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_398_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.2 MiB)
2025-08-10 08:33:03,075 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 398 took 15 ms
2025-08-10 08:33:03,079 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_398 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:33:03,084 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 33.120984 ms
2025-08-10 08:33:03,090 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 410 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,097 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,106 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_410_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.1 MiB)
2025-08-10 08:33:03,111 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 410 took 17 ms
2025-08-10 08:33:03,113 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,114 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_410 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:33:03,136 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,138 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,154 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,156 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,164 [Executor task launch worker for task 0.0 in stage 91.0 (TID 110)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 91.0 (TID 110). 5319 bytes result sent to driver
2025-08-10 08:33:03,167 [Executor task launch worker for task 0.0 in stage 92.0 (TID 111)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 92.0 (TID 111). 5364 bytes result sent to driver
2025-08-10 08:33:03,352 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 112
2025-08-10 08:33:03,352 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 113
2025-08-10 08:33:03,353 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 93.0 (TID 112)
2025-08-10 08:33:03,354 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 93.0 (TID 113)
2025-08-10 08:33:03,356 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 473 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,360 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_473_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 434.1 MiB)
2025-08-10 08:33:03,362 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 473 took 6 ms
2025-08-10 08:33:03,364 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_473 stored as values in memory (estimated size 35.1 KiB, free 434.1 MiB)
2025-08-10 08:33:03,375 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 9.429243 ms
2025-08-10 08:33:03,378 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 449 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,381 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.517192 ms
2025-08-10 08:33:03,383 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_449_piece0 stored as bytes in memory (estimated size 497.0 B, free 434.1 MiB)
2025-08-10 08:33:03,383 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 461 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,386 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 449 took 7 ms
2025-08-10 08:33:03,387 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_461_piece0 stored as bytes in memory (estimated size 1140.0 B, free 434.1 MiB)
2025-08-10 08:33:03,388 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_449 stored as values in memory (estimated size 8.0 MiB, free 426.1 MiB)
2025-08-10 08:33:03,392 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 461 took 9 ms
2025-08-10 08:33:03,392 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 439 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,395 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_461 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:33:03,396 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 442 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,397 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_439_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.1 MiB)
2025-08-10 08:33:03,399 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 439 took 5 ms
2025-08-10 08:33:03,400 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_439 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:33:03,401 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_442_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 418.0 MiB)
2025-08-10 08:33:03,405 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 442 took 7 ms
2025-08-10 08:33:03,408 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_442 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:33:03,411 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,417 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,420 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,426 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,429 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,441 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,442 [Executor task launch worker for task 1.0 in stage 93.0 (TID 113)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 93.0 (TID 113). 7443 bytes result sent to driver
2025-08-10 08:33:03,445 [Executor task launch worker for task 0.0 in stage 93.0 (TID 112)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 93.0 (TID 112). 7271 bytes result sent to driver
2025-08-10 08:33:03,446 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 114
2025-08-10 08:33:03,447 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 94.0 (TID 114)
2025-08-10 08:33:03,448 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 115
2025-08-10 08:33:03,449 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 94.0 (TID 115)
2025-08-10 08:33:03,450 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 474 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,459 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_474_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 418.0 MiB)
2025-08-10 08:33:03,461 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 474 took 6 ms
2025-08-10 08:33:03,463 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_474 stored as values in memory (estimated size 33.7 KiB, free 417.9 MiB)
2025-08-10 08:33:03,475 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.126951 ms
2025-08-10 08:33:03,478 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 451 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,483 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_451_piece0 stored as bytes in memory (estimated size 479.0 B, free 417.9 MiB)
2025-08-10 08:33:03,485 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 20.338678 ms
2025-08-10 08:33:03,487 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 451 took 9 ms
2025-08-10 08:33:03,488 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 431 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,490 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_451 stored as values in memory (estimated size 8.0 MiB, free 409.9 MiB)
2025-08-10 08:33:03,493 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 432 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,494 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_431_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.9 MiB)
2025-08-10 08:33:03,496 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 431 took 8 ms
2025-08-10 08:33:03,498 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_432_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.9 MiB)
2025-08-10 08:33:03,499 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_431 stored as values in memory (estimated size 32.0 KiB, free 409.9 MiB)
2025-08-10 08:33:03,503 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 432 took 9 ms
2025-08-10 08:33:03,505 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_432 stored as values in memory (estimated size 32.0 KiB, free 409.8 MiB)
2025-08-10 08:33:03,510 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,515 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,515 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,523 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,523 [Executor task launch worker for task 0.0 in stage 94.0 (TID 114)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 94.0 (TID 114). 7193 bytes result sent to driver
2025-08-10 08:33:03,529 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 116
2025-08-10 08:33:03,530 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 95.0 (TID 116)
2025-08-10 08:33:03,533 [Executor task launch worker for task 1.0 in stage 94.0 (TID 115)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 94.0 (TID 115). 7194 bytes result sent to driver
2025-08-10 08:33:03,533 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 475 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,537 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 117
2025-08-10 08:33:03,539 [Executor task launch worker for task 1.0 in stage 95.0 (TID 117)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 95.0 (TID 117)
2025-08-10 08:33:03,539 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_475_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 409.8 MiB)
2025-08-10 08:33:03,542 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 475 took 8 ms
2025-08-10 08:33:03,543 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_475 stored as values in memory (estimated size 33.7 KiB, free 409.8 MiB)
2025-08-10 08:33:03,557 [Executor task launch worker for task 1.0 in stage 95.0 (TID 117)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.642829 ms
2025-08-10 08:33:03,560 [Executor task launch worker for task 1.0 in stage 95.0 (TID 117)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 437 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,566 [Executor task launch worker for task 1.0 in stage 95.0 (TID 117)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_437_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.8 MiB)
2025-08-10 08:33:03,566 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 20.365603 ms
2025-08-10 08:33:03,568 [Executor task launch worker for task 1.0 in stage 95.0 (TID 117)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 437 took 7 ms
2025-08-10 08:33:03,569 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 436 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,572 [Executor task launch worker for task 1.0 in stage 95.0 (TID 117)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_437 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 08:33:03,576 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_436_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.7 MiB)
2025-08-10 08:33:03,579 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 436 took 10 ms
2025-08-10 08:33:03,582 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_436 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 08:33:03,587 [Executor task launch worker for task 1.0 in stage 95.0 (TID 117)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,595 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,595 [Executor task launch worker for task 1.0 in stage 95.0 (TID 117)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,602 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,604 [Executor task launch worker for task 1.0 in stage 95.0 (TID 117)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 95.0 (TID 117). 7194 bytes result sent to driver
2025-08-10 08:33:03,613 [Executor task launch worker for task 0.0 in stage 95.0 (TID 116)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 95.0 (TID 116). 7193 bytes result sent to driver
2025-08-10 08:33:03,695 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 118
2025-08-10 08:33:03,696 [Executor task launch worker for task 0.0 in stage 96.0 (TID 118)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 96.0 (TID 118)
2025-08-10 08:33:03,697 [Executor task launch worker for task 0.0 in stage 96.0 (TID 118)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 18 and clearing cache
2025-08-10 08:33:03,699 [Executor task launch worker for task 0.0 in stage 96.0 (TID 118)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 490 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,704 [Executor task launch worker for task 0.0 in stage 96.0 (TID 118)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_490_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 409.7 MiB)
2025-08-10 08:33:03,707 [Executor task launch worker for task 0.0 in stage 96.0 (TID 118)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 490 took 7 ms
2025-08-10 08:33:03,708 [Executor task launch worker for task 0.0 in stage 96.0 (TID 118)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_490 stored as values in memory (estimated size 11.7 KiB, free 409.7 MiB)
2025-08-10 08:33:03,714 [Executor task launch worker for task 0.0 in stage 96.0 (TID 118)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 96.0 (TID 118). 1836 bytes result sent to driver
2025-08-10 08:33:03,742 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 119
2025-08-10 08:33:03,744 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 98.0 (TID 119)
2025-08-10 08:33:03,745 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 19 and clearing cache
2025-08-10 08:33:03,746 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 491 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,750 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_491_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 409.8 MiB)
2025-08-10 08:33:03,752 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 491 took 5 ms
2025-08-10 08:33:03,753 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_491 stored as values in memory (estimated size 12.7 KiB, free 409.8 MiB)
2025-08-10 08:33:03,755 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 13, fetching them
2025-08-10 08:33:03,755 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:33:03,757 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:33:03,759 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:33:03,759 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:33:03,762 [Executor task launch worker for task 0.0 in stage 98.0 (TID 119)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 98.0 (TID 119). 3959 bytes result sent to driver
2025-08-10 08:33:03,811 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 120
2025-08-10 08:33:03,812 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 121
2025-08-10 08:33:03,812 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 100.0 (TID 120)
2025-08-10 08:33:03,812 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 100.0 (TID 121)
2025-08-10 08:33:03,813 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 492 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,817 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_492_piece0 stored as bytes in memory (estimated size 27.9 KiB, free 409.7 MiB)
2025-08-10 08:33:03,818 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 492 took 4 ms
2025-08-10 08:33:03,819 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_492 stored as values in memory (estimated size 81.0 KiB, free 409.7 MiB)
2025-08-10 08:33:03,825 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 12, fetching them
2025-08-10 08:33:03,825 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:33:03,828 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:33:03,830 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:33:03,830 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:33:03,832 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.039689 ms
2025-08-10 08:33:03,834 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 480 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,838 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.573826 ms
2025-08-10 08:33:03,839 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_480_piece0 stored as bytes in memory (estimated size 197.0 B, free 409.7 MiB)
2025-08-10 08:33:03,842 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 480 took 8 ms
2025-08-10 08:33:03,845 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_480 stored as values in memory (estimated size 8.0 MiB, free 401.6 MiB)
2025-08-10 08:33:03,847 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 429 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,851 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.207812 ms
2025-08-10 08:33:03,853 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_429_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 401.6 MiB)
2025-08-10 08:33:03,857 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 429 took 9 ms
2025-08-10 08:33:03,859 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_429 stored as values in memory (estimated size 32.0 KiB, free 401.6 MiB)
2025-08-10 08:33:03,869 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.873568 ms
2025-08-10 08:33:03,871 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,873 [Executor task launch worker for task 2.0 in stage 100.0 (TID 120)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 100.0 (TID 120). 20497 bytes result sent to driver
2025-08-10 08:33:03,878 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 122
2025-08-10 08:33:03,879 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,879 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 100.0 (TID 122)
2025-08-10 08:33:03,887 [Executor task launch worker for task 0.0 in stage 100.0 (TID 121)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 100.0 (TID 121). 19859 bytes result sent to driver
2025-08-10 08:33:03,896 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.889128 ms
2025-08-10 08:33:03,899 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 485 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,905 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_485_piece0 stored as bytes in memory (estimated size 197.0 B, free 401.6 MiB)
2025-08-10 08:33:03,907 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 485 took 7 ms
2025-08-10 08:33:03,909 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_485 stored as values in memory (estimated size 8.0 MiB, free 393.6 MiB)
2025-08-10 08:33:03,911 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 434 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:03,918 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_434_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.6 MiB)
2025-08-10 08:33:03,921 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 434 took 9 ms
2025-08-10 08:33:03,923 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_434 stored as values in memory (estimated size 32.0 KiB, free 393.5 MiB)
2025-08-10 08:33:03,936 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:03,944 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:03,952 [Executor task launch worker for task 1.0 in stage 100.0 (TID 122)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 100.0 (TID 122). 20015 bytes result sent to driver
2025-08-10 08:33:04,090 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 123
2025-08-10 08:33:04,091 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 101.0 (TID 123)
2025-08-10 08:33:04,093 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 495 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,098 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_495_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 393.5 MiB)
2025-08-10 08:33:04,100 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 495 took 6 ms
2025-08-10 08:33:04,101 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_495 stored as values in memory (estimated size 138.9 KiB, free 393.4 MiB)
2025-08-10 08:33:04,176 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.837618 ms
2025-08-10 08:33:04,178 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 493 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,183 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_493_piece0 stored as bytes in memory (estimated size 442.0 B, free 393.4 MiB)
2025-08-10 08:33:04,186 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 493 took 7 ms
2025-08-10 08:33:04,189 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_493 stored as values in memory (estimated size 696.0 B, free 393.4 MiB)
2025-08-10 08:33:04,198 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 3.982457 ms
2025-08-10 08:33:04,207 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 427 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,212 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_427_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 392.8 MiB)
2025-08-10 08:33:04,214 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 427 took 6 ms
2025-08-10 08:33:04,216 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_427 stored as values in memory (estimated size 32.0 KiB, free 392.8 MiB)
2025-08-10 08:33:04,228 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:04,237 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:04,248 [Executor task launch worker for task 0.0 in stage 101.0 (TID 123)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 101.0 (TID 123). 41513 bytes result sent to driver
2025-08-10 08:33:04,291 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 124
2025-08-10 08:33:04,293 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 102.0 (TID 124)
2025-08-10 08:33:04,296 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 497 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,302 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_497_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 393.6 MiB)
2025-08-10 08:33:04,305 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 497 took 8 ms
2025-08-10 08:33:04,306 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_497 stored as values in memory (estimated size 22.3 KiB, free 393.6 MiB)
2025-08-10 08:33:04,325 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.01907 ms
2025-08-10 08:33:04,345 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.583844 ms
2025-08-10 08:33:04,349 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 496 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,368 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_496_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.5 MiB)
2025-08-10 08:33:04,370 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 496 took 20 ms
2025-08-10 08:33:04,372 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_496 stored as values in memory (estimated size 32.0 KiB, free 393.5 MiB)
2025-08-10 08:33:04,386 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:04,396 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:04,427 [Executor task launch worker for task 0.0 in stage 102.0 (TID 124)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 102.0 (TID 124). 4978 bytes result sent to driver
2025-08-10 08:33:04,474 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 125
2025-08-10 08:33:04,475 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 126
2025-08-10 08:33:04,475 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 103.0 (TID 125)
2025-08-10 08:33:04,480 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 103.0 (TID 126)
2025-08-10 08:33:04,480 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 20 and clearing cache
2025-08-10 08:33:04,483 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 507 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,488 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_507_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 393.5 MiB)
2025-08-10 08:33:04,491 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 507 took 8 ms
2025-08-10 08:33:04,493 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_507 stored as values in memory (estimated size 37.5 KiB, free 393.5 MiB)
2025-08-10 08:33:04,513 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 13.794221 ms
2025-08-10 08:33:04,515 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 407 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,522 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 23.400887 ms
2025-08-10 08:33:04,523 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_407_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 393.4 MiB)
2025-08-10 08:33:04,525 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 462 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,529 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 407 took 12 ms
2025-08-10 08:33:04,531 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_407 stored as values in memory (estimated size 32.0 KiB, free 393.4 MiB)
2025-08-10 08:33:04,534 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_462_piece0 stored as bytes in memory (estimated size 1204.0 B, free 393.4 MiB)
2025-08-10 08:33:04,537 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 462 took 9 ms
2025-08-10 08:33:04,540 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_462 stored as values in memory (estimated size 8.0 MiB, free 385.4 MiB)
2025-08-10 08:33:04,542 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 409 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,546 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:04,549 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_409_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 385.4 MiB)
2025-08-10 08:33:04,553 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 409 took 10 ms
2025-08-10 08:33:04,555 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_409 stored as values in memory (estimated size 32.0 KiB, free 385.3 MiB)
2025-08-10 08:33:04,556 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:04,571 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:04,579 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:04,581 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:04,591 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:04,597 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:04,598 [Executor task launch worker for task 0.0 in stage 103.0 (TID 125)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 103.0 (TID 125). 7228 bytes result sent to driver
2025-08-10 08:33:04,605 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:04,611 [Executor task launch worker for task 1.0 in stage 103.0 (TID 126)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 103.0 (TID 126). 7357 bytes result sent to driver
2025-08-10 08:33:04,730 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 127
2025-08-10 08:33:04,731 [Executor task launch worker for task 0.0 in stage 104.0 (TID 127)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 104.0 (TID 127)
2025-08-10 08:33:04,732 [Executor task launch worker for task 0.0 in stage 104.0 (TID 127)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 21 and clearing cache
2025-08-10 08:33:04,734 [Executor task launch worker for task 0.0 in stage 104.0 (TID 127)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 530 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,738 [Executor task launch worker for task 0.0 in stage 104.0 (TID 127)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_530_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 385.4 MiB)
2025-08-10 08:33:04,740 [Executor task launch worker for task 0.0 in stage 104.0 (TID 127)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 530 took 6 ms
2025-08-10 08:33:04,741 [Executor task launch worker for task 0.0 in stage 104.0 (TID 127)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_530 stored as values in memory (estimated size 11.7 KiB, free 385.4 MiB)
2025-08-10 08:33:04,745 [Executor task launch worker for task 0.0 in stage 104.0 (TID 127)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 104.0 (TID 127). 1836 bytes result sent to driver
2025-08-10 08:33:04,768 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 128
2025-08-10 08:33:04,769 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 106.0 (TID 128)
2025-08-10 08:33:04,769 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 22 and clearing cache
2025-08-10 08:33:04,771 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 531 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,775 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_531_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 385.4 MiB)
2025-08-10 08:33:04,777 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 531 took 6 ms
2025-08-10 08:33:04,778 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_531 stored as values in memory (estimated size 12.7 KiB, free 385.4 MiB)
2025-08-10 08:33:04,781 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 16, fetching them
2025-08-10 08:33:04,781 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:33:04,784 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:33:04,785 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:33:04,786 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:33:04,788 [Executor task launch worker for task 0.0 in stage 106.0 (TID 128)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 106.0 (TID 128). 3959 bytes result sent to driver
2025-08-10 08:33:04,822 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 129
2025-08-10 08:33:04,823 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 130
2025-08-10 08:33:04,823 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 108.0 (TID 129)
2025-08-10 08:33:04,823 [Executor task launch worker for task 0.0 in stage 108.0 (TID 130)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 108.0 (TID 130)
2025-08-10 08:33:04,825 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 532 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,828 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_532_piece0 stored as bytes in memory (estimated size 31.7 KiB, free 385.4 MiB)
2025-08-10 08:33:04,830 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 532 took 4 ms
2025-08-10 08:33:04,831 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_532 stored as values in memory (estimated size 94.0 KiB, free 385.3 MiB)
2025-08-10 08:33:04,835 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 15, fetching them
2025-08-10 08:33:04,835 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:33:04,839 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:33:04,840 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:33:04,841 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:33:04,844 [Executor task launch worker for task 0.0 in stage 108.0 (TID 130)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.759757 ms
2025-08-10 08:33:04,847 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.386781 ms
2025-08-10 08:33:04,848 [Executor task launch worker for task 0.0 in stage 108.0 (TID 130)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 520 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,853 [Executor task launch worker for task 0.0 in stage 108.0 (TID 130)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_520_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 385.2 MiB)
2025-08-10 08:33:04,858 [Executor task launch worker for task 0.0 in stage 108.0 (TID 130)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 520 took 9 ms
2025-08-10 08:33:04,859 [Executor task launch worker for task 0.0 in stage 108.0 (TID 130)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_520 stored as values in memory (estimated size 32.0 KiB, free 385.2 MiB)
2025-08-10 08:33:04,867 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.519588 ms
2025-08-10 08:33:04,871 [Executor task launch worker for task 0.0 in stage 108.0 (TID 130)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:04,879 [Executor task launch worker for task 0.0 in stage 108.0 (TID 130)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:04,880 [Executor task launch worker for task 2.0 in stage 108.0 (TID 129)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 108.0 (TID 129). 20837 bytes result sent to driver
2025-08-10 08:33:04,884 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 131
2025-08-10 08:33:04,885 [Executor task launch worker for task 1.0 in stage 108.0 (TID 131)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 108.0 (TID 131)
2025-08-10 08:33:04,893 [Executor task launch worker for task 0.0 in stage 108.0 (TID 130)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 108.0 (TID 130). 20192 bytes result sent to driver
2025-08-10 08:33:04,905 [Executor task launch worker for task 1.0 in stage 108.0 (TID 131)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.729969 ms
2025-08-10 08:33:04,910 [Executor task launch worker for task 1.0 in stage 108.0 (TID 131)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 525 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:04,915 [Executor task launch worker for task 1.0 in stage 108.0 (TID 131)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_525_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 385.2 MiB)
2025-08-10 08:33:04,927 [Executor task launch worker for task 1.0 in stage 108.0 (TID 131)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 525 took 17 ms
2025-08-10 08:33:04,929 [Executor task launch worker for task 1.0 in stage 108.0 (TID 131)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_525 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 08:33:04,940 [Executor task launch worker for task 1.0 in stage 108.0 (TID 131)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:33:04,947 [Executor task launch worker for task 1.0 in stage 108.0 (TID 131)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:33:04,965 [Executor task launch worker for task 1.0 in stage 108.0 (TID 131)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 108.0 (TID 131). 20192 bytes result sent to driver
2025-08-10 08:33:05,141 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 132
2025-08-10 08:33:05,141 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 112.0 (TID 132)
2025-08-10 08:33:05,143 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 23 and clearing cache
2025-08-10 08:33:05,144 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 534 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:05,148 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_534_piece0 stored as bytes in memory (estimated size 91.5 KiB, free 385.1 MiB)
2025-08-10 08:33:05,149 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 534 took 4 ms
2025-08-10 08:33:05,150 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_534 stored as values in memory (estimated size 314.8 KiB, free 384.7 MiB)
2025-08-10 08:33:05,193 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 14, fetching them
2025-08-10 08:33:05,193 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:33:05,197 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:33:05,199 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (6.4 KiB) non-empty blocks including 1 (6.4 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:33:05,200 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:33:05,207 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.710363 ms
2025-08-10 08:33:05,214 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.067447 ms
2025-08-10 08:33:05,222 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.188582 ms
2025-08-10 08:33:05,224 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 17, fetching them
2025-08-10 08:33:05,224 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:33:05,228 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:33:05,231 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 3 (4.2 KiB) non-empty blocks including 3 (4.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:33:05,231 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
2025-08-10 08:33:05,240 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.205513 ms
2025-08-10 08:33:05,267 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 18.046365 ms
2025-08-10 08:33:05,283 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.154462 ms
2025-08-10 08:33:05,292 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.367347 ms
2025-08-10 08:33:05,299 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 3.631007 ms
2025-08-10 08:33:05,313 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.651273 ms
2025-08-10 08:33:05,324 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.352257 ms
2025-08-10 08:33:05,338 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.551547 ms
2025-08-10 08:33:05,379 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.657768 ms
2025-08-10 08:33:05,381 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 533 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:33:05,386 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_533_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 384.6 MiB)
2025-08-10 08:33:05,389 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 533 took 7 ms
2025-08-10 08:33:05,391 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_533 stored as values in memory (estimated size 32.0 KiB, free 384.6 MiB)
2025-08-10 08:33:05,395 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:33:05,427 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:33:05,461 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 132, attempt 0, stage 112.0)
2025-08-10 08:33:05,465 [Executor task launch worker for task 0.0 in stage 112.0 (TID 132)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 112.0 (TID 132). 119538 bytes result sent to driver
2025-08-10 08:33:05,821 [block-manager-storage-async-thread-pool-378] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:09,265 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 133
2025-08-10 08:34:09,266 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 134
2025-08-10 08:34:09,266 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 113.0 (TID 133)
2025-08-10 08:34:09,267 [Executor task launch worker for task 1.0 in stage 113.0 (TID 134)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 113.0 (TID 134)
2025-08-10 08:34:09,268 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 536 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:09,272 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_536_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 385.3 MiB)
2025-08-10 08:34:09,274 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 536 took 5 ms
2025-08-10 08:34:09,275 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_536 stored as values in memory (estimated size 8.0 KiB, free 385.3 MiB)
2025-08-10 08:34:09,277 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 535 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:09,280 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_535_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 385.3 MiB)
2025-08-10 08:34:09,282 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 535 took 5 ms
2025-08-10 08:34:09,283 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_535 stored as values in memory (estimated size 32.0 KiB, free 385.2 MiB)
2025-08-10 08:34:09,286 [Executor task launch worker for task 1.0 in stage 113.0 (TID 134)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:34:09,286 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:34:09,288 [Executor task launch worker for task 1.0 in stage 113.0 (TID 134)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:34:09,289 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:34:09,322 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 133, attempt 0, stage 113.0)
2025-08-10 08:34:09,324 [Executor task launch worker for task 0.0 in stage 113.0 (TID 133)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 113.0 (TID 133). 4074 bytes result sent to driver
2025-08-10 08:34:09,325 [Executor task launch worker for task 1.0 in stage 113.0 (TID 134)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 134, attempt 0, stage 113.0)
2025-08-10 08:34:09,327 [Executor task launch worker for task 1.0 in stage 113.0 (TID 134)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 113.0 (TID 134). 4072 bytes result sent to driver
2025-08-10 08:34:16,972 [block-manager-storage-async-thread-pool-485] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,636 [block-manager-storage-async-thread-pool-491] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,654 [block-manager-storage-async-thread-pool-500] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,680 [block-manager-storage-async-thread-pool-515] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,692 [block-manager-storage-async-thread-pool-521] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,732 [block-manager-storage-async-thread-pool-554] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,749 [block-manager-storage-async-thread-pool-472] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,756 [block-manager-storage-async-thread-pool-484] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,778 [block-manager-storage-async-thread-pool-511] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,802 [block-manager-storage-async-thread-pool-544] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,807 [block-manager-storage-async-thread-pool-547] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,809 [block-manager-storage-async-thread-pool-550] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,815 [block-manager-storage-async-thread-pool-555] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,821 [block-manager-storage-async-thread-pool-562] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,832 [block-manager-storage-async-thread-pool-475] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,842 [block-manager-storage-async-thread-pool-481] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,848 [block-manager-storage-async-thread-pool-490] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,855 [block-manager-storage-async-thread-pool-496] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:17,860 [block-manager-storage-async-thread-pool-505] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:34:18,123 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 135
2025-08-10 08:34:18,124 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 114.0 (TID 135)
2025-08-10 08:34:18,128 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 619 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,133 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 136
2025-08-10 08:34:18,133 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_619_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
2025-08-10 08:34:18,134 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 115.0 (TID 136)
2025-08-10 08:34:18,139 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 619 took 11 ms
2025-08-10 08:34:18,140 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 620 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,141 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_619 stored as values in memory (estimated size 13.6 KiB, free 434.4 MiB)
2025-08-10 08:34:18,145 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 575 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,146 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_620_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.4 MiB)
2025-08-10 08:34:18,148 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 620 took 6 ms
2025-08-10 08:34:18,150 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_620 stored as values in memory (estimated size 14.3 KiB, free 434.4 MiB)
2025-08-10 08:34:18,150 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_575_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 434.3 MiB)
2025-08-10 08:34:18,152 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 575 took 7 ms
2025-08-10 08:34:18,153 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 582 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,154 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_575 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:34:18,160 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_582_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:34:18,163 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 582 took 8 ms
2025-08-10 08:34:18,166 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_582 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:34:18,171 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,179 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,180 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,190 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,201 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,205 [Executor task launch worker for task 0.0 in stage 115.0 (TID 136)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 115.0 (TID 136). 4674 bytes result sent to driver
2025-08-10 08:34:18,210 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 137
2025-08-10 08:34:18,210 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,211 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 116.0 (TID 137)
2025-08-10 08:34:18,215 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 621 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,216 [Executor task launch worker for task 0.0 in stage 114.0 (TID 135)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 114.0 (TID 135). 4679 bytes result sent to driver
2025-08-10 08:34:18,222 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 138
2025-08-10 08:34:18,223 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_621_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 434.2 MiB)
2025-08-10 08:34:18,223 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 117.0 (TID 138)
2025-08-10 08:34:18,227 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 621 took 11 ms
2025-08-10 08:34:18,228 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 622 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,229 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_621 stored as values in memory (estimated size 19.9 KiB, free 434.2 MiB)
2025-08-10 08:34:18,233 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 572 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,242 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_622_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.2 MiB)
2025-08-10 08:34:18,242 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_572_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.2 MiB)
2025-08-10 08:34:18,245 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 622 took 17 ms
2025-08-10 08:34:18,245 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 572 took 11 ms
2025-08-10 08:34:18,246 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_622 stored as values in memory (estimated size 20.5 KiB, free 434.2 MiB)
2025-08-10 08:34:18,247 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_572 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:34:18,249 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 584 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,254 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_584_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.1 MiB)
2025-08-10 08:34:18,257 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 584 took 8 ms
2025-08-10 08:34:18,259 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_584 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:34:18,262 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,271 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,274 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,283 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,288 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,294 [Executor task launch worker for task 0.0 in stage 117.0 (TID 138)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 117.0 (TID 138). 5323 bytes result sent to driver
2025-08-10 08:34:18,299 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,309 [Executor task launch worker for task 0.0 in stage 116.0 (TID 137)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 116.0 (TID 137). 5360 bytes result sent to driver
2025-08-10 08:34:18,456 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 139
2025-08-10 08:34:18,457 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 140
2025-08-10 08:34:18,457 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 118.0 (TID 139)
2025-08-10 08:34:18,458 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 118.0 (TID 140)
2025-08-10 08:34:18,459 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 647 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,463 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_647_piece0 stored as bytes in memory (estimated size 11.6 KiB, free 434.1 MiB)
2025-08-10 08:34:18,465 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 647 took 5 ms
2025-08-10 08:34:18,466 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_647 stored as values in memory (estimated size 35.1 KiB, free 434.1 MiB)
2025-08-10 08:34:18,468 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 636 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,468 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 623 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,471 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_623_piece0 stored as bytes in memory (estimated size 481.0 B, free 434.1 MiB)
2025-08-10 08:34:18,471 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_636_piece0 stored as bytes in memory (estimated size 1189.0 B, free 434.1 MiB)
2025-08-10 08:34:18,473 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 636 took 5 ms
2025-08-10 08:34:18,473 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 623 took 5 ms
2025-08-10 08:34:18,475 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_623 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:34:18,475 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_636 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:34:18,476 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 616 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,476 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 613 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,480 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_616_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 418.1 MiB)
2025-08-10 08:34:18,480 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_613_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.1 MiB)
2025-08-10 08:34:18,481 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 613 took 5 ms
2025-08-10 08:34:18,482 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 616 took 5 ms
2025-08-10 08:34:18,483 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_613 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:34:18,483 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_616 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:34:18,491 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,491 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,496 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,496 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,505 [Executor task launch worker for task 1.0 in stage 118.0 (TID 140)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 118.0 (TID 140). 7357 bytes result sent to driver
2025-08-10 08:34:18,506 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,509 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 141
2025-08-10 08:34:18,510 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 119.0 (TID 141)
2025-08-10 08:34:18,511 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,512 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 648 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,515 [Executor task launch worker for task 0.0 in stage 118.0 (TID 139)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 118.0 (TID 139). 7357 bytes result sent to driver
2025-08-10 08:34:18,515 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_648_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 418.0 MiB)
2025-08-10 08:34:18,518 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 648 took 5 ms
2025-08-10 08:34:18,519 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_648 stored as values in memory (estimated size 33.7 KiB, free 417.9 MiB)
2025-08-10 08:34:18,519 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 142
2025-08-10 08:34:18,520 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 119.0 (TID 142)
2025-08-10 08:34:18,522 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 605 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,524 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 624 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,527 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_605_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 417.9 MiB)
2025-08-10 08:34:18,527 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_624_piece0 stored as bytes in memory (estimated size 492.0 B, free 417.9 MiB)
2025-08-10 08:34:18,529 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 605 took 6 ms
2025-08-10 08:34:18,530 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 624 took 5 ms
2025-08-10 08:34:18,539 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_605 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 08:34:18,540 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_624 stored as values in memory (estimated size 8.0 MiB, free 409.9 MiB)
2025-08-10 08:34:18,541 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 606 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,545 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_606_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.9 MiB)
2025-08-10 08:34:18,547 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 606 took 5 ms
2025-08-10 08:34:18,549 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_606 stored as values in memory (estimated size 32.0 KiB, free 409.8 MiB)
2025-08-10 08:34:18,550 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,555 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,556 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,560 [Executor task launch worker for task 0.0 in stage 119.0 (TID 141)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 119.0 (TID 141). 7236 bytes result sent to driver
2025-08-10 08:34:18,560 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,564 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 143
2025-08-10 08:34:18,564 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 120.0 (TID 143)
2025-08-10 08:34:18,566 [Executor task launch worker for task 1.0 in stage 119.0 (TID 142)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 119.0 (TID 142). 7206 bytes result sent to driver
2025-08-10 08:34:18,566 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 649 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,569 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 144
2025-08-10 08:34:18,570 [Executor task launch worker for task 1.0 in stage 120.0 (TID 144)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 120.0 (TID 144)
2025-08-10 08:34:18,570 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_649_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 409.8 MiB)
2025-08-10 08:34:18,573 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 649 took 6 ms
2025-08-10 08:34:18,575 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_649 stored as values in memory (estimated size 33.7 KiB, free 409.8 MiB)
2025-08-10 08:34:18,577 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 610 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,577 [Executor task launch worker for task 1.0 in stage 120.0 (TID 144)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 611 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,581 [Executor task launch worker for task 1.0 in stage 120.0 (TID 144)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_611_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.7 MiB)
2025-08-10 08:34:18,581 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_610_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.7 MiB)
2025-08-10 08:34:18,582 [Executor task launch worker for task 1.0 in stage 120.0 (TID 144)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 611 took 5 ms
2025-08-10 08:34:18,583 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 610 took 5 ms
2025-08-10 08:34:18,584 [Executor task launch worker for task 1.0 in stage 120.0 (TID 144)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_611 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 08:34:18,584 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_610 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 08:34:18,592 [Executor task launch worker for task 1.0 in stage 120.0 (TID 144)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,592 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,597 [Executor task launch worker for task 1.0 in stage 120.0 (TID 144)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,597 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,604 [Executor task launch worker for task 1.0 in stage 120.0 (TID 144)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 120.0 (TID 144). 7163 bytes result sent to driver
2025-08-10 08:34:18,604 [Executor task launch worker for task 0.0 in stage 120.0 (TID 143)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 120.0 (TID 143). 7193 bytes result sent to driver
2025-08-10 08:34:18,665 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 145
2025-08-10 08:34:18,666 [Executor task launch worker for task 0.0 in stage 121.0 (TID 145)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 121.0 (TID 145)
2025-08-10 08:34:18,667 [Executor task launch worker for task 0.0 in stage 121.0 (TID 145)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 24 and clearing cache
2025-08-10 08:34:18,669 [Executor task launch worker for task 0.0 in stage 121.0 (TID 145)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 664 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,673 [Executor task launch worker for task 0.0 in stage 121.0 (TID 145)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_664_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 409.7 MiB)
2025-08-10 08:34:18,675 [Executor task launch worker for task 0.0 in stage 121.0 (TID 145)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 664 took 6 ms
2025-08-10 08:34:18,677 [Executor task launch worker for task 0.0 in stage 121.0 (TID 145)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_664 stored as values in memory (estimated size 11.7 KiB, free 409.7 MiB)
2025-08-10 08:34:18,683 [Executor task launch worker for task 0.0 in stage 121.0 (TID 145)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 121.0 (TID 145). 1836 bytes result sent to driver
2025-08-10 08:34:18,710 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 146
2025-08-10 08:34:18,711 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 123.0 (TID 146)
2025-08-10 08:34:18,712 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 25 and clearing cache
2025-08-10 08:34:18,713 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 665 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,718 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_665_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 409.8 MiB)
2025-08-10 08:34:18,720 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 665 took 6 ms
2025-08-10 08:34:18,721 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_665 stored as values in memory (estimated size 12.7 KiB, free 409.8 MiB)
2025-08-10 08:34:18,722 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 19, fetching them
2025-08-10 08:34:18,723 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:34:18,725 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:34:18,727 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:34:18,727 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:34:18,729 [Executor task launch worker for task 0.0 in stage 123.0 (TID 146)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 123.0 (TID 146). 3959 bytes result sent to driver
2025-08-10 08:34:18,781 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 147
2025-08-10 08:34:18,781 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 148
2025-08-10 08:34:18,781 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 125.0 (TID 147)
2025-08-10 08:34:18,782 [Executor task launch worker for task 0.0 in stage 125.0 (TID 148)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 125.0 (TID 148)
2025-08-10 08:34:18,783 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 666 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,787 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_666_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.7 MiB)
2025-08-10 08:34:18,789 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 666 took 5 ms
2025-08-10 08:34:18,791 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_666 stored as values in memory (estimated size 88.3 KiB, free 409.7 MiB)
2025-08-10 08:34:18,797 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 18, fetching them
2025-08-10 08:34:18,797 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:34:18,802 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:34:18,804 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 2 (152.0 B) non-empty blocks including 2 (152.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:34:18,804 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:34:18,805 [Executor task launch worker for task 0.0 in stage 125.0 (TID 148)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.95604 ms
2025-08-10 08:34:18,808 [Executor task launch worker for task 0.0 in stage 125.0 (TID 148)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 602 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,813 [Executor task launch worker for task 0.0 in stage 125.0 (TID 148)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_602_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.6 MiB)
2025-08-10 08:34:18,816 [Executor task launch worker for task 0.0 in stage 125.0 (TID 148)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 602 took 7 ms
2025-08-10 08:34:18,818 [Executor task launch worker for task 0.0 in stage 125.0 (TID 148)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_602 stored as values in memory (estimated size 32.0 KiB, free 401.5 MiB)
2025-08-10 08:34:18,832 [Executor task launch worker for task 0.0 in stage 125.0 (TID 148)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,833 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.554122 ms
2025-08-10 08:34:18,837 [Executor task launch worker for task 3.0 in stage 125.0 (TID 147)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 125.0 (TID 147). 22960 bytes result sent to driver
2025-08-10 08:34:18,840 [Executor task launch worker for task 0.0 in stage 125.0 (TID 148)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,841 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 149
2025-08-10 08:34:18,842 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 125.0 (TID 149)
2025-08-10 08:34:18,846 [Executor task launch worker for task 0.0 in stage 125.0 (TID 148)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 125.0 (TID 148). 22272 bytes result sent to driver
2025-08-10 08:34:18,847 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 654 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,850 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 150
2025-08-10 08:34:18,851 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 125.0 (TID 150)
2025-08-10 08:34:18,851 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_654_piece0 stored as bytes in memory (estimated size 180.0 B, free 409.6 MiB)
2025-08-10 08:34:18,853 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 654 took 5 ms
2025-08-10 08:34:18,855 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_654 stored as values in memory (estimated size 8.0 MiB, free 401.6 MiB)
2025-08-10 08:34:18,855 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 603 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,857 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 659 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,860 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_603_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 401.6 MiB)
2025-08-10 08:34:18,861 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_659_piece0 stored as bytes in memory (estimated size 180.0 B, free 401.6 MiB)
2025-08-10 08:34:18,862 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 603 took 6 ms
2025-08-10 08:34:18,863 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 659 took 5 ms
2025-08-10 08:34:18,863 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_603 stored as values in memory (estimated size 32.0 KiB, free 401.5 MiB)
2025-08-10 08:34:18,865 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_659 stored as values in memory (estimated size 8.0 MiB, free 393.5 MiB)
2025-08-10 08:34:18,866 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 608 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,871 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_608_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.5 MiB)
2025-08-10 08:34:18,874 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,874 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 608 took 7 ms
2025-08-10 08:34:18,875 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_608 stored as values in memory (estimated size 32.0 KiB, free 393.5 MiB)
2025-08-10 08:34:18,878 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,885 [Executor task launch worker for task 1.0 in stage 125.0 (TID 149)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 125.0 (TID 149). 22308 bytes result sent to driver
2025-08-10 08:34:18,886 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,892 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:18,897 [Executor task launch worker for task 2.0 in stage 125.0 (TID 150)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 125.0 (TID 150). 22471 bytes result sent to driver
2025-08-10 08:34:18,949 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 151
2025-08-10 08:34:18,949 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 126.0 (TID 151)
2025-08-10 08:34:18,951 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 669 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,955 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_669_piece0 stored as bytes in memory (estimated size 47.1 KiB, free 393.4 MiB)
2025-08-10 08:34:18,957 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 669 took 5 ms
2025-08-10 08:34:18,958 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_669 stored as values in memory (estimated size 139.0 KiB, free 393.3 MiB)
2025-08-10 08:34:18,963 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 667 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,967 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_667_piece0 stored as bytes in memory (estimated size 466.0 B, free 393.3 MiB)
2025-08-10 08:34:18,969 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 667 took 5 ms
2025-08-10 08:34:18,971 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_667 stored as values in memory (estimated size 760.0 B, free 393.3 MiB)
2025-08-10 08:34:18,976 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 601 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:18,979 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_601_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 392.8 MiB)
2025-08-10 08:34:18,982 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 601 took 6 ms
2025-08-10 08:34:18,984 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_601 stored as values in memory (estimated size 32.0 KiB, free 392.7 MiB)
2025-08-10 08:34:18,993 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:18,999 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:19,005 [Executor task launch worker for task 0.0 in stage 126.0 (TID 151)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 126.0 (TID 151). 41625 bytes result sent to driver
2025-08-10 08:34:19,029 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 152
2025-08-10 08:34:19,029 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 127.0 (TID 152)
2025-08-10 08:34:19,032 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 671 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,036 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_671_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 393.2 MiB)
2025-08-10 08:34:19,039 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 671 took 6 ms
2025-08-10 08:34:19,040 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_671 stored as values in memory (estimated size 22.3 KiB, free 393.2 MiB)
2025-08-10 08:34:19,044 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 670 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,048 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_670_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.2 MiB)
2025-08-10 08:34:19,049 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 670 took 4 ms
2025-08-10 08:34:19,051 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_670 stored as values in memory (estimated size 32.0 KiB, free 393.1 MiB)
2025-08-10 08:34:19,061 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:19,067 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:19,092 [Executor task launch worker for task 0.0 in stage 127.0 (TID 152)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 127.0 (TID 152). 4892 bytes result sent to driver
2025-08-10 08:34:19,118 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 153
2025-08-10 08:34:19,118 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 154
2025-08-10 08:34:19,118 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 128.0 (TID 153)
2025-08-10 08:34:19,119 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 128.0 (TID 154)
2025-08-10 08:34:19,119 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 26 and clearing cache
2025-08-10 08:34:19,121 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 681 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,124 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_681_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 393.1 MiB)
2025-08-10 08:34:19,127 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 681 took 5 ms
2025-08-10 08:34:19,128 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_681 stored as values in memory (estimated size 37.5 KiB, free 393.1 MiB)
2025-08-10 08:34:19,130 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 634 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,130 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 581 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,139 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_581_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 393.1 MiB)
2025-08-10 08:34:19,139 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_634_piece0 stored as bytes in memory (estimated size 1145.0 B, free 393.1 MiB)
2025-08-10 08:34:19,141 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 581 took 10 ms
2025-08-10 08:34:19,142 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 634 took 12 ms
2025-08-10 08:34:19,144 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_581 stored as values in memory (estimated size 32.0 KiB, free 393.1 MiB)
2025-08-10 08:34:19,145 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_634 stored as values in memory (estimated size 8.0 MiB, free 385.1 MiB)
2025-08-10 08:34:19,148 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 583 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,156 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_583_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 385.1 MiB)
2025-08-10 08:34:19,158 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:19,162 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 583 took 13 ms
2025-08-10 08:34:19,164 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_583 stored as values in memory (estimated size 32.0 KiB, free 385.3 MiB)
2025-08-10 08:34:19,173 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:19,178 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:19,187 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:19,188 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:19,196 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:19,201 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:19,205 [Executor task launch worker for task 0.0 in stage 128.0 (TID 153)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 128.0 (TID 153). 7357 bytes result sent to driver
2025-08-10 08:34:19,209 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:19,215 [Executor task launch worker for task 1.0 in stage 128.0 (TID 154)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 128.0 (TID 154). 7357 bytes result sent to driver
2025-08-10 08:34:19,337 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 155
2025-08-10 08:34:19,338 [Executor task launch worker for task 0.0 in stage 129.0 (TID 155)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 129.0 (TID 155)
2025-08-10 08:34:19,338 [Executor task launch worker for task 0.0 in stage 129.0 (TID 155)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 27 and clearing cache
2025-08-10 08:34:19,340 [Executor task launch worker for task 0.0 in stage 129.0 (TID 155)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 704 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,343 [Executor task launch worker for task 0.0 in stage 129.0 (TID 155)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_704_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 385.3 MiB)
2025-08-10 08:34:19,345 [Executor task launch worker for task 0.0 in stage 129.0 (TID 155)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 704 took 5 ms
2025-08-10 08:34:19,346 [Executor task launch worker for task 0.0 in stage 129.0 (TID 155)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_704 stored as values in memory (estimated size 11.7 KiB, free 385.3 MiB)
2025-08-10 08:34:19,349 [Executor task launch worker for task 0.0 in stage 129.0 (TID 155)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 129.0 (TID 155). 1836 bytes result sent to driver
2025-08-10 08:34:19,366 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 156
2025-08-10 08:34:19,367 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 131.0 (TID 156)
2025-08-10 08:34:19,367 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 28 and clearing cache
2025-08-10 08:34:19,368 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 705 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,371 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_705_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 385.3 MiB)
2025-08-10 08:34:19,373 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 705 took 4 ms
2025-08-10 08:34:19,374 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_705 stored as values in memory (estimated size 12.7 KiB, free 385.3 MiB)
2025-08-10 08:34:19,375 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 22, fetching them
2025-08-10 08:34:19,375 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:34:19,377 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:34:19,378 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:34:19,379 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 08:34:19,386 [Executor task launch worker for task 0.0 in stage 131.0 (TID 156)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 131.0 (TID 156). 4002 bytes result sent to driver
2025-08-10 08:34:19,414 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 157
2025-08-10 08:34:19,415 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 158
2025-08-10 08:34:19,415 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 133.0 (TID 157)
2025-08-10 08:34:19,415 [Executor task launch worker for task 0.0 in stage 133.0 (TID 158)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 133.0 (TID 158)
2025-08-10 08:34:19,417 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 706 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,420 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_706_piece0 stored as bytes in memory (estimated size 34.5 KiB, free 385.2 MiB)
2025-08-10 08:34:19,421 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 706 took 4 ms
2025-08-10 08:34:19,422 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_706 stored as values in memory (estimated size 105.2 KiB, free 385.1 MiB)
2025-08-10 08:34:19,427 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 21, fetching them
2025-08-10 08:34:19,427 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:34:19,430 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:34:19,431 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 2 (435.0 B) non-empty blocks including 2 (435.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:34:19,432 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:34:19,433 [Executor task launch worker for task 0.0 in stage 133.0 (TID 158)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.206403 ms
2025-08-10 08:34:19,436 [Executor task launch worker for task 0.0 in stage 133.0 (TID 158)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 693 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,439 [Executor task launch worker for task 0.0 in stage 133.0 (TID 158)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_693_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 377.1 MiB)
2025-08-10 08:34:19,442 [Executor task launch worker for task 0.0 in stage 133.0 (TID 158)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 693 took 5 ms
2025-08-10 08:34:19,443 [Executor task launch worker for task 0.0 in stage 133.0 (TID 158)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_693 stored as values in memory (estimated size 32.0 KiB, free 377.0 MiB)
2025-08-10 08:34:19,452 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.305714 ms
2025-08-10 08:34:19,455 [Executor task launch worker for task 0.0 in stage 133.0 (TID 158)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:19,462 [Executor task launch worker for task 0.0 in stage 133.0 (TID 158)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:19,465 [Executor task launch worker for task 3.0 in stage 133.0 (TID 157)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 133.0 (TID 157). 23293 bytes result sent to driver
2025-08-10 08:34:19,470 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 159
2025-08-10 08:34:19,471 [Executor task launch worker for task 1.0 in stage 133.0 (TID 159)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 133.0 (TID 159)
2025-08-10 08:34:19,477 [Executor task launch worker for task 0.0 in stage 133.0 (TID 158)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 133.0 (TID 158). 22605 bytes result sent to driver
2025-08-10 08:34:19,479 [Executor task launch worker for task 1.0 in stage 133.0 (TID 159)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 694 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,480 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 160
2025-08-10 08:34:19,481 [Executor task launch worker for task 2.0 in stage 133.0 (TID 160)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 133.0 (TID 160)
2025-08-10 08:34:19,482 [Executor task launch worker for task 1.0 in stage 133.0 (TID 159)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_694_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 385.1 MiB)
2025-08-10 08:34:19,484 [Executor task launch worker for task 1.0 in stage 133.0 (TID 159)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 694 took 4 ms
2025-08-10 08:34:19,485 [Executor task launch worker for task 1.0 in stage 133.0 (TID 159)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_694 stored as values in memory (estimated size 32.0 KiB, free 385.0 MiB)
2025-08-10 08:34:19,488 [Executor task launch worker for task 2.0 in stage 133.0 (TID 160)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 699 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,491 [Executor task launch worker for task 2.0 in stage 133.0 (TID 160)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_699_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 385.0 MiB)
2025-08-10 08:34:19,493 [Executor task launch worker for task 2.0 in stage 133.0 (TID 160)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 699 took 4 ms
2025-08-10 08:34:19,493 [Executor task launch worker for task 1.0 in stage 133.0 (TID 159)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:19,494 [Executor task launch worker for task 2.0 in stage 133.0 (TID 160)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_699 stored as values in memory (estimated size 32.0 KiB, free 385.0 MiB)
2025-08-10 08:34:19,498 [Executor task launch worker for task 1.0 in stage 133.0 (TID 159)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:19,501 [Executor task launch worker for task 2.0 in stage 133.0 (TID 160)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:34:19,506 [Executor task launch worker for task 2.0 in stage 133.0 (TID 160)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:34:19,508 [Executor task launch worker for task 1.0 in stage 133.0 (TID 159)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 133.0 (TID 159). 22648 bytes result sent to driver
2025-08-10 08:34:19,519 [Executor task launch worker for task 2.0 in stage 133.0 (TID 160)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 133.0 (TID 160). 22648 bytes result sent to driver
2025-08-10 08:34:19,602 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 161
2025-08-10 08:34:19,603 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 137.0 (TID 161)
2025-08-10 08:34:19,604 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 29 and clearing cache
2025-08-10 08:34:19,605 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 708 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,609 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_708_piece0 stored as bytes in memory (estimated size 91.7 KiB, free 385.1 MiB)
2025-08-10 08:34:19,610 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 708 took 5 ms
2025-08-10 08:34:19,611 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_708 stored as values in memory (estimated size 315.1 KiB, free 384.8 MiB)
2025-08-10 08:34:19,619 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 20, fetching them
2025-08-10 08:34:19,619 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:34:19,621 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:34:19,622 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (6.8 KiB) non-empty blocks including 1 (6.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:34:19,623 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 08:34:19,625 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 23, fetching them
2025-08-10 08:34:19,626 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:34:19,628 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:34:19,629 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 (4.7 KiB) non-empty blocks including 4 (4.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:34:19,629 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 08:34:19,643 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 707 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:34:19,647 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_707_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 384.6 MiB)
2025-08-10 08:34:19,648 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 707 took 5 ms
2025-08-10 08:34:19,650 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_707 stored as values in memory (estimated size 32.0 KiB, free 384.6 MiB)
2025-08-10 08:34:19,651 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:34:19,658 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:34:19,684 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 161, attempt 0, stage 137.0)
2025-08-10 08:34:19,688 [Executor task launch worker for task 0.0 in stage 137.0 (TID 161)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 137.0 (TID 161). 119762 bytes result sent to driver
2025-08-10 08:39:50,638 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 162
2025-08-10 08:39:50,639 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 163
2025-08-10 08:39:50,639 [Executor task launch worker for task 0.0 in stage 138.0 (TID 162)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 138.0 (TID 162)
2025-08-10 08:39:50,640 [Executor task launch worker for task 1.0 in stage 138.0 (TID 163)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 138.0 (TID 163)
2025-08-10 08:39:50,642 [Executor task launch worker for task 1.0 in stage 138.0 (TID 163)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 710 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:50,647 [Executor task launch worker for task 1.0 in stage 138.0 (TID 163)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_710_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 384.7 MiB)
2025-08-10 08:39:50,650 [Executor task launch worker for task 1.0 in stage 138.0 (TID 163)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 710 took 7 ms
2025-08-10 08:39:50,651 [Executor task launch worker for task 1.0 in stage 138.0 (TID 163)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_710 stored as values in memory (estimated size 8.0 KiB, free 384.7 MiB)
2025-08-10 08:39:50,653 [Executor task launch worker for task 0.0 in stage 138.0 (TID 162)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 709 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:50,657 [Executor task launch worker for task 0.0 in stage 138.0 (TID 162)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_709_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 384.7 MiB)
2025-08-10 08:39:50,659 [Executor task launch worker for task 0.0 in stage 138.0 (TID 162)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 709 took 5 ms
2025-08-10 08:39:50,661 [Executor task launch worker for task 0.0 in stage 138.0 (TID 162)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_709 stored as values in memory (estimated size 32.0 KiB, free 384.7 MiB)
2025-08-10 08:39:50,664 [Executor task launch worker for task 1.0 in stage 138.0 (TID 163)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:39:50,664 [Executor task launch worker for task 0.0 in stage 138.0 (TID 162)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:39:50,665 [Executor task launch worker for task 0.0 in stage 138.0 (TID 162)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:39:50,665 [Executor task launch worker for task 1.0 in stage 138.0 (TID 163)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:39:50,695 [Executor task launch worker for task 0.0 in stage 138.0 (TID 162)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 162, attempt 0, stage 138.0)
2025-08-10 08:39:50,697 [Executor task launch worker for task 0.0 in stage 138.0 (TID 162)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 138.0 (TID 162). 4074 bytes result sent to driver
2025-08-10 08:39:50,737 [Executor task launch worker for task 1.0 in stage 138.0 (TID 163)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 163, attempt 0, stage 138.0)
2025-08-10 08:39:50,739 [Executor task launch worker for task 1.0 in stage 138.0 (TID 163)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 138.0 (TID 163). 4072 bytes result sent to driver
2025-08-10 08:39:58,190 [block-manager-storage-async-thread-pool-567] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:58,213 [block-manager-storage-async-thread-pool-576] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,550 [block-manager-storage-async-thread-pool-588] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,640 [block-manager-storage-async-thread-pool-648] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,659 [block-manager-storage-async-thread-pool-661] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,665 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 164
2025-08-10 08:39:59,667 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 139.0 (TID 164)
2025-08-10 08:39:59,672 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 793 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,675 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 165
2025-08-10 08:39:59,677 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 140.0 (TID 165)
2025-08-10 08:39:59,680 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_793_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 393.4 MiB)
2025-08-10 08:39:59,681 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 794 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,684 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 793 took 11 ms
2025-08-10 08:39:59,685 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_793 stored as values in memory (estimated size 14.3 KiB, free 393.4 MiB)
2025-08-10 08:39:59,686 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_794_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 393.4 MiB)
2025-08-10 08:39:59,686 [block-manager-storage-async-thread-pool-581] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,688 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 756 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,690 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 794 took 8 ms
2025-08-10 08:39:59,691 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_794 stored as values in memory (estimated size 13.6 KiB, free 393.4 MiB)
2025-08-10 08:39:59,693 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_756_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 401.4 MiB)
2025-08-10 08:39:59,694 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 749 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,696 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 756 took 7 ms
2025-08-10 08:39:59,698 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_756 stored as values in memory (estimated size 32.0 KiB, free 401.3 MiB)
2025-08-10 08:39:59,699 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_749_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 401.3 MiB)
2025-08-10 08:39:59,701 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 749 took 6 ms
2025-08-10 08:39:59,704 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_749 stored as values in memory (estimated size 32.0 KiB, free 409.3 MiB)
2025-08-10 08:39:59,711 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:39:59,716 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:39:59,716 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:39:59,721 [block-manager-storage-async-thread-pool-626] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,722 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:39:59,726 [Executor task launch worker for task 0.0 in stage 139.0 (TID 164)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 139.0 (TID 164). 4679 bytes result sent to driver
2025-08-10 08:39:59,730 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 166
2025-08-10 08:39:59,730 [block-manager-storage-async-thread-pool-632] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,731 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 141.0 (TID 166)
2025-08-10 08:39:59,733 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 795 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,739 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:39:59,741 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_795_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 417.4 MiB)
2025-08-10 08:39:59,744 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 795 took 10 ms
2025-08-10 08:39:59,745 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_795 stored as values in memory (estimated size 19.9 KiB, free 417.4 MiB)
2025-08-10 08:39:59,747 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:39:59,747 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 746 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,751 [Executor task launch worker for task 0.0 in stage 140.0 (TID 165)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 140.0 (TID 165). 4679 bytes result sent to driver
2025-08-10 08:39:59,752 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_746_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 417.4 MiB)
2025-08-10 08:39:59,754 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 746 took 5 ms
2025-08-10 08:39:59,754 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 167
2025-08-10 08:39:59,755 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 142.0 (TID 167)
2025-08-10 08:39:59,755 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_746 stored as values in memory (estimated size 32.0 KiB, free 417.3 MiB)
2025-08-10 08:39:59,757 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 796 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,762 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_796_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 417.3 MiB)
2025-08-10 08:39:59,764 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 796 took 6 ms
2025-08-10 08:39:59,765 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_796 stored as values in memory (estimated size 20.5 KiB, free 417.3 MiB)
2025-08-10 08:39:59,767 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:39:59,768 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 758 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,772 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_758_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.3 MiB)
2025-08-10 08:39:59,775 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:39:59,776 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 758 took 7 ms
2025-08-10 08:39:59,777 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_758 stored as values in memory (estimated size 32.0 KiB, free 425.3 MiB)
2025-08-10 08:39:59,778 [block-manager-storage-async-thread-pool-591] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,782 [block-manager-storage-async-thread-pool-597] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,784 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:39:59,788 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:39:59,790 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:39:59,795 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:39:59,796 [Executor task launch worker for task 0.0 in stage 141.0 (TID 166)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 141.0 (TID 166). 5362 bytes result sent to driver
2025-08-10 08:39:59,796 [block-manager-storage-async-thread-pool-606] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,798 [block-manager-storage-async-thread-pool-612] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,803 [Executor task launch worker for task 0.0 in stage 142.0 (TID 167)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 142.0 (TID 167). 5367 bytes result sent to driver
2025-08-10 08:39:59,810 [block-manager-storage-async-thread-pool-618] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,821 [block-manager-storage-async-thread-pool-639] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,826 [block-manager-storage-async-thread-pool-647] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,831 [block-manager-storage-async-thread-pool-650] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,832 [block-manager-storage-async-thread-pool-654] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,835 [block-manager-storage-async-thread-pool-657] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,839 [block-manager-storage-async-thread-pool-663] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,843 [block-manager-storage-async-thread-pool-567] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,846 [block-manager-storage-async-thread-pool-570] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,849 [block-manager-storage-async-thread-pool-577] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:39:59,907 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 168
2025-08-10 08:39:59,907 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 169
2025-08-10 08:39:59,907 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 143.0 (TID 168)
2025-08-10 08:39:59,908 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 143.0 (TID 169)
2025-08-10 08:39:59,909 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 821 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,912 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_821_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 434.1 MiB)
2025-08-10 08:39:59,914 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 821 took 4 ms
2025-08-10 08:39:59,915 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_821 stored as values in memory (estimated size 35.0 KiB, free 434.0 MiB)
2025-08-10 08:39:59,917 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 808 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,917 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 797 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,920 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_808_piece0 stored as bytes in memory (estimated size 1195.0 B, free 434.0 MiB)
2025-08-10 08:39:59,920 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_797_piece0 stored as bytes in memory (estimated size 493.0 B, free 434.0 MiB)
2025-08-10 08:39:59,922 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 797 took 4 ms
2025-08-10 08:39:59,922 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 808 took 4 ms
2025-08-10 08:39:59,924 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_797 stored as values in memory (estimated size 8.0 MiB, free 418.0 MiB)
2025-08-10 08:39:59,924 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_808 stored as values in memory (estimated size 8.0 MiB, free 418.0 MiB)
2025-08-10 08:39:59,925 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 787 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,925 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 790 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,928 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_787_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.0 MiB)
2025-08-10 08:39:59,928 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_790_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 418.0 MiB)
2025-08-10 08:39:59,929 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 790 took 4 ms
2025-08-10 08:39:59,930 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 787 took 4 ms
2025-08-10 08:39:59,931 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_787 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 08:39:59,931 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_790 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 08:39:59,937 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:39:59,937 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:39:59,941 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:39:59,941 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:39:59,949 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:39:59,949 [Executor task launch worker for task 1.0 in stage 143.0 (TID 169)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 143.0 (TID 169). 7357 bytes result sent to driver
2025-08-10 08:39:59,953 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 170
2025-08-10 08:39:59,953 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 144.0 (TID 170)
2025-08-10 08:39:59,954 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:39:59,955 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 822 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,957 [Executor task launch worker for task 0.0 in stage 143.0 (TID 168)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 143.0 (TID 168). 7228 bytes result sent to driver
2025-08-10 08:39:59,958 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_822_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 417.9 MiB)
2025-08-10 08:39:59,960 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 171
2025-08-10 08:39:59,960 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 822 took 4 ms
2025-08-10 08:39:59,961 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 144.0 (TID 171)
2025-08-10 08:39:59,961 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_822 stored as values in memory (estimated size 33.7 KiB, free 417.9 MiB)
2025-08-10 08:39:59,963 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 779 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,963 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 800 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,967 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_779_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 417.8 MiB)
2025-08-10 08:39:59,967 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_800_piece0 stored as bytes in memory (estimated size 492.0 B, free 417.8 MiB)
2025-08-10 08:39:59,973 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 800 took 9 ms
2025-08-10 08:39:59,973 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 779 took 9 ms
2025-08-10 08:39:59,983 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_779 stored as values in memory (estimated size 32.0 KiB, free 417.8 MiB)
2025-08-10 08:39:59,984 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_800 stored as values in memory (estimated size 8.0 MiB, free 409.8 MiB)
2025-08-10 08:39:59,985 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 780 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:39:59,990 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_780_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.8 MiB)
2025-08-10 08:39:59,993 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 780 took 7 ms
2025-08-10 08:39:59,995 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_780 stored as values in memory (estimated size 32.0 KiB, free 409.8 MiB)
2025-08-10 08:39:59,996 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,003 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,006 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,013 [Executor task launch worker for task 0.0 in stage 144.0 (TID 170)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 144.0 (TID 170). 7236 bytes result sent to driver
2025-08-10 08:40:00,013 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,017 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 172
2025-08-10 08:40:00,019 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 145.0 (TID 172)
2025-08-10 08:40:00,021 [Executor task launch worker for task 1.0 in stage 144.0 (TID 171)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 144.0 (TID 171). 7206 bytes result sent to driver
2025-08-10 08:40:00,023 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 823 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,027 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 173
2025-08-10 08:40:00,028 [Executor task launch worker for task 1.0 in stage 145.0 (TID 173)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 145.0 (TID 173)
2025-08-10 08:40:00,029 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_823_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 409.8 MiB)
2025-08-10 08:40:00,033 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 823 took 9 ms
2025-08-10 08:40:00,035 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_823 stored as values in memory (estimated size 33.7 KiB, free 409.8 MiB)
2025-08-10 08:40:00,038 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 784 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,038 [Executor task launch worker for task 1.0 in stage 145.0 (TID 173)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 785 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,042 [Executor task launch worker for task 1.0 in stage 145.0 (TID 173)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_785_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.7 MiB)
2025-08-10 08:40:00,042 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_784_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.7 MiB)
2025-08-10 08:40:00,055 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 784 took 16 ms
2025-08-10 08:40:00,063 [Executor task launch worker for task 1.0 in stage 145.0 (TID 173)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 785 took 24 ms
2025-08-10 08:40:00,064 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_784 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 08:40:00,064 [Executor task launch worker for task 1.0 in stage 145.0 (TID 173)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_785 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 08:40:00,075 [Executor task launch worker for task 1.0 in stage 145.0 (TID 173)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,075 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,081 [Executor task launch worker for task 1.0 in stage 145.0 (TID 173)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,081 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,087 [Executor task launch worker for task 0.0 in stage 145.0 (TID 172)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 145.0 (TID 172). 7193 bytes result sent to driver
2025-08-10 08:40:00,087 [Executor task launch worker for task 1.0 in stage 145.0 (TID 173)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 145.0 (TID 173). 7163 bytes result sent to driver
2025-08-10 08:40:00,136 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 174
2025-08-10 08:40:00,137 [Executor task launch worker for task 0.0 in stage 146.0 (TID 174)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 146.0 (TID 174)
2025-08-10 08:40:00,138 [Executor task launch worker for task 0.0 in stage 146.0 (TID 174)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 30 and clearing cache
2025-08-10 08:40:00,139 [Executor task launch worker for task 0.0 in stage 146.0 (TID 174)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 838 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,142 [Executor task launch worker for task 0.0 in stage 146.0 (TID 174)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_838_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 409.7 MiB)
2025-08-10 08:40:00,143 [Executor task launch worker for task 0.0 in stage 146.0 (TID 174)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 838 took 3 ms
2025-08-10 08:40:00,144 [Executor task launch worker for task 0.0 in stage 146.0 (TID 174)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_838 stored as values in memory (estimated size 11.7 KiB, free 409.7 MiB)
2025-08-10 08:40:00,147 [Executor task launch worker for task 0.0 in stage 146.0 (TID 174)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 146.0 (TID 174). 1836 bytes result sent to driver
2025-08-10 08:40:00,161 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 175
2025-08-10 08:40:00,162 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 148.0 (TID 175)
2025-08-10 08:40:00,162 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 31 and clearing cache
2025-08-10 08:40:00,163 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 839 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,166 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_839_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 409.7 MiB)
2025-08-10 08:40:00,168 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 839 took 4 ms
2025-08-10 08:40:00,169 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_839 stored as values in memory (estimated size 12.7 KiB, free 409.7 MiB)
2025-08-10 08:40:00,171 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 25, fetching them
2025-08-10 08:40:00,171 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:00,174 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:00,176 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:00,176 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:40:00,178 [Executor task launch worker for task 0.0 in stage 148.0 (TID 175)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 148.0 (TID 175). 3959 bytes result sent to driver
2025-08-10 08:40:00,208 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 176
2025-08-10 08:40:00,208 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 177
2025-08-10 08:40:00,208 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 150.0 (TID 176)
2025-08-10 08:40:00,208 [Executor task launch worker for task 0.0 in stage 150.0 (TID 177)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 150.0 (TID 177)
2025-08-10 08:40:00,209 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 840 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,212 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_840_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.6 MiB)
2025-08-10 08:40:00,213 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 840 took 3 ms
2025-08-10 08:40:00,214 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_840 stored as values in memory (estimated size 88.3 KiB, free 409.6 MiB)
2025-08-10 08:40:00,217 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 24, fetching them
2025-08-10 08:40:00,218 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:00,218 [Executor task launch worker for task 0.0 in stage 150.0 (TID 177)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 776 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,220 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:00,220 [Executor task launch worker for task 0.0 in stage 150.0 (TID 177)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_776_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.5 MiB)
2025-08-10 08:40:00,221 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (72.0 B) non-empty blocks including 1 (72.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:00,221 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 08:40:00,222 [Executor task launch worker for task 0.0 in stage 150.0 (TID 177)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 776 took 3 ms
2025-08-10 08:40:00,223 [Executor task launch worker for task 0.0 in stage 150.0 (TID 177)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_776 stored as values in memory (estimated size 32.0 KiB, free 409.5 MiB)
2025-08-10 08:40:00,230 [Executor task launch worker for task 0.0 in stage 150.0 (TID 177)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,234 [Executor task launch worker for task 0.0 in stage 150.0 (TID 177)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,235 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.34505 ms
2025-08-10 08:40:00,238 [Executor task launch worker for task 3.0 in stage 150.0 (TID 176)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 150.0 (TID 176). 22953 bytes result sent to driver
2025-08-10 08:40:00,240 [Executor task launch worker for task 0.0 in stage 150.0 (TID 177)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 150.0 (TID 177). 22282 bytes result sent to driver
2025-08-10 08:40:00,242 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 178
2025-08-10 08:40:00,242 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 150.0 (TID 178)
2025-08-10 08:40:00,242 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 179
2025-08-10 08:40:00,243 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 150.0 (TID 179)
2025-08-10 08:40:00,246 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 828 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,246 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 833 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,249 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_828_piece0 stored as bytes in memory (estimated size 180.0 B, free 409.5 MiB)
2025-08-10 08:40:00,249 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_833_piece0 stored as bytes in memory (estimated size 180.0 B, free 409.5 MiB)
2025-08-10 08:40:00,251 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 833 took 4 ms
2025-08-10 08:40:00,251 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 828 took 4 ms
2025-08-10 08:40:00,252 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_833 stored as values in memory (estimated size 8.0 MiB, free 401.5 MiB)
2025-08-10 08:40:00,253 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 782 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,253 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_828 stored as values in memory (estimated size 8.0 MiB, free 393.5 MiB)
2025-08-10 08:40:00,253 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 777 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,255 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_782_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.4 MiB)
2025-08-10 08:40:00,255 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_777_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 393.4 MiB)
2025-08-10 08:40:00,257 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 782 took 3 ms
2025-08-10 08:40:00,257 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 777 took 3 ms
2025-08-10 08:40:00,258 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_782 stored as values in memory (estimated size 32.0 KiB, free 393.4 MiB)
2025-08-10 08:40:00,258 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_777 stored as values in memory (estimated size 32.0 KiB, free 393.4 MiB)
2025-08-10 08:40:00,265 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,265 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,269 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,269 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,275 [Executor task launch worker for task 1.0 in stage 150.0 (TID 178)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 150.0 (TID 178). 22308 bytes result sent to driver
2025-08-10 08:40:00,275 [Executor task launch worker for task 2.0 in stage 150.0 (TID 179)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 150.0 (TID 179). 22481 bytes result sent to driver
2025-08-10 08:40:00,320 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 180
2025-08-10 08:40:00,320 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 151.0 (TID 180)
2025-08-10 08:40:00,322 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 843 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,327 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_843_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 393.3 MiB)
2025-08-10 08:40:00,329 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 843 took 6 ms
2025-08-10 08:40:00,329 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_843 stored as values in memory (estimated size 139.0 KiB, free 393.2 MiB)
2025-08-10 08:40:00,337 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 841 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,340 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_841_piece0 stored as bytes in memory (estimated size 465.0 B, free 393.2 MiB)
2025-08-10 08:40:00,342 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 841 took 4 ms
2025-08-10 08:40:00,343 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_841 stored as values in memory (estimated size 792.0 B, free 393.2 MiB)
2025-08-10 08:40:00,347 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 775 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,350 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_775_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 392.7 MiB)
2025-08-10 08:40:00,352 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 775 took 4 ms
2025-08-10 08:40:00,353 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_775 stored as values in memory (estimated size 32.0 KiB, free 392.6 MiB)
2025-08-10 08:40:00,359 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,376 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,381 [Executor task launch worker for task 0.0 in stage 151.0 (TID 180)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 151.0 (TID 180). 41625 bytes result sent to driver
2025-08-10 08:40:00,403 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 181
2025-08-10 08:40:00,403 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 152.0 (TID 181)
2025-08-10 08:40:00,405 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 845 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,407 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_845_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 393.4 MiB)
2025-08-10 08:40:00,409 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 845 took 3 ms
2025-08-10 08:40:00,411 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_845 stored as values in memory (estimated size 22.3 KiB, free 393.4 MiB)
2025-08-10 08:40:00,415 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 844 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,418 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_844_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.4 MiB)
2025-08-10 08:40:00,420 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 844 took 4 ms
2025-08-10 08:40:00,422 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_844 stored as values in memory (estimated size 32.0 KiB, free 393.4 MiB)
2025-08-10 08:40:00,432 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,436 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,445 [Executor task launch worker for task 0.0 in stage 152.0 (TID 181)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 152.0 (TID 181). 4892 bytes result sent to driver
2025-08-10 08:40:00,487 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 182
2025-08-10 08:40:00,488 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 183
2025-08-10 08:40:00,488 [Executor task launch worker for task 0.0 in stage 153.0 (TID 182)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 153.0 (TID 182)
2025-08-10 08:40:00,488 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 153.0 (TID 183)
2025-08-10 08:40:00,489 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 32 and clearing cache
2025-08-10 08:40:00,490 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 855 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,493 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_855_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 393.5 MiB)
2025-08-10 08:40:00,494 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 855 took 4 ms
2025-08-10 08:40:00,495 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_855 stored as values in memory (estimated size 37.5 KiB, free 393.4 MiB)
2025-08-10 08:40:00,497 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 810 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,497 [Executor task launch worker for task 0.0 in stage 153.0 (TID 182)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 755 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,500 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_810_piece0 stored as bytes in memory (estimated size 1201.0 B, free 393.4 MiB)
2025-08-10 08:40:00,500 [Executor task launch worker for task 0.0 in stage 153.0 (TID 182)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_755_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 393.4 MiB)
2025-08-10 08:40:00,503 [Executor task launch worker for task 0.0 in stage 153.0 (TID 182)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 755 took 4 ms
2025-08-10 08:40:00,503 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 810 took 5 ms
2025-08-10 08:40:00,504 [Executor task launch worker for task 0.0 in stage 153.0 (TID 182)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_755 stored as values in memory (estimated size 32.0 KiB, free 393.4 MiB)
2025-08-10 08:40:00,504 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_810 stored as values in memory (estimated size 8.0 MiB, free 385.4 MiB)
2025-08-10 08:40:00,505 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 757 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,508 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_757_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 385.3 MiB)
2025-08-10 08:40:00,510 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 757 took 4 ms
2025-08-10 08:40:00,511 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_757 stored as values in memory (estimated size 32.0 KiB, free 385.3 MiB)
2025-08-10 08:40:00,512 [Executor task launch worker for task 0.0 in stage 153.0 (TID 182)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,516 [Executor task launch worker for task 0.0 in stage 153.0 (TID 182)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,518 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,522 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,524 [Executor task launch worker for task 0.0 in stage 153.0 (TID 182)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,528 [Executor task launch worker for task 0.0 in stage 153.0 (TID 182)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,531 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,532 [Executor task launch worker for task 0.0 in stage 153.0 (TID 182)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 153.0 (TID 182). 7228 bytes result sent to driver
2025-08-10 08:40:00,535 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,539 [Executor task launch worker for task 1.0 in stage 153.0 (TID 183)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 153.0 (TID 183). 7357 bytes result sent to driver
2025-08-10 08:40:00,648 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 184
2025-08-10 08:40:00,649 [Executor task launch worker for task 0.0 in stage 154.0 (TID 184)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 154.0 (TID 184)
2025-08-10 08:40:00,650 [Executor task launch worker for task 0.0 in stage 154.0 (TID 184)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 33 and clearing cache
2025-08-10 08:40:00,651 [Executor task launch worker for task 0.0 in stage 154.0 (TID 184)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 878 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,655 [Executor task launch worker for task 0.0 in stage 154.0 (TID 184)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_878_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 385.4 MiB)
2025-08-10 08:40:00,657 [Executor task launch worker for task 0.0 in stage 154.0 (TID 184)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 878 took 5 ms
2025-08-10 08:40:00,658 [Executor task launch worker for task 0.0 in stage 154.0 (TID 184)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_878 stored as values in memory (estimated size 11.7 KiB, free 385.3 MiB)
2025-08-10 08:40:00,661 [Executor task launch worker for task 0.0 in stage 154.0 (TID 184)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 154.0 (TID 184). 1836 bytes result sent to driver
2025-08-10 08:40:00,678 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 185
2025-08-10 08:40:00,678 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 156.0 (TID 185)
2025-08-10 08:40:00,679 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 34 and clearing cache
2025-08-10 08:40:00,679 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 879 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,682 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_879_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 385.3 MiB)
2025-08-10 08:40:00,683 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 879 took 3 ms
2025-08-10 08:40:00,683 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_879 stored as values in memory (estimated size 12.7 KiB, free 385.3 MiB)
2025-08-10 08:40:00,685 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 28, fetching them
2025-08-10 08:40:00,685 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:00,686 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:00,687 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:00,687 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 08:40:00,695 [Executor task launch worker for task 0.0 in stage 156.0 (TID 185)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 156.0 (TID 185). 4002 bytes result sent to driver
2025-08-10 08:40:00,726 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 186
2025-08-10 08:40:00,727 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 187
2025-08-10 08:40:00,727 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 158.0 (TID 186)
2025-08-10 08:40:00,727 [Executor task launch worker for task 0.0 in stage 158.0 (TID 187)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 158.0 (TID 187)
2025-08-10 08:40:00,728 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 880 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,731 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_880_piece0 stored as bytes in memory (estimated size 34.4 KiB, free 385.3 MiB)
2025-08-10 08:40:00,732 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 880 took 3 ms
2025-08-10 08:40:00,733 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_880 stored as values in memory (estimated size 105.2 KiB, free 385.2 MiB)
2025-08-10 08:40:00,736 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 27, fetching them
2025-08-10 08:40:00,736 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:00,738 [Executor task launch worker for task 0.0 in stage 158.0 (TID 187)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 867 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,738 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:00,739 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:00,739 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 08:40:00,740 [Executor task launch worker for task 0.0 in stage 158.0 (TID 187)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_867_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 385.2 MiB)
2025-08-10 08:40:00,742 [Executor task launch worker for task 0.0 in stage 158.0 (TID 187)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 867 took 4 ms
2025-08-10 08:40:00,743 [Executor task launch worker for task 0.0 in stage 158.0 (TID 187)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_867 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 08:40:00,750 [Executor task launch worker for task 0.0 in stage 158.0 (TID 187)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,754 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.873077 ms
2025-08-10 08:40:00,755 [Executor task launch worker for task 0.0 in stage 158.0 (TID 187)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,762 [Executor task launch worker for task 3.0 in stage 158.0 (TID 186)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 158.0 (TID 186). 23293 bytes result sent to driver
2025-08-10 08:40:00,765 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 188
2025-08-10 08:40:00,765 [Executor task launch worker for task 1.0 in stage 158.0 (TID 188)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 158.0 (TID 188)
2025-08-10 08:40:00,768 [Executor task launch worker for task 0.0 in stage 158.0 (TID 187)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 158.0 (TID 187). 22605 bytes result sent to driver
2025-08-10 08:40:00,771 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 189
2025-08-10 08:40:00,772 [Executor task launch worker for task 1.0 in stage 158.0 (TID 188)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 868 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,772 [Executor task launch worker for task 2.0 in stage 158.0 (TID 189)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 158.0 (TID 189)
2025-08-10 08:40:00,775 [Executor task launch worker for task 1.0 in stage 158.0 (TID 188)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_868_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 385.1 MiB)
2025-08-10 08:40:00,777 [Executor task launch worker for task 1.0 in stage 158.0 (TID 188)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 868 took 4 ms
2025-08-10 08:40:00,778 [Executor task launch worker for task 1.0 in stage 158.0 (TID 188)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_868 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 08:40:00,778 [Executor task launch worker for task 2.0 in stage 158.0 (TID 189)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 873 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,782 [Executor task launch worker for task 2.0 in stage 158.0 (TID 189)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_873_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 385.0 MiB)
2025-08-10 08:40:00,784 [Executor task launch worker for task 2.0 in stage 158.0 (TID 189)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 873 took 5 ms
2025-08-10 08:40:00,785 [Executor task launch worker for task 2.0 in stage 158.0 (TID 189)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_873 stored as values in memory (estimated size 32.0 KiB, free 385.0 MiB)
2025-08-10 08:40:00,787 [Executor task launch worker for task 1.0 in stage 158.0 (TID 188)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,791 [Executor task launch worker for task 1.0 in stage 158.0 (TID 188)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,793 [Executor task launch worker for task 2.0 in stage 158.0 (TID 189)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:00,798 [Executor task launch worker for task 2.0 in stage 158.0 (TID 189)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:00,801 [Executor task launch worker for task 1.0 in stage 158.0 (TID 188)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 158.0 (TID 188). 22648 bytes result sent to driver
2025-08-10 08:40:00,810 [Executor task launch worker for task 2.0 in stage 158.0 (TID 189)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 158.0 (TID 189). 22648 bytes result sent to driver
2025-08-10 08:40:00,872 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 190
2025-08-10 08:40:00,873 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 162.0 (TID 190)
2025-08-10 08:40:00,873 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 35 and clearing cache
2025-08-10 08:40:00,874 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 882 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,877 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_882_piece0 stored as bytes in memory (estimated size 91.4 KiB, free 384.9 MiB)
2025-08-10 08:40:00,880 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 882 took 5 ms
2025-08-10 08:40:00,880 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_882 stored as values in memory (estimated size 315.1 KiB, free 384.6 MiB)
2025-08-10 08:40:00,888 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 26, fetching them
2025-08-10 08:40:00,889 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:00,891 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:00,893 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (7.5 KiB) non-empty blocks including 1 (7.5 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:00,893 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 08:40:00,897 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 29, fetching them
2025-08-10 08:40:00,897 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:00,900 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:00,901 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 (4.9 KiB) non-empty blocks including 4 (4.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:00,901 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:40:00,914 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 881 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:00,917 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_881_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 384.5 MiB)
2025-08-10 08:40:00,920 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 881 took 5 ms
2025-08-10 08:40:00,921 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_881 stored as values in memory (estimated size 32.0 KiB, free 384.4 MiB)
2025-08-10 08:40:00,923 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:40:00,928 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:40:00,949 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 190, attempt 0, stage 162.0)
2025-08-10 08:40:00,951 [Executor task launch worker for task 0.0 in stage 162.0 (TID 190)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 162.0 (TID 190). 119762 bytes result sent to driver
2025-08-10 08:40:31,254 [block-manager-storage-async-thread-pool-600] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:31,588 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 191
2025-08-10 08:40:31,589 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 192
2025-08-10 08:40:31,589 [Executor task launch worker for task 0.0 in stage 163.0 (TID 191)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 163.0 (TID 191)
2025-08-10 08:40:31,589 [Executor task launch worker for task 1.0 in stage 163.0 (TID 192)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 163.0 (TID 192)
2025-08-10 08:40:31,591 [Executor task launch worker for task 0.0 in stage 163.0 (TID 191)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 884 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:31,593 [Executor task launch worker for task 0.0 in stage 163.0 (TID 191)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_884_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 385.2 MiB)
2025-08-10 08:40:31,595 [Executor task launch worker for task 0.0 in stage 163.0 (TID 191)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 884 took 4 ms
2025-08-10 08:40:31,596 [Executor task launch worker for task 0.0 in stage 163.0 (TID 191)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_884 stored as values in memory (estimated size 8.0 KiB, free 385.2 MiB)
2025-08-10 08:40:31,597 [Executor task launch worker for task 1.0 in stage 163.0 (TID 192)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 883 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:31,599 [Executor task launch worker for task 1.0 in stage 163.0 (TID 192)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_883_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 385.1 MiB)
2025-08-10 08:40:31,601 [Executor task launch worker for task 1.0 in stage 163.0 (TID 192)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 883 took 3 ms
2025-08-10 08:40:31,602 [Executor task launch worker for task 1.0 in stage 163.0 (TID 192)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_883 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 08:40:31,604 [Executor task launch worker for task 1.0 in stage 163.0 (TID 192)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:40:31,604 [Executor task launch worker for task 0.0 in stage 163.0 (TID 191)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:40:31,605 [Executor task launch worker for task 0.0 in stage 163.0 (TID 191)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:40:31,605 [Executor task launch worker for task 1.0 in stage 163.0 (TID 192)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 08:40:31,626 [Executor task launch worker for task 1.0 in stage 163.0 (TID 192)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 192, attempt 0, stage 163.0)
2025-08-10 08:40:31,628 [Executor task launch worker for task 1.0 in stage 163.0 (TID 192)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 163.0 (TID 192). 4072 bytes result sent to driver
2025-08-10 08:40:31,653 [Executor task launch worker for task 0.0 in stage 163.0 (TID 191)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 191, attempt 0, stage 163.0)
2025-08-10 08:40:31,654 [Executor task launch worker for task 0.0 in stage 163.0 (TID 191)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 163.0 (TID 191). 4074 bytes result sent to driver
2025-08-10 08:40:39,124 [block-manager-storage-async-thread-pool-617] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,779 [block-manager-storage-async-thread-pool-625] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,786 [block-manager-storage-async-thread-pool-634] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,795 [block-manager-storage-async-thread-pool-633] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,801 [block-manager-storage-async-thread-pool-645] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,816 [block-manager-storage-async-thread-pool-581] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,821 [block-manager-storage-async-thread-pool-588] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,825 [block-manager-storage-async-thread-pool-603] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,840 [block-manager-storage-async-thread-pool-620] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,849 [block-manager-storage-async-thread-pool-634] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,857 [block-manager-storage-async-thread-pool-653] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,861 [block-manager-storage-async-thread-pool-656] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,865 [block-manager-storage-async-thread-pool-569] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,867 [block-manager-storage-async-thread-pool-567] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,877 [block-manager-storage-async-thread-pool-586] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,879 [block-manager-storage-async-thread-pool-584] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,891 [block-manager-storage-async-thread-pool-602] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,904 [block-manager-storage-async-thread-pool-606] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,909 [block-manager-storage-async-thread-pool-615] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,912 [block-manager-storage-async-thread-pool-623] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:39,928 [block-manager-storage-async-thread-pool-650] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:40:40,242 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 193
2025-08-10 08:40:40,243 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 164.0 (TID 193)
2025-08-10 08:40:40,245 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 967 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,250 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_967_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
2025-08-10 08:40:40,251 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 194
2025-08-10 08:40:40,252 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 165.0 (TID 194)
2025-08-10 08:40:40,254 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 967 took 8 ms
2025-08-10 08:40:40,255 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_967 stored as values in memory (estimated size 13.6 KiB, free 434.4 MiB)
2025-08-10 08:40:40,256 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 968 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,258 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 923 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,260 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_968_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.4 MiB)
2025-08-10 08:40:40,262 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 968 took 6 ms
2025-08-10 08:40:40,263 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_923_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 434.3 MiB)
2025-08-10 08:40:40,264 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_968 stored as values in memory (estimated size 14.3 KiB, free 434.3 MiB)
2025-08-10 08:40:40,266 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 923 took 7 ms
2025-08-10 08:40:40,266 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 930 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,268 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_923 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 08:40:40,271 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_930_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 08:40:40,273 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 930 took 6 ms
2025-08-10 08:40:40,275 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_930 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 08:40:40,282 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,285 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,288 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,290 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,295 [Executor task launch worker for task 0.0 in stage 165.0 (TID 194)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 165.0 (TID 194). 4679 bytes result sent to driver
2025-08-10 08:40:40,295 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,299 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 195
2025-08-10 08:40:40,300 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 166.0 (TID 195)
2025-08-10 08:40:40,302 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 969 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,303 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,307 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_969_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 434.2 MiB)
2025-08-10 08:40:40,307 [Executor task launch worker for task 0.0 in stage 164.0 (TID 193)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 164.0 (TID 193). 4680 bytes result sent to driver
2025-08-10 08:40:40,313 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 969 took 11 ms
2025-08-10 08:40:40,315 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_969 stored as values in memory (estimated size 19.9 KiB, free 434.2 MiB)
2025-08-10 08:40:40,315 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 196
2025-08-10 08:40:40,316 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 167.0 (TID 196)
2025-08-10 08:40:40,317 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 920 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,318 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 970 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,321 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_920_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.2 MiB)
2025-08-10 08:40:40,322 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_970_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.2 MiB)
2025-08-10 08:40:40,323 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 920 took 5 ms
2025-08-10 08:40:40,324 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 970 took 5 ms
2025-08-10 08:40:40,325 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_920 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:40:40,325 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_970 stored as values in memory (estimated size 20.5 KiB, free 434.1 MiB)
2025-08-10 08:40:40,327 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 932 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,332 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_932_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.1 MiB)
2025-08-10 08:40:40,334 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 932 took 6 ms
2025-08-10 08:40:40,336 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_932 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 08:40:40,336 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,342 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,346 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,351 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,351 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,359 [Executor task launch worker for task 0.0 in stage 167.0 (TID 196)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 167.0 (TID 196). 5369 bytes result sent to driver
2025-08-10 08:40:40,359 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,364 [Executor task launch worker for task 0.0 in stage 166.0 (TID 195)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 166.0 (TID 195). 5364 bytes result sent to driver
2025-08-10 08:40:40,519 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 197
2025-08-10 08:40:40,519 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 198
2025-08-10 08:40:40,519 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 168.0 (TID 197)
2025-08-10 08:40:40,520 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 168.0 (TID 198)
2025-08-10 08:40:40,521 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 995 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,525 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_995_piece0 stored as bytes in memory (estimated size 11.6 KiB, free 434.1 MiB)
2025-08-10 08:40:40,527 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 995 took 5 ms
2025-08-10 08:40:40,528 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_995 stored as values in memory (estimated size 35.0 KiB, free 434.1 MiB)
2025-08-10 08:40:40,531 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 971 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,531 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 981 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,535 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_971_piece0 stored as bytes in memory (estimated size 493.0 B, free 434.1 MiB)
2025-08-10 08:40:40,535 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_981_piece0 stored as bytes in memory (estimated size 1191.0 B, free 434.1 MiB)
2025-08-10 08:40:40,536 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 971 took 5 ms
2025-08-10 08:40:40,537 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 981 took 5 ms
2025-08-10 08:40:40,538 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_971 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:40:40,538 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_981 stored as values in memory (estimated size 8.0 MiB, free 418.1 MiB)
2025-08-10 08:40:40,539 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 961 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,539 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 964 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,542 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_961_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.0 MiB)
2025-08-10 08:40:40,542 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_964_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 418.0 MiB)
2025-08-10 08:40:40,544 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 961 took 4 ms
2025-08-10 08:40:40,544 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 964 took 5 ms
2025-08-10 08:40:40,545 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_961 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:40:40,545 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_964 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 08:40:40,555 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,555 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,562 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,563 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,572 [Executor task launch worker for task 1.0 in stage 168.0 (TID 198)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 168.0 (TID 198). 7228 bytes result sent to driver
2025-08-10 08:40:40,576 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,577 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 199
2025-08-10 08:40:40,578 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 169.0 (TID 199)
2025-08-10 08:40:40,580 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 996 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,585 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,585 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_996_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 418.0 MiB)
2025-08-10 08:40:40,588 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 996 took 7 ms
2025-08-10 08:40:40,589 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_996 stored as values in memory (estimated size 33.7 KiB, free 417.9 MiB)
2025-08-10 08:40:40,590 [Executor task launch worker for task 0.0 in stage 168.0 (TID 197)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 168.0 (TID 197). 7357 bytes result sent to driver
2025-08-10 08:40:40,592 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 958 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,596 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 200
2025-08-10 08:40:40,598 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 169.0 (TID 200)
2025-08-10 08:40:40,601 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_958_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.9 MiB)
2025-08-10 08:40:40,603 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 974 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,604 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 958 took 9 ms
2025-08-10 08:40:40,606 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_958 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 08:40:40,608 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_974_piece0 stored as bytes in memory (estimated size 484.0 B, free 417.9 MiB)
2025-08-10 08:40:40,610 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 974 took 7 ms
2025-08-10 08:40:40,621 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_974 stored as values in memory (estimated size 8.0 MiB, free 409.9 MiB)
2025-08-10 08:40:40,623 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 959 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,627 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,630 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_959_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.8 MiB)
2025-08-10 08:40:40,635 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 959 took 11 ms
2025-08-10 08:40:40,637 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,638 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_959 stored as values in memory (estimated size 32.0 KiB, free 409.8 MiB)
2025-08-10 08:40:40,648 [Executor task launch worker for task 0.0 in stage 169.0 (TID 199)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 169.0 (TID 199). 7206 bytes result sent to driver
2025-08-10 08:40:40,654 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,654 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 201
2025-08-10 08:40:40,655 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 170.0 (TID 201)
2025-08-10 08:40:40,659 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 997 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,663 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,667 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_997_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 409.8 MiB)
2025-08-10 08:40:40,670 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 997 took 8 ms
2025-08-10 08:40:40,671 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_997 stored as values in memory (estimated size 33.7 KiB, free 409.8 MiB)
2025-08-10 08:40:40,672 [Executor task launch worker for task 1.0 in stage 169.0 (TID 200)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 169.0 (TID 200). 7236 bytes result sent to driver
2025-08-10 08:40:40,676 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 953 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,678 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 202
2025-08-10 08:40:40,678 [Executor task launch worker for task 1.0 in stage 170.0 (TID 202)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 170.0 (TID 202)
2025-08-10 08:40:40,681 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_953_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.7 MiB)
2025-08-10 08:40:40,685 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 953 took 8 ms
2025-08-10 08:40:40,686 [Executor task launch worker for task 1.0 in stage 170.0 (TID 202)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 954 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,688 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_953 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 08:40:40,691 [Executor task launch worker for task 1.0 in stage 170.0 (TID 202)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_954_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.7 MiB)
2025-08-10 08:40:40,694 [Executor task launch worker for task 1.0 in stage 170.0 (TID 202)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 954 took 7 ms
2025-08-10 08:40:40,698 [Executor task launch worker for task 1.0 in stage 170.0 (TID 202)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_954 stored as values in memory (estimated size 32.0 KiB, free 409.6 MiB)
2025-08-10 08:40:40,702 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,709 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,711 [Executor task launch worker for task 1.0 in stage 170.0 (TID 202)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,716 [Executor task launch worker for task 0.0 in stage 170.0 (TID 201)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 170.0 (TID 201). 7163 bytes result sent to driver
2025-08-10 08:40:40,721 [Executor task launch worker for task 1.0 in stage 170.0 (TID 202)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,727 [Executor task launch worker for task 1.0 in stage 170.0 (TID 202)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 170.0 (TID 202). 7193 bytes result sent to driver
2025-08-10 08:40:40,780 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 203
2025-08-10 08:40:40,781 [Executor task launch worker for task 0.0 in stage 171.0 (TID 203)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 171.0 (TID 203)
2025-08-10 08:40:40,782 [Executor task launch worker for task 0.0 in stage 171.0 (TID 203)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 36 and clearing cache
2025-08-10 08:40:40,783 [Executor task launch worker for task 0.0 in stage 171.0 (TID 203)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1012 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,786 [Executor task launch worker for task 0.0 in stage 171.0 (TID 203)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1012_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 409.6 MiB)
2025-08-10 08:40:40,788 [Executor task launch worker for task 0.0 in stage 171.0 (TID 203)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1012 took 5 ms
2025-08-10 08:40:40,789 [Executor task launch worker for task 0.0 in stage 171.0 (TID 203)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1012 stored as values in memory (estimated size 11.7 KiB, free 409.6 MiB)
2025-08-10 08:40:40,792 [Executor task launch worker for task 0.0 in stage 171.0 (TID 203)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 171.0 (TID 203). 1836 bytes result sent to driver
2025-08-10 08:40:40,811 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 204
2025-08-10 08:40:40,811 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 173.0 (TID 204)
2025-08-10 08:40:40,816 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 37 and clearing cache
2025-08-10 08:40:40,817 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1013 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,821 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1013_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 409.6 MiB)
2025-08-10 08:40:40,823 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1013 took 5 ms
2025-08-10 08:40:40,824 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1013 stored as values in memory (estimated size 12.7 KiB, free 409.6 MiB)
2025-08-10 08:40:40,825 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 31, fetching them
2025-08-10 08:40:40,825 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:40,827 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:40,828 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:40,828 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 08:40:40,830 [Executor task launch worker for task 0.0 in stage 173.0 (TID 204)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 173.0 (TID 204). 3959 bytes result sent to driver
2025-08-10 08:40:40,870 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 205
2025-08-10 08:40:40,871 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 175.0 (TID 205)
2025-08-10 08:40:40,871 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 206
2025-08-10 08:40:40,871 [Executor task launch worker for task 0.0 in stage 175.0 (TID 206)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 175.0 (TID 206)
2025-08-10 08:40:40,872 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1014 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,875 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1014_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.6 MiB)
2025-08-10 08:40:40,876 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1014 took 3 ms
2025-08-10 08:40:40,877 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1014 stored as values in memory (estimated size 88.3 KiB, free 409.5 MiB)
2025-08-10 08:40:40,880 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 30, fetching them
2025-08-10 08:40:40,880 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:40,880 [Executor task launch worker for task 0.0 in stage 175.0 (TID 206)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 950 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,882 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:40,883 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:40,883 [Executor task launch worker for task 0.0 in stage 175.0 (TID 206)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_950_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.5 MiB)
2025-08-10 08:40:40,884 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 08:40:40,885 [Executor task launch worker for task 0.0 in stage 175.0 (TID 206)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 950 took 4 ms
2025-08-10 08:40:40,887 [Executor task launch worker for task 0.0 in stage 175.0 (TID 206)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_950 stored as values in memory (estimated size 32.0 KiB, free 409.4 MiB)
2025-08-10 08:40:40,896 [Executor task launch worker for task 0.0 in stage 175.0 (TID 206)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,898 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.46092 ms
2025-08-10 08:40:40,900 [Executor task launch worker for task 3.0 in stage 175.0 (TID 205)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 175.0 (TID 205). 22953 bytes result sent to driver
2025-08-10 08:40:40,901 [Executor task launch worker for task 0.0 in stage 175.0 (TID 206)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,903 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 207
2025-08-10 08:40:40,905 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 175.0 (TID 207)
2025-08-10 08:40:40,908 [Executor task launch worker for task 0.0 in stage 175.0 (TID 206)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 175.0 (TID 206). 22292 bytes result sent to driver
2025-08-10 08:40:40,909 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1007 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,911 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 208
2025-08-10 08:40:40,911 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 175.0 (TID 208)
2025-08-10 08:40:40,913 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1007_piece0 stored as bytes in memory (estimated size 180.0 B, free 409.4 MiB)
2025-08-10 08:40:40,915 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1007 took 5 ms
2025-08-10 08:40:40,916 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1007 stored as values in memory (estimated size 8.0 MiB, free 401.4 MiB)
2025-08-10 08:40:40,916 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1002 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,917 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 951 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,919 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1002_piece0 stored as bytes in memory (estimated size 180.0 B, free 401.4 MiB)
2025-08-10 08:40:40,919 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_951_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 401.4 MiB)
2025-08-10 08:40:40,921 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1002 took 4 ms
2025-08-10 08:40:40,921 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 951 took 3 ms
2025-08-10 08:40:40,922 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_951 stored as values in memory (estimated size 32.0 KiB, free 401.4 MiB)
2025-08-10 08:40:40,923 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1002 stored as values in memory (estimated size 8.0 MiB, free 393.4 MiB)
2025-08-10 08:40:40,923 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 956 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:40,927 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_956_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.3 MiB)
2025-08-10 08:40:40,929 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 956 took 4 ms
2025-08-10 08:40:40,930 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_956 stored as values in memory (estimated size 32.0 KiB, free 393.3 MiB)
2025-08-10 08:40:40,930 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,934 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,936 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:40,939 [Executor task launch worker for task 1.0 in stage 175.0 (TID 207)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 175.0 (TID 207). 22308 bytes result sent to driver
2025-08-10 08:40:40,941 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:40,946 [Executor task launch worker for task 2.0 in stage 175.0 (TID 208)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 175.0 (TID 208). 22481 bytes result sent to driver
2025-08-10 08:40:41,027 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 209
2025-08-10 08:40:41,028 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 176.0 (TID 209)
2025-08-10 08:40:41,030 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1017 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,034 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1017_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 393.5 MiB)
2025-08-10 08:40:41,037 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1017 took 5 ms
2025-08-10 08:40:41,038 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1017 stored as values in memory (estimated size 139.0 KiB, free 393.4 MiB)
2025-08-10 08:40:41,045 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1015 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,048 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1015_piece0 stored as bytes in memory (estimated size 481.0 B, free 393.4 MiB)
2025-08-10 08:40:41,050 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1015 took 4 ms
2025-08-10 08:40:41,051 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1015 stored as values in memory (estimated size 824.0 B, free 393.4 MiB)
2025-08-10 08:40:41,055 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 949 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,058 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_949_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 392.9 MiB)
2025-08-10 08:40:41,060 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 949 took 4 ms
2025-08-10 08:40:41,061 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_949 stored as values in memory (estimated size 32.0 KiB, free 392.8 MiB)
2025-08-10 08:40:41,069 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:41,074 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:41,079 [Executor task launch worker for task 0.0 in stage 176.0 (TID 209)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 176.0 (TID 209). 41625 bytes result sent to driver
2025-08-10 08:40:41,111 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 210
2025-08-10 08:40:41,112 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 177.0 (TID 210)
2025-08-10 08:40:41,114 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1019 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,122 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1019_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 393.5 MiB)
2025-08-10 08:40:41,123 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1019 took 9 ms
2025-08-10 08:40:41,124 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1019 stored as values in memory (estimated size 22.3 KiB, free 393.5 MiB)
2025-08-10 08:40:41,128 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1018 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,134 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1018_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.5 MiB)
2025-08-10 08:40:41,135 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1018 took 6 ms
2025-08-10 08:40:41,136 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1018 stored as values in memory (estimated size 32.0 KiB, free 393.4 MiB)
2025-08-10 08:40:41,145 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:41,150 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:41,164 [Executor task launch worker for task 0.0 in stage 177.0 (TID 210)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 177.0 (TID 210). 4892 bytes result sent to driver
2025-08-10 08:40:41,264 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 211
2025-08-10 08:40:41,264 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 212
2025-08-10 08:40:41,265 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 178.0 (TID 211)
2025-08-10 08:40:41,266 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 178.0 (TID 212)
2025-08-10 08:40:41,267 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 38 and clearing cache
2025-08-10 08:40:41,270 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1029 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,275 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1029_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 393.4 MiB)
2025-08-10 08:40:41,278 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1029 took 6 ms
2025-08-10 08:40:41,280 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1029 stored as values in memory (estimated size 37.5 KiB, free 393.4 MiB)
2025-08-10 08:40:41,284 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 929 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,285 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 980 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,312 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_929_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 393.4 MiB)
2025-08-10 08:40:41,312 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_980_piece0 stored as bytes in memory (estimated size 1203.0 B, free 393.4 MiB)
2025-08-10 08:40:41,315 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 929 took 30 ms
2025-08-10 08:40:41,315 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 980 took 29 ms
2025-08-10 08:40:41,316 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_929 stored as values in memory (estimated size 32.0 KiB, free 385.3 MiB)
2025-08-10 08:40:41,316 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_980 stored as values in memory (estimated size 8.0 MiB, free 385.3 MiB)
2025-08-10 08:40:41,317 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 931 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,322 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_931_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 385.3 MiB)
2025-08-10 08:40:41,324 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 931 took 6 ms
2025-08-10 08:40:41,326 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_931 stored as values in memory (estimated size 32.0 KiB, free 385.3 MiB)
2025-08-10 08:40:41,331 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:41,335 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:41,336 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:41,345 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:41,350 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:41,358 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:41,358 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:41,367 [Executor task launch worker for task 0.0 in stage 178.0 (TID 211)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 178.0 (TID 211). 7357 bytes result sent to driver
2025-08-10 08:40:41,369 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:41,375 [Executor task launch worker for task 1.0 in stage 178.0 (TID 212)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 178.0 (TID 212). 7228 bytes result sent to driver
2025-08-10 08:40:41,544 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 213
2025-08-10 08:40:41,546 [Executor task launch worker for task 0.0 in stage 179.0 (TID 213)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 179.0 (TID 213)
2025-08-10 08:40:41,547 [Executor task launch worker for task 0.0 in stage 179.0 (TID 213)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 39 and clearing cache
2025-08-10 08:40:41,550 [Executor task launch worker for task 0.0 in stage 179.0 (TID 213)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1052 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,556 [Executor task launch worker for task 0.0 in stage 179.0 (TID 213)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1052_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 385.3 MiB)
2025-08-10 08:40:41,560 [Executor task launch worker for task 0.0 in stage 179.0 (TID 213)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1052 took 9 ms
2025-08-10 08:40:41,564 [Executor task launch worker for task 0.0 in stage 179.0 (TID 213)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1052 stored as values in memory (estimated size 11.7 KiB, free 385.3 MiB)
2025-08-10 08:40:41,569 [Executor task launch worker for task 0.0 in stage 179.0 (TID 213)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 179.0 (TID 213). 1836 bytes result sent to driver
2025-08-10 08:40:41,604 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 214
2025-08-10 08:40:41,604 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 181.0 (TID 214)
2025-08-10 08:40:41,605 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 40 and clearing cache
2025-08-10 08:40:41,606 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1053 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,610 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1053_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 385.3 MiB)
2025-08-10 08:40:41,612 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1053 took 6 ms
2025-08-10 08:40:41,613 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1053 stored as values in memory (estimated size 12.7 KiB, free 385.3 MiB)
2025-08-10 08:40:41,614 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 34, fetching them
2025-08-10 08:40:41,614 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:41,624 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:41,626 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:41,627 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
2025-08-10 08:40:41,638 [Executor task launch worker for task 0.0 in stage 181.0 (TID 214)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 181.0 (TID 214). 4002 bytes result sent to driver
2025-08-10 08:40:41,694 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 215
2025-08-10 08:40:41,694 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 216
2025-08-10 08:40:41,694 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 183.0 (TID 215)
2025-08-10 08:40:41,695 [Executor task launch worker for task 0.0 in stage 183.0 (TID 216)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 183.0 (TID 216)
2025-08-10 08:40:41,697 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1054 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,704 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1054_piece0 stored as bytes in memory (estimated size 34.4 KiB, free 385.3 MiB)
2025-08-10 08:40:41,706 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1054 took 8 ms
2025-08-10 08:40:41,707 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1054 stored as values in memory (estimated size 105.2 KiB, free 385.2 MiB)
2025-08-10 08:40:41,712 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 33, fetching them
2025-08-10 08:40:41,713 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:41,716 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:41,716 [Executor task launch worker for task 0.0 in stage 183.0 (TID 216)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1041 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,718 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (207.0 B) non-empty blocks including 1 (207.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:41,719 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:40:41,724 [Executor task launch worker for task 0.0 in stage 183.0 (TID 216)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1041_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 385.2 MiB)
2025-08-10 08:40:41,728 [Executor task launch worker for task 0.0 in stage 183.0 (TID 216)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1041 took 10 ms
2025-08-10 08:40:41,731 [Executor task launch worker for task 0.0 in stage 183.0 (TID 216)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1041 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 08:40:41,749 [Executor task launch worker for task 0.0 in stage 183.0 (TID 216)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:41,754 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.530304 ms
2025-08-10 08:40:41,759 [Executor task launch worker for task 0.0 in stage 183.0 (TID 216)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:41,769 [Executor task launch worker for task 3.0 in stage 183.0 (TID 215)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 183.0 (TID 215). 23293 bytes result sent to driver
2025-08-10 08:40:41,774 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 217
2025-08-10 08:40:41,776 [Executor task launch worker for task 1.0 in stage 183.0 (TID 217)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 183.0 (TID 217)
2025-08-10 08:40:41,777 [Executor task launch worker for task 0.0 in stage 183.0 (TID 216)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 183.0 (TID 216). 22605 bytes result sent to driver
2025-08-10 08:40:41,780 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 218
2025-08-10 08:40:41,781 [Executor task launch worker for task 2.0 in stage 183.0 (TID 218)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 183.0 (TID 218)
2025-08-10 08:40:41,785 [Executor task launch worker for task 1.0 in stage 183.0 (TID 217)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1042 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,790 [Executor task launch worker for task 1.0 in stage 183.0 (TID 217)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1042_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 385.1 MiB)
2025-08-10 08:40:41,791 [Executor task launch worker for task 2.0 in stage 183.0 (TID 218)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1047 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,793 [Executor task launch worker for task 1.0 in stage 183.0 (TID 217)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1042 took 7 ms
2025-08-10 08:40:41,794 [Executor task launch worker for task 1.0 in stage 183.0 (TID 217)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1042 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 08:40:41,795 [Executor task launch worker for task 2.0 in stage 183.0 (TID 218)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1047_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 385.0 MiB)
2025-08-10 08:40:41,796 [Executor task launch worker for task 2.0 in stage 183.0 (TID 218)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1047 took 4 ms
2025-08-10 08:40:41,798 [Executor task launch worker for task 2.0 in stage 183.0 (TID 218)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1047 stored as values in memory (estimated size 32.0 KiB, free 385.0 MiB)
2025-08-10 08:40:41,804 [Executor task launch worker for task 1.0 in stage 183.0 (TID 217)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:41,806 [Executor task launch worker for task 2.0 in stage 183.0 (TID 218)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 08:40:41,809 [Executor task launch worker for task 1.0 in stage 183.0 (TID 217)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:41,814 [Executor task launch worker for task 2.0 in stage 183.0 (TID 218)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 08:40:41,823 [Executor task launch worker for task 1.0 in stage 183.0 (TID 217)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 183.0 (TID 217). 22648 bytes result sent to driver
2025-08-10 08:40:41,841 [Executor task launch worker for task 2.0 in stage 183.0 (TID 218)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 183.0 (TID 218). 22648 bytes result sent to driver
2025-08-10 08:40:41,928 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 219
2025-08-10 08:40:41,928 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 187.0 (TID 219)
2025-08-10 08:40:41,929 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 41 and clearing cache
2025-08-10 08:40:41,930 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1056 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:41,934 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1056_piece0 stored as bytes in memory (estimated size 91.6 KiB, free 384.9 MiB)
2025-08-10 08:40:41,935 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1056 took 5 ms
2025-08-10 08:40:41,936 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1056 stored as values in memory (estimated size 315.1 KiB, free 384.6 MiB)
2025-08-10 08:40:41,947 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 32, fetching them
2025-08-10 08:40:41,947 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:41,956 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:41,958 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (7.9 KiB) non-empty blocks including 1 (7.9 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:41,958 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 08:40:41,962 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 35, fetching them
2025-08-10 08:40:41,963 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 08:40:41,971 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 08:40:41,975 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 (5.1 KiB) non-empty blocks including 4 (5.1 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 08:40:41,975 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
2025-08-10 08:40:41,996 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1055 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 08:40:42,003 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1055_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 384.6 MiB)
2025-08-10 08:40:42,005 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1055 took 7 ms
2025-08-10 08:40:42,007 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1055 stored as values in memory (estimated size 32.0 KiB, free 384.6 MiB)
2025-08-10 08:40:42,009 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 08:40:42,016 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 08:40:42,056 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 219, attempt 0, stage 187.0)
2025-08-10 08:40:42,060 [Executor task launch worker for task 0.0 in stage 187.0 (TID 219)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 187.0 (TID 219). 119762 bytes result sent to driver
2025-08-10 08:57:40,358 [block-manager-storage-async-thread-pool-688] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,370 [block-manager-storage-async-thread-pool-694] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,375 [block-manager-storage-async-thread-pool-697] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,388 [block-manager-storage-async-thread-pool-703] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,411 [block-manager-storage-async-thread-pool-727] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,426 [block-manager-storage-async-thread-pool-736] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,454 [block-manager-storage-async-thread-pool-757] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,465 [block-manager-storage-async-thread-pool-668] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,470 [block-manager-storage-async-thread-pool-681] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,475 [block-manager-storage-async-thread-pool-687] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,487 [block-manager-storage-async-thread-pool-705] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,493 [block-manager-storage-async-thread-pool-711] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,494 [block-manager-storage-async-thread-pool-714] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,505 [block-manager-storage-async-thread-pool-738] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,520 [block-manager-storage-async-thread-pool-766] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,529 [block-manager-storage-async-thread-pool-682] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,536 [block-manager-storage-async-thread-pool-694] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,542 [block-manager-storage-async-thread-pool-703] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,547 [block-manager-storage-async-thread-pool-712] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,550 [block-manager-storage-async-thread-pool-715] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,552 [block-manager-storage-async-thread-pool-718] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 08:57:40,660 [dispatcher-event-loop-10] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20250810075737-0000/5
2025-08-10 08:57:40,664 [ExecutorRunner for app-20250810075737-0000/5] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20250810075737-0000/5 interrupted
2025-08-10 08:57:40,664 [ExecutorRunner for app-20250810075737-0000/5] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2025-08-10 08:57:40,673 [SIGTERM handler] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - RECEIVED SIGNAL TERM
2025-08-10 08:57:40,724 [shutdown-hook-0] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
2025-08-10 08:57:40,724 [shutdown-hook-0] INFO  org.apache.spark.storage.BlockManager - BlockManager stopped
2025-08-10 08:57:40,729 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager - Shutdown hook called
2025-08-10 08:57:40,735 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Stopping s3a-file-system metrics system...
2025-08-10 08:57:40,735 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system stopped.
2025-08-10 08:57:40,736 [shutdown-hook-0] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system shutdown complete.
2025-08-10 08:57:40,826 [dispatcher-event-loop-3] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20250810075737-0000/5 finished with state KILLED exitStatus 143
2025-08-10 08:57:40,828 [dispatcher-event-loop-3] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Clean up non-shuffle and non-RDD files associated with the finished executor 5
2025-08-10 08:57:40,829 [dispatcher-event-loop-3] INFO  org.apache.spark.network.shuffle.ExternalShuffleBlockResolver - Executor is not registered (appId=app-20250810075737-0000, execId=5)
2025-08-10 09:27:43,066 [dispatcher-event-loop-0] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20250810075737-0000/6 for Thrift JDBC/ODBC Server
2025-08-10 09:27:43,083 [ExecutorRunner for app-20250810075737-0000/6] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 09:27:43,084 [ExecutorRunner for app-20250810075737-0000/6] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 09:27:43,085 [ExecutorRunner for app-20250810075737-0000/6] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 09:27:43,085 [ExecutorRunner for app-20250810075737-0000/6] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 09:27:43,085 [ExecutorRunner for app-20250810075737-0000/6] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 09:27:43,132 [ExecutorRunner for app-20250810075737-0000/6] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/bitnami/java/bin/java" "-cp" "/opt/bitnami/spark/conf/:/opt/bitnami/spark/jars/*" "-Xmx1024M" "-Dspark.driver.port=41435" "-Djava.net.preferIPv6Addresses=false" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "-Djdk.reflect.useDirectMethodHandle=false" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@3c3beacd57f0:41435" "--executor-id" "6" "--hostname" "172.18.0.11" "--cores" "2" "--app-id" "app-20250810075737-0000" "--worker-url" "spark://Worker@172.18.0.11:44407" "--resourceProfileId" "0"
2025-08-10 09:27:44,713 [main] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Started daemon with process name: 1884@661307a8e8bd
2025-08-10 09:27:44,721 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for TERM
2025-08-10 09:27:44,723 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for HUP
2025-08-10 09:27:44,723 [main] INFO  org.apache.spark.util.SignalUtils - Registering signal handler for INT
2025-08-10 09:27:45,120 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2025-08-10 09:27:45,285 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 09:27:45,285 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 09:27:45,286 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 09:27:45,287 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 09:27:45,287 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 09:27:45,566 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 62 ms (0 ms spent in bootstraps)
2025-08-10 09:27:45,671 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: spark
2025-08-10 09:27:45,672 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls to: spark
2025-08-10 09:27:45,676 [main] INFO  org.apache.spark.SecurityManager - Changing view acls groups to: 
2025-08-10 09:27:45,677 [main] INFO  org.apache.spark.SecurityManager - Changing modify acls groups to: 
2025-08-10 09:27:45,677 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
2025-08-10 09:27:45,739 [netty-rpc-connection-0] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:41435 after 1 ms (0 ms spent in bootstraps)
2025-08-10 09:27:45,810 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-40702174-4f13-4067-a184-4956d5932ca1/executor-03c5b1f9-784d-4cb3-b3f5-31b8e233e3c5/blockmgr-2a9fd55c-1708-49c0-a6b4-f59e415daf0f
2025-08-10 09:27:45,845 [main] INFO  org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 434.4 MiB
2025-08-10 09:27:46,038 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: spark://CoarseGrainedScheduler@3c3beacd57f0:41435
2025-08-10 09:27:46,038 [main] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker spark://Worker@172.18.0.11:44407
2025-08-10 09:27:46,050 [netty-rpc-connection-1] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to /172.18.0.11:44407 after 9 ms (0 ms spent in bootstraps)
2025-08-10 09:27:46,059 [dispatcher-event-loop-1] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to spark://Worker@172.18.0.11:44407
2025-08-10 09:27:46,062 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 09:27:46,063 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.executor.
2025-08-10 09:27:46,064 [dispatcher-Executor] INFO  org.apache.spark.resource.ResourceUtils - ==============================================================
2025-08-10 09:27:46,088 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2025-08-10 09:27:46,091 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor ID 6 on host 172.18.0.11
2025-08-10 09:27:46,135 [dispatcher-Executor] INFO  org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34187.
2025-08-10 09:27:46,136 [dispatcher-Executor] INFO  org.apache.spark.network.netty.NettyBlockTransferService - Server created on 172.18.0.11:34187
2025-08-10 09:27:46,139 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2025-08-10 09:27:46,147 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(6, 172.18.0.11, 34187, None)
2025-08-10 09:27:46,159 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(6, 172.18.0.11, 34187, None)
2025-08-10 09:27:46,160 [dispatcher-Executor] INFO  org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(6, 172.18.0.11, 34187, None)
2025-08-10 09:27:46,166 [dispatcher-Executor] INFO  org.apache.spark.executor.Executor - Starting executor with user classpath (userClassPathFirst = false): ''
2025-08-10 09:27:46,204 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 220
2025-08-10 09:27:46,210 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 221
2025-08-10 09:27:46,215 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 188.0 (TID 221)
2025-08-10 09:27:46,215 [Executor task launch worker for task 0.0 in stage 188.0 (TID 220)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 188.0 (TID 220)
2025-08-10 09:27:46,298 [Executor task launch worker for task 0.0 in stage 188.0 (TID 220)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 42 and clearing cache
2025-08-10 09:27:46,340 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1058 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:46,375 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.network.client.TransportClientFactory - Successfully created connection to 3c3beacd57f0/172.18.0.12:45089 after 2 ms (0 ms spent in bootstraps)
2025-08-10 09:27:46,397 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1058_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 434.4 MiB)
2025-08-10 09:27:46,404 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1058 took 63 ms
2025-08-10 09:27:46,449 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1058 stored as values in memory (estimated size 8.0 KiB, free 434.4 MiB)
2025-08-10 09:27:46,636 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1057 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:46,643 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1057_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 434.4 MiB)
2025-08-10 09:27:46,646 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1057 took 9 ms
2025-08-10 09:27:46,685 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1057 stored as values in memory (estimated size 32.0 KiB, free 434.3 MiB)
2025-08-10 09:27:47,202 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] WARN  org.apache.hadoop.metrics2.impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties
2025-08-10 09:27:47,213 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - Scheduled Metric snapshot period at 10 second(s).
2025-08-10 09:27:47,213 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.hadoop.metrics2.impl.MetricsSystemImpl - s3a-file-system metrics system started
2025-08-10 09:27:48,201 [Executor task launch worker for task 0.0 in stage 188.0 (TID 220)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 09:27:48,201 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 09:27:48,531 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 09:27:48,531 [Executor task launch worker for task 0.0 in stage 188.0 (TID 220)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 09:27:49,200 [Executor task launch worker for task 0.0 in stage 188.0 (TID 220)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 220, attempt 0, stage 188.0)
2025-08-10 09:27:49,200 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 221, attempt 0, stage 188.0)
2025-08-10 09:27:49,232 [Executor task launch worker for task 0.0 in stage 188.0 (TID 220)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 188.0 (TID 220). 4160 bytes result sent to driver
2025-08-10 09:27:49,232 [Executor task launch worker for task 1.0 in stage 188.0 (TID 221)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 188.0 (TID 221). 4158 bytes result sent to driver
2025-08-10 09:27:57,499 [block-manager-storage-async-thread-pool-3] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:27:58,355 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 222
2025-08-10 09:27:58,357 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 189.0 (TID 222)
2025-08-10 09:27:58,357 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 223
2025-08-10 09:27:58,360 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 190.0 (TID 223)
2025-08-10 09:27:58,417 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1141 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:58,417 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1142 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:58,425 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1141_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.4 MiB)
2025-08-10 09:27:58,425 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1142_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 434.4 MiB)
2025-08-10 09:27:58,428 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1141 took 11 ms
2025-08-10 09:27:58,429 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1142 took 11 ms
2025-08-10 09:27:58,430 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1141 stored as values in memory (estimated size 13.6 KiB, free 434.4 MiB)
2025-08-10 09:27:58,430 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1142 stored as values in memory (estimated size 20.5 KiB, free 434.4 MiB)
2025-08-10 09:27:58,769 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 192.204752 ms
2025-08-10 09:27:58,779 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 202.710275 ms
2025-08-10 09:27:58,782 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1097 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:58,782 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1106 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:58,788 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1097_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 434.3 MiB)
2025-08-10 09:27:58,788 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1106_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.3 MiB)
2025-08-10 09:27:58,791 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1097 took 8 ms
2025-08-10 09:27:58,791 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1106 took 8 ms
2025-08-10 09:27:58,799 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1106 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 09:27:58,799 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1097 stored as values in memory (estimated size 32.0 KiB, free 434.2 MiB)
2025-08-10 09:27:58,884 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:58,884 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:58,920 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:58,921 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Enabling arrow.enable_unsafe_memory_access
2025-08-10 09:27:58,922 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.iceberg.spark.data.vectorized.VectorizedSparkParquetReaders - Disabling arrow.enable_null_check_for_get
2025-08-10 09:27:58,934 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.BaseAllocator - Debug mode disabled. Enable with the VM option -Darrow.memory.debug.allocator=true.
2025-08-10 09:27:58,939 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.DefaultAllocationManagerOption - allocation manager type not specified, using netty as the default type
2025-08-10 09:27:58,941 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.iceberg.shaded.org.apache.arrow.memory.CheckAllocator - Using DefaultAllocationManager at memory/DefaultAllocationManagerFactory.class
2025-08-10 09:27:59,071 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,250 [Executor task launch worker for task 0.0 in stage 190.0 (TID 223)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 190.0 (TID 223). 5456 bytes result sent to driver
2025-08-10 09:27:59,254 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 224
2025-08-10 09:27:59,255 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 191.0 (TID 224)
2025-08-10 09:27:59,257 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,259 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1143 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,265 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1143_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 434.2 MiB)
2025-08-10 09:27:59,265 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,267 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1143 took 7 ms
2025-08-10 09:27:59,268 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1143 stored as values in memory (estimated size 19.9 KiB, free 434.2 MiB)
2025-08-10 09:27:59,273 [Executor task launch worker for task 0.0 in stage 189.0 (TID 222)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 189.0 (TID 222). 4767 bytes result sent to driver
2025-08-10 09:27:59,282 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 225
2025-08-10 09:27:59,283 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 192.0 (TID 225)
2025-08-10 09:27:59,286 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1144 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,292 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1144_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 434.2 MiB)
2025-08-10 09:27:59,295 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1144 took 8 ms
2025-08-10 09:27:59,297 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1144 stored as values in memory (estimated size 14.3 KiB, free 434.2 MiB)
2025-08-10 09:27:59,298 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 26.486777 ms
2025-08-10 09:27:59,300 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1094 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,305 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1094_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 434.2 MiB)
2025-08-10 09:27:59,309 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1094 took 8 ms
2025-08-10 09:27:59,311 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1094 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 09:27:59,312 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.680524 ms
2025-08-10 09:27:59,314 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1104 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,320 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1104_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 434.1 MiB)
2025-08-10 09:27:59,323 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1104 took 8 ms
2025-08-10 09:27:59,325 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1104 stored as values in memory (estimated size 32.0 KiB, free 434.1 MiB)
2025-08-10 09:27:59,328 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,337 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,340 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,350 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,353 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,363 [Executor task launch worker for task 0.0 in stage 192.0 (TID 225)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 192.0 (TID 225). 4722 bytes result sent to driver
2025-08-10 09:27:59,364 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,378 [Executor task launch worker for task 0.0 in stage 191.0 (TID 224)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 191.0 (TID 224). 5447 bytes result sent to driver
2025-08-10 09:27:59,509 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 226
2025-08-10 09:27:59,510 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 227
2025-08-10 09:27:59,510 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 193.0 (TID 226)
2025-08-10 09:27:59,511 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 193.0 (TID 227)
2025-08-10 09:27:59,518 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1179 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,523 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1179_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 434.1 MiB)
2025-08-10 09:27:59,526 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1179 took 6 ms
2025-08-10 09:27:59,527 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1179 stored as values in memory (estimated size 35.2 KiB, free 434.0 MiB)
2025-08-10 09:27:59,596 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 16.803404 ms
2025-08-10 09:27:59,599 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1157 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,605 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 25.533388 ms
2025-08-10 09:27:59,605 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1157_piece0 stored as bytes in memory (estimated size 493.0 B, free 434.0 MiB)
2025-08-10 09:27:59,607 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1160 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,609 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1157 took 9 ms
2025-08-10 09:27:59,612 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1160_piece0 stored as bytes in memory (estimated size 1247.0 B, free 434.0 MiB)
2025-08-10 09:27:59,616 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1160 took 8 ms
2025-08-10 09:27:59,621 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1160 stored as values in memory (estimated size 8.0 MiB, free 426.0 MiB)
2025-08-10 09:27:59,627 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1157 stored as values in memory (estimated size 8.0 MiB, free 418.0 MiB)
2025-08-10 09:27:59,631 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1138 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,631 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1135 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,636 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1138_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 418.0 MiB)
2025-08-10 09:27:59,636 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1135_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 418.0 MiB)
2025-08-10 09:27:59,640 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1138 took 7 ms
2025-08-10 09:27:59,640 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1135 took 8 ms
2025-08-10 09:27:59,642 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1138 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 09:27:59,643 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1135 stored as values in memory (estimated size 32.0 KiB, free 417.9 MiB)
2025-08-10 09:27:59,655 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,655 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,663 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,663 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,678 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,686 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,701 [Executor task launch worker for task 0.0 in stage 193.0 (TID 226)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 193.0 (TID 226). 7271 bytes result sent to driver
2025-08-10 09:27:59,701 [Executor task launch worker for task 1.0 in stage 193.0 (TID 227)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 193.0 (TID 227). 7400 bytes result sent to driver
2025-08-10 09:27:59,706 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 228
2025-08-10 09:27:59,707 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 229
2025-08-10 09:27:59,707 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 194.0 (TID 228)
2025-08-10 09:27:59,708 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 194.0 (TID 229)
2025-08-10 09:27:59,711 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1180 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,717 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1180_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 417.9 MiB)
2025-08-10 09:27:59,723 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1180 took 11 ms
2025-08-10 09:27:59,726 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1180 stored as values in memory (estimated size 34.1 KiB, free 417.9 MiB)
2025-08-10 09:27:59,747 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 16.873093 ms
2025-08-10 09:27:59,750 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1146 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,757 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1146_piece0 stored as bytes in memory (estimated size 504.0 B, free 417.9 MiB)
2025-08-10 09:27:59,758 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 28.148152 ms
2025-08-10 09:27:59,761 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1132 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,761 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1146 took 10 ms
2025-08-10 09:27:59,777 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1132_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 417.9 MiB)
2025-08-10 09:27:59,780 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1132 took 18 ms
2025-08-10 09:27:59,781 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1146 stored as values in memory (estimated size 8.0 MiB, free 409.9 MiB)
2025-08-10 09:27:59,783 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1132 stored as values in memory (estimated size 32.0 KiB, free 409.9 MiB)
2025-08-10 09:27:59,783 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1133 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,790 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1133_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.9 MiB)
2025-08-10 09:27:59,794 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1133 took 9 ms
2025-08-10 09:27:59,797 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1133 stored as values in memory (estimated size 32.0 KiB, free 409.8 MiB)
2025-08-10 09:27:59,799 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,807 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,811 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,824 [Executor task launch worker for task 0.0 in stage 194.0 (TID 228)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 194.0 (TID 228). 7237 bytes result sent to driver
2025-08-10 09:27:59,828 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,831 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 230
2025-08-10 09:27:59,832 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 195.0 (TID 230)
2025-08-10 09:27:59,837 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1181 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,848 [Executor task launch worker for task 1.0 in stage 194.0 (TID 229)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 194.0 (TID 229). 7249 bytes result sent to driver
2025-08-10 09:27:59,852 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1181_piece0 stored as bytes in memory (estimated size 11.0 KiB, free 409.8 MiB)
2025-08-10 09:27:59,857 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 231
2025-08-10 09:27:59,858 [Executor task launch worker for task 1.0 in stage 195.0 (TID 231)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 195.0 (TID 231)
2025-08-10 09:27:59,860 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1181 took 21 ms
2025-08-10 09:27:59,863 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1181 stored as values in memory (estimated size 34.1 KiB, free 409.8 MiB)
2025-08-10 09:27:59,883 [Executor task launch worker for task 1.0 in stage 195.0 (TID 231)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 16.212774 ms
2025-08-10 09:27:59,886 [Executor task launch worker for task 1.0 in stage 195.0 (TID 231)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1128 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,893 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 26.966764 ms
2025-08-10 09:27:59,894 [Executor task launch worker for task 1.0 in stage 195.0 (TID 231)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1128_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.8 MiB)
2025-08-10 09:27:59,896 [Executor task launch worker for task 1.0 in stage 195.0 (TID 231)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1128 took 9 ms
2025-08-10 09:27:59,896 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1127 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:27:59,899 [Executor task launch worker for task 1.0 in stage 195.0 (TID 231)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1128 stored as values in memory (estimated size 32.0 KiB, free 409.8 MiB)
2025-08-10 09:27:59,903 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1127_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.7 MiB)
2025-08-10 09:27:59,906 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1127 took 9 ms
2025-08-10 09:27:59,909 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1127 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 09:27:59,915 [Executor task launch worker for task 1.0 in stage 195.0 (TID 231)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,923 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:27:59,923 [Executor task launch worker for task 1.0 in stage 195.0 (TID 231)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,935 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:27:59,937 [Executor task launch worker for task 1.0 in stage 195.0 (TID 231)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 195.0 (TID 231). 7206 bytes result sent to driver
2025-08-10 09:27:59,954 [Executor task launch worker for task 0.0 in stage 195.0 (TID 230)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 195.0 (TID 230). 7237 bytes result sent to driver
2025-08-10 09:28:00,060 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 232
2025-08-10 09:28:00,063 [Executor task launch worker for task 0.0 in stage 196.0 (TID 232)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 196.0 (TID 232)
2025-08-10 09:28:00,064 [Executor task launch worker for task 0.0 in stage 196.0 (TID 232)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 43 and clearing cache
2025-08-10 09:28:00,066 [Executor task launch worker for task 0.0 in stage 196.0 (TID 232)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1196 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:00,071 [Executor task launch worker for task 0.0 in stage 196.0 (TID 232)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1196_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 409.7 MiB)
2025-08-10 09:28:00,073 [Executor task launch worker for task 0.0 in stage 196.0 (TID 232)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1196 took 7 ms
2025-08-10 09:28:00,075 [Executor task launch worker for task 0.0 in stage 196.0 (TID 232)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1196 stored as values in memory (estimated size 11.7 KiB, free 409.7 MiB)
2025-08-10 09:28:00,087 [Executor task launch worker for task 0.0 in stage 196.0 (TID 232)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.927383 ms
2025-08-10 09:28:00,094 [Executor task launch worker for task 0.0 in stage 196.0 (TID 232)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 196.0 (TID 232). 1922 bytes result sent to driver
2025-08-10 09:28:00,125 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 233
2025-08-10 09:28:00,126 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 198.0 (TID 233)
2025-08-10 09:28:00,131 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 44 and clearing cache
2025-08-10 09:28:00,135 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1197 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:00,140 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1197_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 409.7 MiB)
2025-08-10 09:28:00,143 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1197 took 7 ms
2025-08-10 09:28:00,144 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1197 stored as values in memory (estimated size 12.7 KiB, free 409.7 MiB)
2025-08-10 09:28:00,154 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 37, fetching them
2025-08-10 09:28:00,156 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:28:00,165 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:28:00,192 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:28:00,194 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 11 ms
2025-08-10 09:28:00,205 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.474127 ms
2025-08-10 09:28:00,217 [Executor task launch worker for task 0.0 in stage 198.0 (TID 233)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 198.0 (TID 233). 4002 bytes result sent to driver
2025-08-10 09:28:00,287 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 234
2025-08-10 09:28:00,288 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 235
2025-08-10 09:28:00,288 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 200.0 (TID 234)
2025-08-10 09:28:00,289 [Executor task launch worker for task 0.0 in stage 200.0 (TID 235)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 200.0 (TID 235)
2025-08-10 09:28:00,291 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1198 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:00,296 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1198_piece0 stored as bytes in memory (estimated size 29.9 KiB, free 409.6 MiB)
2025-08-10 09:28:00,299 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1198 took 7 ms
2025-08-10 09:28:00,301 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1198 stored as values in memory (estimated size 88.3 KiB, free 409.6 MiB)
2025-08-10 09:28:00,503 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 36, fetching them
2025-08-10 09:28:00,508 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:28:00,511 [Executor task launch worker for task 0.0 in stage 200.0 (TID 235)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.859973 ms
2025-08-10 09:28:00,512 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:28:00,513 [Executor task launch worker for task 0.0 in stage 200.0 (TID 235)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1124 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:00,514 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:28:00,514 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 09:28:00,519 [Executor task launch worker for task 0.0 in stage 200.0 (TID 235)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1124_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.5 MiB)
2025-08-10 09:28:00,522 [Executor task launch worker for task 0.0 in stage 200.0 (TID 235)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1124 took 8 ms
2025-08-10 09:28:00,524 [Executor task launch worker for task 0.0 in stage 200.0 (TID 235)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1124 stored as values in memory (estimated size 32.0 KiB, free 409.5 MiB)
2025-08-10 09:28:00,527 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.138208 ms
2025-08-10 09:28:00,537 [Executor task launch worker for task 0.0 in stage 200.0 (TID 235)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:00,547 [Executor task launch worker for task 0.0 in stage 200.0 (TID 235)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:00,574 [Executor task launch worker for task 0.0 in stage 200.0 (TID 235)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 200.0 (TID 235). 22345 bytes result sent to driver
2025-08-10 09:28:00,582 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 236
2025-08-10 09:28:00,583 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 200.0 (TID 236)
2025-08-10 09:28:00,610 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.47991 ms
2025-08-10 09:28:00,613 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1191 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:00,620 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1191_piece0 stored as bytes in memory (estimated size 181.0 B, free 409.5 MiB)
2025-08-10 09:28:00,625 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1191 took 10 ms
2025-08-10 09:28:00,635 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 16.528282 ms
2025-08-10 09:28:00,638 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1191 stored as values in memory (estimated size 8.0 MiB, free 401.5 MiB)
2025-08-10 09:28:00,641 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1125 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:00,649 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1125_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 401.5 MiB)
2025-08-10 09:28:00,657 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1125 took 15 ms
2025-08-10 09:28:00,660 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1125 stored as values in memory (estimated size 32.0 KiB, free 401.4 MiB)
2025-08-10 09:28:00,675 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:00,685 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:00,687 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.610466 ms
2025-08-10 09:28:00,709 [Executor task launch worker for task 1.0 in stage 200.0 (TID 236)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 200.0 (TID 236). 22351 bytes result sent to driver
2025-08-10 09:28:00,715 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 237
2025-08-10 09:28:00,716 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 200.0 (TID 237)
2025-08-10 09:28:00,727 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.30785 ms
2025-08-10 09:28:00,734 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.619488 ms
2025-08-10 09:28:00,744 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.871799 ms
2025-08-10 09:28:00,746 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1186 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:00,752 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1186_piece0 stored as bytes in memory (estimated size 181.0 B, free 401.4 MiB)
2025-08-10 09:28:00,757 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1186 took 9 ms
2025-08-10 09:28:00,760 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1186 stored as values in memory (estimated size 8.0 MiB, free 393.4 MiB)
2025-08-10 09:28:00,763 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1130 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:00,775 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1130_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.4 MiB)
2025-08-10 09:28:00,779 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1130 took 15 ms
2025-08-10 09:28:00,782 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1130 stored as values in memory (estimated size 32.0 KiB, free 393.4 MiB)
2025-08-10 09:28:00,793 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.718684 ms
2025-08-10 09:28:00,795 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:00,805 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:00,825 [Executor task launch worker for task 2.0 in stage 200.0 (TID 237)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 200.0 (TID 237). 22524 bytes result sent to driver
2025-08-10 09:28:00,826 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.417533 ms
2025-08-10 09:28:00,834 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.966104 ms
2025-08-10 09:28:00,844 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.962084 ms
2025-08-10 09:28:00,851 [Executor task launch worker for task 3.0 in stage 200.0 (TID 234)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 200.0 (TID 234). 22996 bytes result sent to driver
2025-08-10 09:28:00,930 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 238
2025-08-10 09:28:00,931 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 201.0 (TID 238)
2025-08-10 09:28:00,935 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1201 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:00,941 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1201_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 393.3 MiB)
2025-08-10 09:28:00,944 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1201 took 9 ms
2025-08-10 09:28:00,947 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1201 stored as values in memory (estimated size 139.0 KiB, free 393.2 MiB)
2025-08-10 09:28:01,036 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 24.163315 ms
2025-08-10 09:28:01,039 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1199 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,044 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1199_piece0 stored as bytes in memory (estimated size 492.0 B, free 393.2 MiB)
2025-08-10 09:28:01,047 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1199 took 7 ms
2025-08-10 09:28:01,052 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1199 stored as values in memory (estimated size 856.0 B, free 393.2 MiB)
2025-08-10 09:28:01,062 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 5.204987 ms
2025-08-10 09:28:01,072 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1123 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,077 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1123_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 392.7 MiB)
2025-08-10 09:28:01,080 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1123 took 7 ms
2025-08-10 09:28:01,083 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1123 stored as values in memory (estimated size 32.0 KiB, free 392.6 MiB)
2025-08-10 09:28:01,096 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:01,108 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:01,123 [Executor task launch worker for task 0.0 in stage 201.0 (TID 238)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 201.0 (TID 238). 41625 bytes result sent to driver
2025-08-10 09:28:01,159 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 239
2025-08-10 09:28:01,160 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 202.0 (TID 239)
2025-08-10 09:28:01,165 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1203 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,171 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1203_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 393.5 MiB)
2025-08-10 09:28:01,174 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1203 took 8 ms
2025-08-10 09:28:01,177 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1203 stored as values in memory (estimated size 22.3 KiB, free 393.4 MiB)
2025-08-10 09:28:01,209 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 16.933785 ms
2025-08-10 09:28:01,242 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 13.346774 ms
2025-08-10 09:28:01,245 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1202 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,253 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1202_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.5 MiB)
2025-08-10 09:28:01,257 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1202 took 10 ms
2025-08-10 09:28:01,261 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1202 stored as values in memory (estimated size 32.0 KiB, free 393.5 MiB)
2025-08-10 09:28:01,276 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:01,285 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:01,307 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 240
2025-08-10 09:28:01,308 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 203.0 (TID 240)
2025-08-10 09:28:01,310 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1213 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,315 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1213_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 393.4 MiB)
2025-08-10 09:28:01,318 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1213 took 6 ms
2025-08-10 09:28:01,319 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1213 stored as values in memory (estimated size 37.5 KiB, free 393.4 MiB)
2025-08-10 09:28:01,322 [Executor task launch worker for task 0.0 in stage 202.0 (TID 239)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 202.0 (TID 239). 4892 bytes result sent to driver
2025-08-10 09:28:01,326 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 241
2025-08-10 09:28:01,329 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 203.0 (TID 241)
2025-08-10 09:28:01,334 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.551717 ms
2025-08-10 09:28:01,337 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1103 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,343 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1103_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 393.4 MiB)
2025-08-10 09:28:01,347 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1103 took 9 ms
2025-08-10 09:28:01,350 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1103 stored as values in memory (estimated size 32.0 KiB, free 393.3 MiB)
2025-08-10 09:28:01,359 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 25.518282 ms
2025-08-10 09:28:01,362 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1145 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,364 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:01,367 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1145_piece0 stored as bytes in memory (estimated size 1204.0 B, free 393.3 MiB)
2025-08-10 09:28:01,372 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1145 took 9 ms
2025-08-10 09:28:01,375 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1145 stored as values in memory (estimated size 8.0 MiB, free 385.3 MiB)
2025-08-10 09:28:01,375 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:01,378 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1105 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,383 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1105_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 385.3 MiB)
2025-08-10 09:28:01,386 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1105 took 8 ms
2025-08-10 09:28:01,390 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1105 stored as values in memory (estimated size 32.0 KiB, free 385.3 MiB)
2025-08-10 09:28:01,391 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:01,399 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:01,403 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:01,407 [Executor task launch worker for task 0.0 in stage 203.0 (TID 240)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 203.0 (TID 240). 7228 bytes result sent to driver
2025-08-10 09:28:01,411 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:01,426 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:01,434 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:01,442 [Executor task launch worker for task 1.0 in stage 203.0 (TID 241)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 203.0 (TID 241). 7357 bytes result sent to driver
2025-08-10 09:28:01,533 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 242
2025-08-10 09:28:01,534 [Executor task launch worker for task 0.0 in stage 204.0 (TID 242)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 204.0 (TID 242)
2025-08-10 09:28:01,535 [Executor task launch worker for task 0.0 in stage 204.0 (TID 242)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 46 and clearing cache
2025-08-10 09:28:01,538 [Executor task launch worker for task 0.0 in stage 204.0 (TID 242)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1236 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,543 [Executor task launch worker for task 0.0 in stage 204.0 (TID 242)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1236_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 385.3 MiB)
2025-08-10 09:28:01,545 [Executor task launch worker for task 0.0 in stage 204.0 (TID 242)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1236 took 7 ms
2025-08-10 09:28:01,547 [Executor task launch worker for task 0.0 in stage 204.0 (TID 242)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1236 stored as values in memory (estimated size 11.7 KiB, free 385.3 MiB)
2025-08-10 09:28:01,551 [Executor task launch worker for task 0.0 in stage 204.0 (TID 242)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 204.0 (TID 242). 1836 bytes result sent to driver
2025-08-10 09:28:01,567 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 243
2025-08-10 09:28:01,568 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 206.0 (TID 243)
2025-08-10 09:28:01,569 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 47 and clearing cache
2025-08-10 09:28:01,571 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1237 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,574 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1237_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 385.3 MiB)
2025-08-10 09:28:01,576 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1237 took 5 ms
2025-08-10 09:28:01,578 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1237 stored as values in memory (estimated size 12.7 KiB, free 385.3 MiB)
2025-08-10 09:28:01,579 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 40, fetching them
2025-08-10 09:28:01,580 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:28:01,582 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:28:01,584 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:28:01,584 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 09:28:01,586 [Executor task launch worker for task 0.0 in stage 206.0 (TID 243)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 206.0 (TID 243). 3959 bytes result sent to driver
2025-08-10 09:28:01,612 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 244
2025-08-10 09:28:01,612 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 245
2025-08-10 09:28:01,612 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 208.0 (TID 244)
2025-08-10 09:28:01,613 [Executor task launch worker for task 0.0 in stage 208.0 (TID 245)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 208.0 (TID 245)
2025-08-10 09:28:01,615 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1238 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,619 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1238_piece0 stored as bytes in memory (estimated size 34.4 KiB, free 385.2 MiB)
2025-08-10 09:28:01,622 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1238 took 6 ms
2025-08-10 09:28:01,623 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1238 stored as values in memory (estimated size 105.2 KiB, free 385.1 MiB)
2025-08-10 09:28:01,630 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 39, fetching them
2025-08-10 09:28:01,631 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:28:01,634 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:28:01,636 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (189.0 B) non-empty blocks including 1 (189.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:28:01,636 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 09:28:01,642 [Executor task launch worker for task 0.0 in stage 208.0 (TID 245)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 11.297042 ms
2025-08-10 09:28:01,644 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.956439 ms
2025-08-10 09:28:01,649 [Executor task launch worker for task 0.0 in stage 208.0 (TID 245)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1225 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,654 [Executor task launch worker for task 0.0 in stage 208.0 (TID 245)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1225_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 385.1 MiB)
2025-08-10 09:28:01,657 [Executor task launch worker for task 0.0 in stage 208.0 (TID 245)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1225 took 7 ms
2025-08-10 09:28:01,660 [Executor task launch worker for task 0.0 in stage 208.0 (TID 245)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1225 stored as values in memory (estimated size 32.0 KiB, free 385.0 MiB)
2025-08-10 09:28:01,674 [Executor task launch worker for task 0.0 in stage 208.0 (TID 245)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:01,681 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.757967 ms
2025-08-10 09:28:01,683 [Executor task launch worker for task 0.0 in stage 208.0 (TID 245)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:01,699 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.243704 ms
2025-08-10 09:28:01,705 [Executor task launch worker for task 0.0 in stage 208.0 (TID 245)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 208.0 (TID 245). 22605 bytes result sent to driver
2025-08-10 09:28:01,710 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 246
2025-08-10 09:28:01,711 [Executor task launch worker for task 1.0 in stage 208.0 (TID 246)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 208.0 (TID 246)
2025-08-10 09:28:01,713 [Executor task launch worker for task 3.0 in stage 208.0 (TID 244)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 208.0 (TID 244). 23293 bytes result sent to driver
2025-08-10 09:28:01,717 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 247
2025-08-10 09:28:01,719 [Executor task launch worker for task 2.0 in stage 208.0 (TID 247)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 208.0 (TID 247)
2025-08-10 09:28:01,732 [Executor task launch worker for task 1.0 in stage 208.0 (TID 246)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 12.456598 ms
2025-08-10 09:28:01,738 [Executor task launch worker for task 1.0 in stage 208.0 (TID 246)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1226 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,743 [Executor task launch worker for task 2.0 in stage 208.0 (TID 247)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 14.618995 ms
2025-08-10 09:28:01,744 [Executor task launch worker for task 1.0 in stage 208.0 (TID 246)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1226_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 385.0 MiB)
2025-08-10 09:28:01,747 [Executor task launch worker for task 1.0 in stage 208.0 (TID 246)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1226 took 7 ms
2025-08-10 09:28:01,749 [Executor task launch worker for task 1.0 in stage 208.0 (TID 246)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1226 stored as values in memory (estimated size 32.0 KiB, free 385.0 MiB)
2025-08-10 09:28:01,749 [Executor task launch worker for task 2.0 in stage 208.0 (TID 247)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1231 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,754 [Executor task launch worker for task 2.0 in stage 208.0 (TID 247)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1231_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 385.0 MiB)
2025-08-10 09:28:01,757 [Executor task launch worker for task 2.0 in stage 208.0 (TID 247)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1231 took 7 ms
2025-08-10 09:28:01,760 [Executor task launch worker for task 2.0 in stage 208.0 (TID 247)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1231 stored as values in memory (estimated size 32.0 KiB, free 384.9 MiB)
2025-08-10 09:28:01,762 [Executor task launch worker for task 1.0 in stage 208.0 (TID 246)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:01,769 [Executor task launch worker for task 1.0 in stage 208.0 (TID 246)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:01,770 [Executor task launch worker for task 2.0 in stage 208.0 (TID 247)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:28:01,778 [Executor task launch worker for task 2.0 in stage 208.0 (TID 247)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:28:01,783 [Executor task launch worker for task 1.0 in stage 208.0 (TID 246)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 208.0 (TID 246). 22648 bytes result sent to driver
2025-08-10 09:28:01,801 [Executor task launch worker for task 2.0 in stage 208.0 (TID 247)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 208.0 (TID 247). 22648 bytes result sent to driver
2025-08-10 09:28:01,878 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 248
2025-08-10 09:28:01,879 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 212.0 (TID 248)
2025-08-10 09:28:01,881 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 48 and clearing cache
2025-08-10 09:28:01,883 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1240 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:01,888 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1240_piece0 stored as bytes in memory (estimated size 91.3 KiB, free 385.0 MiB)
2025-08-10 09:28:01,894 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1240 took 10 ms
2025-08-10 09:28:01,895 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1240 stored as values in memory (estimated size 315.1 KiB, free 384.7 MiB)
2025-08-10 09:28:01,954 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 38, fetching them
2025-08-10 09:28:01,955 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:28:01,958 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:28:01,961 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (8.2 KiB) non-empty blocks including 1 (8.2 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:28:01,961 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 2 ms
2025-08-10 09:28:01,969 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.021114 ms
2025-08-10 09:28:01,977 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.790276 ms
2025-08-10 09:28:01,987 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.070908 ms
2025-08-10 09:28:01,989 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 41, fetching them
2025-08-10 09:28:01,990 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:28:01,994 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:28:01,996 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 (5.3 KiB) non-empty blocks including 4 (5.3 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:28:01,996 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 09:28:02,006 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 8.630754 ms
2025-08-10 09:28:02,032 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 19.475798 ms
2025-08-10 09:28:02,045 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.195054 ms
2025-08-10 09:28:02,052 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.112608 ms
2025-08-10 09:28:02,058 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 3.014584 ms
2025-08-10 09:28:02,072 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.062865 ms
2025-08-10 09:28:02,087 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.995449 ms
2025-08-10 09:28:02,101 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.706326 ms
2025-08-10 09:28:02,131 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.534668 ms
2025-08-10 09:28:02,133 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1239 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:28:02,138 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1239_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 384.6 MiB)
2025-08-10 09:28:02,143 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1239 took 9 ms
2025-08-10 09:28:02,145 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1239 stored as values in memory (estimated size 32.0 KiB, free 384.6 MiB)
2025-08-10 09:28:02,148 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 09:28:02,190 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 09:28:02,233 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 248, attempt 0, stage 212.0)
2025-08-10 09:28:02,237 [Executor task launch worker for task 0.0 in stage 212.0 (TID 248)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 212.0 (TID 248). 119796 bytes result sent to driver
2025-08-10 09:29:12,189 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 249
2025-08-10 09:29:12,191 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 250
2025-08-10 09:29:12,191 [Executor task launch worker for task 0.0 in stage 213.0 (TID 249)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 213.0 (TID 249)
2025-08-10 09:29:12,192 [Executor task launch worker for task 1.0 in stage 213.0 (TID 250)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 213.0 (TID 250)
2025-08-10 09:29:12,194 [Executor task launch worker for task 0.0 in stage 213.0 (TID 249)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1242 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:12,199 [Executor task launch worker for task 0.0 in stage 213.0 (TID 249)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1242_piece0 stored as bytes in memory (estimated size 4.5 KiB, free 385.1 MiB)
2025-08-10 09:29:12,201 [Executor task launch worker for task 0.0 in stage 213.0 (TID 249)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1242 took 6 ms
2025-08-10 09:29:12,203 [Executor task launch worker for task 0.0 in stage 213.0 (TID 249)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1242 stored as values in memory (estimated size 8.0 KiB, free 385.1 MiB)
2025-08-10 09:29:12,206 [Executor task launch worker for task 1.0 in stage 213.0 (TID 250)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1241 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:12,209 [Executor task launch worker for task 1.0 in stage 213.0 (TID 250)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1241_piece0 stored as bytes in memory (estimated size 29.4 KiB, free 385.1 MiB)
2025-08-10 09:29:12,212 [Executor task launch worker for task 1.0 in stage 213.0 (TID 250)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1241 took 5 ms
2025-08-10 09:29:12,215 [Executor task launch worker for task 1.0 in stage 213.0 (TID 250)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1241 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 09:29:12,218 [Executor task launch worker for task 1.0 in stage 213.0 (TID 250)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 09:29:12,218 [Executor task launch worker for task 0.0 in stage 213.0 (TID 249)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 09:29:12,220 [Executor task launch worker for task 1.0 in stage 213.0 (TID 250)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 1 is committing.
2025-08-10 09:29:12,220 [Executor task launch worker for task 0.0 in stage 213.0 (TID 249)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 09:29:12,248 [Executor task launch worker for task 1.0 in stage 213.0 (TID 250)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 1 (task 250, attempt 0, stage 213.0)
2025-08-10 09:29:12,250 [Executor task launch worker for task 1.0 in stage 213.0 (TID 250)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 213.0 (TID 250). 4072 bytes result sent to driver
2025-08-10 09:29:12,256 [Executor task launch worker for task 0.0 in stage 213.0 (TID 249)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 249, attempt 0, stage 213.0)
2025-08-10 09:29:12,258 [Executor task launch worker for task 0.0 in stage 213.0 (TID 249)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 213.0 (TID 249). 4074 bytes result sent to driver
2025-08-10 09:29:26,863 [block-manager-storage-async-thread-pool-100] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:26,872 [block-manager-storage-async-thread-pool-106] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,015 [block-manager-storage-async-thread-pool-124] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,022 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 251
2025-08-10 09:29:28,023 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 214.0 (TID 251)
2025-08-10 09:29:28,032 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 252
2025-08-10 09:29:28,032 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1325 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,037 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 215.0 (TID 252)
2025-08-10 09:29:28,043 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1326 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,055 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1325_piece0 stored as bytes in memory (estimated size 7.2 KiB, free 385.2 MiB)
2025-08-10 09:29:28,059 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1326_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 385.2 MiB)
2025-08-10 09:29:28,067 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1325 took 31 ms
2025-08-10 09:29:28,072 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1325 stored as values in memory (estimated size 20.5 KiB, free 385.2 MiB)
2025-08-10 09:29:28,075 [block-manager-storage-async-thread-pool-136] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,081 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1326 took 37 ms
2025-08-10 09:29:28,082 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1326 stored as values in memory (estimated size 13.6 KiB, free 385.3 MiB)
2025-08-10 09:29:28,083 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1290 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,090 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1281 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,092 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1290_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 385.2 MiB)
2025-08-10 09:29:28,098 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1290 took 14 ms
2025-08-10 09:29:28,102 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1281_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 385.2 MiB)
2025-08-10 09:29:28,102 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1290 stored as values in memory (estimated size 32.0 KiB, free 385.2 MiB)
2025-08-10 09:29:28,110 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1281 took 18 ms
2025-08-10 09:29:28,114 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1281 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 09:29:28,126 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,132 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,142 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,144 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,161 [Executor task launch worker for task 0.0 in stage 214.0 (TID 251)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 214.0 (TID 251). 5370 bytes result sent to driver
2025-08-10 09:29:28,170 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,170 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 253
2025-08-10 09:29:28,177 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 216.0 (TID 253)
2025-08-10 09:29:28,184 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1327 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,188 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,191 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1327_piece0 stored as bytes in memory (estimated size 5.7 KiB, free 393.1 MiB)
2025-08-10 09:29:28,194 [Executor task launch worker for task 0.0 in stage 215.0 (TID 252)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 215.0 (TID 252). 4685 bytes result sent to driver
2025-08-10 09:29:28,196 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1327 took 10 ms
2025-08-10 09:29:28,198 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1327 stored as values in memory (estimated size 14.3 KiB, free 393.1 MiB)
2025-08-10 09:29:28,201 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 254
2025-08-10 09:29:28,202 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 217.0 (TID 254)
2025-08-10 09:29:28,204 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1288 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,206 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1328 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,211 [block-manager-storage-async-thread-pool-181] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,214 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1288_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.2 MiB)
2025-08-10 09:29:28,215 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1328_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 393.1 MiB)
2025-08-10 09:29:28,221 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1288 took 14 ms
2025-08-10 09:29:28,221 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1328 took 13 ms
2025-08-10 09:29:28,222 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1328 stored as values in memory (estimated size 19.9 KiB, free 393.1 MiB)
2025-08-10 09:29:28,223 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1288 stored as values in memory (estimated size 32.0 KiB, free 393.1 MiB)
2025-08-10 09:29:28,225 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1278 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,234 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1278_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 393.1 MiB)
2025-08-10 09:29:28,237 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1278 took 11 ms
2025-08-10 09:29:28,241 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1278 stored as values in memory (estimated size 32.0 KiB, free 393.0 MiB)
2025-08-10 09:29:28,242 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,254 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,257 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,261 [block-manager-storage-async-thread-pool-111] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,264 [Executor task launch worker for task 0.0 in stage 216.0 (TID 253)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 216.0 (TID 253). 4679 bytes result sent to driver
2025-08-10 09:29:28,267 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,277 [block-manager-storage-async-thread-pool-120] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,286 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,286 [block-manager-storage-async-thread-pool-132] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,295 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,313 [Executor task launch worker for task 0.0 in stage 217.0 (TID 254)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 217.0 (TID 254). 5491 bytes result sent to driver
2025-08-10 09:29:28,327 [block-manager-storage-async-thread-pool-152] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,334 [block-manager-storage-async-thread-pool-155] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,340 [block-manager-storage-async-thread-pool-159] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,343 [block-manager-storage-async-thread-pool-162] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,361 [block-manager-storage-async-thread-pool-177] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,366 [block-manager-storage-async-thread-pool-182] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,375 [block-manager-storage-async-thread-pool-190] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,381 [block-manager-storage-async-thread-pool-199] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,389 [block-manager-storage-async-thread-pool-109] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,394 [block-manager-storage-async-thread-pool-111] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,502 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 255
2025-08-10 09:29:28,502 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 256
2025-08-10 09:29:28,502 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 218.0 (TID 255)
2025-08-10 09:29:28,503 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 218.0 (TID 256)
2025-08-10 09:29:28,505 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1363 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,510 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1363_piece0 stored as bytes in memory (estimated size 11.7 KiB, free 433.9 MiB)
2025-08-10 09:29:28,515 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1363 took 8 ms
2025-08-10 09:29:28,516 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1363 stored as values in memory (estimated size 35.1 KiB, free 433.8 MiB)
2025-08-10 09:29:28,520 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1338 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,524 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1338_piece0 stored as bytes in memory (estimated size 493.0 B, free 433.9 MiB)
2025-08-10 09:29:28,525 [block-manager-storage-async-thread-pool-155] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,527 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1338 took 7 ms
2025-08-10 09:29:28,530 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1338 stored as values in memory (estimated size 8.0 MiB, free 425.9 MiB)
2025-08-10 09:29:28,531 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1319 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,535 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1319_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 425.9 MiB)
2025-08-10 09:29:28,537 [block-manager-storage-async-thread-pool-169] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,538 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1319 took 6 ms
2025-08-10 09:29:28,540 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1319 stored as values in memory (estimated size 32.0 KiB, free 426.0 MiB)
2025-08-10 09:29:28,541 [block-manager-storage-async-thread-pool-170] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,546 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 26.335365 ms
2025-08-10 09:29:28,549 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1344 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,552 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,554 [block-manager-storage-async-thread-pool-191] INFO  org.apache.iceberg.spark.source.SerializableTableWithSize - Releasing resources
2025-08-10 09:29:28,555 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1344_piece0 stored as bytes in memory (estimated size 1245.0 B, free 426.1 MiB)
2025-08-10 09:29:28,557 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1344 took 7 ms
2025-08-10 09:29:28,560 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1344 stored as values in memory (estimated size 8.0 MiB, free 418.0 MiB)
2025-08-10 09:29:28,561 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,562 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1322 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,566 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1322_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 418.0 MiB)
2025-08-10 09:29:28,569 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1322 took 7 ms
2025-08-10 09:29:28,571 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1322 stored as values in memory (estimated size 32.0 KiB, free 418.0 MiB)
2025-08-10 09:29:28,575 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,581 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,585 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,588 [Executor task launch worker for task 0.0 in stage 218.0 (TID 255)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 218.0 (TID 255). 7357 bytes result sent to driver
2025-08-10 09:29:28,592 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 257
2025-08-10 09:29:28,593 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 219.0 (TID 257)
2025-08-10 09:29:28,593 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,596 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1364 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,600 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1364_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 418.0 MiB)
2025-08-10 09:29:28,602 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1364 took 6 ms
2025-08-10 09:29:28,603 [Executor task launch worker for task 1.0 in stage 218.0 (TID 256)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 218.0 (TID 256). 7357 bytes result sent to driver
2025-08-10 09:29:28,604 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1364 stored as values in memory (estimated size 33.7 KiB, free 417.9 MiB)
2025-08-10 09:29:28,607 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 258
2025-08-10 09:29:28,607 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 219.0 (TID 258)
2025-08-10 09:29:28,618 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 7.365418 ms
2025-08-10 09:29:28,621 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1330 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,622 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.078577 ms
2025-08-10 09:29:28,624 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1311 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,625 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1330_piece0 stored as bytes in memory (estimated size 500.0 B, free 417.9 MiB)
2025-08-10 09:29:28,627 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1330 took 6 ms
2025-08-10 09:29:28,627 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1311_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 417.9 MiB)
2025-08-10 09:29:28,630 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1311 took 5 ms
2025-08-10 09:29:28,630 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1330 stored as values in memory (estimated size 8.0 MiB, free 409.9 MiB)
2025-08-10 09:29:28,631 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1312 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,632 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1311 stored as values in memory (estimated size 32.0 KiB, free 409.9 MiB)
2025-08-10 09:29:28,636 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1312_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.9 MiB)
2025-08-10 09:29:28,639 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1312 took 7 ms
2025-08-10 09:29:28,641 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1312 stored as values in memory (estimated size 32.0 KiB, free 409.8 MiB)
2025-08-10 09:29:28,644 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,650 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,652 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,658 [Executor task launch worker for task 0.0 in stage 219.0 (TID 257)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 219.0 (TID 257). 7194 bytes result sent to driver
2025-08-10 09:29:28,659 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,661 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 259
2025-08-10 09:29:28,662 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 220.0 (TID 259)
2025-08-10 09:29:28,665 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1365 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,668 [Executor task launch worker for task 1.0 in stage 219.0 (TID 258)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 219.0 (TID 258). 7163 bytes result sent to driver
2025-08-10 09:29:28,669 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1365_piece0 stored as bytes in memory (estimated size 10.7 KiB, free 409.8 MiB)
2025-08-10 09:29:28,671 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 260
2025-08-10 09:29:28,672 [Executor task launch worker for task 1.0 in stage 220.0 (TID 260)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 220.0 (TID 260)
2025-08-10 09:29:28,672 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1365 took 6 ms
2025-08-10 09:29:28,673 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1365 stored as values in memory (estimated size 33.7 KiB, free 409.8 MiB)
2025-08-10 09:29:28,686 [Executor task launch worker for task 1.0 in stage 220.0 (TID 260)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 10.472949 ms
2025-08-10 09:29:28,689 [Executor task launch worker for task 1.0 in stage 220.0 (TID 260)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1317 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,691 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 15.932554 ms
2025-08-10 09:29:28,694 [Executor task launch worker for task 1.0 in stage 220.0 (TID 260)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1317_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 409.8 MiB)
2025-08-10 09:29:28,695 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1316 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,697 [Executor task launch worker for task 1.0 in stage 220.0 (TID 260)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1317 took 7 ms
2025-08-10 09:29:28,698 [Executor task launch worker for task 1.0 in stage 220.0 (TID 260)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1317 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 09:29:28,699 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1316_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.7 MiB)
2025-08-10 09:29:28,701 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1316 took 5 ms
2025-08-10 09:29:28,703 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1316 stored as values in memory (estimated size 32.0 KiB, free 409.7 MiB)
2025-08-10 09:29:28,709 [Executor task launch worker for task 1.0 in stage 220.0 (TID 260)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,712 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,715 [Executor task launch worker for task 1.0 in stage 220.0 (TID 260)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,719 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,723 [Executor task launch worker for task 1.0 in stage 220.0 (TID 260)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 220.0 (TID 260). 7163 bytes result sent to driver
2025-08-10 09:29:28,735 [Executor task launch worker for task 0.0 in stage 220.0 (TID 259)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 220.0 (TID 259). 7280 bytes result sent to driver
2025-08-10 09:29:28,792 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 261
2025-08-10 09:29:28,792 [Executor task launch worker for task 0.0 in stage 221.0 (TID 261)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 221.0 (TID 261)
2025-08-10 09:29:28,793 [Executor task launch worker for task 0.0 in stage 221.0 (TID 261)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 49 and clearing cache
2025-08-10 09:29:28,795 [Executor task launch worker for task 0.0 in stage 221.0 (TID 261)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1380 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,799 [Executor task launch worker for task 0.0 in stage 221.0 (TID 261)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1380_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 409.7 MiB)
2025-08-10 09:29:28,802 [Executor task launch worker for task 0.0 in stage 221.0 (TID 261)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1380 took 6 ms
2025-08-10 09:29:28,803 [Executor task launch worker for task 0.0 in stage 221.0 (TID 261)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1380 stored as values in memory (estimated size 11.7 KiB, free 409.6 MiB)
2025-08-10 09:29:28,807 [Executor task launch worker for task 0.0 in stage 221.0 (TID 261)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 221.0 (TID 261). 1836 bytes result sent to driver
2025-08-10 09:29:28,824 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 262
2025-08-10 09:29:28,824 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 223.0 (TID 262)
2025-08-10 09:29:28,825 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 50 and clearing cache
2025-08-10 09:29:28,826 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1381 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,829 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1381_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 409.6 MiB)
2025-08-10 09:29:28,831 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1381 took 4 ms
2025-08-10 09:29:28,832 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1381 stored as values in memory (estimated size 12.7 KiB, free 409.6 MiB)
2025-08-10 09:29:28,833 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 43, fetching them
2025-08-10 09:29:28,833 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:29:28,836 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:29:28,837 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:29:28,838 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 09:29:28,841 [Executor task launch worker for task 0.0 in stage 223.0 (TID 262)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 223.0 (TID 262). 3959 bytes result sent to driver
2025-08-10 09:29:28,873 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 263
2025-08-10 09:29:28,873 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 264
2025-08-10 09:29:28,873 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 225.0 (TID 263)
2025-08-10 09:29:28,874 [Executor task launch worker for task 0.0 in stage 225.0 (TID 264)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 225.0 (TID 264)
2025-08-10 09:29:28,876 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1382 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,880 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1382_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.6 MiB)
2025-08-10 09:29:28,883 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1382 took 6 ms
2025-08-10 09:29:28,884 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1382 stored as values in memory (estimated size 88.3 KiB, free 409.5 MiB)
2025-08-10 09:29:28,890 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 42, fetching them
2025-08-10 09:29:28,890 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:29:28,890 [Executor task launch worker for task 0.0 in stage 225.0 (TID 264)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1308 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,898 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:29:28,898 [Executor task launch worker for task 0.0 in stage 225.0 (TID 264)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1308_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 409.5 MiB)
2025-08-10 09:29:28,900 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 2 (160.0 B) non-empty blocks including 2 (160.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:29:28,900 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 1 ms
2025-08-10 09:29:28,901 [Executor task launch worker for task 0.0 in stage 225.0 (TID 264)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1308 took 9 ms
2025-08-10 09:29:28,902 [Executor task launch worker for task 0.0 in stage 225.0 (TID 264)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1308 stored as values in memory (estimated size 32.0 KiB, free 409.5 MiB)
2025-08-10 09:29:28,916 [Executor task launch worker for task 0.0 in stage 225.0 (TID 264)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,925 [Executor task launch worker for task 0.0 in stage 225.0 (TID 264)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,926 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 6.090026 ms
2025-08-10 09:29:28,931 [Executor task launch worker for task 3.0 in stage 225.0 (TID 263)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 225.0 (TID 263). 22960 bytes result sent to driver
2025-08-10 09:29:28,936 [Executor task launch worker for task 0.0 in stage 225.0 (TID 264)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 225.0 (TID 264). 22312 bytes result sent to driver
2025-08-10 09:29:28,940 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 265
2025-08-10 09:29:28,941 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 225.0 (TID 265)
2025-08-10 09:29:28,941 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 266
2025-08-10 09:29:28,942 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 225.0 (TID 266)
2025-08-10 09:29:28,949 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1375 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,949 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1370 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,952 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1375_piece0 stored as bytes in memory (estimated size 181.0 B, free 409.6 MiB)
2025-08-10 09:29:28,952 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1370_piece0 stored as bytes in memory (estimated size 181.0 B, free 409.6 MiB)
2025-08-10 09:29:28,954 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1370 took 5 ms
2025-08-10 09:29:28,954 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1375 took 5 ms
2025-08-10 09:29:28,956 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1375 stored as values in memory (estimated size 8.0 MiB, free 401.6 MiB)
2025-08-10 09:29:28,957 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1370 stored as values in memory (estimated size 8.0 MiB, free 393.6 MiB)
2025-08-10 09:29:28,957 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1314 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,958 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1309 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:28,960 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1314_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.6 MiB)
2025-08-10 09:29:28,960 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1309_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 393.6 MiB)
2025-08-10 09:29:28,962 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1309 took 4 ms
2025-08-10 09:29:28,963 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1314 took 5 ms
2025-08-10 09:29:28,964 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1309 stored as values in memory (estimated size 32.0 KiB, free 393.5 MiB)
2025-08-10 09:29:28,964 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1314 stored as values in memory (estimated size 32.0 KiB, free 393.5 MiB)
2025-08-10 09:29:28,974 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,974 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:28,982 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,982 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:28,991 [Executor task launch worker for task 2.0 in stage 225.0 (TID 266)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 225.0 (TID 266). 22481 bytes result sent to driver
2025-08-10 09:29:28,991 [Executor task launch worker for task 1.0 in stage 225.0 (TID 265)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 225.0 (TID 265). 22308 bytes result sent to driver
2025-08-10 09:29:29,065 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 267
2025-08-10 09:29:29,066 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 226.0 (TID 267)
2025-08-10 09:29:29,068 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1385 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,072 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1385_piece0 stored as bytes in memory (estimated size 47.3 KiB, free 393.6 MiB)
2025-08-10 09:29:29,074 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1385 took 5 ms
2025-08-10 09:29:29,075 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1385 stored as values in memory (estimated size 139.0 KiB, free 393.4 MiB)
2025-08-10 09:29:29,081 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1383 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,084 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1383_piece0 stored as bytes in memory (estimated size 513.0 B, free 393.4 MiB)
2025-08-10 09:29:29,086 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1383 took 4 ms
2025-08-10 09:29:29,087 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1383 stored as values in memory (estimated size 920.0 B, free 393.4 MiB)
2025-08-10 09:29:29,092 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1307 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,095 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1307_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 392.9 MiB)
2025-08-10 09:29:29,096 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1307 took 4 ms
2025-08-10 09:29:29,098 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1307 stored as values in memory (estimated size 32.0 KiB, free 392.9 MiB)
2025-08-10 09:29:29,106 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:29,114 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:29,128 [Executor task launch worker for task 0.0 in stage 226.0 (TID 267)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 226.0 (TID 267). 41668 bytes result sent to driver
2025-08-10 09:29:29,147 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 268
2025-08-10 09:29:29,147 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 227.0 (TID 268)
2025-08-10 09:29:29,149 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1387 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,153 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1387_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 393.4 MiB)
2025-08-10 09:29:29,155 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1387 took 5 ms
2025-08-10 09:29:29,156 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1387 stored as values in memory (estimated size 22.3 KiB, free 393.3 MiB)
2025-08-10 09:29:29,161 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1386 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,164 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1386_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 393.3 MiB)
2025-08-10 09:29:29,166 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1386 took 5 ms
2025-08-10 09:29:29,168 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1386 stored as values in memory (estimated size 32.0 KiB, free 393.3 MiB)
2025-08-10 09:29:29,178 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:29,187 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:29,215 [Executor task launch worker for task 0.0 in stage 227.0 (TID 268)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 227.0 (TID 268). 4892 bytes result sent to driver
2025-08-10 09:29:29,242 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 269
2025-08-10 09:29:29,242 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 270
2025-08-10 09:29:29,242 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 228.0 (TID 269)
2025-08-10 09:29:29,243 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 228.0 (TID 270)
2025-08-10 09:29:29,244 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 51 and clearing cache
2025-08-10 09:29:29,245 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1397 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,249 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1397_piece0 stored as bytes in memory (estimated size 12.3 KiB, free 393.3 MiB)
2025-08-10 09:29:29,251 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1397 took 5 ms
2025-08-10 09:29:29,252 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1397 stored as values in memory (estimated size 37.5 KiB, free 393.2 MiB)
2025-08-10 09:29:29,254 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1287 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,254 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1329 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,258 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1287_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 393.2 MiB)
2025-08-10 09:29:29,258 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1329_piece0 stored as bytes in memory (estimated size 1204.0 B, free 393.2 MiB)
2025-08-10 09:29:29,260 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1329 took 5 ms
2025-08-10 09:29:29,260 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1287 took 5 ms
2025-08-10 09:29:29,262 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1329 stored as values in memory (estimated size 8.0 MiB, free 385.2 MiB)
2025-08-10 09:29:29,262 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1287 stored as values in memory (estimated size 32.0 KiB, free 385.2 MiB)
2025-08-10 09:29:29,263 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1289 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,267 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1289_piece0 stored as bytes in memory (estimated size 29.6 KiB, free 385.1 MiB)
2025-08-10 09:29:29,272 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1289 took 8 ms
2025-08-10 09:29:29,274 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1289 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 09:29:29,274 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:29,282 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:29,286 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:29,293 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:29,296 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:29,303 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:29,307 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:29,310 [Executor task launch worker for task 0.0 in stage 228.0 (TID 269)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 228.0 (TID 269). 7357 bytes result sent to driver
2025-08-10 09:29:29,316 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:29,321 [Executor task launch worker for task 1.0 in stage 228.0 (TID 270)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 228.0 (TID 270). 7357 bytes result sent to driver
2025-08-10 09:29:29,422 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 271
2025-08-10 09:29:29,422 [Executor task launch worker for task 0.0 in stage 229.0 (TID 271)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 229.0 (TID 271)
2025-08-10 09:29:29,424 [Executor task launch worker for task 0.0 in stage 229.0 (TID 271)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 52 and clearing cache
2025-08-10 09:29:29,425 [Executor task launch worker for task 0.0 in stage 229.0 (TID 271)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1420 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,429 [Executor task launch worker for task 0.0 in stage 229.0 (TID 271)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1420_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 385.1 MiB)
2025-08-10 09:29:29,431 [Executor task launch worker for task 0.0 in stage 229.0 (TID 271)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1420 took 5 ms
2025-08-10 09:29:29,432 [Executor task launch worker for task 0.0 in stage 229.0 (TID 271)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1420 stored as values in memory (estimated size 11.7 KiB, free 385.1 MiB)
2025-08-10 09:29:29,442 [Executor task launch worker for task 0.0 in stage 229.0 (TID 271)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 229.0 (TID 271). 1922 bytes result sent to driver
2025-08-10 09:29:29,464 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 272
2025-08-10 09:29:29,465 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 231.0 (TID 272)
2025-08-10 09:29:29,466 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 53 and clearing cache
2025-08-10 09:29:29,468 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1421 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,471 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1421_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 385.3 MiB)
2025-08-10 09:29:29,473 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1421 took 4 ms
2025-08-10 09:29:29,474 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1421 stored as values in memory (estimated size 12.7 KiB, free 385.3 MiB)
2025-08-10 09:29:29,476 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 46, fetching them
2025-08-10 09:29:29,476 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:29:29,478 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:29:29,479 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:29:29,480 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 09:29:29,481 [Executor task launch worker for task 0.0 in stage 231.0 (TID 272)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 231.0 (TID 272). 3959 bytes result sent to driver
2025-08-10 09:29:29,512 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 273
2025-08-10 09:29:29,513 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 274
2025-08-10 09:29:29,513 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.executor.Executor - Running task 3.0 in stage 233.0 (TID 273)
2025-08-10 09:29:29,513 [Executor task launch worker for task 0.0 in stage 233.0 (TID 274)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 233.0 (TID 274)
2025-08-10 09:29:29,514 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1422 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,518 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1422_piece0 stored as bytes in memory (estimated size 34.4 KiB, free 385.3 MiB)
2025-08-10 09:29:29,521 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1422 took 5 ms
2025-08-10 09:29:29,522 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1422 stored as values in memory (estimated size 105.2 KiB, free 385.2 MiB)
2025-08-10 09:29:29,526 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 45, fetching them
2025-08-10 09:29:29,527 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:29:29,532 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:29:29,532 [Executor task launch worker for task 0.0 in stage 233.0 (TID 274)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1409 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,533 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 2 (396.0 B) non-empty blocks including 2 (396.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:29:29,533 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 09:29:29,535 [Executor task launch worker for task 0.0 in stage 233.0 (TID 274)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1409_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 385.2 MiB)
2025-08-10 09:29:29,538 [Executor task launch worker for task 0.0 in stage 233.0 (TID 274)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1409 took 5 ms
2025-08-10 09:29:29,539 [Executor task launch worker for task 0.0 in stage 233.0 (TID 274)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1409 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 09:29:29,549 [Executor task launch worker for task 0.0 in stage 233.0 (TID 274)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:29,550 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 4.826521 ms
2025-08-10 09:29:29,556 [Executor task launch worker for task 0.0 in stage 233.0 (TID 274)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:29,559 [Executor task launch worker for task 3.0 in stage 233.0 (TID 273)] INFO  org.apache.spark.executor.Executor - Finished task 3.0 in stage 233.0 (TID 273). 23293 bytes result sent to driver
2025-08-10 09:29:29,563 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 275
2025-08-10 09:29:29,563 [Executor task launch worker for task 1.0 in stage 233.0 (TID 275)] INFO  org.apache.spark.executor.Executor - Running task 1.0 in stage 233.0 (TID 275)
2025-08-10 09:29:29,570 [Executor task launch worker for task 1.0 in stage 233.0 (TID 275)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1410 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,571 [Executor task launch worker for task 0.0 in stage 233.0 (TID 274)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 233.0 (TID 274). 22605 bytes result sent to driver
2025-08-10 09:29:29,574 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 276
2025-08-10 09:29:29,575 [Executor task launch worker for task 1.0 in stage 233.0 (TID 275)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1410_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 385.1 MiB)
2025-08-10 09:29:29,575 [Executor task launch worker for task 2.0 in stage 233.0 (TID 276)] INFO  org.apache.spark.executor.Executor - Running task 2.0 in stage 233.0 (TID 276)
2025-08-10 09:29:29,577 [Executor task launch worker for task 1.0 in stage 233.0 (TID 275)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1410 took 6 ms
2025-08-10 09:29:29,579 [Executor task launch worker for task 1.0 in stage 233.0 (TID 275)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1410 stored as values in memory (estimated size 32.0 KiB, free 385.1 MiB)
2025-08-10 09:29:29,583 [Executor task launch worker for task 2.0 in stage 233.0 (TID 276)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1415 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,586 [Executor task launch worker for task 2.0 in stage 233.0 (TID 276)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1415_piece0 stored as bytes in memory (estimated size 29.7 KiB, free 385.1 MiB)
2025-08-10 09:29:29,588 [Executor task launch worker for task 2.0 in stage 233.0 (TID 276)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1415 took 5 ms
2025-08-10 09:29:29,588 [Executor task launch worker for task 1.0 in stage 233.0 (TID 275)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:29,590 [Executor task launch worker for task 2.0 in stage 233.0 (TID 276)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1415 stored as values in memory (estimated size 32.0 KiB, free 385.0 MiB)
2025-08-10 09:29:29,595 [Executor task launch worker for task 1.0 in stage 233.0 (TID 275)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:29,598 [Executor task launch worker for task 2.0 in stage 233.0 (TID 276)] INFO  org.apache.hadoop.fs.s3a.S3AInputStream - Switching to Random IO seek policy
2025-08-10 09:29:29,604 [Executor task launch worker for task 2.0 in stage 233.0 (TID 276)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.zstd]
2025-08-10 09:29:29,615 [Executor task launch worker for task 1.0 in stage 233.0 (TID 275)] INFO  org.apache.spark.executor.Executor - Finished task 1.0 in stage 233.0 (TID 275). 22734 bytes result sent to driver
2025-08-10 09:29:29,628 [Executor task launch worker for task 2.0 in stage 233.0 (TID 276)] INFO  org.apache.spark.executor.Executor - Finished task 2.0 in stage 233.0 (TID 276). 22734 bytes result sent to driver
2025-08-10 09:29:29,720 [dispatcher-Executor] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 277
2025-08-10 09:29:29,722 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.executor.Executor - Running task 0.0 in stage 237.0 (TID 277)
2025-08-10 09:29:29,723 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 54 and clearing cache
2025-08-10 09:29:29,724 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1424 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,727 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1424_piece0 stored as bytes in memory (estimated size 91.5 KiB, free 385.0 MiB)
2025-08-10 09:29:29,729 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1424 took 5 ms
2025-08-10 09:29:29,730 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1424 stored as values in memory (estimated size 315.1 KiB, free 384.6 MiB)
2025-08-10 09:29:29,741 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 44, fetching them
2025-08-10 09:29:29,742 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:29:29,744 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:29:29,745 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (8.6 KiB) non-empty blocks including 1 (8.6 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:29:29,746 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 09:29:29,749 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 47, fetching them
2025-08-10 09:29:29,749 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker endpoint = NettyRpcEndpointRef(spark://MapOutputTracker@3c3beacd57f0:41435)
2025-08-10 09:29:29,751 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.MapOutputTrackerWorker - Got the map output locations
2025-08-10 09:29:29,752 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 4 (5.7 KiB) non-empty blocks including 4 (5.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
2025-08-10 09:29:29,753 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
2025-08-10 09:29:29,767 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Started reading broadcast variable 1423 with 1 pieces (estimated total size 4.0 MiB)
2025-08-10 09:29:29,770 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1423_piece0 stored as bytes in memory (estimated size 29.8 KiB, free 384.5 MiB)
2025-08-10 09:29:29,772 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.broadcast.TorrentBroadcast - Reading broadcast variable 1423 took 5 ms
2025-08-10 09:29:29,774 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.storage.memory.MemoryStore - Block broadcast_1423 stored as values in memory (estimated size 32.0 KiB, free 384.5 MiB)
2025-08-10 09:29:29,776 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.hadoop.io.compress.CodecPool - Got brand-new compressor [.zstd]
2025-08-10 09:29:29,789 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Writer for partition 0 is committing.
2025-08-10 09:29:29,811 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 277, attempt 0, stage 237.0)
2025-08-10 09:29:29,819 [Executor task launch worker for task 0.0 in stage 237.0 (TID 277)] INFO  org.apache.spark.executor.Executor - Finished task 0.0 in stage 237.0 (TID 277). 119848 bytes result sent to driver
