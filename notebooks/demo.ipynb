{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd80d1a2-5da8-4f91-ade1-ebfae1e44fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/31 08:27:37 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dữ liệu mẫu ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------+---+\n",
      "|id |name                   |age|\n",
      "+---+-----------------------+---+\n",
      "|1  |Nguyễn Văn A           |30 |\n",
      "|2  |Trần Thị B             |25 |\n",
      "|3  |Lê Văn C               |28 |\n",
      "|4  |Nguyễn Lương Hoàng Tùng|21 |\n",
      "+---+-----------------------+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Đã ghi dữ liệu vào hive_catalog.default.users\n",
      "+---+-----------------------+---+\n",
      "|id |name                   |age|\n",
      "+---+-----------------------+---+\n",
      "|1  |Nguyễn Văn A           |30 |\n",
      "|2  |Trần Thị B             |25 |\n",
      "|1  |Nguyễn Văn A           |30 |\n",
      "|3  |Lê Văn C               |28 |\n",
      "|1  |Nguyễn Văn A           |30 |\n",
      "|2  |Trần Thị B             |25 |\n",
      "|4  |Nguyễn Lương Hoàng Tùng|21 |\n",
      "|2  |Trần Thị B             |25 |\n",
      "|3  |Lê Văn C               |28 |\n",
      "|3  |Lê Văn C               |28 |\n",
      "|4  |Nguyễn Lương Hoàng Tùng|21 |\n",
      "|4  |Nguyễn Lương Hoàng Tùng|21 |\n",
      "+---+-----------------------+---+\n",
      "\n",
      "=== Dữ liệu trong bảng Iceberg ===\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|made_current_at        |snapshot_id        |parent_id          |is_current_ancestor|\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "|2025-07-31 08:27:39.371|6036102057306511325|659609171530464219 |true               |\n",
      "|2025-07-31 08:23:24.622|659609171530464219 |2936590077811643809|true               |\n",
      "|2025-07-31 08:15:29    |2936590077811643809|null               |true               |\n",
      "+-----------------------+-------------------+-------------------+-------------------+\n",
      "\n",
      "=== Lịch sử commit của bảng (mới nhất trước) ===\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "|        committed_at|        snapshot_id|          parent_id|operation|       manifest_list|             summary|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "| 2025-07-31 08:15:29|2936590077811643809|               null|   append|s3a://iceberg-war...|{spark.app.id -> ...|\n",
      "|2025-07-31 08:23:...| 659609171530464219|2936590077811643809|   append|s3a://iceberg-war...|{spark.app.id -> ...|\n",
      "|2025-07-31 08:27:...|6036102057306511325| 659609171530464219|   append|s3a://iceberg-war...|{spark.app.id -> ...|\n",
      "+--------------------+-------------------+-------------------+---------+--------------------+--------------------+\n",
      "\n",
      "=== Danh sách snapshot hiện tại ===\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "def main():\n",
    "   # Khởi SparkSession (nạp spark-defaults.conf và hive-site.xml)\n",
    "   spark = SparkSession.builder \\\n",
    "       .appName(\"IcebergHiveCatalogExample\") \\\n",
    "       .master(\"spark://spark-master:7077\") \\\n",
    "       .enableHiveSupport() \\\n",
    "       .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "       .config(\"spark.sql.catalog.spark_catalog.type\", \"hive\") \\\n",
    "       .config(\"spark.sql.catalog.spark_catalog.uri\", \"thrift://hive-metastore:9083\") \\\n",
    "       .config(\"spark.jars\", \"/home/jovyan/jars/iceberg-spark-runtime-3.5_2.12-1.9.2.jar\") \\\n",
    "       .getOrCreate()\n",
    "   \n",
    "   # Tạo DataFrame mẫu\n",
    "   schema = StructType([\n",
    "       StructField(\"id\",   IntegerType(), False),\n",
    "       StructField(\"name\", StringType(),  False),\n",
    "       StructField(\"age\",  IntegerType(), True)\n",
    "   ])\n",
    "   data = [\n",
    "       (1, \"Nguyễn Văn A\", 30),\n",
    "       (2, \"Trần Thị B\",   25),\n",
    "       (3, \"Lê Văn C\",     28),\n",
    "       (4, \"Nguyễn Lương Hoàng Tùng\", 21)\n",
    "   ]\n",
    "   df = spark.createDataFrame(data, schema)\n",
    "   \n",
    "   print(\"=== Dữ liệu mẫu ===\")\n",
    "   df.show(truncate=False)\n",
    "   \n",
    "   # Tạo namespace (database) nếu chưa có\n",
    "   spark.sql(\"CREATE NAMESPACE IF NOT EXISTS hive_catalog.default\")\n",
    "   \n",
    "   # Tạo table Iceberg (nếu chưa tồn tại)\n",
    "   spark.sql(\"\"\"\n",
    "     CREATE TABLE IF NOT EXISTS hive_catalog.default.users (\n",
    "       id   INT,\n",
    "       name STRING,\n",
    "       age  INT\n",
    "     ) USING iceberg\n",
    "   \"\"\")\n",
    "   \n",
    "   # Ghi dữ liệu vào bảng (append)\n",
    "   df.writeTo(\"hive_catalog.default.users\").append()\n",
    "   print(\">>> Đã ghi dữ liệu vào hive_catalog.default.users\")\n",
    "   \n",
    "   # Đọc lại và hiển thị\n",
    "   spark.table(\"hive_catalog.default.users\").show(truncate=False)\n",
    "   print(\"=== Dữ liệu trong bảng Iceberg ===\")\n",
    "   \n",
    "   # Hiển thị lịch sử commit, sắp xếp theo made_current_at DESC\n",
    "   hist_df = spark.table(\"hive_catalog.default.users.history\") \\\n",
    "                 .orderBy(col(\"made_current_at\").desc())\n",
    "   hist_df.show(10, truncate=False)\n",
    "   print(\"=== Lịch sử commit của bảng (mới nhất trước) ===\")\n",
    "   \n",
    "   # Xem danh sách snapshots\n",
    "   snap_df = spark.table(\"hive_catalog.default.users.snapshots\")\n",
    "   snap_df.show(truncate=True)\n",
    "   print(\"=== Danh sách snapshot hiện tại ===\")\n",
    "   \n",
    "   spark.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "113e9a97-7c8e-4ad0-90cc-357929d45f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spark://spark-master:7077'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298df854-3e58-42a0-a688-844a65ec54d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/31 08:34:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/07/31 08:34:36 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     50\u001b[39m    spark.stop()\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m    \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Liệt kê các snapshot hiện có\u001b[39;00m\n\u001b[32m     18\u001b[39m snapshots_df = spark.sql(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSELECT snapshot_id, committed_at, summary FROM \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcatalog_table\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.snapshots\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m snapshots_df.orderBy(\u001b[33m\"\u001b[39m\u001b[33mcommitted_at\u001b[39m\u001b[33m\"\u001b[39m).show(truncate=\u001b[43mT\u001b[49m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Danh sách snapshots ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Giả sử chúng ta lấy snapshot đầu tiên (cũ nhất) để time-travel:\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def main():\n",
    "   spark = (\n",
    "       SparkSession.builder\n",
    "           .appName(\"IcebergTimeTravelExample\") \\\n",
    "           .master(\"spark://spark-master:7077\") \\\n",
    "           .enableHiveSupport() \\\n",
    "           .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkSessionCatalog\") \\\n",
    "           .config(\"spark.sql.catalog.spark_catalog.type\", \"hive\") \\\n",
    "           .config(\"spark.sql.catalog.spark_catalog.uri\", \"thrift://hive-metastore:9083\") \\\n",
    "           .getOrCreate()\n",
    "   )\n",
    "   \n",
    "   catalog_table = \"hive_catalog.default.users\"\n",
    "   \n",
    "   # Liệt kê các snapshot hiện có\n",
    "   snapshots_df = spark.sql(f\"SELECT snapshot_id, committed_at, summary FROM {catalog_table}.snapshots\")\n",
    "   snapshots_df.orderBy(\"committed_at\").show(truncate=True)\n",
    "   print(\"=== Danh sách snapshots ===\")\n",
    "   \n",
    "   # Giả sử chúng ta lấy snapshot đầu tiên (cũ nhất) để time-travel:\n",
    "   first_snapshot_id = snapshots_df.orderBy(\"committed_at\").first()[\"snapshot_id\"]\n",
    "   print(f\">>> Sẽ time-travel về snapshot_id = {first_snapshot_id}\")\n",
    "   \n",
    "   # Đọc dữ liệu tại snapshot đó (version-as-of)\n",
    "   df_time_travel = spark.read \\\n",
    "       .format(\"iceberg\") \\\n",
    "       .option(\"snapshot-id\", first_snapshot_id) \\\n",
    "       .load(catalog_table)\n",
    "   df_time_travel.show(truncate=False)\n",
    "   print(f\"=== Dữ liệu tại snapshot {first_snapshot_id} ===\")\n",
    "   \n",
    "   # Hoặc dùng SQL cú pháp VERSION AS OF\n",
    "   df_sql = spark.sql(f\"SELECT * FROM {catalog_table} VERSION AS OF {first_snapshot_id}\")\n",
    "   df_sql.show(truncate=False)\n",
    "   print(f\"=== (SQL) Dữ liệu tại snapshot {first_snapshot_id} ===\")\n",
    "   \n",
    "   # Time-travel theo timestamp (ví dụ 5 phút trước)\n",
    "   import datetime, pytz\n",
    "   ts = (datetime.datetime.now(pytz.UTC) - datetime.timedelta(minutes=5)).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "   print(f\">>> Sẽ time-travel theo timestamp = {ts}\")\n",
    "   df_ts = spark.read \\\n",
    "       .format(\"iceberg\") \\\n",
    "       .option(\"timestamp-as-of\", ts) \\\n",
    "       .load(catalog_table)\n",
    "   df_ts.show(truncate=False)\n",
    "   print(f\"=== Dữ liệu tại timestamp {ts} ===\")\n",
    "   \n",
    "   spark.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98667974-2ca0-4132-89c2-d8cd561a71b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
